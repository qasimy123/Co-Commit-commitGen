{"prompt": " file path A: jina/clients/request/__init__.py | file path B: jina/clients/request/__init__.py\n\n@@ -38,7 +38,7 @@ if TYPE_CHECKING:  # pragma: no cover\n \n def request_generator(\n     exec_endpoint: str,\n-    data: 'GeneratorSourceType',\n+    data: Optional['GeneratorSourceType'] = None,\n     request_size: int = 0,\n     data_type: DataInputType = DataInputType.AUTO,\n     target_executor: Optional[str] = None,\n@@ -58,8 +58,6 @@ def request_generator(\n     :yield: request\n     \"\"\"\n \n-    _kwargs = dict(extra_kwargs=kwargs)\n-\n     try:\n         if data is None:\n             # this allows empty inputs, i.e. a data request with only parameters\n@@ -71,7 +69,6 @@ def request_generator(\n                 data = [data]\n             for batch in batch_iterator(data, request_size):\n                 yield _new_data_request_from_batch(\n-                    _kwargs=kwargs,\n                     batch=batch,\n                     data_type=data_type,\n                     endpoint=exec_endpoint,\n\n---\n file path A: jina/clients/request/asyncio.py | file path B: jina/clients/request/asyncio.py\n\n@@ -6,15 +6,15 @@ from jina.clients.request.helper import _new_data_request, _new_data_request_fro\n from jina.enums import DataInputType\n from jina.importer import ImportExtensions\n from jina.logging.predefined import default_logger\n-from jina.types.request import Request\n \n if TYPE_CHECKING:  # pragma: no cover\n     from jina.clients.request import GeneratorSourceType\n+    from jina.types.request import Request\n \n \n async def request_generator(\n     exec_endpoint: str,\n-    data: 'GeneratorSourceType',\n+    data: Optional['GeneratorSourceType'] = None,\n     request_size: int = 0,\n     data_type: DataInputType = DataInputType.AUTO,\n     target_executor: Optional[str] = None,\n@@ -34,8 +34,6 @@ async def request_generator(\n     :yield: request\n     \"\"\"\n \n-    _kwargs = dict(extra_kwargs=kwargs)\n-\n     try:\n         if data is None:\n             # this allows empty inputs, i.e. a data request with only parameters\n@@ -48,7 +46,6 @@ async def request_generator(\n \n             async for batch in aiostream.stream.chunks(data, request_size):\n                 yield _new_data_request_from_batch(\n-                    _kwargs=kwargs,\n                     batch=batch,\n                     data_type=data_type,\n                     endpoint=exec_endpoint,\n\n---\n file path A: jina/clients/request/helper.py | file path B: jina/clients/request/helper.py\n\n@@ -1,5 +1,5 @@\n \"\"\"Module for helper functions for clients.\"\"\"\n-from typing import Tuple\n+from typing import Tuple, Optional\n \n from docarray import Document, DocumentArray\n from jina.enums import DataInputType\n@@ -7,22 +7,21 @@ from jina.types.request.data import DataRequest\n \n \n def _new_data_request_from_batch(\n-    _kwargs, batch, data_type, endpoint, target, parameters\n-):\n+    batch, data_type: DataInputType, endpoint: str, target: Optional[str], parameters: Optional[dict]\n+) -> DataRequest:\n     req = _new_data_request(endpoint, target, parameters)\n \n     # add docs fields\n-    _add_docs(req, batch, data_type, _kwargs)\n+    _add_docs(req, batch, data_type)\n \n     return req\n \n \n-def _new_data_request(endpoint, target, parameters):\n+def _new_data_request(endpoint: str, target: Optional[str], parameters: Optional[dict]) -> DataRequest:\n     req = DataRequest()\n \n     # set up header\n-    if endpoint:\n-        req.header.exec_endpoint = endpoint\n+    req.header.exec_endpoint = endpoint\n     if target:\n         req.header.target_executor = target\n     # add parameters field\n@@ -32,14 +31,13 @@ def _new_data_request(endpoint, target, parameters):\n \n \n def _new_doc_from_data(\n-    data, data_type: DataInputType, **kwargs\n+    data, data_type: DataInputType\n ) -> Tuple['Document', 'DataInputType']:\n     def _build_doc_from_content():\n-        return Document(content=data, **kwargs), DataInputType.CONTENT\n+        return Document(content=data), DataInputType.CONTENT\n \n     if data_type == DataInputType.DICT:\n-        doc = Document.from_dict(data)\n-        return doc, DataInputType.DICT\n+        return Document.from_dict(data), DataInputType.DICT\n     if data_type == DataInputType.AUTO or data_type == DataInputType.DOCUMENT:\n         if isinstance(data, Document):\n             # if incoming is already primitive type Document, then all good, best practice!\n@@ -47,8 +45,8 @@ def _new_doc_from_data(\n         elif isinstance(data, dict):\n             return Document.from_dict(data), DataInputType.DICT\n         try:\n-            d = Document(data, **kwargs)\n-            return d, DataInputType.DOCUMENT\n+            d = Document(data)\n+            return d, DataInputType.DOCUMENT # NOT HIT\n         except ValueError:\n             # AUTO has a fallback, now reconsider it as content\n             if data_type == DataInputType.AUTO:\n@@ -59,13 +57,9 @@ def _new_doc_from_data(\n         return _build_doc_from_content()\n \n \n-def _add_docs(req, batch, data_type, _kwargs):\n+def _add_docs(req: DataRequest, batch, data_type: DataInputType) -> None:\n     da = DocumentArray()\n     for content in batch:\n-        if isinstance(content, tuple) and len(content) == 2:\n-            d, data_type = _new_doc_from_data(content[0], data_type, **_kwargs)\n-            da.append(d)\n-        else:\n-            d, data_type = _new_doc_from_data(content, data_type, **_kwargs)\n-            da.append(d)\n+        d, data_type = _new_doc_from_data(content, data_type)\n+        da.append(d)\n     req.data.docs = da\n\n---\n file path A: tests/integration/v2_api/test_func_routing.py | file path B: tests/integration/v2_api/test_func_routing.py\n\n@@ -20,7 +20,7 @@ def test_func_simple_routing():\n     with f:\n         results = Client(port=f.port).post(\n             on='/search',\n-            inputs=[(Document(), Document()) for _ in range(3)],\n+            inputs=[Document() for _ in range(3)],\n             parameters={'hello': 'world', 'topk': 10},\n             return_responses=True,\n         )\n\n---\n file path A: tests/unit/clients/test_asyncio.py | file path B: tests/unit/clients/test_asyncio.py\n\n@@ -41,3 +41,22 @@ def test_asyncio_bad_input_generator():\n     # exception not handled\n     data = ['text' for _ in range(20)]\n     request_generator('/', data, request_size=10)\n+\n+\n+@pytest.mark.asyncio\n+async def test_asyncio_bad_input_generator2():\n+    async def input_function():\n+        for _ in range(NUM_INPUT_DOCS):\n+            yield 42\n+\n+    with pytest.raises(TypeError):\n+        async for req in request_generator(exec_endpoint='/', data=input_function(), request_size=REQUEST_SIZE):\n+            print(req.docs.summary())\n+\n+    async def input_function():\n+        yield Document()\n+        yield 42\n+\n+    with pytest.raises(ValueError):\n+        async for req in request_generator(exec_endpoint='/', data=input_function(), request_size=REQUEST_SIZE):\n+            print(req.docs.summary())\n\n---\n file path A: tests/unit/clients/test_helper.py | file path B: tests/unit/clients/test_helper.py\n\n@@ -32,6 +32,24 @@ async def test_http_clientlet():\n             url=f'http://localhost:{port}/post', logger=logger\n         ) as iolet:\n             request = _new_data_request('/', None, {'a': 'b'})\n+            assert request.header.target_executor == ''\n+            r = await iolet.send_message(request)\n+            response = DataRequest(await r.json())\n+    assert response.header.exec_endpoint == '/'\n+    assert response.parameters == {'a': 'b'}\n+\n+\n+@pytest.mark.asyncio\n+async def test_http_clientlet_target():\n+    from jina.helper import random_port\n+\n+    port = random_port()\n+    with Flow(port=port, protocol='http').add():\n+        async with HTTPClientlet(\n+            url=f'http://localhost:{port}/post', logger=logger\n+        ) as iolet:\n+            request = _new_data_request('/', 'nothing', {'a': 'b'})\n+            assert request.header.target_executor == 'nothing'\n             r = await iolet.send_message(request)\n             response = DataRequest(await r.json())\n     assert response.header.exec_endpoint == '/'\n\n\n###\n\n", "completion": "refactor: remove dead code, improve test coverage and fix convoluted client code (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/composite/gateway.py | file path B: jina/serve/runtimes/gateway/composite/gateway.py\n\n@@ -1,5 +1,5 @@\n import copy\n-from typing import List, Optional\n+from typing import Any, List, Optional\n \n from jina.serve.gateway import BaseGateway\n \n@@ -21,10 +21,13 @@ class CompositeGateway(BaseGateway):\n         self.gateways: List[BaseGateway] = []\n         for port, protocol in zip(self.ports, self.protocols):\n             gateway_cls = _get_gateway_class(protocol)\n-            runtime_args = copy.deepcopy(self.runtime_args)\n+            # ignore metrics_registry since it is not copyable\n+            runtime_args = self._deepcopy_with_ignore_attrs(\n+                self.runtime_args, ['metrics_registry']\n+            )\n             runtime_args.port = [port]\n             runtime_args.protocol = [protocol]\n-            gateway_kwargs = copy.deepcopy(kwargs)\n+            gateway_kwargs = {k: v for k, v in kwargs.items() if k != 'runtime_args'}\n             gateway_kwargs['runtime_args'] = dict(vars(runtime_args))\n             gateway = gateway_cls(**gateway_kwargs)\n             self.gateways.append(gateway)\n@@ -46,6 +49,22 @@ class CompositeGateway(BaseGateway):\n         for gateway in self.gateways:\n             await gateway.run_server()\n \n+    @staticmethod\n+    def _deepcopy_with_ignore_attrs(obj: Any, ignore_attrs: List[str]) -> Any:\n+        \"\"\"Deep copy an object and ignore some attributes\n+\n+        :param obj: the object to copy\n+        :param ignore_attrs: the attributes to ignore\n+        :return: the copied object\n+        \"\"\"\n+\n+        memo = {}\n+        for k in ignore_attrs:\n+            if hasattr(obj, k):\n+                memo[id(getattr(obj, k))] = None  # getattr(obj, k)\n+\n+        return copy.deepcopy(obj, memo)\n+\n     @property\n     def _should_exit(self) -> bool:\n         should_exit_values = [\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_multiprotocol.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_multiprotocol.py\n\n@@ -118,3 +118,14 @@ def test_flow_multiprotocol_ports_protocols_mismatch():\n         'You need to specify as much protocols as ports if you want to use a jina built-in gateway'\n         in err_info.value.args[0]\n     )\n+\n+\n+def test_flow_multiprotocol_with_monitoring():\n+    ports = [random_port(), random_port(), random_port()]\n+    protocols = PROTOCOLS\n+    flow = Flow().config_gateway(port=ports, protocol=protocols, monitoring=True)\n+    \n+    with flow:\n+        for port, protocol in zip(ports, protocols):\n+            client = Client(port=port, protocol=protocol)\n+            client.post('/', inputs=[Document()])\n\n\n###\n\n", "completion": "fix: multi protocol gateway supports monitoring (#<issue-num>)"}
{"prompt": " file path A: jina/clients/request/helper.py | file path B: jina/clients/request/helper.py\n\n@@ -64,7 +64,6 @@ def _add_docs(req, batch, data_type, _kwargs):\n     for content in batch:\n         if isinstance(content, tuple) and len(content) == 2:\n             d, data_type = _new_doc_from_data(content[0], data_type, **_kwargs)\n-            gt, _ = _new_doc_from_data(content[1], data_type, **_kwargs)\n             da.append(d)\n         else:\n             d, data_type = _new_doc_from_data(content, data_type, **_kwargs)\n\n\n###\n\n", "completion": "refactor: removing seemingly useless line (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/head/request_handling.py | file path B: jina/serve/runtimes/head/request_handling.py\n\n@@ -164,9 +164,7 @@ class HeaderRequestHandler(MonitoringRequestMixin):\n         elif len(worker_results) > 1 and not reduce:\n             # worker returned multiple responses, but the head is configured to skip reduction\n             # just concatenate the docs in this case\n-            response_request.data.docs = WorkerRequestHandler.get_docs_from_request(\n-                requests, field='docs'\n-            )\n+            response_request.data.docs = WorkerRequestHandler.get_docs_from_request(requests)\n \n         merged_metadata = self._merge_metadata(\n             metadata,\n\n---\n file path A: jina/serve/runtimes/worker/request_handling.py | file path B: jina/serve/runtimes/worker/request_handling.py\n\n@@ -414,10 +414,7 @@ class WorkerRequestHandler:\n             )\n             await task\n         else:\n-            docs = WorkerRequestHandler.get_docs_from_request(\n-                requests,\n-                field='docs',\n-            )\n+            docs = WorkerRequestHandler.get_docs_from_request(requests)\n \n             docs_matrix, docs_map = WorkerRequestHandler._get_docs_matrix_from_request(\n                 requests\n@@ -531,26 +528,22 @@ class WorkerRequestHandler:\n     @staticmethod\n     def get_docs_from_request(\n         requests: List['DataRequest'],\n-        field: str,\n     ) -> 'DocumentArray':\n         \"\"\"\n         Gets a field from the message\n \n-        :param requests: requests to get the field from\n-        :param field: field name to access\n+        :param requests: requests to get the docs from\n \n         :returns: DocumentArray extracted from the field from all messages\n         \"\"\"\n         if len(requests) > 1:\n             result = DocumentArray(\n-                [\n                     d\n-                    for r in reversed([request for request in requests])\n-                    for d in getattr(r, field)\n-                ]\n+                    for r in reversed(requests)\n+                    for d in getattr(r, 'docs')\n             )\n         else:\n-            result = getattr(requests[0], field)\n+            result = getattr(requests[0], 'docs')\n \n         return result\n \n\n\n###\n\n", "completion": "refactor: simplify get docs from requests (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -103,6 +103,7 @@ class K8sDeploymentConfig:\n                 monitoring=self.common_args.monitoring,\n                 port_monitoring=self.common_args.port_monitoring,\n                 protocol=self.common_args.protocol,\n+                timeout_ready=self.common_args.timeout_ready,\n             )\n \n         def _get_image_name(self, uses: Optional[str]):\n@@ -213,6 +214,7 @@ class K8sDeploymentConfig:\n                 monitoring=cargs.monitoring,\n                 port_monitoring=cargs.port_monitoring,\n                 volumes=getattr(cargs, 'volumes', None),\n+                timeout_ready=cargs.timeout_ready,\n             )\n \n     def __init__(\n\n---\n file path A: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py | file path B: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py\n\n@@ -1,11 +1,15 @@\n import json\n+import math\n import os\n+import warnings\n from argparse import Namespace\n from typing import Dict, List, Optional, Tuple, Union\n \n from jina.orchestrate.deployments.config.k8slib import kubernetes_tools\n from jina.serve.networking import GrpcConnectionPool\n \n+PERIOD_SECONDS = 5\n+\n \n def get_template_yamls(\n     name: str,\n@@ -32,6 +36,7 @@ def get_template_yamls(\n     port_monitoring: Optional[int] = None,\n     protocol: Optional[Union[str, List[str]]] = None,\n     volumes: Optional[List[str]] = None,\n+    timeout_ready: int = 600000,\n ) -> List[Dict]:\n     \"\"\"Get the yaml description of a service on Kubernetes\n \n@@ -59,6 +64,9 @@ def get_template_yamls(\n     :param port_monitoring: port which will be exposed, for the prometheus server, by the deployed containers\n     :param protocol: In case of being a Gateway, the protocol or protocols list used to expose its server\n     :param volumes: If volumes are passed to Executors, Jina will create a StatefulSet instead of Deployment and include the first volume in the volume mounts\n+    :param timeout_ready: The timeout in milliseconds of a Pod waits for the runtime to be ready. This parameter will be\n+        reflected in Kubernetes in the startup configuration where the failureThreshold will be calculated depending on\n+        timeout_ready. Value -1 is not supported for kubernetes\n     :return: Return a dictionary with all the yaml configuration needed for a deployment\n     \"\"\"\n     # we can always assume the ports are the same for all executors since they run on different k8s pods\n@@ -79,6 +87,13 @@ def get_template_yamls(\n     else:\n         protocols = protocol\n \n+    if timeout_ready == -1:\n+        warnings.warn(\n+            'timeout_ready=-1 is not supported, setting timeout_ready to 10 minutes'\n+        )\n+        timeout_ready = 600000\n+    failure_threshold = max(math.ceil((timeout_ready / 1000) / PERIOD_SECONDS), 3)\n+\n     template_params = {\n         'name': name,\n         'namespace': namespace,\n@@ -102,6 +117,8 @@ def get_template_yamls(\n         'env_from_secret': env_from_secret,\n         'protocol': str(protocols[0]).lower() if protocols[0] is not None else '',\n         'volume_path': volumes[0] if volumes is not None else None,\n+        'period_seconds': PERIOD_SECONDS,\n+        'failure_threshold': failure_threshold,\n     }\n \n     if gpus and gpus != 'all':\n\n---\n file path A: jina/resources/k8s/template/deployment-executor.yml | file path B: jina/resources/k8s/template/deployment-executor.yml\n\n@@ -58,7 +58,8 @@ spec:\n                 - executor\n                 - 127.0.0.1:{port}\n             initialDelaySeconds: 5\n-            periodSeconds: 5\n+            periodSeconds: {period_seconds}\n+            failureThreshold: {failure_threshold}\n             timeoutSeconds: 10\n           livenessProbe:\n             exec:\n\n---\n file path A: jina/resources/k8s/template/deployment-gateway.yml | file path B: jina/resources/k8s/template/deployment-gateway.yml\n\n@@ -57,7 +57,8 @@ spec:\n                 - gateway\n                 - {protocol}://127.0.0.1:{port}\n             initialDelaySeconds: 5\n-            periodSeconds: 5\n+            periodSeconds: {period_seconds}\n+            failureThreshold: {failure_threshold}\n             timeoutSeconds: 10\n           livenessProbe:\n             exec:\n\n---\n file path A: jina/resources/k8s/template/deployment-uses-after.yml | file path B: jina/resources/k8s/template/deployment-uses-after.yml\n\n@@ -58,7 +58,8 @@ spec:\n               - executor\n               - 127.0.0.1:{port}\n           initialDelaySeconds: 5\n-          periodSeconds: 5\n+          periodSeconds: {period_seconds}\n+          failureThreshold: {failure_threshold}\n           timeoutSeconds: 10\n         livenessProbe:\n           exec:\n@@ -107,7 +108,8 @@ spec:\n               - executor\n               - 127.0.0.1:{port_uses_after}\n           initialDelaySeconds: 5\n-          periodSeconds: 5\n+          periodSeconds: {period_seconds}\n+          failureThreshold: {failure_threshold}\n           timeoutSeconds: 10\n         livenessProbe:\n           exec:\n\n---\n file path A: jina/resources/k8s/template/deployment-uses-before-after.yml | file path B: jina/resources/k8s/template/deployment-uses-before-after.yml\n\n@@ -58,7 +58,8 @@ spec:\n               - executor\n               - 127.0.0.1:{port_uses}\n           initialDelaySeconds: 5\n-          periodSeconds: 5\n+          periodSeconds: {period_seconds}\n+          failureThreshold: {failure_threshold}\n           timeoutSeconds: 10\n         livenessProbe:\n           exec:\n@@ -107,7 +108,8 @@ spec:\n               - executor\n               - 127.0.0.1:{port_uses_before}\n           initialDelaySeconds: 5\n-          periodSeconds: 5\n+          periodSeconds: {period_seconds}\n+          failureThreshold: {failure_threshold}\n           timeoutSeconds: 10\n         livenessProbe:\n           exec:\n@@ -156,7 +158,8 @@ spec:\n               - executor\n               - 127.0.0.1:{port_uses_after}\n           initialDelaySeconds: 5\n-          periodSeconds: 5\n+          periodSeconds: {period_seconds}\n+          failureThreshold: {failure_threshold}\n           timeoutSeconds: 10\n         livenessProbe:\n           exec:\n\n---\n file path A: jina/resources/k8s/template/deployment-uses-before.yml | file path B: jina/resources/k8s/template/deployment-uses-before.yml\n\n@@ -58,7 +58,8 @@ spec:\n               - executor\n               - 127.0.0.1:{port}\n           initialDelaySeconds: 5\n-          periodSeconds: 5\n+          periodSeconds: {period_seconds}\n+          failureThreshold: {failure_threshold}\n           timeoutSeconds: 10\n         livenessProbe:\n           exec:\n@@ -107,7 +108,8 @@ spec:\n               - executor\n               - 127.0.0.1:{port_uses_before}\n           initialDelaySeconds: 5\n-          periodSeconds: 5\n+          periodSeconds: {period_seconds}\n+          failureThreshold: {failure_threshold}\n           timeoutSeconds: 10\n         livenessProbe:\n           exec:\n\n---\n file path A: jina/resources/k8s/template/statefulset-executor.yml | file path B: jina/resources/k8s/template/statefulset-executor.yml\n\n@@ -58,7 +58,8 @@ spec:\n                 - executor\n                 - 127.0.0.1:{port}\n             initialDelaySeconds: 5\n-            periodSeconds: 5\n+            periodSeconds: {period_seconds}\n+            failureThreshold: {failure_threshold}\n             timeoutSeconds: 10\n           livenessProbe:\n             exec:\n\n---\n file path A: tests/k8s/conftest.py | file path B: tests/k8s/conftest.py\n\n@@ -4,11 +4,11 @@ import subprocess\n import tempfile\n import time\n from pathlib import Path\n-from typing import List, Dict\n-from pytest import FixtureRequest\n+from typing import Dict, List\n \n import docker\n import pytest\n+from pytest import FixtureRequest\n from pytest_kind import KindCluster\n \n from jina.logging.logger import JinaLogger\n@@ -161,6 +161,7 @@ def image_name_tag_map() -> Dict[str, str]:\n         'custom-gateway': '0.1.1',\n         'test-stateful-executor': '0.13.1',\n         'multiprotocol-gateway': '0.1.1',\n+        'slow-load-executor': '0.1.1',\n     }\n \n \n\n---\n file path A: None | file path B: tests/k8s/slow-load-executor/.dockerignore\n\n@@ -0,0 +1,8 @@\n+.git\n+.venv\n+.github\n+.pytest_cache\n+tests\n+__pycache__\n+scripts\n+env\n\\ No newline at end of file\n\n---\n file path A: None | file path B: tests/k8s/slow-load-executor/Dockerfile\n\n@@ -0,0 +1,8 @@\n+# TODO use fixed jina version for deterministic execution\n+FROM jinaai/jina:test-pip\n+\n+# setup the workspace\n+COPY . /workspace\n+WORKDIR /workspace\n+\n+ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n\n---\n file path A: None | file path B: tests/k8s/slow-load-executor/config.yml\n\n@@ -0,0 +1,3 @@\n+jtype: SlowLoadExecutor\n+py_modules:\n+  - slow_load_executor.py\n\n---\n file path A: None | file path B: tests/k8s/slow-load-executor/slow_load_executor.py\n\n@@ -0,0 +1,9 @@\n+import time\n+\n+from jina import Executor\n+\n+time.sleep(60)\n+\n+\n+class SlowLoadExecutor(Executor):\n+    pass\n\n---\n file path A: tests/k8s/test_k8s.py | file path B: tests/k8s/test_k8s.py\n\n@@ -1637,3 +1637,55 @@ async def test_really_slow_executor_liveness_probe_works(docker_images, tmpdir,\n                 ).stdout.strip(\"\\n\")\n                 print(out)\n         raise exc\n+\n+\n+@pytest.mark.asyncio\n+@pytest.mark.timeout(3600)\n+@pytest.mark.parametrize(\n+    'docker_images',\n+    [['slow-load-executor']],\n+    indirect=True,\n+)\n+async def test_flow_slow_load_executor(logger, docker_images, tmpdir, k8s_cluster):\n+    from kubernetes import client\n+\n+    api_client = client.ApiClient()\n+    core_client = client.CoreV1Api(api_client=api_client)\n+    app_client = client.AppsV1Api(api_client=api_client)\n+    try:\n+        port = 8080\n+        flow = Flow().add(\n+            name='slow_load_executor',\n+            uses=f'docker://{docker_images[0]}',\n+            timeout_ready=65000,\n+        )\n+\n+        dump_path = os.path.join(str(tmpdir), 'k8s-slow-load-executor')\n+        namespace = 'slow-load-executor'\n+        flow.to_kubernetes_yaml(dump_path, k8s_namespace=namespace)\n+\n+        await create_all_flow_deployments_and_wait_ready(\n+            dump_path,\n+            namespace=namespace,\n+            api_client=api_client,\n+            app_client=app_client,\n+            core_client=core_client,\n+            deployment_replicas_expected={'gateway': 1, 'slow-load-executor': 1},\n+            logger=logger,\n+        )\n+\n+        executor_pod_name = (\n+            core_client.list_namespaced_pod(\n+                namespace=namespace, label_selector='app=slow-load-executor'\n+            )\n+            .items[0]\n+            .metadata.name\n+        )\n+        with shell_portforward(\n+            k8s_cluster._cluster.kubectl_path, executor_pod_name, port, port, namespace\n+        ):\n+            assert AsyncNewLoopRuntime.is_ready(f'localhost:{port}')\n+\n+    except Exception as exc:\n+        logger.error(f' Exception raised {exc}')\n+        raise exc\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py\n\n@@ -16,7 +16,7 @@ def test_flow_to_k8s_yaml(tmpdir, protocol, flow_port):\n         flow_kwargs['port'] = flow_port\n     flow = (\n         Flow(**flow_kwargs)\n-        .add(name='executor0', uses_with={'param': 0})\n+        .add(name='executor0', uses_with={'param': 0}, timeout_ready=60000)\n         .add(\n             name='executor1',\n             shards=2,\n@@ -149,6 +149,13 @@ def test_flow_to_k8s_yaml(tmpdir, protocol, flow_port):\n     assert executor0_objects[2]['metadata']['namespace'] == namespace\n     assert executor0_objects[2]['metadata']['name'] == 'executor0'\n     assert executor0_objects[2]['spec']['replicas'] == 1\n+\n+    executor0_startup_probe = executor0_objects[2]['spec']['template']['spec'][\n+        'containers'\n+    ][0]['startupProbe']\n+    assert executor0_startup_probe['failureThreshold'] == 12\n+    assert executor0_startup_probe['periodSeconds'] == 5\n+\n     executor0_args = executor0_objects[2]['spec']['template']['spec']['containers'][0][\n         'args'\n     ]\n\n\n###\n\n", "completion": "fix: respect timeout_ready when generating startup probe (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/install_requirements_helper.py | file path B: jina/orchestrate/deployments/install_requirements_helper.py\n\n@@ -205,13 +205,15 @@ def install_package_dependencies(\n         if requirements_file.exists():\n             _install_requirements(requirements_file)\n \n-\n def _get_package_path_from_uses(uses: str) -> Optional['Path']:\n     if isinstance(uses, str) and os.path.exists(uses):\n         from pathlib import Path\n         return Path(os.path.dirname(os.path.abspath(uses)))\n     else:\n-        from jina.logging.predefined import default_logger\n-        default_logger.warning(\n-            f'Error getting the directory name from {uses}. `--install-requirements` option is only valid when `uses` is a configuration file.')\n+        from hubble.executor.helper import is_valid_huburi\n+        if not is_valid_huburi(uses):\n+            from jina.logging.predefined import default_logger\n+            \n+            default_logger.warning(\n+                f'Error getting the directory name from {uses}. `--install-requirements` option is only valid when `uses` is a configuration file.')\n         return None\n\n\n###\n\n", "completion": "fix: remove unwanted warning (#<issue-num>)"}
{"prompt": " file path A: docs/concepts/client/index.md | file path B: docs/concepts/client/index.md\n\n@@ -150,15 +150,14 @@ Client(host='https://my.awesome.flow:1234', port=4321)\n \n ````{admonition} Caution\n :class: caution\n-In case you instanciate a `Client` object using the `grpc` protocol, keep in mind that `grpc` clients cannot be used in \n-a multi-threaded environment (check [this gRPC issue](https://github.com/grpc/grpc/issues/25364) for reference).\n+\n+We apply `RLock` to avoid [this gRPC issue](https://github.com/grpc/grpc/issues/25364), so that `grpc` clients can be used in a multi-threaded environment.\n+\n What you should do, is to rely on asynchronous programming or multi-processing rather than multi-threading.\n For instance, if you're building a web server, you can introduce multi-processing based parallelism to your app using \n `gunicorn`: `gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker ...`\n ````\n \n-\n-\n (client-compress)=\n ## Enable compression\n \n\n---\n file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -1,10 +1,10 @@\n import asyncio\n import json\n+import threading\n from typing import TYPE_CHECKING, Optional, Tuple\n \n import grpc\n from grpc import RpcError\n-\n from jina.clients.base import BaseClient\n from jina.clients.helper import callback_exec\n from jina.excepts import BadClientInput, BadServerFlow, InternalNetworkError\n@@ -24,6 +24,8 @@ class GRPCBaseClient(BaseClient):\n \n     It manages the asyncio event loop internally, so all interfaces are synchronous from the outside.\n     \"\"\"\n+    \n+    _lock = threading.RLock()\n \n     async def _is_flow_ready(self, **kwargs) -> bool:\n         \"\"\"Sends a dry run to the Flow to validate if the Flow is ready to receive requests\n@@ -203,81 +205,82 @@ class GRPCBaseClient(BaseClient):\n                 metadata = metadata or ()\n                 metadata = metadata + (('__results_in_order__', 'true'),)\n \n-            async with GrpcConnectionPool.get_grpc_channel(\n-                    f'{self.args.host}:{self.args.port}',\n-                    options=options,\n-                    asyncio=True,\n-                    tls=self.args.tls,\n-                    aio_tracing_client_interceptors=self.aio_tracing_client_interceptors(),\n-            ) as channel:\n-                self.logger.debug(f'connected to {self.args.host}:{self.args.port}')\n+            with self._lock:\n+                async with GrpcConnectionPool.get_grpc_channel(\n+                        f'{self.args.host}:{self.args.port}',\n+                        options=options,\n+                        asyncio=True,\n+                        tls=self.args.tls,\n+                        aio_tracing_client_interceptors=self.aio_tracing_client_interceptors(),\n+                ) as channel:\n+                    self.logger.debug(f'connected to {self.args.host}:{self.args.port}')\n \n-                with ProgressBar(\n-                        total_length=self._inputs_length, disable=not self.show_progress\n-                ) as p_bar:\n-                    try:\n-                        if stream:\n-                            async for resp in self._stream_rpc(\n-                                    channel=channel,\n-                                    req_iter=req_iter,\n-                                    metadata=metadata,\n-                                    on_error=on_error,\n-                                    on_done=on_done,\n-                                    on_always=on_always,\n-                                    continue_on_error=continue_on_error,\n-                                    p_bar=p_bar,\n-                                    **kwargs,\n-                            ):\n-                                yield resp\n-                        else:\n-                            async for resp in self._unary_rpc(\n-                                    channel=channel,\n-                                    req_iter=req_iter,\n-                                    metadata=metadata,\n-                                    on_error=on_error,\n-                                    on_done=on_done,\n-                                    on_always=on_always,\n-                                    continue_on_error=continue_on_error,\n-                                    p_bar=p_bar,\n-                                    results_in_order=results_in_order,\n-                                    **kwargs,\n-                            ):\n-                                yield resp\n+                    with ProgressBar(\n+                            total_length=self._inputs_length, disable=not self.show_progress\n+                    ) as p_bar:\n+                        try:\n+                            if stream:\n+                                async for resp in self._stream_rpc(\n+                                        channel=channel,\n+                                        req_iter=req_iter,\n+                                        metadata=metadata,\n+                                        on_error=on_error,\n+                                        on_done=on_done,\n+                                        on_always=on_always,\n+                                        continue_on_error=continue_on_error,\n+                                        p_bar=p_bar,\n+                                        **kwargs,\n+                                ):\n+                                    yield resp\n+                            else:\n+                                async for resp in self._unary_rpc(\n+                                        channel=channel,\n+                                        req_iter=req_iter,\n+                                        metadata=metadata,\n+                                        on_error=on_error,\n+                                        on_done=on_done,\n+                                        on_always=on_always,\n+                                        continue_on_error=continue_on_error,\n+                                        p_bar=p_bar,\n+                                        results_in_order=results_in_order,\n+                                        **kwargs,\n+                                ):\n+                                    yield resp\n \n-                    except (grpc.aio._call.AioRpcError, InternalNetworkError) as err:\n-                        my_code = err.code()\n-                        my_details = err.details()\n-                        trailing_metadata = extract_trailing_metadata(err)\n-                        msg = f'gRPC error: {my_code} {my_details}'\n-                        if trailing_metadata:\n-                            msg = f'gRPC error: {my_code} {my_details}\\n{trailing_metadata}'\n+                        except (grpc.aio._call.AioRpcError, InternalNetworkError) as err:\n+                            my_code = err.code()\n+                            my_details = err.details()\n+                            trailing_metadata = extract_trailing_metadata(err)\n+                            msg = f'gRPC error: {my_code} {my_details}'\n+                            if trailing_metadata:\n+                                msg = f'gRPC error: {my_code} {my_details}\\n{trailing_metadata}'\n \n-                        if my_code == grpc.StatusCode.UNAVAILABLE:\n-                            self.logger.error(\n-                                f'{msg}\\nThe ongoing request is terminated as the server is not available or closed already.'\n-                            )\n-                            raise ConnectionError(my_details)\n-                        elif my_code == grpc.StatusCode.DEADLINE_EXCEEDED:\n-                            self.logger.error(\n-                                f'{msg}\\nThe ongoing request is terminated due to a server-side timeout.'\n-                            )\n-                            raise ConnectionError(my_details)\n-                        elif my_code == grpc.StatusCode.INTERNAL:\n-                            self.logger.error(\n-                                f'{msg}\\ninternal error on the server side'\n-                            )\n-                            raise err\n-                        elif (\n-                                my_code == grpc.StatusCode.UNKNOWN\n-                                and 'asyncio.exceptions.TimeoutError' in my_details\n-                        ):\n-                            raise BadClientInput(\n-                                f'{msg}\\n'\n-                                'often the case is that you define/send a bad input iterator to jina, '\n-                                'please double check your input iterator'\n-                            ) from err\n-                        else:\n-                            raise BadServerFlow(msg) from err\n+                            if my_code == grpc.StatusCode.UNAVAILABLE:\n+                                self.logger.error(\n+                                    f'{msg}\\nThe ongoing request is terminated as the server is not available or closed already.'\n+                                )\n+                                raise ConnectionError(my_details)\n+                            elif my_code == grpc.StatusCode.DEADLINE_EXCEEDED:\n+                                self.logger.error(\n+                                    f'{msg}\\nThe ongoing request is terminated due to a server-side timeout.'\n+                                )\n+                                raise ConnectionError(my_details)\n+                            elif my_code == grpc.StatusCode.INTERNAL:\n+                                self.logger.error(\n+                                    f'{msg}\\ninternal error on the server side'\n+                                )\n+                                raise err\n+                            elif (\n+                                    my_code == grpc.StatusCode.UNKNOWN\n+                                    and 'asyncio.exceptions.TimeoutError' in my_details\n+                            ):\n+                                raise BadClientInput(\n+                                    f'{msg}\\n'\n+                                    'often the case is that you define/send a bad input iterator to jina, '\n+                                    'please double check your input iterator'\n+                                ) from err\n+                            else:\n+                                raise BadServerFlow(msg) from err\n \n         except KeyboardInterrupt:\n             self.logger.warning('user cancel the process')\n\n---\n file path A: None | file path B: tests/integration/concurrent_clients/test_multithread_client.py\n\n@@ -0,0 +1,57 @@\n+\n+import threading\n+import time\n+from concurrent.futures import ThreadPoolExecutor\n+\n+from jina import Client, Document, Executor, Flow, requests\n+from jina.helper import random_port\n+\n+\n+class MyExecutor(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        for doc in docs:\n+            doc.text = 'I am coming from MyExecutor'\n+                \n+def flow_run(flow, stop_event):\n+    with flow:\n+        flow.block(stop_event)\n+\n+\n+def client_post(doc, client):\n+    result = client.post(on='/', inputs=doc)[0]\n+    return result\n+\n+\n+def test_multithread_client(capsys):\n+    port = random_port()\n+    stop_event = threading.Event()\n+    flow = Flow(port=port).add(uses=MyExecutor)\n+    t = threading.Thread(target=flow_run, args=(flow, stop_event))\n+\n+    c = Client(port=port)\n+\n+    try:\n+        with capsys.disabled():\n+            t.start()\n+            time.sleep(5)\n+\n+        with ThreadPoolExecutor(max_workers=50) as pool:\n+            tasks = []\n+            for i in range(1000):\n+                doc = Document(id=f'{i}', text='hello world')\n+                task = pool.submit(client_post, doc, c)\n+                tasks.append(task)\n+\n+            for i,task in enumerate(tasks):\n+                result = task.result()\n+                assert result.id == f'{i}'\n+                assert result.text == 'I am coming from MyExecutor'\n+\n+        with capsys.disabled():\n+            stdout, stderr = capsys.readouterr()\n+            assert 'BlockingIOError' not in stderr\n+\n+    finally:\n+        stop_event.set()\n+        t.join()\n\n\n###\n\n", "completion": "feat: add RLock for GRPCClient (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -607,6 +607,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.11.0`)](#release-note-3110)\n - [Release Note (`3.12.0`)](#release-note-3120)\n - [Release Note (`3.13.0`)](#release-note-3130)\n+- [Release Note (`3.13.1`)](#release-note-3131)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -605,6 +605,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.10.1`)](#release-note-3101)\n - [Release Note (`3.11.0`)](#release-note-3110)\n - [Release Note (`3.12.0`)](#release-note-3120)\n+- [Release Note (`3.13.0`)](#release-note-3130)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -603,6 +603,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.10.0`)](#release-note-3100)\n - [Release Note (`3.10.1`)](#release-note-3101)\n - [Release Note (`3.11.0`)](#release-note-3110)\n+- [Release Note (`3.12.0`)](#release-note-3120)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -601,6 +601,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.9.3`)](#release-note-393)\n - [Release Note (`3.10.0`)](#release-note-3100)\n - [Release Note (`3.10.1`)](#release-note-3101)\n+- [Release Note (`3.11.0`)](#release-note-3110)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -599,6 +599,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.9.2`)](#release-note-392)\n - [Release Note (`3.9.3`)](#release-note-393)\n - [Release Note (`3.10.0`)](#release-note-3100)\n+- [Release Note (`3.10.1`)](#release-note-3101)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -596,6 +596,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.9.0`)](#release-note-390)\n - [Release Note (`3.9.1`)](#release-note-391)\n - [Release Note (`3.9.2`)](#release-note-392)\n+- [Release Note (`3.9.3`)](#release-note-393)\n+- [Release Note (`3.10.0`)](#release-note-3100)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -593,6 +593,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.8.4`)](#release-note-384)\n - [Release Note (`3.9.0`)](#release-note-390)\n - [Release Note (`3.9.1`)](#release-note-391)\n+- [Release Note (`3.9.2`)](#release-note-392)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -589,6 +589,9 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.8.1`)](#release-note-381)\n - [Release Note (`3.8.2`)](#release-note-382)\n - [Release Note (`3.8.3`)](#release-note-383)\n+- [Release Note (`3.8.4`)](#release-note-384)\n+- [Release Note (`3.9.0`)](#release-note-390)\n+- [Release Note (`3.9.1`)](#release-note-391)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -585,6 +585,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.8.0`)](#release-note-380)\n - [Release Note (`3.8.1`)](#release-note-381)\n - [Release Note (`3.8.2`)](#release-note-382)\n+- [Release Note (`3.8.3`)](#release-note-383)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -583,6 +583,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.14`)](#release-note-3714)\n - [Release Note (`3.8.0`)](#release-note-380)\n - [Release Note (`3.8.1`)](#release-note-381)\n+- [Release Note (`3.8.2`)](#release-note-382)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -581,6 +581,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.13`)](#release-note-3713)\n - [Release Note (`3.7.14`)](#release-note-3714)\n - [Release Note (`3.8.0`)](#release-note-380)\n+- [Release Note (`3.8.1`)](#release-note-381)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -579,6 +579,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.12`)](#release-note-3712)\n - [Release Note (`3.7.13`)](#release-note-3713)\n - [Release Note (`3.7.14`)](#release-note-3714)\n+- [Release Note (`3.8.0`)](#release-note-380)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -577,6 +577,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.11`)](#release-note-3711)\n - [Release Note (`3.7.12`)](#release-note-3712)\n - [Release Note (`3.7.13`)](#release-note-3713)\n+- [Release Note (`3.7.14`)](#release-note-3714)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -575,6 +575,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.10`)](#release-note-3710)\n - [Release Note (`3.7.11`)](#release-note-3711)\n - [Release Note (`3.7.12`)](#release-note-3712)\n+- [Release Note (`3.7.13`)](#release-note-3713)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -573,6 +573,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.9`)](#release-note-379)\n - [Release Note (`3.7.10`)](#release-note-3710)\n - [Release Note (`3.7.11`)](#release-note-3711)\n+- [Release Note (`3.7.12`)](#release-note-3712)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -570,6 +570,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.7`)](#release-note-377)\n - [Release Note (`3.7.8`)](#release-note-378)\n - [Release Note (`3.7.9`)](#release-note-379)\n+- [Release Note (`3.7.10`)](#release-note-3710)\n+- [Release Note (`3.7.11`)](#release-note-3711)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -566,6 +566,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.5`)](#release-note-375)\n - [Release Note (`3.7.6`)](#release-note-376)\n - [Release Note (`3.7.7`)](#release-note-377)\n+- [Release Note (`3.7.8`)](#release-note-378)\n+- [Release Note (`3.7.9`)](#release-note-379)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -562,6 +562,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.3`)](#release-note-373)\n - [Release Note (`3.7.4`)](#release-note-374)\n - [Release Note (`3.7.5`)](#release-note-375)\n+- [Release Note (`3.7.6`)](#release-note-376)\n+- [Release Note (`3.7.7`)](#release-note-377)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -559,6 +559,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.2`)](#release-note-372)\n - [Release Note (`3.7.3`)](#release-note-373)\n - [Release Note (`3.7.4`)](#release-note-374)\n+- [Release Note (`3.7.5`)](#release-note-375)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -557,6 +557,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.7.1`)](#release-note-371)\n - [Release Note (`3.7.2`)](#release-note-372)\n - [Release Note (`3.7.3`)](#release-note-373)\n+- [Release Note (`3.7.4`)](#release-note-374)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -554,6 +554,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.16`)](#release-note-3616)\n - [Release Note (`3.7.0`)](#release-note-370)\n - [Release Note (`3.7.1`)](#release-note-371)\n+- [Release Note (`3.7.2`)](#release-note-372)\n+- [Release Note (`3.7.3`)](#release-note-373)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -551,6 +551,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.15`)](#release-note-3615)\n - [Release Note (`3.6.16`)](#release-note-3616)\n - [Release Note (`3.7.0`)](#release-note-370)\n+- [Release Note (`3.7.1`)](#release-note-371)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -548,6 +548,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.13`)](#release-note-3613)\n - [Release Note (`3.6.14`)](#release-note-3614)\n - [Release Note (`3.6.15`)](#release-note-3615)\n+- [Release Note (`3.6.16`)](#release-note-3616)\n+- [Release Note (`3.7.0`)](#release-note-370)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -545,6 +545,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.12`)](#release-note-3612)\n - [Release Note (`3.6.13`)](#release-note-3613)\n - [Release Note (`3.6.14`)](#release-note-3614)\n+- [Release Note (`3.6.15`)](#release-note-3615)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -543,6 +543,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.11`)](#release-note-3611)\n - [Release Note (`3.6.12`)](#release-note-3612)\n - [Release Note (`3.6.13`)](#release-note-3613)\n+- [Release Note (`3.6.14`)](#release-note-3614)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -540,6 +540,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.9`)](#release-note-369)\n - [Release Note (`3.6.10`)](#release-note-3610)\n - [Release Note (`3.6.11`)](#release-note-3611)\n+- [Release Note (`3.6.12`)](#release-note-3612)\n+- [Release Note (`3.6.13`)](#release-note-3613)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -537,6 +537,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.8`)](#release-note-368)\n - [Release Note (`3.6.9`)](#release-note-369)\n - [Release Note (`3.6.10`)](#release-note-3610)\n+- [Release Note (`3.6.11`)](#release-note-3611)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -535,6 +535,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.7`)](#release-note-367)\n - [Release Note (`3.6.8`)](#release-note-368)\n - [Release Note (`3.6.9`)](#release-note-369)\n+- [Release Note (`3.6.10`)](#release-note-3610)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -533,6 +533,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.6`)](#release-note-366)\n - [Release Note (`3.6.7`)](#release-note-367)\n - [Release Note (`3.6.8`)](#release-note-368)\n+- [Release Note (`3.6.9`)](#release-note-369)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -530,6 +530,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.4`)](#release-note-364)\n - [Release Note (`3.6.5`)](#release-note-365)\n - [Release Note (`3.6.6`)](#release-note-366)\n+- [Release Note (`3.6.7`)](#release-note-367)\n+- [Release Note (`3.6.8`)](#release-note-368)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -527,6 +527,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.3`)](#release-note-363)\n - [Release Note (`3.6.4`)](#release-note-364)\n - [Release Note (`3.6.5`)](#release-note-365)\n+- [Release Note (`3.6.6`)](#release-note-366)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -525,6 +525,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.2`)](#release-note-362)\n - [Release Note (`3.6.3`)](#release-note-363)\n - [Release Note (`3.6.4`)](#release-note-364)\n+- [Release Note (`3.6.5`)](#release-note-365)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -523,6 +523,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.1`)](#release-note-361)\n - [Release Note (`3.6.2`)](#release-note-362)\n - [Release Note (`3.6.3`)](#release-note-363)\n+- [Release Note (`3.6.4`)](#release-note-364)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -521,6 +521,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.6.0`)](#release-note-360)\n - [Release Note (`3.6.1`)](#release-note-361)\n - [Release Note (`3.6.2`)](#release-note-362)\n+- [Release Note (`3.6.3`)](#release-note-363)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -519,6 +519,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.5.0`)](#release-note-350)\n - [Release Note (`3.6.0`)](#release-note-360)\n - [Release Note (`3.6.1`)](#release-note-361)\n+- [Release Note (`3.6.2`)](#release-note-362)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -517,6 +517,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.11`)](#release-note-3411)\n - [Release Note (`3.5.0`)](#release-note-350)\n - [Release Note (`3.6.0`)](#release-note-360)\n+- [Release Note (`3.6.1`)](#release-note-361)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -515,6 +515,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.10`)](#release-note-3410)\n - [Release Note (`3.4.11`)](#release-note-3411)\n - [Release Note (`3.5.0`)](#release-note-350)\n+- [Release Note (`3.6.0`)](#release-note-360)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -513,6 +513,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.9`)](#release-note-349)\n - [Release Note (`3.4.10`)](#release-note-3410)\n - [Release Note (`3.4.11`)](#release-note-3411)\n+- [Release Note (`3.5.0`)](#release-note-350)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -511,6 +511,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.8`)](#release-note-348)\n - [Release Note (`3.4.9`)](#release-note-349)\n - [Release Note (`3.4.10`)](#release-note-3410)\n+- [Release Note (`3.4.11`)](#release-note-3411)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -509,6 +509,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.7`)](#release-note-347)\n - [Release Note (`3.4.8`)](#release-note-348)\n - [Release Note (`3.4.9`)](#release-note-349)\n+- [Release Note (`3.4.10`)](#release-note-3410)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -506,6 +506,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.5`)](#release-note-345)\n - [Release Note (`3.4.6`)](#release-note-346)\n - [Release Note (`3.4.7`)](#release-note-347)\n+- [Release Note (`3.4.8`)](#release-note-348)\n+- [Release Note (`3.4.9`)](#release-note-349)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -503,6 +503,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.4`)](#release-note-344)\n - [Release Note (`3.4.5`)](#release-note-345)\n - [Release Note (`3.4.6`)](#release-note-346)\n+- [Release Note (`3.4.7`)](#release-note-347)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -500,6 +500,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.2`)](#release-note-342)\n - [Release Note (`3.4.3`)](#release-note-343)\n - [Release Note (`3.4.4`)](#release-note-344)\n+- [Release Note (`3.4.5`)](#release-note-345)\n+- [Release Note (`3.4.6`)](#release-note-346)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -497,6 +497,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.1`)](#release-note-341)\n - [Release Note (`3.4.2`)](#release-note-342)\n - [Release Note (`3.4.3`)](#release-note-343)\n+- [Release Note (`3.4.4`)](#release-note-344)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -495,6 +495,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.4.0`)](#release-note-340)\n - [Release Note (`3.4.1`)](#release-note-341)\n - [Release Note (`3.4.2`)](#release-note-342)\n+- [Release Note (`3.4.3`)](#release-note-343)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -492,6 +492,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.24`)](#release-note-3324)\n - [Release Note (`3.3.25`)](#release-note-3325)\n - [Release Note (`3.4.0`)](#release-note-340)\n+- [Release Note (`3.4.1`)](#release-note-341)\n+- [Release Note (`3.4.2`)](#release-note-342)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -489,6 +489,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.23`)](#release-note-3323)\n - [Release Note (`3.3.24`)](#release-note-3324)\n - [Release Note (`3.3.25`)](#release-note-3325)\n+- [Release Note (`3.4.0`)](#release-note-340)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -487,6 +487,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.22`)](#release-note-3322)\n - [Release Note (`3.3.23`)](#release-note-3323)\n - [Release Note (`3.3.24`)](#release-note-3324)\n+- [Release Note (`3.3.25`)](#release-note-3325)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -485,6 +485,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.21`)](#release-note-3321)\n - [Release Note (`3.3.22`)](#release-note-3322)\n - [Release Note (`3.3.23`)](#release-note-3323)\n+- [Release Note (`3.3.24`)](#release-note-3324)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -483,6 +483,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.20`)](#release-note-3320)\n - [Release Note (`3.3.21`)](#release-note-3321)\n - [Release Note (`3.3.22`)](#release-note-3322)\n+- [Release Note (`3.3.23`)](#release-note-3323)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -481,6 +481,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.19`)](#release-note-3319)\n - [Release Note (`3.3.20`)](#release-note-3320)\n - [Release Note (`3.3.21`)](#release-note-3321)\n+- [Release Note (`3.3.22`)](#release-note-3322)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -478,6 +478,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.17`)](#release-note-3317)\n - [Release Note (`3.3.18`)](#release-note-3318)\n - [Release Note (`3.3.19`)](#release-note-3319)\n+- [Release Note (`3.3.20`)](#release-note-3320)\n+- [Release Note (`3.3.21`)](#release-note-3321)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -474,6 +474,8 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.15`)](#release-note-3315)\n - [Release Note (`3.3.16`)](#release-note-3316)\n - [Release Note (`3.3.17`)](#release-note-3317)\n+- [Release Note (`3.3.18`)](#release-note-3318)\n+- [Release Note (`3.3.19`)](#release-note-3319)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -466,6 +466,12 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.9`)](#release-note-339)\n - [Release Note (`3.3.10`)](#release-note-3310)\n - [Release Note (`3.3.11`)](#release-note-3311)\n+- [Release Note (`3.3.12`)](#release-note-3312)\n+- [Release Note (`3.3.13`)](#release-note-3313)\n+- [Release Note (`3.3.14`)](#release-note-3314)\n+- [Release Note (`3.3.15`)](#release-note-3315)\n+- [Release Note (`3.3.16`)](#release-note-3316)\n+- [Release Note (`3.3.17`)](#release-note-3317)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -459,6 +459,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.8`)](#release-note-338)\n - [Release Note (`3.3.9`)](#release-note-339)\n - [Release Note (`3.3.10`)](#release-note-3310)\n+- [Release Note (`3.3.11`)](#release-note-3311)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -454,6 +454,10 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.4`)](#release-note-334)\n - [Release Note (`3.3.5`)](#release-note-335)\n - [Release Note (`3.3.6`)](#release-note-336)\n+- [Release Note (`3.3.7`)](#release-note-337)\n+- [Release Note (`3.3.8`)](#release-note-338)\n+- [Release Note (`3.3.9`)](#release-note-339)\n+- [Release Note (`3.3.10`)](#release-note-3310)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -449,6 +449,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.3`)](#release-note-333)\n - [Release Note (`3.3.4`)](#release-note-334)\n - [Release Note (`3.3.5`)](#release-note-335)\n+- [Release Note (`3.3.6`)](#release-note-336)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -445,6 +445,9 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.3.0`)](#release-note-330)\n - [Release Note (`3.3.1`)](#release-note-331)\n - [Release Note (`3.3.2`)](#release-note-332)\n+- [Release Note (`3.3.3`)](#release-note-333)\n+- [Release Note (`3.3.4`)](#release-note-334)\n+- [Release Note (`3.3.5`)](#release-note-335)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -441,6 +441,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.10`)](#release-note-3210)\n - [Release Note (`3.3.0`)](#release-note-330)\n - [Release Note (`3.3.1`)](#release-note-331)\n+- [Release Note (`3.3.2`)](#release-note-332)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -439,6 +439,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.9`)](#release-note-329)\n - [Release Note (`3.2.10`)](#release-note-3210)\n - [Release Note (`3.3.0`)](#release-note-330)\n+- [Release Note (`3.3.1`)](#release-note-331)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -437,6 +437,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.8`)](#release-note-328)\n - [Release Note (`3.2.9`)](#release-note-329)\n - [Release Note (`3.2.10`)](#release-note-3210)\n+- [Release Note (`3.3.0`)](#release-note-330)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -435,6 +435,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.7`)](#release-note-327)\n - [Release Note (`3.2.8`)](#release-note-328)\n - [Release Note (`3.2.9`)](#release-note-329)\n+- [Release Note (`3.2.10`)](#release-note-3210)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -433,6 +433,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.6`)](#release-note-326)\n - [Release Note (`3.2.7`)](#release-note-327)\n - [Release Note (`3.2.8`)](#release-note-328)\n+- [Release Note (`3.2.9`)](#release-note-329)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -431,6 +431,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.5`)](#release-note-325)\n - [Release Note (`3.2.6`)](#release-note-326)\n - [Release Note (`3.2.7`)](#release-note-327)\n+- [Release Note (`3.2.8`)](#release-note-328)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -429,6 +429,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.4`)](#release-note-324)\n - [Release Note (`3.2.5`)](#release-note-325)\n - [Release Note (`3.2.6`)](#release-note-326)\n+- [Release Note (`3.2.7`)](#release-note-327)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -425,6 +425,9 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.2.1`)](#release-note-321)\n - [Release Note (`3.2.2`)](#release-note-322)\n - [Release Note (`3.2.3`)](#release-note-323)\n+- [Release Note (`3.2.4`)](#release-note-324)\n+- [Release Note (`3.2.5`)](#release-note-325)\n+- [Release Note (`3.2.6`)](#release-note-326)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -419,6 +419,9 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.1.5`)](#release-note-315)\n - [Release Note (`3.1.6`)](#release-note-316)\n - [Release Note (`3.2.0`)](#release-note-320)\n+- [Release Note (`3.2.1`)](#release-note-321)\n+- [Release Note (`3.2.2`)](#release-note-322)\n+- [Release Note (`3.2.3`)](#release-note-323)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -413,6 +413,9 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.1.2`)](#release-note-312)\n - [Release Note (`3.1.3`)](#release-note-313)\n - [Release Note (`3.1.4`)](#release-note-314)\n+- [Release Note (`3.1.5`)](#release-note-315)\n+- [Release Note (`3.1.6`)](#release-note-316)\n+- [Release Note (`3.2.0`)](#release-note-320)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -409,6 +409,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.1.1`)](#release-note-311)\n - [Release Note (`3.1.2`)](#release-note-312)\n - [Release Note (`3.1.3`)](#release-note-313)\n+- [Release Note (`3.1.4`)](#release-note-314)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -407,6 +407,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.1.0`)](#release-note-310)\n - [Release Note (`3.1.1`)](#release-note-311)\n - [Release Note (`3.1.2`)](#release-note-312)\n+- [Release Note (`3.1.3`)](#release-note-313)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -405,6 +405,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.0.4`)](#release-note-304)\n - [Release Note (`3.1.0`)](#release-note-310)\n - [Release Note (`3.1.1`)](#release-note-311)\n+- [Release Note (`3.1.2`)](#release-note-312)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n---\n file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -403,6 +403,7 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n - [Release Note (`3.0.3`)](#release-note-303)\n - [Release Note (`3.0.4`)](#release-note-304)\n - [Release Note (`3.1.0`)](#release-note-310)\n+- [Release Note (`3.1.1`)](#release-note-311)\n \n <!-- END doctoc generated TOC please keep comment here to allow auto update -->\n \n\n\n###\n\n", "completion": "chore(docs): update TOC"}
{"prompt": " file path A: tests/unit/orchestrate/flow/flow-async/test_asyncflow.py | file path B: tests/unit/orchestrate/flow/flow-async/test_asyncflow.py\n\n@@ -40,15 +40,17 @@ def documents(start_index, end_index):\n @pytest.mark.parametrize(\n     'return_responses, return_class', [(True, Request), (False, DocumentArray)]\n )\n+@pytest.mark.parametrize('use_stream', [False, True])\n async def test_run_async_flow(\n-    protocol, mocker, flow_cls, return_responses, return_class\n+        protocol, mocker, flow_cls, return_responses, return_class, use_stream\n ):\n     r_val = mocker.Mock()\n     with flow_cls(protocol=protocol, asyncio=True).add() as f:\n         async for r in f.index(\n-            from_ndarray(np.random.random([num_docs, 4])),\n-            on_done=r_val,\n-            return_responses=return_responses,\n+                from_ndarray(np.random.random([num_docs, 4])),\n+                on_done=r_val,\n+                return_responses=return_responses,\n+                stream=use_stream\n         ):\n             assert isinstance(r, return_class)\n     validate_callback(r_val, validate)\n@@ -69,18 +71,22 @@ async def async_input_function2():\n @pytest.mark.slow\n @pytest.mark.asyncio\n @pytest.mark.parametrize(\n-    'inputs',\n+    'inputs, use_stream',\n     [\n-        async_input_function,\n-        async_input_function(),\n-        async_input_function2(),\n-        async_input_function2,\n+        (async_input_function, False),\n+        (async_input_function, True),\n+        (async_input_function(), True),\n+        (async_input_function(), False),\n+        (async_input_function2(), False),\n+        (async_input_function2(), True),\n+        (async_input_function2, True),\n+        (async_input_function2, False),\n     ],\n )\n-async def test_run_async_flow_async_input(inputs, mocker):\n+async def test_run_async_flow_async_input(inputs, use_stream, mocker):\n     r_val = mocker.Mock()\n     with AsyncFlow(asyncio=True).add() as f:\n-        async for r in f.index(inputs, on_done=r_val):\n+        async for r in f.index(inputs, on_done=r_val, stream=use_stream):\n             assert isinstance(r, DocumentArray)\n     validate_callback(r_val, validate)\n \n@@ -95,8 +101,8 @@ class Wait5s(Executor):\n \n async def run_async_flow_5s(flow):\n     async for r in flow.index(\n-        from_ndarray(np.random.random([num_docs, 4])),\n-        on_done=validate,\n+            from_ndarray(np.random.random([num_docs, 4])),\n+            on_done=validate,\n     ):\n         assert isinstance(r, DocumentArray)\n \n@@ -148,9 +154,10 @@ async def test_run_async_flow_other_task_concurrent(protocol):\n @pytest.mark.asyncio\n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n @pytest.mark.parametrize('flow_cls', [Flow, AsyncFlow])\n-async def test_return_results_async_flow(protocol, flow_cls):\n+@pytest.mark.parametrize('use_stream', [False, True])\n+async def test_return_results_async_flow(protocol, flow_cls, use_stream):\n     with flow_cls(protocol=protocol, asyncio=True).add() as f:\n-        async for r in f.index(from_ndarray(np.random.random([10, 2]))):\n+        async for r in f.index(from_ndarray(np.random.random([10, 2])), stream=use_stream):\n             assert isinstance(r, DocumentArray)\n \n \n@@ -159,9 +166,10 @@ async def test_return_results_async_flow(protocol, flow_cls):\n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n @pytest.mark.parametrize('flow_api', ['delete', 'index', 'update', 'search'])\n @pytest.mark.parametrize('flow_cls', [Flow, AsyncFlow])\n-async def test_return_results_async_flow_crud(protocol, flow_api, flow_cls):\n+@pytest.mark.parametrize('use_stream', [False, True])\n+async def test_return_results_async_flow_crud(protocol, flow_api, flow_cls, use_stream):\n     with flow_cls(protocol=protocol, asyncio=True).add() as f:\n-        async for r in getattr(f, flow_api)(documents(0, 10)):\n+        async for r in getattr(f, flow_api)(documents(0, 10), stream=use_stream):\n             assert isinstance(r, DocumentArray)\n \n \n@@ -173,7 +181,8 @@ class MyExec(Executor):\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('flow_cls', [Flow, AsyncFlow])\n-async def test_async_flow_empty_data(flow_cls):\n+@pytest.mark.parametrize('use_stream', [False, True])\n+async def test_async_flow_empty_data(flow_cls, use_stream):\n     with flow_cls(asyncio=True).add(uses=MyExec) as f:\n-        async for r in f.post('/hello', parameters={'hello': 'world'}):\n+        async for r in f.post('/hello', parameters={'hello': 'world'}, stream=use_stream):\n             assert isinstance(r, DocumentArray)\n\n\n###\n\n", "completion": "test: add tests for stream false and async flow (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -237,6 +237,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15477,3 +15478,42 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```854f6d2b```](https://github.com/jina-ai/jina/commit/854f6d2b79711ebc4ce2fce5f33f8ae03d58345b)] __-__ fix old docs script (#5459) (*Joan Fontanals*)\n  - [[```ce7e5b77```](https://github.com/jina-ai/jina/commit/ce7e5b7760b02790eff777359748392e9d2903ab)] __-__ __version__: the next version will be 3.12.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-13-1></a>\n+## Release Note (`3.13.1`)\n+\n+> Release time: 2022-12-21 12:58:15\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Nan Wang,  Joan Fontanals,  AlaeddineAbdessalem,  Jackmin801,  Anne Yang,  Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```b4189601```](https://github.com/jina-ai/jina/commit/b4189601136b565fbaa644f76b659d40b39b8358)] __-__ using unary rpc from client respects results_in_order (#5513) (*Joan Fontanals*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```6b56c0cb```](https://github.com/jina-ai/jina/commit/6b56c0cb76f77eab2935c42f252db485d06cc00e)] __-__ do not raise exception to end iteration (#5544) (*Joan Fontanals*)\n+ - [[```77e936af```](https://github.com/jina-ai/jina/commit/77e936afd16c7d2bca9c781df891f97e4b25eff3)] __-__ fix installing build essentials for python 3.11 (#5542) (*AlaeddineAbdessalem*)\n+ - [[```5e0d0dc4```](https://github.com/jina-ai/jina/commit/5e0d0dc4e5ca1e94d4f8ff2e7210a4b9aae9f3f7)] __-__ install build essentials before pip install for python 3.11 docker image (#5541) (*AlaeddineAbdessalem*)\n+ - [[```1ea52c57```](https://github.com/jina-ai/jina/commit/1ea52c57e32bc2b5a278869cc79fba8262e5d3f5)] __-__ add gcc-c++ and python devel for python 3.11 (#5540) (*AlaeddineAbdessalem*)\n+ - [[```73ac83ec```](https://github.com/jina-ai/jina/commit/73ac83eca70e4036cb934ae92b46c1799b26f0cd)] __-__ support python 3.11 (#5529) (*Jackmin801*)\n+ - [[```3c09e6e2```](https://github.com/jina-ai/jina/commit/3c09e6e214eccc30f64d3003d9fbbc1224071118)] __-__ support composite gateway for k8s export (#5532) (*AlaeddineAbdessalem*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```fe2d6232```](https://github.com/jina-ai/jina/commit/fe2d6232687edd05aa483e0eabd151f78870b040)] __-__ do the flow readiness check async and not in thread (#5531) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```c321d44c```](https://github.com/jina-ai/jina/commit/c321d44ce44de2953f2fca057da4a7a9b1a76aa2)] __-__ fix the reference to gateway (#5546) (*Nan Wang*)\n+ - [[```27acb889```](https://github.com/jina-ai/jina/commit/27acb8897beeb5d51f8f8cfb30349671926ab2e0)] __-__ common args inheritence from Flow API (#5535) (*Anne Yang*)\n+ - [[```d4075be0```](https://github.com/jina-ai/jina/commit/d4075be08649ebb7feac74b52c19967885876a3e)] __-__ add icons to top-level chapters (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```9645c7ab```](https://github.com/jina-ai/jina/commit/9645c7ab9393afe8ca1d61ae118a915ef247a373)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```3f31aa87```](https://github.com/jina-ai/jina/commit/3f31aa87748b9ebd773891493e075c07c6f140cd)] __-__ __version__: the next version will be 3.13.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: docs/_versions.json | file path B: docs/_versions.json\n\n@@ -1 +1 @@\n-[{\"version\": \"v3.13.0\"}, {\"version\": \"v3.12.0\"}, {\"version\": \"v3.11.0\"}, {\"version\": \"v3.10.1\"}, {\"version\": \"v3.10.0\"}, {\"version\": \"v3.9.3\"}, {\"version\": \"v3.9.2\"}, {\"version\": \"v3.9.1\"}, {\"version\": \"v3.9.0\"}, {\"version\": \"v3.8.4\"}, {\"version\": \"v3.8.3\"}, {\"version\": \"v3.8.2\"}, {\"version\": \"v3.8.1\"}, {\"version\": \"v3.8.0\"}, {\"version\": \"v3.7.14\"}, {\"version\": \"v3.7.13\"}, {\"version\": \"v3.7.12\"}, {\"version\": \"v3.7.11\"}, {\"version\": \"v3.7.10\"}, {\"version\": \"v3.7.9\"}, {\"version\": \"v3.7.8\"}, {\"version\": \"v3.7.7\"}, {\"version\": \"v3.7.6\"}, {\"version\": \"v3.7.5\"}, {\"version\": \"v3.7.4\"}, {\"version\": \"v3.7.3\"}, {\"version\": \"v3.7.2\"}, {\"version\": \"v3.7.1\"}, {\"version\": \"v3.7.0\"}, {\"version\": \"v3.6.16\"}, {\"version\": \"v3.6.15\"}, {\"version\": \"v3.6.14\"}, {\"version\": \"v3.6.13\"}, {\"version\": \"v3.6.12\"}, {\"version\": \"v3.6.11\"}, {\"version\": \"v3.6.10\"}, {\"version\": \"v3.6.9\"}, {\"version\": \"v3.6.8\"}, {\"version\": \"v3.6.7\"}, {\"version\": \"v3.6.6\"}, {\"version\": \"v3.6.5\"}, {\"version\": \"v3.6.4\"}, {\"version\": \"v3.6.3\"}, {\"version\": \"v3.6.2\"}, {\"version\": \"v3.6.1\"}, {\"version\": \"v3.6.0\"}, {\"version\": \"v3.5.0\"}, {\"version\": \"v3.4.11\"}, {\"version\": \"v3.4.10\"}, {\"version\": \"v3.4.9\"}, {\"version\": \"v3.4.8\"}, {\"version\": \"v3.4.7\"}, {\"version\": \"v3.4.6\"}, {\"version\": \"v3.4.5\"}, {\"version\": \"v3.4.4\"}, {\"version\": \"v3.4.3\"}, {\"version\": \"v3.4.2\"}, {\"version\": \"v3.4.1\"}, {\"version\": \"v3.4.0\"}, {\"version\": \"v3.3.25\"}, {\"version\": \"v3.3.24\"}, {\"version\": \"v3.3.23\"}, {\"version\": \"v3.3.22\"}, {\"version\": \"v3.3.21\"}, {\"version\": \"v3.3.20\"}, {\"version\": \"v3.3.19\"}, {\"version\": \"v3.3.18\"}, {\"version\": \"v3.3.17\"}, {\"version\": \"v3.3.16\"}, {\"version\": \"v3.3.15\"}, {\"version\": \"v3.3.14\"}, {\"version\": \"v3.3.13\"}, {\"version\": \"v3.3.7\"}, {\"version\": \"v3.3.12\"}, {\"version\": \"v3.3.11\"}, {\"version\": \"v3.3.10\"}, {\"version\": \"v3.3.9\"}, {\"version\": \"v3.3.8\"}, {\"version\": \"v3.3.7\"}, {\"version\": \"v3.3.6\"}, {\"version\": \"v3.3.5\"}, {\"version\": \"v3.3.4\"}, {\"version\": \"v3.3.3\"}, {\"version\": \"v3.3.2\"}, {\"version\": \"v3.3.1\"}, {\"version\": \"v3.3.0\"}, {\"version\": \"v3.2.10\"}, {\"version\": \"v3.2.9\"}, {\"version\": \"v3.2.8\"}, {\"version\": \"v3.2.7\"}, {\"version\": \"v3.2.6\"}, {\"version\": \"v3.2.5\"}, {\"version\": \"v3.2.4\"}, {\"version\": \"v3.2.3\"}, {\"version\": \"v3.2.2\"}, {\"version\": \"v3.2.1\"}, {\"version\": \"v3.2.0\"}, {\"version\": \"v3.1.6\"}, {\"version\": \"v3.1.5\"}, {\"version\": \"v3.1.4\"}, {\"version\": \"v3.1.3\"}, {\"version\": \"v3.1.2\"}, {\"version\": \"v3.1.1\"}, {\"version\": \"v3.1.0\"}, {\"version\": \"v3.0.4\"}, {\"version\": \"v3.0.3\"}, {\"version\": \"v3.0.2\"}, {\"version\": \"v3.0.1\"}, {\"version\": \"v3.0.0\"}]\n\\ No newline at end of file\n+[{\"version\": \"v3.13.1\"}, {\"version\": \"v3.13.0\"}, {\"version\": \"v3.12.0\"}, {\"version\": \"v3.11.0\"}, {\"version\": \"v3.10.1\"}, {\"version\": \"v3.10.0\"}, {\"version\": \"v3.9.3\"}, {\"version\": \"v3.9.2\"}, {\"version\": \"v3.9.1\"}, {\"version\": \"v3.9.0\"}, {\"version\": \"v3.8.4\"}, {\"version\": \"v3.8.3\"}, {\"version\": \"v3.8.2\"}, {\"version\": \"v3.8.1\"}, {\"version\": \"v3.8.0\"}, {\"version\": \"v3.7.14\"}, {\"version\": \"v3.7.13\"}, {\"version\": \"v3.7.12\"}, {\"version\": \"v3.7.11\"}, {\"version\": \"v3.7.10\"}, {\"version\": \"v3.7.9\"}, {\"version\": \"v3.7.8\"}, {\"version\": \"v3.7.7\"}, {\"version\": \"v3.7.6\"}, {\"version\": \"v3.7.5\"}, {\"version\": \"v3.7.4\"}, {\"version\": \"v3.7.3\"}, {\"version\": \"v3.7.2\"}, {\"version\": \"v3.7.1\"}, {\"version\": \"v3.7.0\"}, {\"version\": \"v3.6.16\"}, {\"version\": \"v3.6.15\"}, {\"version\": \"v3.6.14\"}, {\"version\": \"v3.6.13\"}, {\"version\": \"v3.6.12\"}, {\"version\": \"v3.6.11\"}, {\"version\": \"v3.6.10\"}, {\"version\": \"v3.6.9\"}, {\"version\": \"v3.6.8\"}, {\"version\": \"v3.6.7\"}, {\"version\": \"v3.6.6\"}, {\"version\": \"v3.6.5\"}, {\"version\": \"v3.6.4\"}, {\"version\": \"v3.6.3\"}, {\"version\": \"v3.6.2\"}, {\"version\": \"v3.6.1\"}, {\"version\": \"v3.6.0\"}, {\"version\": \"v3.5.0\"}, {\"version\": \"v3.4.11\"}, {\"version\": \"v3.4.10\"}, {\"version\": \"v3.4.9\"}, {\"version\": \"v3.4.8\"}, {\"version\": \"v3.4.7\"}, {\"version\": \"v3.4.6\"}, {\"version\": \"v3.4.5\"}, {\"version\": \"v3.4.4\"}, {\"version\": \"v3.4.3\"}, {\"version\": \"v3.4.2\"}, {\"version\": \"v3.4.1\"}, {\"version\": \"v3.4.0\"}, {\"version\": \"v3.3.25\"}, {\"version\": \"v3.3.24\"}, {\"version\": \"v3.3.23\"}, {\"version\": \"v3.3.22\"}, {\"version\": \"v3.3.21\"}, {\"version\": \"v3.3.20\"}, {\"version\": \"v3.3.19\"}, {\"version\": \"v3.3.18\"}, {\"version\": \"v3.3.17\"}, {\"version\": \"v3.3.16\"}, {\"version\": \"v3.3.15\"}, {\"version\": \"v3.3.14\"}, {\"version\": \"v3.3.13\"}, {\"version\": \"v3.3.7\"}, {\"version\": \"v3.3.12\"}, {\"version\": \"v3.3.11\"}, {\"version\": \"v3.3.10\"}, {\"version\": \"v3.3.9\"}, {\"version\": \"v3.3.8\"}, {\"version\": \"v3.3.7\"}, {\"version\": \"v3.3.6\"}, {\"version\": \"v3.3.5\"}, {\"version\": \"v3.3.4\"}, {\"version\": \"v3.3.3\"}, {\"version\": \"v3.3.2\"}, {\"version\": \"v3.3.1\"}, {\"version\": \"v3.3.0\"}, {\"version\": \"v3.2.10\"}, {\"version\": \"v3.2.9\"}, {\"version\": \"v3.2.8\"}, {\"version\": \"v3.2.7\"}, {\"version\": \"v3.2.6\"}, {\"version\": \"v3.2.5\"}, {\"version\": \"v3.2.4\"}, {\"version\": \"v3.2.3\"}, {\"version\": \"v3.2.2\"}, {\"version\": \"v3.2.1\"}, {\"version\": \"v3.2.0\"}, {\"version\": \"v3.1.6\"}, {\"version\": \"v3.1.5\"}, {\"version\": \"v3.1.4\"}, {\"version\": \"v3.1.3\"}, {\"version\": \"v3.1.2\"}, {\"version\": \"v3.1.1\"}, {\"version\": \"v3.1.0\"}, {\"version\": \"v3.0.4\"}, {\"version\": \"v3.0.3\"}, {\"version\": \"v3.0.2\"}, {\"version\": \"v3.0.1\"}, {\"version\": \"v3.0.0\"}]\n\\ No newline at end of file\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.13.1'\n+__version__ = '3.13.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.13.2"}
{"prompt": " file path A: docs/cloud-nativeness/k8s.md | file path B: docs/cloud-nativeness/k8s.md\n\n@@ -117,7 +117,7 @@ If you want to learn more about this limitation, see [this](https://kubernetes.i\n ````\n \n ## Scaling the Gateway\n-The {ref}`Gateway <flow>` is responsible for providing the API of the {ref}`Flow <flow>`.\n+The {ref}`Gateway <gateway>` is responsible for providing the API of the {ref}`Flow <flow>`.\n If you have a large Flow with many Clients and many replicated Executors, the Gateway can become the bottleneck.\n In this case you can also scale up the Gateway deployment to be backed by multiple Kubernetes Pods.\n This is done by the regular means of Kubernetes: Either increase the number of replicas in the  {ref}`generated yaml configuration files <kubernetes-export>` or [add replicas while running](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#scaling-a-deployment).\n\n---\n file path A: docs/concepts/client/third-party-clients.md | file path B: docs/concepts/client/third-party-clients.md\n\n@@ -312,5 +312,5 @@ The Flow defaults to `json` if you don't specify a sub-protocol while establishi\n ## See also\n \n - {ref}`Access a Flow with the Client <client>`\n-- {ref}`Configure a Flow <flow>`\n+- {ref}`Configure a Flow <flow-cookbook>`\n - [Flow REST API reference](https://api.jina.ai/rest/)\n\n---\n file path A: docs/concepts/flow/basics.md | file path B: docs/concepts/flow/basics.md\n\n@@ -32,7 +32,7 @@ jtype: Flow\n `````\n \n ```{tip}\n-An empty Flow contains only {ref}`the Gateway<flow>`.\n+An empty Flow contains only {ref}`the Gateway<gateway>`.\n ```\n \n ```{figure} zero-flow.svg\n\n---\n file path A: docs/concepts/flow/index.md | file path B: docs/concepts/flow/index.md\n\n@@ -6,7 +6,7 @@ Documents \"flow\" through the pipeline and are processed by Executors.\n \n You can think of Flow as an interface to configure and launch your {ref}`microservice architecture <architecture-overview>`,\n while the heavy lifting is done by the {ref}`services <executor-cookbook>` themselves.\n-In particular, each Flow also launches a *Gateway* service, which can expose all other services through an API that you define.\n+In particular, each Flow also launches a {ref}`Gateway <gateway>` service, which can expose all other services through an API that you define.\n \n The most important methods of the `Flow` object are the following:\n \n\n---\n file path A: docs/concepts/gateway/index.md | file path B: docs/concepts/gateway/index.md\n\n@@ -1,4 +1,4 @@\n-(flow)=\n+(gateway)=\n \n # {fas}`door-open` Gateway\n \n\n\n###\n\n", "completion": "docs: fix the reference to gateway (#<issue-num>)"}
{"prompt": " file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -30,7 +30,7 @@ class RequestStreamer:\n     A base async request/response streamer.\n     \"\"\"\n \n-    class _EndOfStreaming(Exception):\n+    class _EndOfStreaming:\n         pass\n \n     def __init__(\n@@ -133,7 +133,7 @@ class RequestStreamer:\n                 all_requests_handled.set()\n \n         async def end_future():\n-            raise self._EndOfStreaming\n+            return self._EndOfStreaming()\n \n         async def exception_raise(exception):\n             raise exception\n@@ -207,13 +207,12 @@ class RequestStreamer:\n                 and not empty_requests_iterator.is_set()\n             ):\n                 hanging_response = await floating_results_queue.get()\n-                try:\n-                    hanging_response.result()\n-                    floating_tasks_to_handle.count -= 1\n-                    if floating_tasks_to_handle.count == 0 and end_of_iter.is_set():\n-                        all_floating_requests_awaited.set()\n-                except self._EndOfStreaming:\n-                    pass\n+                res = hanging_response.result()\n+                if isinstance(res, self._EndOfStreaming):\n+                    break\n+                floating_tasks_to_handle.count -= 1\n+                if floating_tasks_to_handle.count == 0 and end_of_iter.is_set():\n+                    all_floating_requests_awaited.set()\n \n         iterate_requests_task = asyncio.create_task(iterate_requests())\n         handle_floating_task = asyncio.create_task(handle_floating_responses())\n@@ -239,13 +238,13 @@ class RequestStreamer:\n                 else:\n                     future = await future_queue.get()\n                     await future\n-                try:\n-                    response = self._result_handler(future.result())\n-                    yield response\n-                    requests_to_handle.count -= 1\n-                    update_all_handled()\n-                except self._EndOfStreaming:\n-                    pass\n+                result = future.result()\n+                if isinstance(result, self._EndOfStreaming):\n+                    break\n+                response = self._result_handler(result)\n+                yield response\n+                requests_to_handle.count -= 1\n+                update_all_handled()\n \n         async for response in receive_responses():\n             yield response\n\n---\n file path A: tests/integration/issues/github_5543/__init__.py | file path B: tests/integration/issues/github_5543/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/issues/github_5543/test_reentrant_flows.py\n\n@@ -0,0 +1,11 @@\n+import pytest\n+from jina import Flow, DocumentArray\n+\n+\n+@pytest.mark.parametrize('use_stream', [False, True])\n+def test_reentrant(use_stream):\n+    for _ in range(10):\n+        f = Flow().add()\n+        with f:\n+            docs = f.post(on='/', inputs=DocumentArray.empty(100), request_size=1, stream=use_stream)\n+            assert len(docs) == 100\n\n\n###\n\n", "completion": "fix: do not raise exception to end iteration (#<issue-num>)"}
{"prompt": " file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -43,7 +43,7 @@ RUN cd /tmp/ && \\\n     if [ -n \"${APT_PACKAGES}\" ]; then apt-get update && apt-get upgrade -y && \\\n     apt-get --only-upgrade install openssl libssl1.1 -y && \\\n     apt-get install --no-install-recommends -y ${APT_PACKAGES}; fi && \\\n-    if [[ $PY_VERSION==3.11 ]]; then apt-get install --no-install-recommends -y build-essential ; fi && \\\n+    if [ $PY_VERSION==3.11 ]; then apt-get install --no-install-recommends -y build-essential ; fi && \\\n     if [ -n \"${PIP_TAG}\" ]; then pip install --default-timeout=1000 --compile --extra-index-url $PIP_EXTRA_INDEX_URL \".[${PIP_TAG}]\" ; fi && \\\n     pip install --default-timeout=1000 --compile --extra-index-url ${PIP_EXTRA_INDEX_URL} . && \\\n     # now remove apt packages\n\n\n###\n\n", "completion": "fix: fix installing build essentials for python 3.11 (#<issue-num>)"}
{"prompt": " file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -43,9 +43,9 @@ RUN cd /tmp/ && \\\n     if [ -n \"${APT_PACKAGES}\" ]; then apt-get update && apt-get upgrade -y && \\\n     apt-get --only-upgrade install openssl libssl1.1 -y && \\\n     apt-get install --no-install-recommends -y ${APT_PACKAGES}; fi && \\\n+    if [[ $PY_VERSION==3.11 ]]; then apt-get install --no-install-recommends -y build-essential ; fi && \\\n     if [ -n \"${PIP_TAG}\" ]; then pip install --default-timeout=1000 --compile --extra-index-url $PIP_EXTRA_INDEX_URL \".[${PIP_TAG}]\" ; fi && \\\n     pip install --default-timeout=1000 --compile --extra-index-url ${PIP_EXTRA_INDEX_URL} . && \\\n-    if [[ $PY_VERSION==3.11 ]]; then apt-get install --no-install-recommends -y build-essential ; fi && \\\n     # now remove apt packages\n     if [ -n \"${APT_PACKAGES}\" ]; then apt-get remove -y --auto-remove ${APT_PACKAGES} && apt-get autoremove && apt-get clean && rm -rf /var/lib/apt/lists/*; fi && \\\n     rm -rf /tmp/* && rm -rf /jina\n\n\n###\n\n", "completion": "fix: install build essentials before pip install for python 3.11 docker image (#<issue-num>)"}
{"prompt": " file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -45,6 +45,7 @@ RUN cd /tmp/ && \\\n     apt-get install --no-install-recommends -y ${APT_PACKAGES}; fi && \\\n     if [ -n \"${PIP_TAG}\" ]; then pip install --default-timeout=1000 --compile --extra-index-url $PIP_EXTRA_INDEX_URL \".[${PIP_TAG}]\" ; fi && \\\n     pip install --default-timeout=1000 --compile --extra-index-url ${PIP_EXTRA_INDEX_URL} . && \\\n+    if [[ $PY_VERSION==3.11 ]]; then apt-get install --no-install-recommends -y build-essential ; fi && \\\n     # now remove apt packages\n     if [ -n \"${APT_PACKAGES}\" ]; then apt-get remove -y --auto-remove ${APT_PACKAGES} && apt-get autoremove && apt-get clean && rm -rf /var/lib/apt/lists/*; fi && \\\n     rm -rf /tmp/* && rm -rf /jina\n\n---\n file path A: Dockerfiles/pip-perf.Dockerfile | file path B: Dockerfiles/pip-perf.Dockerfile\n\n@@ -5,6 +5,8 @@ FROM python:${PY_VERSION}-slim\n \n RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev net-tools procps htop lsof dnsutils\n \n+RUN if [[ $PY_VERSION==3.11 ]]; then apt-get install --no-install-recommends -y build-essential ; fi\n+\n COPY . /jina/\n \n RUN cd /jina && pip install .\"$PIP_TAG\"\n\n---\n file path A: Dockerfiles/pip.Dockerfile | file path B: Dockerfiles/pip.Dockerfile\n\n@@ -5,6 +5,8 @@ FROM python:${PY_VERSION}-slim\n \n RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev\n \n+RUN if [[ $PY_VERSION==3.11 ]]; then apt-get install --no-install-recommends -y build-essential ; fi\n+\n COPY . /jina/\n \n RUN cd /jina && pip install .\"$PIP_TAG\"\n\n\n###\n\n", "completion": "fix: add gcc-c++ and python devel for python 3.11 (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -167,15 +167,16 @@ jobs:\n       matrix:\n         core: ['', 'true']\n         perf: ['', 'true']\n+        python-env: ['3.7', '3.8', '3.9', '3.10', '3.11']\n         exclude: \n           - core: 'true'\n             perf: 'true'\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.7\n+      - name: Set up Python\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.7\n+          python-version: ${{ matrix.python-env }}\n       - name: Prepare enviroment\n         run: |\n           python -m pip install --upgrade pip\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -399,15 +399,16 @@ jobs:\n       matrix:\n         core: ['', 'true']\n         perf: ['', 'true']\n+        python-env: ['3.7', '3.8', '3.9', '3.10', '3.11']\n         exclude:\n           - core: 'true'\n             perf: 'true'\n     steps:\n       - uses: actions/checkout@v2.5.0\n-      - name: Set up Python 3.7\n+      - name: Set up Python\n         uses: actions/setup-python@v4\n         with:\n-          python-version: 3.7\n+          python-version: ${{ matrix.python-env }}\n       - name: Prepare enviroment\n         run: |\n           python -m pip install --upgrade pip\n\n---\n file path A: setup.py | file path B: setup.py\n\n@@ -149,6 +149,14 @@ if os.environ.get('JINA_PIP_INSTALL_CORE'):\n elif os.environ.get('JINA_PIP_INSTALL_PERF'):\n     final_deps = perf_deps\n \n+if sys.version_info.major == 3 and sys.version_info.minor >= 11:\n+    for dep in list(final_deps):\n+        if dep.startswith('grpcio'):\n+            final_deps.remove(dep)\n+    final_deps.add('grpcio>=1.49.0')\n+    final_deps.add('grpcio-health-checking>=1.49.0')\n+    final_deps.add('grpcio-reflection>=1.49.0')\n+\n setup(\n     name=pkg_name,\n     packages=find_packages(),\n\n\n###\n\n", "completion": "fix: support python 3.11 (#<issue-num>)"}
{"prompt": " file path A: docs/concepts/flow/basics.md | file path B: docs/concepts/flow/basics.md\n\n@@ -18,6 +18,13 @@ f = Flow()\n ```\n ````\n \n+```{important}\n+All arguments received by {class}`~jina.Flow()` API will be propagated to other entities (Gateway, Executor) with the following exceptions:\n+\n+- `uses` and `uses_with` won't be passed to Gateway\n+- `port`, `port_monitoring`, `uses` and `uses_with` won't be passed to Executor\n+```\n+\n `````{tab} YAML\n ```yaml\n jtype: Flow\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -366,6 +366,11 @@ class Flow(\n                 f = Flow.load_config('flow.yml')  # load Flow from YAML config\n                 with f:\n                     f.bock()  # serve Flow\n+            \n+        All arguments received by {class}`~jina.Flow()` API will be propagated to other entities (Gateway, Executor) with the following exceptions:\n+\n+        - `uses` and `uses_with` won't be passed to Gateway\n+        - `port`, `port_monitoring`, `uses` and `uses_with` won't be passed to Executor\n \n         :param asyncio: If set, then the input and output of this Client work in an asynchronous manner.\n         :param host: The host of the Gateway, which the client should connect to, by default it is 0.0.0.0.\n\n\n###\n\n", "completion": "docs: common args inheritence from Flow API (#<issue-num>)"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -119,6 +119,7 @@ __default_gateway__ = 'BaseGateway'\n __default_http_gateway__ = 'HTTPGateway'\n __default_websocket_gateway__ = 'WebSocketGateway'\n __default_grpc_gateway__ = 'GRPCGateway'\n+__default_composite_gateway__ = 'CompositeGateway'\n __default_endpoint__ = '/default'\n __ready_msg__ = 'ready and listening'\n __stop_msg__ = 'terminated'\n\n---\n file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -4,6 +4,7 @@ from argparse import Namespace\n from typing import Dict, List, Optional, Tuple, Union\n \n from jina import (\n+    __default_composite_gateway__,\n     __default_executor__,\n     __default_grpc_gateway__,\n     __default_http_gateway__,\n@@ -80,6 +81,7 @@ class DockerComposeConfig:\n                 __default_http_gateway__,\n                 __default_websocket_gateway__,\n                 __default_grpc_gateway__,\n+                __default_composite_gateway__,\n             ]:\n                 cargs.uses = 'config.yml'\n \n@@ -92,9 +94,7 @@ class DockerComposeConfig:\n \n             protocol = str(non_defaults.get('protocol', ['grpc'])[0]).lower()\n \n-            ports = cargs.port + (\n-                [cargs.port_monitoring] if cargs.monitoring else []\n-            )\n+            ports = cargs.port + ([cargs.port_monitoring] if cargs.monitoring else [])\n \n             envs = [f'JINA_LOG_LEVEL={os.getenv(\"JINA_LOG_LEVEL\", \"INFO\")}']\n             if cargs.env:\n@@ -125,6 +125,7 @@ class DockerComposeConfig:\n                 __default_http_gateway__,\n                 __default_websocket_gateway__,\n                 __default_grpc_gateway__,\n+                __default_composite_gateway__,\n             ]:\n                 image_name = get_image_name(uses)\n \n\n---\n file path A: jina/orchestrate/deployments/config/helper.py | file path B: jina/orchestrate/deployments/config/helper.py\n\n@@ -5,6 +5,7 @@ from hubble.executor.helper import is_valid_docker_uri, parse_hub_uri\n from hubble.executor.hubio import HubIO\n \n from jina import (\n+    __default_composite_gateway__,\n     __default_executor__,\n     __default_grpc_gateway__,\n     __default_http_gateway__,\n@@ -132,6 +133,7 @@ def validate_uses(uses: str):\n             __default_http_gateway__,\n             __default_websocket_gateway__,\n             __default_grpc_gateway__,\n+            __default_composite_gateway__,\n             __default_executor__,\n         ]\n         or uses.startswith('docker://')\n\n---\n file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -3,6 +3,7 @@ from argparse import Namespace\n from typing import Dict, List, Optional, Tuple, Union\n \n from jina import (\n+    __default_composite_gateway__,\n     __default_executor__,\n     __default_grpc_gateway__,\n     __default_http_gateway__,\n@@ -78,6 +79,7 @@ class K8sDeploymentConfig:\n                 __default_http_gateway__,\n                 __default_websocket_gateway__,\n                 __default_grpc_gateway__,\n+                __default_composite_gateway__,\n             ]:\n                 cargs.uses = 'config.yml'\n \n@@ -114,6 +116,7 @@ class K8sDeploymentConfig:\n                 __default_http_gateway__,\n                 __default_websocket_gateway__,\n                 __default_grpc_gateway__,\n+                __default_composite_gateway__,\n             ]:\n                 image_name = get_image_name(uses)\n \n\n---\n file path A: tests/k8s/test_k8s.py | file path B: tests/k8s/test_k8s.py\n\n@@ -1224,18 +1224,18 @@ async def test_flow_with_custom_gateway(logger, docker_images, tmpdir):\n     [['multiprotocol-gateway']],\n     indirect=True,\n )\n-async def test_flow_multiple_protocols_gateway(\n+async def test_flow_multiple_protocols_custom_gateway(\n     logger, docker_images, tmpdir, k8s_cluster\n ):\n     from kubernetes import client\n \n-    namespace = 'flow-multiprotocol-gateway'.lower()\n     api_client = client.ApiClient()\n     core_client = client.CoreV1Api(api_client=api_client)\n     app_client = client.AppsV1Api(api_client=api_client)\n     try:\n         http_port = random_port()\n         grpc_port = random_port()\n+\n         flow = Flow().config_gateway(\n             uses=f'docker://{docker_images[0]}',\n             port=[http_port, grpc_port],\n@@ -1276,8 +1276,83 @@ async def test_flow_multiple_protocols_gateway(\n                 import requests\n \n                 resp = requests.get(f'http://localhost:{http_port}').json()\n-                assert resp['protocol'] == 'http'\n+                assert resp == {'protocol': 'http'}\n+\n+        # test portforwarding the gateway pod and service using grpc\n+        forward_args = [\n+            [gateway_pod_name, grpc_port, grpc_port, namespace],\n+            ['service/gateway-1-grpc', grpc_port, grpc_port, namespace],\n+        ]\n+        for forward in forward_args:\n+            with shell_portforward(k8s_cluster._cluster.kubectl_path, *forward):\n+                grpc_client = Client(protocol='grpc', port=grpc_port, asyncio=True)\n+                async for _ in grpc_client.post('/', inputs=DocumentArray.empty(5)):\n+                    pass\n+                assert AsyncNewLoopRuntime.is_ready(f'localhost:{grpc_port}')\n+    except Exception as exc:\n+        logger.error(f' Exception raised {exc}')\n+        raise exc\n+\n+\n+@pytest.mark.asyncio\n+@pytest.mark.timeout(3600)\n+@pytest.mark.parametrize(\n+    'docker_images',\n+    [['multiprotocol-gateway']],\n+    indirect=True,\n+)\n+async def test_flow_multiple_protocols_built_in(\n+    logger, docker_images, tmpdir, k8s_cluster\n+):\n+    from kubernetes import client\n+\n+    api_client = client.ApiClient()\n+    core_client = client.CoreV1Api(api_client=api_client)\n+    app_client = client.AppsV1Api(api_client=api_client)\n+    try:\n+        http_port = random_port()\n+        grpc_port = random_port()\n+\n+        flow = Flow().config_gateway(\n+            port=[http_port, grpc_port],\n+            protocol=['http', 'grpc'],\n+        )\n+\n+        dump_path = os.path.join(str(tmpdir), 'k8s-flow-multiprotocol-gateway-builtin')\n+        namespace = 'flow-multiprotocol-gateway-builtin'\n+        flow.to_kubernetes_yaml(dump_path, k8s_namespace=namespace)\n+\n+        await create_all_flow_deployments_and_wait_ready(\n+            dump_path,\n+            namespace=namespace,\n+            api_client=api_client,\n+            app_client=app_client,\n+            core_client=core_client,\n+            deployment_replicas_expected={\n+                'gateway': 1,\n+            },\n+            logger=logger,\n+        )\n \n+        gateway_pod_name = (\n+            core_client.list_namespaced_pod(\n+                namespace=namespace, label_selector='app=gateway'\n+            )\n+            .items[0]\n+            .metadata.name\n+        )\n+\n+        # test portforwarding the gateway pod and service using http\n+        forward_args = [\n+            [gateway_pod_name, http_port, http_port, namespace],\n+            ['service/gateway', http_port, http_port, namespace],\n+        ]\n+        for forward in forward_args:\n+            with shell_portforward(k8s_cluster._cluster.kubectl_path, *forward):\n+                import requests\n+\n+                resp = requests.get(f'http://localhost:{http_port}').json()\n+                assert resp == {}\n         # test portforwarding the gateway pod and service using grpc\n         forward_args = [\n             [gateway_pod_name, grpc_port, grpc_port, namespace],\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_docker_compose_pod_config.py | file path B: tests/unit/orchestrate/deployments/config/test_docker_compose_pod_config.py\n\n@@ -367,15 +367,25 @@ def test_worker_services(name: str, shards: str):\n \n \n @pytest.mark.parametrize('deployments_addresses', [None, {'1': 'executor-head:8081'}])\n+@pytest.mark.parametrize(\n+    'port,protocol',\n+    [\n+        (['12345'], None),\n+        (['12345'], ['grpc']),\n+        (['12345', '12344'], ['grpc', 'http']),\n+        (['12345', '12344', '12343'], ['grpc', 'http', 'websocket']),\n+    ],\n+)\n @pytest.mark.parametrize('custom_gateway', ['jinaai/jina:custom-gateway', None])\n-def test_docker_compose_gateway(deployments_addresses, custom_gateway):\n+def test_docker_compose_gateway(deployments_addresses, custom_gateway, port, protocol):\n     if custom_gateway:\n         os.environ['JINA_GATEWAY_IMAGE'] = custom_gateway\n     elif 'JINA_GATEWAY_IMAGE' in os.environ:\n         del os.environ['JINA_GATEWAY_IMAGE']\n-    args = set_gateway_parser().parse_args(\n-        ['--env', 'ENV_VAR:ENV_VALUE', '--port', '32465']\n-    )  # envs are\n+    args_list = ['--env', 'ENV_VAR:ENV_VALUE', '--port', *port]\n+    if protocol:\n+        args_list.extend(['--protocol', *protocol])\n+    args = set_gateway_parser().parse_args(args_list)  # envs are\n     # ignored for gateway\n     deployment_config = DockerComposeConfig(\n         args, deployments_addresses=deployments_addresses\n@@ -388,12 +398,15 @@ def test_docker_compose_gateway(deployments_addresses, custom_gateway):\n         else f'jinaai/jina:{deployment_config.worker_services[0].version}-py38-standard'\n     )\n     assert gateway_config['entrypoint'] == ['jina']\n-    assert gateway_config['ports'] == [f'{args.port[0]}:{args.port[0]}']\n-    assert gateway_config['expose'] == [args.port[0]]\n+    assert gateway_config['ports'] == [f'{_port}:{_port}' for _port in args.port]\n+    assert gateway_config['expose'] == args.port\n     args = gateway_config['command']\n     assert args[0] == 'gateway'\n     assert '--port' in args\n-    assert args[args.index('--port') + 1] == '32465'\n+\n+    for i, _port in enumerate(port):\n+        assert args[args.index('--port') + i + 1] == _port\n+\n     assert '--env' not in args\n     if deployments_addresses is not None:\n         assert '--deployments-addresses' in args\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py | file path B: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py\n\n@@ -276,15 +276,25 @@ def assert_config_map_config(\n \n \n @pytest.mark.parametrize('deployments_addresses', [None, {'1': 'address.svc'}])\n+@pytest.mark.parametrize(\n+    'port,protocol',\n+    [\n+        (['12345'], None),\n+        (['12345'], ['grpc']),\n+        (['12345', '12344'], ['grpc', 'http']),\n+        (['12345', '12344', '12343'], ['grpc', 'http', 'websocket']),\n+    ],\n+)\n @pytest.mark.parametrize('custom_gateway', ['jinaai/jina:custom-gateway', None])\n-def test_k8s_yaml_gateway(deployments_addresses, custom_gateway):\n+def test_k8s_yaml_gateway(deployments_addresses, custom_gateway, port, protocol):\n     if custom_gateway:\n         os.environ['JINA_GATEWAY_IMAGE'] = custom_gateway\n     elif 'JINA_GATEWAY_IMAGE' in os.environ:\n         del os.environ['JINA_GATEWAY_IMAGE']\n-    args = set_gateway_parser().parse_args(\n-        ['--env', 'ENV_VAR:ENV_VALUE', '--port', '32465']\n-    )  # envs are\n+    args_list = ['--env', 'ENV_VAR:ENV_VALUE', '--port', *port]\n+    if protocol:\n+        args_list.extend(['--protocol', *protocol])\n+    args = set_gateway_parser().parse_args(args_list)  # envs are\n     # ignored for gateway\n     deployment_config = K8sDeploymentConfig(\n         args, 'default-namespace', deployments_addresses\n@@ -293,7 +303,7 @@ def test_k8s_yaml_gateway(deployments_addresses, custom_gateway):\n     assert len(yaml_configs) == 1\n     name, configs = yaml_configs[0]\n     assert name == 'gateway'\n-    assert len(configs) == 3  # 3 configs per yaml (configmap, service and deployment)\n+    assert len(configs) == 2 + len(port)  # configmap, deployment and 1 service per port\n     config_map = configs[0]\n     assert_config_map_config(\n         config_map,\n@@ -306,24 +316,31 @@ def test_k8s_yaml_gateway(deployments_addresses, custom_gateway):\n         },\n     )\n \n-    service = configs[1]\n-    assert service['kind'] == 'Service'\n-    assert service['metadata'] == {\n-        'name': 'gateway',\n-        'namespace': 'default-namespace',\n-        'labels': {'app': 'gateway'},\n-    }\n-    spec_service = service['spec']\n-    assert spec_service['type'] == 'ClusterIP'\n-    assert len(spec_service['ports']) == 1\n-    port = spec_service['ports'][0]\n-    assert port['name'] == 'port'\n-    assert port['protocol'] == 'TCP'\n-    assert port['port'] == 32465\n-    assert port['targetPort'] == 32465\n-    assert spec_service['selector'] == {'app': 'gateway'}\n-\n-    deployment = configs[2]\n+    for i, (expected_port, service) in enumerate(zip(port, configs[1 : 1 + len(port)])):\n+        assert service['kind'] == 'Service'\n+        service_gateway_name = (\n+            'gateway'\n+            if i == 0\n+            else f'gateway-{i}-{protocol[i] if protocol else \"grpc\"}'\n+        )\n+        assert service['metadata'] == {\n+            'name': service_gateway_name,\n+            'namespace': 'default-namespace',\n+            'labels': {'app': service_gateway_name},\n+        }\n+        spec_service = service['spec']\n+        assert spec_service['type'] == 'ClusterIP'\n+        assert len(spec_service['ports']) == 1\n+        actual_port = spec_service['ports'][0]\n+        assert actual_port['name'] == 'port'\n+        assert actual_port['protocol'] == 'TCP'\n+        assert actual_port['port'] == int(expected_port)\n+        assert actual_port['targetPort'] == int(expected_port)\n+        assert spec_service['selector'] == {'app': 'gateway'}\n+\n+        assert spec_service['selector'] == {'app': 'gateway'}\n+\n+    deployment = configs[1 + len(port)]\n     assert deployment['kind'] == 'Deployment'\n     assert deployment['metadata'] == {\n         'name': 'gateway',\n@@ -364,7 +381,8 @@ def test_k8s_yaml_gateway(deployments_addresses, custom_gateway):\n     assert '--k8s-namespace' in args\n     assert args[args.index('--k8s-namespace') + 1] == 'default-namespace'\n     assert '--port' in args\n-    assert args[args.index('--port') + 1] == '32465'\n+    for i, _port in enumerate(port):\n+        assert args[args.index('--port') + i + 1] == _port\n     assert '--env' not in args\n     if deployments_addresses is not None:\n         assert '--deployments-addresses' in args\n\n\n###\n\n", "completion": "fix: support composite gateway for k8s export (#<issue-num>)"}
{"prompt": " file path A: docs/concepts/client/index.md | file path B: docs/concepts/client/index.md\n\n@@ -1,5 +1,5 @@\n (client)=\n-# Client\n+# {fas}`laptop-code` Client\n {class}`~jina.Client` enables you to send Documents to a running {class}`~jina.Flow`. Same as Gateway, Client supports four networking protocols: **gRPC**, **HTTP**, **WebSocket** and **GraphQL** with/without TLS.\n \n You may have observed two styles of using a Client in the docs:\n\n---\n file path A: docs/concepts/executor/index.md | file path B: docs/concepts/executor/index.md\n\n@@ -1,5 +1,5 @@\n (executor-cookbook)=\n-# Executor\n+# {fas}`gears` Executor\n \n {class}`~jina.Executor` is a self-contained component and performs a group of tasks on a `DocumentArray`. \n \n\n---\n file path A: docs/concepts/flow/index.md | file path B: docs/concepts/flow/index.md\n\n@@ -1,5 +1,5 @@\n (flow-cookbook)=\n-# Flow\n+# {fas}`network-wired` Flow\n \n A {class}`~jina.Flow` orchestrates {class}`~jina.Executor`s into a processing pipeline to accomplish a task.\n Documents \"flow\" through the pipeline and are processed by Executors.\n\n---\n file path A: docs/concepts/gateway/index.md | file path B: docs/concepts/gateway/index.md\n\n@@ -1,6 +1,6 @@\n (flow)=\n \n-# Gateway\n+# {fas}`door-open` Gateway\n \n Every {class}`~jina.Flow` has a Gateway component that receives requests over the network, allowing clients to send data\n to the Flow for processing.\n\n---\n file path A: docs/concepts/preliminaries/index.md | file path B: docs/concepts/preliminaries/index.md\n\n@@ -1,5 +1,5 @@\n (architecture-overview)=\n-# Preliminaries\n+# {fas}`egg` Preliminaries\n \n This chapter introduces the basic terminology you will encounter in the docs. But first, look at the code below:\n \n\n---\n file path A: docs/envs/index.md | file path B: docs/envs/index.md\n\n@@ -1,5 +1,5 @@\n (jina-env-vars)=\n-# Environment Variables\n+# {octicon}`list-unordered` Environment Variables\n \n Jina uses a number of environment variables to determine different behaviours. To see all supported environment variables and their current values, run\n \n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -1,4 +1,4 @@\n-# {octicon}`milestone` Create First Project\n+# {fas}`folder-plus` Create First Project\n \n Let's build a toy application with Jina. To start, use Jina CLI to make a new project:\n \n\n---\n file path A: docs/get-started/install.md | file path B: docs/get-started/install.md\n\n@@ -1,5 +1,5 @@\n (install)=\n-# Install\n+# {octicon}`desktop-download` Install\n \n Jina comes with multiple installation options, enabling different feature sets.\n Standard install enables all major features of Jina and is the recommended installation for most users.\n\n---\n file path A: docs/get-started/install/docker.md | file path B: docs/get-started/install/docker.md\n\n@@ -1,4 +1,4 @@\n-# Docker image\n+# Via Docker Image\n \n Our universal Docker image is ready-to-use on linux/amd64 and linux/arm64. The Docker image name always starts with `jinaai/jina` followed by a tag composed of three parts:\n \n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -150,13 +150,13 @@ Jina AI Cloud is the MLOps platform for hosting Jina projects.\n \n get-started/install/index\n get-started/create-app\n+concepts/preliminaries/index\n ```\n \n ```{toctree}\n :caption: Concepts\n :hidden:\n \n-concepts/preliminaries/index\n concepts/executor/index\n concepts/flow/index\n concepts/gateway/index\n@@ -184,9 +184,9 @@ jina-ai-cloud/index\n api-rst\n cli/index\n yaml-spec\n-proto/docs\n envs/index\n telemetry\n+proto/docs\n ```\n \n ```{toctree}\n\n---\n file path A: docs/telemetry.md | file path B: docs/telemetry.md\n\n@@ -1,4 +1,4 @@\n-# Telemetry\n+# {fas}`tower-cell` Telemetry\n \n ```{warning}\n To opt out from telemetry, set the `JINA_OPTOUT_TELEMETRY=1` as an environment variable.\n\n\n###\n\n", "completion": "docs: add icons to top-level chapters"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.12.1'\n+__version__ = '3.13.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: update jina version (#<issue-num>)"}
{"prompt": " file path A: jina/serve/gateway.py | file path B: jina/serve/gateway.py\n\n@@ -1,7 +1,6 @@\n import abc\n-import argparse\n from types import SimpleNamespace\n-from typing import TYPE_CHECKING, Dict, Optional, Sequence\n+from typing import Dict, Optional\n \n from jina.jaml import JAMLCompatible\n from jina.logging.logger import JinaLogger\n@@ -9,15 +8,6 @@ from jina.serve.helper import store_init_kwargs, wrap_func\n \n __all__ = ['BaseGateway']\n \n-if TYPE_CHECKING:  # pragma: no cover\n-    from grpc.aio._interceptor import ClientInterceptor, ServerInterceptor\n-    from opentelemetry import trace\n-    from opentelemetry.instrumentation.grpc._client import (\n-        OpenTelemetryClientInterceptor,\n-    )\n-    from opentelemetry.metrics import Meter\n-    from prometheus_client import CollectorRegistry\n-\n \n class GatewayType(type(JAMLCompatible), type):\n     \"\"\"The class of Gateway type, which is the metaclass of :class:`BaseGateway`.\"\"\"\n\n---\n file path A: jina/serve/runtimes/gateway/grpc/gateway.py | file path B: jina/serve/runtimes/gateway/grpc/gateway.py\n\n@@ -1,4 +1,4 @@\n-from typing import Optional\n+from typing import Optional, AsyncIterator, TYPE_CHECKING\n \n import grpc\n from grpc_health.v1 import health, health_pb2, health_pb2_grpc\n@@ -9,17 +9,20 @@ from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.gateway import BaseGateway\n from jina.serve.runtimes.helper import _get_grpc_server_options\n from jina.types.request.status import StatusMessage\n+from jina.types.request.data import DataRequest\n \n+if TYPE_CHECKING:  # pragma: no cover\n+    from jina.types.request import Request\n \n class GRPCGateway(BaseGateway):\n     \"\"\"GRPC Gateway implementation\"\"\"\n \n     def __init__(\n-        self,\n-        grpc_server_options: Optional[dict] = None,\n-        ssl_keyfile: Optional[str] = None,\n-        ssl_certfile: Optional[str] = None,\n-        **kwargs,\n+            self,\n+            grpc_server_options: Optional[dict] = None,\n+            ssl_keyfile: Optional[str] = None,\n+            ssl_certfile: Optional[str] = None,\n+            **kwargs,\n     ):\n         \"\"\"Initialize the gateway\n         :param grpc_server_options: Dictionary of kwargs arguments that will be passed to the grpc server as options when starting the server, example : {'grpc.max_send_message_length': -1}\n@@ -43,11 +46,11 @@ class GRPCGateway(BaseGateway):\n         )\n \n         jina_pb2_grpc.add_JinaRPCServicer_to_server(\n-            self.streamer._streamer, self.server\n+            self, self.server\n         )\n \n         jina_pb2_grpc.add_JinaSingleDataRequestRPCServicer_to_server(\n-            self.streamer._streamer, self.server\n+            self, self.server\n         )\n \n         jina_pb2_grpc.add_JinaGatewayDryRunRPCServicer_to_server(self, self.server)\n@@ -83,7 +86,7 @@ class GRPCGateway(BaseGateway):\n             )\n             self.server.add_secure_port(bind_addr, server_credentials)\n         elif (\n-            self.ssl_keyfile != self.ssl_certfile\n+                self.ssl_keyfile != self.ssl_certfile\n         ):  # if we have only ssl_keyfile and not ssl_certfile or vice versa\n             raise ValueError(\n                 f\"you can't pass a ssl_keyfile without a ssl_certfile and vice versa\"\n@@ -121,7 +124,7 @@ class GRPCGateway(BaseGateway):\n         da = DocumentArray([Document()])\n         try:\n             async for _ in self.streamer.stream_docs(\n-                docs=da, exec_endpoint=__dry_run_endpoint__, request_size=1\n+                    docs=da, exec_endpoint=__dry_run_endpoint__, request_size=1\n             ):\n                 pass\n             status_message = StatusMessage()\n@@ -147,3 +150,28 @@ class GRPCGateway(BaseGateway):\n         for k, v in env_info.items():\n             info_proto.envs[k] = str(v)\n         return info_proto\n+\n+    async def stream(self, request_iterator, context=None, *args, **kwargs) -> AsyncIterator['Request']:\n+        \"\"\"\n+        stream requests from client iterator and stream responses back.\n+\n+        :param request_iterator: iterator of requests\n+        :param context: context of the grpc call\n+        :param args: positional arguments\n+        :param kwargs: keyword arguments\n+        :yield: responses to the request after streaming to Executors in Flow\n+        \"\"\"\n+        async for resp in self.streamer.stream(request_iterator=request_iterator, context=context, *args, **kwargs):\n+            yield resp\n+\n+    async def process_single_data(\n+            self, request: DataRequest, context=None\n+    ) -> DataRequest:\n+        \"\"\"Implements request and response handling of a single DataRequest\n+        :param request: DataRequest from Client\n+        :param context: grpc context\n+        :return: response DataRequest\n+        \"\"\"\n+        return await self.streamer.process_single_data(request, context)\n+\n+    Call = stream\n\n\n###\n\n", "completion": "refactor: make server link to gateway so that custom gateway can inherit (#<issue-num>)"}
{"prompt": " file path A: docs/concepts/executor/dynamic-batching.md | file path B: docs/concepts/executor/dynamic-batching.md\n\n@@ -34,20 +34,22 @@ batching enabled.\n ---\n emphasize-lines: 12\n ---\n-from jina import requests, dynamic_batching, Executor, DocumentArray, Flow\n+from jina import Executor, requests, dynamic_batching, Flow, DocumentArray, Document\n+import numpy as np\n+import torch\n+\n \n class MyExecutor(Executor):\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n         \n         # initialize model\n-        import torch\n         self.model = torch.nn.Linear(in_features=128, out_features=128)\n     \n     @requests(on='/bar')\n     @dynamic_batching(preferred_batch_size=10, timeout=200)\n-    def embed(self, docs: DocumentArray):\n-        docs.embeddings = self.model(docs.tensors)\n+    def embed(self, docs: DocumentArray, **kwargs):\n+        docs.embeddings = self.model(torch.Tensor(docs.tensors))\n \n flow = Flow().add(uses=MyExecutor)\n ```\n\n\n###\n\n", "completion": "docs: fix dynamic batching example (#<issue-num>)"}
{"prompt": " file path A: docs/correct_some_requirements.sh | file path B: docs/correct_some_requirements.sh\n\n@@ -1,7 +1,11 @@\n #!/bin/bash\n \n grep -rl 'opentelemetry-exporter-prometheus' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-prometheus==1.12.0/opentelemetry-exporter-prometheus==1.12.0rc1/g'\n-grep -rl 'opentelemetry-exporter-otlp-proto-grpc' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-otlp-proto-grpc==1.13.0/opentelemetry-exporter-otlp-proto-grpc==1.12.0/g'\n-grep -rl 'opentelemetry-sdk' extra-requirements.txt | xargs sed -i 's/opentelemetry-sdk>=1.12.0/opentelemetry-sdk>=1.14.0/g'\n+grep -rl 'opentelemetry-exporter-otlp-proto-grpc' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-otlp-proto-grpc==1.13.0/opentelemetry-exporter-otlp-proto-grpc==1.13.0/g'\n+grep -rl 'opentelemetry-sdk' extra-requirements.txt | xargs sed -i 's/opentelemetry-sdk==1.12.0/opentelemetry-sdk==1.14.0/g'\n grep -rl 'opentelemetry-semantic-conventions' extra-requirements.txt | xargs sed -i '/opentelemetry-semantic-conventions/d'\n+grep -rl 'opentelemetry-exporter-otlp' extra-requirements.txt | xargs sed -i '/opentelemetry-exporter-otlp/d'\n+grep -rl 'opentelemetry-api' extra-requirements.txt | xargs sed -i '/opentelemetry-api/d'\n grep -rl 'pyyaml' extra-requirements.txt | xargs sed -i 's/pyyaml==5.3.1/pyyaml==5.4.1/g'\n+\n+cat extra-requirements.txt\n\n\n###\n\n", "completion": "ci: fix old docs build opentelemetry sdk pin (#<issue-num>)"}
{"prompt": " file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -38,6 +38,7 @@ class RequestStreamer:\n         request_handler: Callable[['Request'], Tuple[Awaitable['Request'], Optional[Awaitable['Request']]]],\n         result_handler: Callable[['Request'], Optional['Request']],\n         prefetch: int = 0,\n+        iterate_sync_in_thread: bool = True,\n         end_of_iter_handler: Optional[Callable[[], None]] = None,\n         logger: Optional['JinaLogger'] = None,\n         **logger_kwargs,\n@@ -47,6 +48,7 @@ class RequestStreamer:\n         :param result_handler: The callable responsible for handling the response.\n         :param end_of_iter_handler: Optional callable to handle the end of iteration if some special action needs to be taken.\n         :param prefetch: How many Requests are processed from the Client at the same time.\n+        :param iterate_sync_in_thread: if True, blocking iterators will call __next__ in a Thread.\n         :param logger: Optional logger that can be used for logging\n         :param logger_kwargs: Extra keyword arguments that may be passed to the internal logger constructor if none is provided\n \n@@ -56,6 +58,7 @@ class RequestStreamer:\n         self._request_handler = request_handler\n         self._result_handler = result_handler\n         self._end_of_iter_handler = end_of_iter_handler\n+        self._iterate_sync_in_thread = iterate_sync_in_thread\n         self.total_num_floating_tasks_alive = 0\n \n     async def stream(\n@@ -164,6 +167,7 @@ class RequestStreamer:\n                 iterator=request_iterator,\n                 request_counter=requests_to_handle,\n                 prefetch=self._prefetch,\n+                iterate_sync_in_thread=self._iterate_sync_in_thread\n             ):\n                 num_reqs += 1\n                 requests_to_handle.count += 1\n\n---\n file path A: jina/serve/stream/helper.py | file path B: jina/serve/stream/helper.py\n\n@@ -29,20 +29,23 @@ class AsyncRequestsIterator:\n     \"\"\"Iterator to allow async iteration of blocking/non-blocking iterator from the Client\"\"\"\n \n     def __init__(\n-        self,\n-        iterator: Union[Iterator, AsyncIterator],\n-        request_counter: Optional[_RequestsCounter] = None,\n-        prefetch: int = 0,\n+            self,\n+            iterator: Union[Iterator, AsyncIterator],\n+            request_counter: Optional[_RequestsCounter] = None,\n+            prefetch: int = 0,\n+            iterate_sync_in_thread: bool = True,\n     ) -> None:\n         \"\"\"Async request iterator\n \n         :param iterator: request iterator\n         :param request_counter: counter of the numbers of request being handled at a given moment\n         :param prefetch: The max amount of requests to be handled at a given moment (0 disables feature)\n+        :param iterate_sync_in_thread: if True, blocking iterators will call __next__ in a Thread.\n         \"\"\"\n         self.iterator = iterator\n         self._request_counter = request_counter\n         self._prefetch = prefetch\n+        self._iterate_sync_in_thread = iterate_sync_in_thread\n \n     def iterator__next__(self):\n         \"\"\"\n@@ -61,14 +64,24 @@ class AsyncRequestsIterator:\n \n     async def __anext__(self):\n         if isinstance(self.iterator, Iterator):\n-\n             \"\"\"\n             An `Iterator` indicates \"blocking\" code, which might block all tasks in the event loop.\n             Hence we iterate in the default executor provided by asyncio.\n             \"\"\"\n-            request = await get_or_reuse_loop().run_in_executor(\n-                None, self.iterator__next__\n-            )\n+\n+            if not self._iterate_sync_in_thread:\n+                async def _get_next():\n+                    try:\n+                        req = self.iterator.__next__()\n+                    except StopIteration:\n+                        req = None\n+                    return req\n+\n+                request = await asyncio.create_task(_get_next())\n+            else:\n+                request = await get_or_reuse_loop().run_in_executor(\n+                    None, self.iterator__next__\n+                )\n \n             \"\"\"\n             `iterator.__next__` can be executed directly and that'd raise `StopIteration` in the executor,\n\n---\n file path A: tests/unit/serve/stream/test_stream.py | file path B: tests/unit/serve/stream/test_stream.py\n\n@@ -10,7 +10,7 @@ from jina.types.request.data import DataRequest\n \n \n class RequestStreamerWrapper:\n-    def __init__(self, num_requests, prefetch):\n+    def __init__(self, num_requests, prefetch, iterate_sync_in_thread):\n         self.num_requests = num_requests\n         self.requests_handled = []\n         self.results_handled = []\n@@ -24,6 +24,7 @@ class RequestStreamerWrapper:\n             result_handler=self.result_handle_fn,\n             end_of_iter_handler=self.end_of_iter_fn,\n             prefetch=getattr(args, 'prefetch', 0),\n+            iterate_sync_in_thread=iterate_sync_in_thread\n         )\n \n     def request_handler_fn(self, request):\n@@ -76,11 +77,12 @@ class RequestStreamerWrapper:\n @pytest.mark.parametrize('num_requests', [1, 5, 13])\n @pytest.mark.parametrize('async_iterator', [False, True])\n @pytest.mark.parametrize('results_in_order', [False, True])\n+@pytest.mark.parametrize('iterate_sync_in_thread', [False, True])\n async def test_request_streamer(\n-    prefetch, num_requests, async_iterator, results_in_order\n+    prefetch, num_requests, async_iterator, results_in_order, iterate_sync_in_thread\n ):\n \n-    test_streamer = RequestStreamerWrapper(num_requests, prefetch)\n+    test_streamer = RequestStreamerWrapper(num_requests, prefetch, iterate_sync_in_thread)\n     streamer = test_streamer.streamer\n \n     it = (\n@@ -110,8 +112,9 @@ async def test_request_streamer(\n \n @pytest.mark.asyncio\n @pytest.mark.parametrize('num_requests', [1, 5, 13])\n-async def test_request_streamer_process_single_data(monkeypatch, num_requests):\n-    test_streamer = RequestStreamerWrapper(num_requests, 0)\n+@pytest.mark.parametrize('iterate_sync_in_thread', [False, True])\n+async def test_request_streamer_process_single_data(monkeypatch, num_requests, iterate_sync_in_thread):\n+    test_streamer = RequestStreamerWrapper(num_requests, 0, iterate_sync_in_thread)\n     streamer = test_streamer.streamer\n \n     def end_of_iter_fn():\n\n\n###\n\n", "completion": "refactor: avoid run in executor creating threads (#<issue-num>)"}
{"prompt": " file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -7,6 +7,7 @@ from typing import (\n     Iterator,\n     Optional,\n     Union,\n+    Tuple\n )\n \n from aiostream.aiter_utils import anext\n@@ -34,7 +35,7 @@ class RequestStreamer:\n \n     def __init__(\n         self,\n-        request_handler: Callable[['Request'], 'Awaitable[Request]'],\n+        request_handler: Callable[['Request'], Tuple[Awaitable['Request'], Optional[Awaitable['Request']]]],\n         result_handler: Callable[['Request'], Optional['Request']],\n         prefetch: int = 0,\n         end_of_iter_handler: Optional[Callable[[], None]] = None,\n\n\n###\n\n", "completion": "chore: change type hint (#<issue-num>)"}
{"prompt": " file path A: docs/redirects.txt | file path B: docs/redirects.txt\n\n@@ -50,3 +50,5 @@ fundamentals/jcloud/yaml-spec.md concepts/jcloud/yaml-spec.md\n fundamentals/clean-code.md concepts/preliminaries/clean-code.md\n fundamentals/preliminaries/coding-in-python-yaml.md concepts/preliminaries/coding-in-python-yaml.md\n fundamentals/architecture-overview.md concepts/preliminaries/index.md\n+fundamentals/executor/hub.md concepts/executor/hub\n+fundamentals/flow.md concepts/flow\n\n\n###\n\n", "completion": "fix: jina ai cloud redirects (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/helper.py | file path B: jina/orchestrate/deployments/config/helper.py\n\n@@ -1,7 +1,7 @@\n import os\n from typing import Dict\n \n-from hubble.executor.helper import parse_hub_uri\n+from hubble.executor.helper import is_valid_docker_uri, parse_hub_uri\n from hubble.executor.hubio import HubIO\n \n from jina import (\n@@ -139,8 +139,6 @@ def validate_uses(uses: str):\n         return True\n \n     try:\n-        scheme, _, _, _ = parse_hub_uri(uses)\n-        if scheme in {'jinahub+docker', 'jinahub+sandbox'}:\n-            return True\n+        return is_valid_docker_uri(uses)\n     except ValueError:\n         return False\n\n---\n file path A: tests/integration/hub_usage/test_hub_usage.py | file path B: tests/integration/hub_usage/test_hub_usage.py\n\n@@ -62,7 +62,10 @@ def local_hub_executor(tmpdir):\n     )\n \n \n-def test_use_from_local_hub_deployment_level(mocker, monkeypatch, local_hub_executor):\n+@pytest.mark.parametrize('uses', ['jinahub://hello', 'jinaai://jina-ai/hello'])\n+def test_use_from_local_hub_deployment_level(\n+    mocker, monkeypatch, local_hub_executor, uses\n+):\n     from hubble.executor.hubio import HubExecutor, HubIO\n \n     mock = mocker.Mock()\n@@ -91,12 +94,13 @@ def test_use_from_local_hub_deployment_level(mocker, monkeypatch, local_hub_exec\n         )\n \n     monkeypatch.setattr(HubIO, 'fetch_meta', _mock_fetch)\n-    a = set_deployment_parser().parse_args(['--uses', 'jinahub://hello'])\n+    a = set_deployment_parser().parse_args(['--uses', uses])\n     with Deployment(a):\n         pass\n \n \n-def test_use_from_local_hub_flow_level(mocker, monkeypatch, local_hub_executor):\n+@pytest.mark.parametrize('uses', ['jinahub://hello', 'jinaai://jina-ai/hello'])\n+def test_use_from_local_hub_flow_level(mocker, monkeypatch, local_hub_executor, uses):\n     from hubble.executor.hubio import HubExecutor, HubIO\n \n     mock = mocker.Mock()\n@@ -126,5 +130,5 @@ def test_use_from_local_hub_flow_level(mocker, monkeypatch, local_hub_executor):\n \n     monkeypatch.setattr(HubIO, 'fetch_meta', _mock_fetch)\n \n-    with Flow().add(uses='jinahub://hello', install_requirements=True):\n+    with Flow().add(uses=uses, install_requirements=True):\n         pass\n\n---\n file path A: tests/integration/issues/github_4488/test_deployment_protocol.py | file path B: tests/integration/issues/github_4488/test_deployment_protocol.py\n\n@@ -32,13 +32,17 @@ def key_pem(cert_prefix):\n \n @pytest.mark.parametrize('protocol', ['http', 'websocket', 'grpc'])\n @pytest.mark.parametrize('tls', [True, False])\n-def test_deployment_protocol(protocol, tls, cert_pem, key_pem):\n+@pytest.mark.parametrize(\n+    'uses',\n+    ['jinaai+sandbox://jina-ai/DummyHubExecutor'],\n+)\n+def test_deployment_protocol(protocol, tls, cert_pem, key_pem, uses):\n     cert = cert_pem if tls else None\n     key = key_pem if tls else None\n     f = (\n         Flow(protocol=protocol, ssl_certfile=cert, ssl_keyfile=key)\n         .add(uses=MyExec)\n-        .add(uses='jinahub+sandbox://DummyHubExecutor')\n+        .add(uses=uses)\n     )\n     with f:\n         for node, v in f._deployment_nodes.items():\n\n---\n file path A: tests/integration/sandbox/test_sandbox.py | file path B: tests/integration/sandbox/test_sandbox.py\n\n@@ -4,8 +4,11 @@ from jina import Document, Flow\n \n \n @pytest.mark.parametrize('endpoint', ['foo', 'bar'])\n-def test_sandbox(endpoint):\n-    with Flow().add(uses='jinahub+sandbox://Hello') as f:\n+@pytest.mark.parametrize(\n+    'uses', ['jinaai+sandbox://jina-ai/Hello']\n+)\n+def test_sandbox(endpoint, uses):\n+    with Flow().add(uses=uses) as f:\n         da = f.post(\n             endpoint,\n             [\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_docker_compose_pod_config.py | file path B: tests/unit/orchestrate/deployments/config/test_docker_compose_pod_config.py\n\n@@ -29,7 +29,13 @@ def namespace_equal(\n \n @pytest.mark.parametrize('shards', [1, 5])\n @pytest.mark.parametrize('replicas', [1, 5])\n-@pytest.mark.parametrize('uses_before', [None, 'jinahub+docker://HubBeforeExecutor'])\n+@pytest.mark.parametrize(\n+    'uses_before',\n+    [\n+        None,\n+        'jinaai+docker://jina-ai/HubBeforeExecutor',\n+    ],\n+)\n @pytest.mark.parametrize('uses_after', [None, 'docker://docker_after_image:latest'])\n @pytest.mark.parametrize('uses_with', ['{\"paramkey\": \"paramvalue\"}', None])\n @pytest.mark.parametrize('uses_metas', ['{\"workspace\": \"workspacevalue\"}', None])\n@@ -399,10 +405,26 @@ def test_docker_compose_gateway(deployments_addresses, custom_gateway):\n @pytest.mark.parametrize('shards', [3, 1])\n @pytest.mark.parametrize('replicas', [3, 1])\n @pytest.mark.parametrize(\n-    'uses', ['jinahub+docker://HubExecutor', 'docker://docker_image:latest']\n+    'uses',\n+    [\n+        'docker://docker_image:latest',\n+        'jinaai+docker://jina-ai/HubExecutor',\n+    ],\n+)\n+@pytest.mark.parametrize(\n+    'uses_before',\n+    [\n+        None,\n+        'jinaai+docker://jina-ai/HubBeforeExecutor',\n+    ],\n+)\n+@pytest.mark.parametrize(\n+    'uses_after',\n+    [\n+        None,\n+        'jinaai+docker://jina-ai/HubAfterExecutor',\n+    ],\n )\n-@pytest.mark.parametrize('uses_before', [None, 'jinahub+docker://HubBeforeExecutor'])\n-@pytest.mark.parametrize('uses_after', [None, 'jinahub+docker://HubAfterExecutor'])\n @pytest.mark.parametrize('uses_with', ['{\"paramkey\": \"paramvalue\"}', None])\n @pytest.mark.parametrize('uses_metas', ['{\"workspace\": \"workspacevalue\"}', None])\n @pytest.mark.parametrize('polling', ['ANY', 'ALL'])\n@@ -533,7 +555,10 @@ def test_docker_compose_yaml_regular_deployment(\n         if uses_before is not None:\n             uses_before_name, uses_before_config = yaml_configs[1]\n             assert uses_before_name == 'executor-uses-before'\n-            assert uses_before_config['image'] == 'jinahub/HubBeforeExecutor'\n+            assert uses_before_config['image'] in {\n+                'jinahub/HubBeforeExecutor',\n+                'jinahub/jina-ai/HubBeforeExecutor',\n+            }\n             assert uses_before_config['entrypoint'] == ['jina']\n             uses_before_args = uses_before_config['command']\n             assert uses_before_args[0] == 'executor'\n@@ -554,7 +579,10 @@ def test_docker_compose_yaml_regular_deployment(\n                 yaml_configs[1] if uses_before is None else yaml_configs[2]\n             )\n             assert uses_after_name == 'executor-uses-after'\n-            assert uses_after_config['image'] == 'jinahub/HubAfterExecutor'\n+            assert uses_after_config['image'] in {\n+                'jinahub/HubAfterExecutor',\n+                'jinahub/jina-ai/HubAfterExecutor',\n+            }\n             assert uses_after_config['entrypoint'] == ['jina']\n             uses_after_args = uses_after_config['command']\n             assert uses_after_args[0] == 'executor'\n@@ -586,11 +614,11 @@ def test_docker_compose_yaml_regular_deployment(\n                 expected_name += f'-rep-{i_replica}'\n                 expected_arg_name += f'/rep-{i_replica}'\n             assert replica_name == expected_name\n-            assert (\n-                replica_config['image'] == 'docker_image:latest'\n-                if uses == 'docker_image:latest'\n-                else 'jinahub/HubExecutor'\n-            )\n+            assert replica_config['image'] in {\n+                'docker_image:latest',\n+                'jinahub/HubExecutor',\n+                'jinahub/jina-ai/HubExecutor',\n+            }\n             assert replica_config['entrypoint'] == ['jina']\n             replica_args = replica_config['command']\n             assert replica_args[0] == 'executor'\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_helper.py | file path B: tests/unit/orchestrate/deployments/config/test_helper.py\n\n@@ -42,7 +42,10 @@ def test_to_compatible_name():\n     assert to_compatible_name('executor/hey-ha_HO') == 'executor-hey-ha-ho'\n \n \n-def test_get_image_name(mocker, monkeypatch):\n+@pytest.mark.parametrize(\n+    'uses', ['jinaai://jina-ai/DummyExecutor']\n+)\n+def test_get_image_name(mocker, monkeypatch, uses):\n     mock = mocker.Mock()\n \n     def _mock_fetch(\n@@ -71,11 +74,9 @@ def test_get_image_name(mocker, monkeypatch):\n \n     monkeypatch.setattr(HubIO, 'fetch_meta', _mock_fetch)\n \n-    uses = 'jinahub://DummyExecutor'\n-\n     image_name = get_image_name(uses)\n \n-    assert image_name == 'jinahub/DummyExecutor'\n+    assert image_name in {'jinahub/DummyExecutor', 'jinahub/jina-ai/DummyExecutor'}\n \n     _, mock_kwargs = mock.call_args_list[0]\n     assert mock_kwargs['rebuild_image'] is True  # default value must be True\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py | file path B: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py\n\n@@ -28,7 +28,13 @@ def namespace_equal(\n \n \n @pytest.mark.parametrize('shards', [1, 5])\n-@pytest.mark.parametrize('uses_before', [None, 'jinahub+docker://HubBeforeExecutor'])\n+@pytest.mark.parametrize(\n+    'uses_before',\n+    [\n+        None,\n+        'jinaai+docker://jina-ai/HubBeforeExecutor',\n+    ],\n+)\n @pytest.mark.parametrize('uses_after', [None, 'docker://docker_after_image:latest'])\n @pytest.mark.parametrize('uses_with', ['{\"paramkey\": \"paramvalue\"}', None])\n @pytest.mark.parametrize('uses_metas', ['{\"workspace\": \"workspacevalue\"}', None])\n@@ -376,10 +382,26 @@ def assert_port_config(port_dict: Dict, name: str, port: int):\n \n @pytest.mark.parametrize('shards', [3, 1])\n @pytest.mark.parametrize(\n-    'uses', ['jinahub+docker://HubExecutor', 'docker://docker_image:latest']\n+    'uses',\n+    [\n+        'docker://docker_image:latest',\n+        'jinaai+docker://jina-ai/HubExecutor',\n+    ],\n+)\n+@pytest.mark.parametrize(\n+    'uses_before',\n+    [\n+        None,\n+        'jinaai+docker://jina-ai/HubBeforeExecutor',\n+    ],\n+)\n+@pytest.mark.parametrize(\n+    'uses_after',\n+    [\n+        None,\n+        'jinaai+docker://jina-ai/HubAfterExecutor',\n+    ],\n )\n-@pytest.mark.parametrize('uses_before', [None, 'jinahub+docker://HubBeforeExecutor'])\n-@pytest.mark.parametrize('uses_after', [None, 'jinahub+docker://HubAfterExecutor'])\n @pytest.mark.parametrize('uses_with', ['{\"paramkey\": \"paramvalue\"}', None])\n @pytest.mark.parametrize('uses_metas', ['{\"workspace\": \"workspacevalue\"}', None])\n @pytest.mark.parametrize('polling', ['ANY', 'ALL'])\n@@ -580,7 +602,10 @@ def test_k8s_yaml_regular_deployment(\n         if uses_before is not None:\n             uses_before_container = head_containers[1]\n             assert uses_before_container['name'] == 'uses-before'\n-            assert uses_before_container['image'] == 'jinahub/HubBeforeExecutor'\n+            assert uses_before_container['image'] in {\n+                'jinahub/HubBeforeExecutor',\n+                'jinahub/jina-ai/HubBeforeExecutor',\n+            }\n             assert uses_before_container['imagePullPolicy'] == 'IfNotPresent'\n             assert uses_before_container['command'] == ['jina']\n             uses_before_runtime_container_args = uses_before_container['args']\n@@ -614,7 +639,10 @@ def test_k8s_yaml_regular_deployment(\n         if uses_after is not None:\n             uses_after_container = head_containers[-1]\n             assert uses_after_container['name'] == 'uses-after'\n-            assert uses_after_container['image'] == 'jinahub/HubAfterExecutor'\n+            assert uses_after_container['image'] in {\n+                'jinahub/HubAfterExecutor',\n+                'jinahub/jina-ai/HubAfterExecutor',\n+            }\n             assert uses_after_container['imagePullPolicy'] == 'IfNotPresent'\n             assert uses_after_container['command'] == ['jina']\n             uses_after_runtime_container_args = uses_after_container['args']\n@@ -708,6 +736,7 @@ def test_k8s_yaml_regular_deployment(\n         assert shard_container['name'] == 'executor'\n         assert shard_container['image'] in {\n             'jinahub/HubExecutor',\n+            'jinahub/jina-ai/HubExecutor',\n             'docker_image:latest',\n         }\n         assert shard_container['imagePullPolicy'] == 'IfNotPresent'\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py\n\n@@ -391,10 +391,12 @@ def test_disable_auto_volume(tmpdir):\n     assert 'volumes' not in services['executor0']\n \n \n-def test_flow_to_docker_compose_sandbox(tmpdir):\n-    flow = Flow(name='test-flow', port=8080).add(\n-        uses=f'jinahub+sandbox://DummyHubExecutor'\n-    )\n+@pytest.mark.parametrize(\n+    'uses',\n+    ['jinaai+sandbox://jina-ai/DummyHubExecutor'],\n+)\n+def test_flow_to_docker_compose_sandbox(tmpdir, uses):\n+    flow = Flow(name='test-flow', port=8080).add(uses=uses)\n \n     dump_path = os.path.join(str(tmpdir), 'test_flow_docker_compose.yml')\n \n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py\n\n@@ -575,11 +575,15 @@ def test_raise_exception_invalid_executor(tmpdir):\n         f.to_kubernetes_yaml(str(tmpdir))\n \n \n-def test_flow_to_k8s_yaml_sandbox(tmpdir):\n-\n-    flow = Flow(name='test-flow', port=8080).add(\n-        uses=f'jinahub+sandbox://DummyHubExecutor'\n-    )\n+@pytest.mark.parametrize(\n+    'uses',\n+    [\n+        f'jinaai+sandbox://jina-ai/DummyHubExecutor',\n+    ],\n+)\n+def test_flow_to_k8s_yaml_sandbox(tmpdir, uses):\n+\n+    flow = Flow(name='test-flow', port=8080).add(uses=uses)\n \n     dump_path = os.path.join(str(tmpdir), 'test_flow_k8s')\n \n\n---\n file path A: tests/unit/orchestrate/pods/test_pod_factory.py | file path B: tests/unit/orchestrate/pods/test_pod_factory.py\n\n@@ -1,10 +1,14 @@\n+import pytest\n from hubble.executor.hubio import HubIO\n \n from jina.orchestrate.pods.factory import PodFactory\n from jina.parsers import set_pod_parser\n \n \n-def test_container_pod(mocker, monkeypatch):\n+@pytest.mark.parametrize(\n+    'uses', ['jinaai+docker://jina-ai/DummyExecutor']\n+)\n+def test_container_pod(mocker, monkeypatch, uses):\n     mock = mocker.Mock()\n \n     def _mock_pull(self):\n@@ -12,7 +16,7 @@ def test_container_pod(mocker, monkeypatch):\n \n     monkeypatch.setattr(HubIO, 'pull', _mock_pull)\n \n-    args = set_pod_parser().parse_args(['--uses', 'jinahub+docker://DummyExecutor'])\n+    args = set_pod_parser().parse_args(['--uses', uses])\n     pod = PodFactory.build_pod(args)\n     assert pod.args.uses == 'docker://jinahub/dummy_executor'\n     assert pod.name == 'ContainerPod'\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -74,10 +74,11 @@ def served_exec(request: FixtureRequest, exposed_port):\n     t.join()\n \n \n-def test_executor_load_from_hub():\n-    exec = Executor.from_hub(\n-        'jinahub://DummyHubExecutor', uses_metas={'name': 'hello123'}\n-    )\n+@pytest.mark.parametrize(\n+    'uses', ['jinaai://jina-ai/DummyHubExecutor']\n+)\n+def test_executor_load_from_hub(uses):\n+    exec = Executor.from_hub(uses, uses_metas={'name': 'hello123'})\n     da = DocumentArray([Document()])\n     exec.foo(da)\n     assert da.texts == ['hello']\n@@ -438,11 +439,15 @@ def test_default_workspace(tmpdir):\n     'exec_type',\n     [Executor.StandaloneExecutorType.EXTERNAL, Executor.StandaloneExecutorType.SHARED],\n )\n-def test_to_k8s_yaml(tmpdir, exec_type):\n+@pytest.mark.parametrize(\n+    'uses',\n+    ['jinahub+docker://DummyHubExecutor', 'jinaai+docker://jina-ai/DummyHubExecutor'],\n+)\n+def test_to_k8s_yaml(tmpdir, exec_type, uses):\n     Executor.to_kubernetes_yaml(\n         output_base_path=tmpdir,\n         port_expose=2020,\n-        uses='jinahub+docker://DummyHubExecutor',\n+        uses=uses,\n         executor_type=exec_type,\n     )\n \n@@ -480,12 +485,16 @@ def test_to_k8s_yaml(tmpdir, exec_type):\n     'exec_type',\n     [Executor.StandaloneExecutorType.EXTERNAL, Executor.StandaloneExecutorType.SHARED],\n )\n-def test_to_docker_compose_yaml(tmpdir, exec_type):\n+@pytest.mark.parametrize(\n+    'uses',\n+    ['jinaai+docker://jina-ai/DummyHubExecutor'],\n+)\n+def test_to_docker_compose_yaml(tmpdir, exec_type, uses):\n     compose_file = os.path.join(tmpdir, 'compose.yml')\n     Executor.to_docker_compose_yaml(\n         output_path=compose_file,\n         port_expose=2020,\n-        uses='jinahub+docker://DummyHubExecutor',\n+        uses=uses,\n         executor_type=exec_type,\n     )\n \n\n---\n file path A: tests/unit/test_cli.py | file path B: tests/unit/test_cli.py\n\n@@ -40,11 +40,14 @@ def test_cli_help():\n     subprocess.check_call(['jina', 'help', 'deployment'])\n \n \n-def test_cli_hub():\n+@pytest.mark.parametrize(\n+    'uses', ['jinaai://jina-ai/DummyHubExecutor']\n+)\n+def test_cli_hub(uses):\n     subprocess.check_call(['jina', 'hub', '--help'])\n     for cmd in ['new', 'status', 'pull', 'push']:\n         subprocess.check_call(['jina', 'hub', cmd, '--help'])\n-    subprocess.check_call(['jina', 'hub', 'pull', 'jinahub://DummyHubExecutor'])\n+    subprocess.check_call(['jina', 'hub', 'pull', uses])\n \n \n def test_cli_warn_unknown_args():\n\n\n###\n\n", "completion": "feat: support jinaai executor scheme (#<issue-num>)"}
{"prompt": " file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -10,6 +10,7 @@ from jina.clients.helper import callback_exec\n from jina.excepts import BadClientInput, BadServerFlow, InternalNetworkError\n from jina.logging.profile import ProgressBar\n from jina.proto import jina_pb2, jina_pb2_grpc\n+from jina.serve.helper import extract_trailing_metadata\n from jina.serve.networking import GrpcConnectionPool\n from jina.serve.stream.helper import AsyncRequestsIterator\n \n@@ -226,7 +227,10 @@ class GRPCBaseClient(BaseClient):\n                     except (grpc.aio._call.AioRpcError, InternalNetworkError) as err:\n                         my_code = err.code()\n                         my_details = err.details()\n+                        trailing_metadata = extract_trailing_metadata(err)\n                         msg = f'gRPC error: {my_code} {my_details}'\n+                        if trailing_metadata:\n+                            msg = f'gRPC error: {my_code} {my_details}\\n{trailing_metadata}'\n \n                         if my_code == grpc.StatusCode.UNAVAILABLE:\n                             self.logger.error(\n\n---\n file path A: jina/excepts.py | file path B: jina/excepts.py\n\n@@ -3,6 +3,8 @@ from typing import Set, Union\n \n import grpc.aio\n \n+from jina.serve.helper import extract_trailing_metadata\n+\n \n class BaseJinaException(BaseException):\n     \"\"\"A base class for all exceptions raised by Jina\"\"\"\n@@ -135,4 +137,11 @@ class InternalNetworkError(grpc.aio.AioRpcError, BaseJinaException):\n         \"\"\"\n         :return: details of this exception\n         \"\"\"\n-        return self._details if self._details else self.og_exception.details()\n+        if self._details:\n+            trailing_metadata = extract_trailing_metadata(self.og_exception)\n+            if trailing_metadata:\n+                return f'{self._details}\\n{trailing_metadata}'\n+            else:\n+                return self._details\n+\n+        return self.og_exception.details()\n\n---\n file path A: jina/serve/helper.py | file path B: jina/serve/helper.py\n\n@@ -3,6 +3,8 @@ import inspect\n import typing\n from typing import Optional, Union\n \n+import grpc\n+\n from jina.helper import convert_tuple_to_list\n \n if typing.TYPE_CHECKING:\n@@ -72,3 +74,29 @@ def store_init_kwargs(\n         return f\n \n     return arg_wrapper\n+\n+\n+def extract_trailing_metadata(error: grpc.aio.AioRpcError) -> Optional[str]:\n+    '''Return formatted string of the trailing metadata if exists otherwise return None\n+    :param error: AioRpcError\n+    :return: string of Metadata or None\n+    '''\n+    if type(error) == grpc.aio.AioRpcError:\n+        trailing_metadata = error.trailing_metadata()\n+        if trailing_metadata and len(trailing_metadata):\n+            return f'trailing_metadata={trailing_metadata}'\n+\n+    return None\n+\n+\n+def format_grpc_error(error: grpc.aio.AioRpcError) -> str:\n+    '''Adds grpc context trainling metadata if available\n+    :param error: AioRpcError\n+    :return: formatted error\n+    '''\n+    default_string = str(error)\n+    trailing_metadata = extract_trailing_metadata(error)\n+    if trailing_metadata:\n+        return f'{default_string}\\n{trailing_metadata}'\n+\n+    return default_string\n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -18,6 +18,7 @@ from jina.excepts import EstablishGrpcConnectionError, InternalNetworkError\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n from jina.proto import jina_pb2, jina_pb2_grpc\n+from jina.serve.helper import format_grpc_error\n from jina.serve.instrumentation import MetricsTimer\n from jina.types.request import Request\n from jina.types.request.data import DataRequest\n@@ -969,7 +970,7 @@ class GrpcConnectionPool:\n         # requests usually gets cancelled when the server shuts down\n         # retries for cancelled requests will hit another replica in K8s\n         self._logger.debug(\n-            f'GRPC call to {current_deployment} errored, getting error {error} for the {retry_i + 1}th time.'\n+            f'GRPC call to {current_deployment} errored, with error {format_grpc_error(error)} and for the {retry_i + 1}th time.'\n         )\n         if (\n             error.code() != grpc.StatusCode.UNAVAILABLE\n@@ -1003,7 +1004,7 @@ class GrpcConnectionPool:\n             )\n         else:\n             self._logger.debug(\n-                f'GRPC call to deployment {current_deployment} failed with code {error.code()}, retry attempt {retry_i + 1}/{total_num_tries - 1}.'\n+                f'GRPC call to deployment {current_deployment} failed with error {format_grpc_error(error)}, for retry attempt {retry_i + 1}/{total_num_tries - 1}.'\n                 f' Trying next replica, if available.'\n             )\n             return None\n\n---\n file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -87,6 +87,7 @@ class RequestStreamer:\n             ):  # inside GrpcGateway we can handle the error directly here through the grpc context\n                 context.set_details(err.details())\n                 context.set_code(err.code())\n+                context.set_trailing_metadata(err.trailing_metadata())\n                 self.logger.error(\n                     f'Error while getting responses from deployments: {err.details()}'\n                 )\n\n---\n file path A: tests/unit/exceptions/test_exceptions.py | file path B: tests/unit/exceptions/test_exceptions.py\n\n@@ -1,6 +1,7 @@\n import grpc.aio\n import pytest\n from grpc import StatusCode\n+from grpc.aio import Metadata\n \n from jina.excepts import BaseJinaException, InternalNetworkError\n \n@@ -30,3 +31,21 @@ def test_ine_details(aio_rpc_error):\n     err = InternalNetworkError(aio_rpc_error, details='I am not a normal grpc error!')\n     assert err.details() == 'I am not a normal grpc error!'\n     assert str(err) == 'I am not a normal grpc error!'\n+\n+\n+@pytest.mark.parametrize('metadata', [None, Metadata(('content-length', '0'))])\n+def test_ine_trailing_metadata(metadata):\n+    aio_rpc_error = grpc.aio.AioRpcError(\n+        StatusCode.OK,\n+        None,\n+        trailing_metadata=metadata,\n+        details='I am a grpc error',\n+    )\n+    err = InternalNetworkError(aio_rpc_error)\n+    if metadata:\n+        assert (\n+            str(err)\n+            == 'I am a grpc error\\ntrailing_metadata=Metadata(((\\'content-length\\', \\'0\\'),))'\n+        )\n+    else:\n+        assert str(err) == 'I am a grpc error'\n\n\n###\n\n", "completion": "feat: add grpc trailing metadata when logging grpc error (#<issue-num>)"}
{"prompt": " file path A: docs/get-started/install/apple-silicon-m1-m2.md | file path B: docs/get-started/install/apple-silicon-m1-m2.md\n\n@@ -88,6 +88,12 @@ Now we can install Jina via `pip`. Ensure you use the correct `pip`:\n \n `grpcio` requires building the wheels, it will take some time.\n \n+Note: If the previous step fails, adding the environment variables below might solve the problem:\n+\n+```bash\n+export GRPC_PYTHON_BUILD_SYSTEM_OPENSSL=1\n+export GRPC_PYTHON_BUILD_SYSTEM_ZLIB=1\n+```\n \n After all the dependencies are installed, you can run Jina CLI and check the system information.\n \n\n\n###\n\n", "completion": "docs: m1 fix (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.26.10:   core\n+jina-hubble-sdk>=0.26.12:   core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.26.10:   core\n+jina-hubble-sdk>=0.26.12:   core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n\n\n###\n\n", "completion": "chore: bump hubble sdk (#<issue-num>)"}
{"prompt": " file path A: tests/unit/serve/instrumentation/test_networking_histograms.py | file path B: tests/unit/serve/instrumentation/test_networking_histograms.py\n\n@@ -1,12 +1,13 @@\n+from typing import Dict, List, Tuple\n+\n import pytest\n-from typing import Tuple, List, Dict\n+from opentelemetry.metrics import Meter\n from opentelemetry.sdk.metrics import MeterProvider\n from opentelemetry.sdk.metrics.export import (\n+    HistogramDataPoint,\n     InMemoryMetricReader,\n     Metric,\n-    HistogramDataPoint,\n )\n-from opentelemetry.metrics import Meter\n \n from jina.serve.networking import _NetworkingHistograms\n \n@@ -59,7 +60,7 @@ def test_recording_methods(metrics_setup: Tuple[InMemoryMetricReader, Meter]):\n         metric_reader.get_metrics_data().resource_metrics[0].scope_metrics[0].metrics\n     )\n     data_points_sums: Dict[str, HistogramDataPoint] = {\n-        hist.name: next(hist.data.data_points).sum for hist in histogram_metrics\n+        hist.name: next(iter(hist.data.data_points)).sum for hist in histogram_metrics\n     }\n     assert data_points_sums == {\n         'request_time': 10,\n\n\n###\n\n", "completion": "test: fix histograms monitoring test (#<issue-num>)"}
{"prompt": " file path A: docs/redirects.txt | file path B: docs/redirects.txt\n\n@@ -0,0 +1,52 @@\n+fundamentals/client/instrumenting-client.md concepts/client/instrumentation.md\n+fundamentals/client/client.md concepts/client/index.md\n+fundamentals/client/index.md concepts/client/index.md\n+fundamentals/client/send-graphql-mutation.md concepts/client/send-graphql-mutation.md\n+fundamentals/client/send-parameters.md concepts/client/send-parameters.md\n+fundamentals/client/send-receive-data.md concepts/client/send-receive-data.md\n+fundamentals/client/third-party-clients.md concepts/client/third-party-clients.md\n+fundamentals/executor/executor-run.md concepts/executor/run.md\n+fundamentals/executor/executor-files.md concepts/executor/file-structure.md\n+fundamentals/executor/executor-methods.md concepts/executor/add-endpoints.md\n+fundamentals/executor/executor-api.md concepts/executor/basics.md\n+fundamentals/executor/containerize-executor.md concepts/executor/containerize.md\n+fundamentals/executor/health-check.md concepts/executor/health-check.md\n+fundamentals/executor/hot-reload.md concepts/executor/hot-reload.md\n+fundamentals/executor/hub/create-hub-executor.md concepts/executor/hub/create-hub-executor.md\n+fundamentals/executor/hub/debug-executor.md concepts/executor/hub/debug-executor.md\n+fundamentals/executor/hub/hub-portal.md concepts/executor/hub/hub-portal.md\n+fundamentals/executor/hub/index.md concepts/executor/hub/index.md\n+fundamentals/executor/hub/push-executor.md concepts/executor/hub/push-executor.md\n+fundamentals/executor/hub/sandbox.md concepts/executor/hub/sandbox.md\n+fundamentals/executor/hub/use-hub-executor.md concepts/executor/hub/use-hub-executor.md\n+fundamentals/executor/index.md concepts/executor/index.md\n+fundamentals/executor/instrumenting-executor.md concepts/executor/instrumentation.md\n+fundamentals/executor/executor-serve.md concepts/executor/serve.md\n+fundamentals/executor/yaml-spec.md concepts/executor/yaml-spec.md\n+how-to/flow-switch.md concepts/flow/add-conditioning.md\n+fundamentals/flow/add-executors.md concepts/flow/add-executors.md\n+fundamentals/flow/topologies.md concepts/flow/add-executors.md\n+how-to/external-executor.md concepts/flow/add-executors.md\n+fundamentals/flow/create-flow.md concepts/flow/basics.md\n+how-to/google-colab.md concepts/flow/basics.md\n+fundamentals/flow/executor-args.md concepts/flow/executor-args.md\n+fundamentals/flow/flow-args.md concepts/flow/flow-args.md\n+fundamentals/flow/gateway-args.md concepts/flow/gateway-args.md\n+fundamentals/flow/when-things-go-wrong.md concepts/flow/handle-exceptions.md\n+fundamentals/flow/health-check.md concepts/flow/health-check.md\n+fundamentals/flow/index.md concepts/flow/index.md\n+fundamentals/flow/instrumenting-flow.md concepts/flow/instrumentation.md\n+fundamentals/flow/health-check.md concepts/flow/readiness.md\n+how-to/scale-out.md concepts/flow/scale-out.md\n+fundamentals/flow/remarks.md concepts/flow/troubleshooting-on-multiprocess.md\n+fundamentals/flow/yaml-spec.md concepts/flow/yaml-spec.md\n+fundamentals/gateway/custom-gateway.md concepts/gateway/customization.md\n+fundamentals/gateway/health-check.md concepts/gateway/health-check.md\n+fundamentals/gateway/index.md concepts/gateway/index.md\n+fundamentals/gateway/rate-limit.md concepts/gateway/rate-limit.md\n+fundamentals/gateway/yaml-spec.md concepts/gateway/yaml-spec.md\n+fundamentals/jcloud/index.md concepts/jcloud/index.md\n+fundamentals/jcloud/yaml-spec.md concepts/jcloud/yaml-spec.md\n+fundamentals/clean-code.md concepts/preliminaries/clean-code.md\n+fundamentals/preliminaries/coding-in-python-yaml.md concepts/preliminaries/coding-in-python-yaml.md\n+fundamentals/architecture-overview.md concepts/preliminaries/index.md\n\n\n###\n\n", "completion": "docs: add files under fundamentals to redirects (#<issue-num>)"}
{"prompt": " file path A: docs/concepts/jcloud/deploy.png | file path B: docs/concepts/jcloud/deploy.png\n\nBinary files a/docs/concepts/jcloud/deploy.png and /dev/null differ\n\n---\n file path A: docs/concepts/jcloud/external-executor.png | file path B: docs/concepts/jcloud/external-executor.png\n\nBinary files a/docs/concepts/jcloud/external-executor.png and /dev/null differ\n\n---\n file path A: docs/concepts/jcloud/external-executors-multiple.png | file path B: docs/concepts/jcloud/external-executors-multiple.png\n\nBinary files a/docs/concepts/jcloud/external-executors-multiple.png and /dev/null differ\n\n---\n file path A: docs/concepts/jcloud/img/deploy.png | file path B: docs/concepts/jcloud/img/deploy.png\n\nBinary files /dev/null and b/docs/concepts/jcloud/img/deploy.png differ\n\n---\n file path A: docs/concepts/jcloud/img/expose-executor.png | file path B: docs/concepts/jcloud/img/expose-executor.png\n\nBinary files /dev/null and b/docs/concepts/jcloud/img/expose-executor.png differ\n\n---\n file path A: docs/concepts/jcloud/img/gateway-and-executors.png | file path B: docs/concepts/jcloud/img/gateway-and-executors.png\n\nBinary files /dev/null and b/docs/concepts/jcloud/img/gateway-and-executors.png differ\n\n---\n file path A: docs/concepts/jcloud/img/list.png | file path B: docs/concepts/jcloud/img/list.png\n\nBinary files /dev/null and b/docs/concepts/jcloud/img/list.png differ\n\n---\n file path A: docs/concepts/jcloud/img/list_all.png | file path B: docs/concepts/jcloud/img/list_all.png\n\nBinary files /dev/null and b/docs/concepts/jcloud/img/list_all.png differ\n\n---\n file path A: docs/concepts/jcloud/img/list_deleted.png | file path B: docs/concepts/jcloud/img/list_deleted.png\n\nBinary files /dev/null and b/docs/concepts/jcloud/img/list_deleted.png differ\n\n---\n file path A: docs/concepts/jcloud/monitoring.png | file path B: docs/concepts/jcloud/img/monitoring.png\n\n\n---\n file path A: docs/concepts/jcloud/img/status.png | file path B: docs/concepts/jcloud/img/status.png\n\nBinary files /dev/null and b/docs/concepts/jcloud/img/status.png differ\n\n---\n file path A: docs/concepts/jcloud/index.md | file path B: docs/concepts/jcloud/index.md\n\n@@ -82,17 +82,16 @@ jina flow --uses flow.yml\n ```\n ````\n \n-\n #### Project folder\n \n ````{tip}\n The best practice of creating a JCloud project is to use:\n \n-```\n+```bash\n jc new\n ```\n-\n This ensures the correct project structure accepted by JCloud.\n+\n ````\n \n Just like a regular Python project, you can have sub-folders of Executor implementations and a `flow.yml` on the top-level to connect all Executors together.\n@@ -124,61 +123,23 @@ jc deploy hello\n \n The Flow is successfully deployed when you see:\n \n-```{figure} deploy.png\n+```{figure} img/deploy.png\n :width: 70%\n ```\n+---\n \n-You will get a Flow ID, say `173503c192`. This ID is required to manage, view logs and remove the Flow.\n+You will get a Flow ID, say `merry-magpie-82b9c0897f`. This ID is required to manage, view logs and remove the Flow.\n \n As this Flow is deployed with the default gRPC gateway (feel free to change it to `http` or `websocket`), you can use `jina.Client` to access it:\n \n ```python\n from jina import Client, Document\n \n-c = Client(host='https://173503c192.wolf.jina.ai')\n-print(c.post('/', Document(text='hello')))\n-```\n-\n-### View logs\n-\n-To watch the logs in real time:\n-\n-```bash\n-jc logs 173503c192\n-```\n-\n-You can also stream logs for a particular Executor by passing its name:\n-\n-```bash\n-jc logs 173503c192 --executor sentencizer\n-```\n-\n-### Remove Flows\n-\n-You can remove a single Flow, multiple Flows or even all Flows by passing different identifiers.\n-\n-To remove a single Flow:\n-\n-```bash\n-jc remove 173503c192\n-```\n-\n-To remove multiple Flows:\n-\n-```bash\n-jc remove 173503c192 887f6313e5 ddb8a2c4ef\n-```\n-\n-To remove all Flows:\n-\n-```bash\n-jc remove all\n-```\n-\n-By default, removing multiple or all Flows is an interactive process where you must give confirmation before each Flow is deleted. To make it non-interactive, set the below environment variable before running the command:\n-\n-```bash\n-export JCLOUD_NO_INTERACTIVE=1\n+print(\n+    Client(host='grpcs://merry-magpie-82b9c0897f.wolf.jina.ai').post(\n+        on='/', inputs=Document(text='hello')\n+    )\n+)\n ```\n \n (jcloud-flow-status)=\n@@ -186,10 +147,10 @@ export JCLOUD_NO_INTERACTIVE=1\n \n To get the status of a Flow:\n ```bash\n-jc status 15937a10bd\n+jc status merry-magpie-82b9c0897f\n ```\n \n-```{figure} status.png\n+```{figure} img/status.png\n :width: 70%\n ```\n \n@@ -197,76 +158,73 @@ jc status 15937a10bd\n \n Basic monitoring is provided to Flows deployed on Jina AI Cloud.\n \n-To access the [Grafana](https://grafana.com/)-powered dashboard, first get {ref}`the status of the Flow<jcloud-flow-status>`. The `dashboards` link is displayed at the bottom of the pane. Visit the URL to find basic metrics like 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n+To access the [Grafana](https://grafana.com/)-powered dashboard, first get {ref}`the status of the Flow<jcloud-flow-status>`. The `Grafana Dashboard` link is displayed at the bottom of the pane. Visit the URL to find basic metrics like 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n \n-```{figure} monitoring.png\n-:width: 70%\n+```{figure} img/monitoring.png\n+:width: 80%\n ```\n \n ### List Flows\n \n-To list all of your \"ALIVE\" Flows:\n+To list all of your \"Serving\" Flows:\n \n ```bash\n jc list\n ```\n \n-```{figure} list.png\n-:width: 70%\n+```{figure} img/list.png\n+:width: 90%\n ```\n \n-You can also filter your Flows by passing a status:\n+You can also filter your Flows by passing a phase:\n \n ```bash\n-jc list --status FAILED\n+jc list --phase Deleted\n ```\n \n \n-```{figure} list_failed.png\n-:width: 70%\n+```{figure} img/list_deleted.png\n+:width: 90%\n ```\n \n Or see all Flows:\n \n ```bash\n-jc list --status ALL\n+jc list --phase all\n ```\n \n-```{figure} list_all.png\n-:width: 70%\n+```{figure} img/list_all.png\n+:width: 90%\n ```\n \n-### Pass environment variables\n+### Remove Flows\n \n-#### Single YAML\n+You can remove a single Flow, multiple Flows or even all Flows by passing different identifiers.\n+\n+To remove a single Flow:\n \n ```bash\n-jc deploy flow.yml --env-file flow.env\n+jc remove merry-magpie-82b9c0897f\n ```\n \n-#### Project folder\n+To remove multiple Flows:\n \n-- You can include your environment variables in the `.env` file in the local project and Jina AI Cloud manages them.\n-- You can optionally pass a `custom.env`.\n-  ```bash\n-  jc deploy ./hello --env-file ./hello/custom.env\n-  ```\n-  \n-## Troubleshooting\n+```bash\n+jc remove merry-magpie-82b9c0897f wondrous-kiwi-b02db6a066\n+```\n \n-If your deployment failed, enable verbose logging and redeploy it. You can add `--loglevel DEBUG` _before_ each CLI subcommand:\n+To remove all Flows:\n \n ```bash\n-jc --loglevel DEBUG deploy flow.yml\n+jc remove all\n ```\n \n-Alternatively, you can configure it by using environment variable `JCLOUD_LOGLEVEL`:\n+By default, removing multiple or all Flows is an interactive process where you must give confirmation before each Flow is deleted. To make it non-interactive, set the below environment variable before running the command:\n \n ```bash\n-JCLOUD_LOGLEVEL=DEBUG jc deploy flow.yml\n+export JCLOUD_NO_INTERACTIVE=1\n ```\n \n-If you don't see any obvious errors, please raise an issue in [the JCloud repository](https://github.com/jina-ai/jcloud/issues/new/choose).\n \n ## Restrictions\n \n\n---\n file path A: docs/concepts/jcloud/list.png | file path B: docs/concepts/jcloud/list.png\n\nBinary files a/docs/concepts/jcloud/list.png and /dev/null differ\n\n---\n file path A: docs/concepts/jcloud/list_all.png | file path B: docs/concepts/jcloud/list_all.png\n\nBinary files a/docs/concepts/jcloud/list_all.png and /dev/null differ\n\n---\n file path A: docs/concepts/jcloud/list_failed.png | file path B: docs/concepts/jcloud/list_failed.png\n\nBinary files a/docs/concepts/jcloud/list_failed.png and /dev/null differ\n\n---\n file path A: docs/concepts/jcloud/status.png | file path B: docs/concepts/jcloud/status.png\n\nBinary files a/docs/concepts/jcloud/status.png and /dev/null differ\n\n---\n file path A: docs/concepts/jcloud/yaml-spec.md | file path B: docs/concepts/jcloud/yaml-spec.md\n\n@@ -44,7 +44,10 @@ JCloud offers the general Intel Xeon processor (Skylake 8175M or Cascade Lake 82\n Maximum of 16 cores is allowed per Executor.\n ```\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 5-7\n+---\n jtype: Flow\n executors:\n   - name: executor1\n@@ -71,7 +74,10 @@ When using GPU resources, it may take a few extra minutes before all Executors a\n An Executor using a `shared` GPU shares this GPU with up to four other Executors.\n This enables time-slicing, which allows workloads that land on oversubscribed GPUs to interleave with one another.\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 5-7\n+---\n jtype: Flow\n executors:\n   - name: executor1\n@@ -89,7 +95,10 @@ The tradeoffs with a `shared` GPU are increased latency, jitter, and potential o\n \n Using a dedicated GPU is the default way to provision GPU for an Executor. This automatically creates nodes or assigns the Executor to land on a GPU node. In this case, the Executor owns the whole GPU. You can assign between 1 and 4 GPUs.\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 5-7\n+---\n jtype: Flow\n executors:\n   - name: executor1\n@@ -103,13 +112,17 @@ executors:\n \n For cost optimization, JCloud tries to deploy all Executors on `spot` capacity. This is ideal for stateless Executors, which can withstand interruptions and restarts. It is recommended to use `on-demand` capacity for stateful Executors (e.g. indexers) however.\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 5-7\n+---\n jtype: Flow\n executors:\n   - name: executor1\n     uses: jinaai+docker://<username>/Executor1\n     jcloud:\n-      capacity: on-demand\n+      resources:\n+        capacity: on-demand\n ```\n \n ### Memory\n@@ -120,7 +133,10 @@ By default, `100M` of RAM is allocated to each Executor. You can use the `memory\n Maximum of 16G RAM is allowed per Executor.\n ```\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 5-7\n+---\n jtype: Flow\n executors:\n   - name: executor1\n@@ -137,15 +153,7 @@ JCloud supports two kinds of storage types: [efs](https://aws.amazon.com/efs/) (\n \n ````{hint}\n \n-By default, we attach an `efs` to all Executors in a Flow. The benefits of doing so are:\n-\n-- It can grow dynamically, so you don't need to shrink/grow volumes as and when necessary.\n-- All Executors in the Flow can share a disk.\n-- The same disk can also be shared with another Flow by passing a workspace-id while deploying a Flow.\n-\n-```bash\n-jc deploy flow.yml --workspace-id <prev-flow-id>\n-```\n+By default, we attach an `efs` to all Executors in a Flow. This lets the `efs` resize dynamically, so you don't need to shrink/grow volumes manually.\n \n If your Executor needs high IO, you can use `ebs` instead. Please note that:\n \n@@ -154,7 +162,10 @@ If your Executor needs high IO, you can use `ebs` instead. Please note that:\n \n ````\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 5-9,12,15\n+---\n jtype: Flow\n executors:\n   - name: executor1\n@@ -198,7 +209,7 @@ For more information about the Knative autoscaling configurations, please visit\n ```\n \n \n-### Scale-out manually\n+### Autoscaling with custom args\n \n If `jinaai+serverless://` doesn't meet your requirements, you can further customize autoscaling configurations by using the `autoscale` argument on a per-Executor basis in the Flow YAML, such as:\n \n@@ -242,12 +253,15 @@ The JCloud gateway is different from Jina's gateway. In JCloud, a gateway works\n \n ### Set timeout\n \n-By default, the JCloud gateway will close connections that have been idle for over 600 seconds. If you want longer a connection timeout threshold, you can change the `timeout` parameter under `gateway`.\n+By default, the JCloud gateway will close connections that have been idle for over 600 seconds. If you want a longer connection timeout threshold, change the `timeout` parameter under `gateway.jcloud`.\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 2-4\n+---\n jtype: Flow\n-jcloud:\n-  gateway:\n+gateway:\n+  jcloud:\n     timeout: 600\n executors:\n   - name: executor1\n@@ -256,15 +270,15 @@ executors:\n \n ### Control gateway resources\n \n-If you'd like to customize the gateway's CPU or memory, you can specify the `memory` and/or `cpu` argument under `jcloud.gateway.resources`:\n+To customize the gateway's CPU or memory, specify the `memory` and/or `cpu` arguments under `gateway.jcloud.resources`:\n \n ```{code-block} yaml\n ---\n-emphasize-lines: 3-7\n+emphasize-lines: 2-6\n ---\n jtype: Flow\n-jcloud:\n-  gateway:\n+gateway:\n+  jcloud:\n     resources:\n       memory: 800M\n       cpu: 0.4\n@@ -273,40 +287,47 @@ executors:\n     uses: jinaai+docker://<username>/Encoder\n ```\n \n-### Disable gateway\n+## Expose Executors\n \n-A Flow deployment without a gateway is often used for {ref}`external-executors`, which can be shared over different Flows. You can disable a gateway by setting `expose_gateway: false`:\n+A Flow deployment without a Gateway is often used for {ref}`external-executors`, which can be shared between different Flows. You can expose an Executor by setting `expose: true` (and un-expose the Gateway by setting `expose: false`):\n \n ```{code-block} yaml\n ---\n-emphasize-lines: 3\n+emphasize-lines: 2-4, 8-9\n ---\n jtype: Flow\n-jcloud:\n-  expose_gateway: false\n+gateway:\n+  jcloud:\n+    expose: false       # don't expose the Gateway\n executors:\n   - name: custom\n     uses: jinaai+docker://<username>/CustomExecutor\n+    jcloud:\n+      expose: true    # expose the Executor\n ```\n \n-```{figure} external-executor.png\n+```{figure} img/expose-executor.png\n :width: 70%\n ```\n \n-You can also deploy and expose multiple external Executors:\n+You can expose the Gateway along with Executors:\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 2-4,8-9\n+---\n jtype: Flow\n-jcloud:\n-  expose_gateway: false\n+gateway:\n+  jcloud:\n+    expose: true\n executors:\n   - name: custom1\n     uses: jinaai+docker://<username>/CustomExecutor1\n-  - name: custom2\n-    uses: jinaai+docker://<username>/CustomExecutor2\n+    jcloud:\n+      expose: true    # expose the Executor\n ```\n \n-```{figure} external-executors-multiple.png\n+```{figure} img/gateway-and-executors.png\n :width: 70%\n ```\n \n@@ -316,10 +337,13 @@ executors:\n \n To control Jina's version while deploying a Flow to `jcloud`, you can pass the `version` argument in the Flow YAML:\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 2-3\n+---\n jtype: Flow\n jcloud:\n-  version: 3.4.11\n+  version: 3.10.0\n executors:\n   - name: executor1\n     uses: jinaai+docker://<username>/Executor1\n@@ -329,7 +353,10 @@ executors:\n \n You can use `labels` (as key-value pairs) to attach metadata to your Flows:\n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 2-5\n+---\n jtype: Flow\n jcloud:\n   labels: \n@@ -348,5 +375,4 @@ Keys in `labels` have the following restrictions:\n   - The following keys are skipped if passed in the Flow YAML.\n     - `user`\n     - `jina`-version\n-    - `retention`-days\n ```\n\n\n###\n\n", "completion": "docs(jcloud): adapt to new api (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -73,9 +73,12 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, InstrumentationMixin, AB\n             metrics_exporter_host=self.args.metrics_exporter_host,\n             metrics_exporter_port=self.args.metrics_exporter_port,\n         )\n-        send_telemetry_event(event='start', obj=self, entity_id=self._entity_id)\n         self._start_time = time.time()\n         self._loop.run_until_complete(self.async_setup())\n+        self._send_telemetry_event()\n+\n+    def _send_telemetry_event(self):\n+        send_telemetry_event(event='start', obj=self, entity_id=self._entity_id)\n \n     def run_forever(self):\n         \"\"\"\n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -7,7 +7,7 @@ from typing import TYPE_CHECKING, Optional, Union\n from jina import __default_host__\n from jina.enums import GatewayProtocolType\n from jina.excepts import PortAlreadyUsed\n-from jina.helper import is_port_free\n+from jina.helper import is_port_free, send_telemetry_event\n from jina.parsers.helper import _update_gateway_args\n from jina.serve.gateway import BaseGateway\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n@@ -105,6 +105,21 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n \n         await self.gateway.setup_server()\n \n+    def _send_telemetry_event(self):\n+        is_custom_gateway = self.gateway.__class__ not in [\n+            CompositeGateway,\n+            GRPCGateway,\n+            HTTPGateway,\n+            WebSocketGateway,\n+        ]\n+        send_telemetry_event(\n+            event='start',\n+            obj=self,\n+            entity_id=self._entity_id,\n+            is_custom_gateway=is_custom_gateway,\n+            protocol=self.args.protocol,\n+        )\n+\n     async def _wait_for_cancel(self):\n         \"\"\"Do NOT override this method when inheriting from :class:`GatewayPod`\"\"\"\n         # handle terminate signals\n\n\n###\n\n", "completion": "chore: send telemetry event before starting gateway object (#<issue-num>)"}
{"prompt": " file path A: jina/serve/instrumentation/__init__.py | file path B: jina/serve/instrumentation/__init__.py\n\n@@ -62,7 +62,6 @@ class InstrumentationMixin:\n             processor = BatchSpanProcessor(\n                 OTLPSpanExporter(\n                     endpoint=f'{traces_exporter_host}:{traces_exporter_port}',\n-                    insecure=True,\n                 )\n             )\n             provider.add_span_processor(processor)\n@@ -85,7 +84,6 @@ class InstrumentationMixin:\n             metric_reader = PeriodicExportingMetricReader(\n                 OTLPMetricExporter(\n                     endpoint=f'{metrics_exporter_host}:{metrics_exporter_port}',\n-                    insecure=True,\n                 )\n             )\n             meter_provider = MeterProvider(\n\n\n###\n\n", "completion": "fix: OpenTelemetry do not force parameter (#<issue-num>)"}
{"prompt": " file path A: docs/cloud-nativeness/opentelemetry.md | file path B: docs/cloud-nativeness/opentelemetry.md\n\n@@ -143,10 +143,10 @@ from jina import Flow, Document, DocumentArray\n \n with Flow(\n     tracing=True,\n-    traces_exporter_host='localhost',\n+    traces_exporter_host='http://localhost',\n     traces_exporter_port=4317,\n     metrics=True,\n-    metrics_exporter_host='localhost',\n+    metrics_exporter_host='http://localhost',\n     metrics_exporter_port=4317,\n ).add(uses='jinaai://jina-ai/SimpleIndexer') as f:\n     f.post('/', DocumentArray([Document(text='hello')]))\n\n---\n file path A: docs/concepts/client/instrumentation.md | file path B: docs/concepts/client/instrumentation.md\n\n@@ -15,7 +15,7 @@ from jina import Flow\n \n f = Flow(\n         tracing=True, \n-        traces_exporter_host='localhost', \n+        traces_exporter_host='http://localhost', \n         traces_exporter_port=4317,\n     )\n \n@@ -36,7 +36,7 @@ from jina import Client\n # must match the Flow setup\n c = Client(\n     tracing=True,\n-    traces_exporter_host='localhost',\n+    traces_exporter_host='http://localhost',\n     traces_exporter_port=4317,\n )\n c.post('/')\n\n---\n file path A: docs/concepts/flow/instrumentation.md | file path B: docs/concepts/flow/instrumentation.md\n\n@@ -24,7 +24,7 @@ from jina import Flow\n \n f = Flow(\n     tracing=True,\n-    traces_exporter_host='localhost',\n+    traces_exporter_host='http://localhost',\n     traces_exporter_port=4317,\n ).add(uses='jinaai://jina-ai/SimpleIndexer')\n \n@@ -102,7 +102,7 @@ from jina import Flow\n \n f = Flow(\n     metrics=True,\n-    metrics_exporter_host='localhost',\n+    metrics_exporter_host='http://localhost',\n     metrics_exporter_port=4317,\n ).add(uses='jinaai://jina-ai/SimpleIndexer')\n \n\n---\n file path A: tests/integration/instrumentation/test_container_instrumentation.py | file path B: tests/integration/instrumentation/test_container_instrumentation.py\n\n@@ -22,10 +22,10 @@ def test_docker_instrumentation(\n ):\n     f = Flow(\n         tracing=True,\n-        traces_exporter_host='localhost',\n+        traces_exporter_host='http://localhost',\n         traces_exporter_port=otlp_receiver_port,\n         metrics=True,\n-        metrics_exporter_host='localhost',\n+        metrics_exporter_host='http://localhost',\n         metrics_exporter_port=otlp_receiver_port,\n     ).add(uses=f'docker://{docker_image_name}')\n \n\n---\n file path A: tests/integration/instrumentation/test_flow_instrumentation.py | file path B: tests/integration/instrumentation/test_flow_instrumentation.py\n\n@@ -37,12 +37,12 @@ def test_gateway_instrumentation(\n     f = Flow(\n         protocol=protocol,\n         tracing=True,\n-        traces_exporter_host='localhost',\n+        traces_exporter_host='http://localhost',\n         traces_exporter_port=otlp_receiver_port,\n     ).add(\n         uses=ExecutorTestWithTracing,\n         tracing=True,\n-        traces_exporter_host='localhost',\n+        traces_exporter_host='http://localhost',\n         traces_exporter_port=otlp_receiver_port,\n     )\n \n@@ -74,7 +74,7 @@ def test_gateway_instrumentation(\n def test_executor_instrumentation(jaeger_port, otlp_collector, otlp_receiver_port):\n     f = Flow(\n         tracing=True,\n-        traces_exporter_host='localhost',\n+        traces_exporter_host='http://localhost',\n         traces_exporter_port=otlp_receiver_port,\n     ).add(uses=ExecutorFailureWithTracing)\n \n@@ -104,7 +104,7 @@ def test_executor_instrumentation(jaeger_port, otlp_collector, otlp_receiver_por\n def test_head_instrumentation(jaeger_port, otlp_collector, otlp_receiver_port):\n     f = Flow(\n         tracing=True,\n-        traces_exporter_host='localhost',\n+        traces_exporter_host='http://localhost',\n         traces_exporter_port=otlp_receiver_port,\n     ).add(uses=ExecutorTestWithTracing, shards=2)\n \n@@ -150,13 +150,13 @@ def test_flow_metrics(\n ):\n     f = Flow(\n         metrics=True,\n-        metrics_exporter_host='localhost',\n+        metrics_exporter_host='http://localhost',\n         metrics_exporter_port=otlp_receiver_port,\n     ).add(\n         uses=ExecutorFailureWithTracing,\n         shards=2,\n         metrics=True,\n-        metrics_exporter_host='localhost',\n+        metrics_exporter_host='http://localhost',\n         metrics_exporter_port=otlp_receiver_port,\n     )\n \n\n---\n file path A: tests/integration/instrumentation/test_worker_instrumentation.py | file path B: tests/integration/instrumentation/test_worker_instrumentation.py\n\n@@ -7,7 +7,7 @@ from tests.integration.instrumentation import ExecutorTestWithTracing, get_trace\n def test_span_order(jaeger_port, otlp_collector, otlp_receiver_port):\n     f = Flow(\n         tracing=True,\n-        traces_exporter_host='localhost',\n+        traces_exporter_host='http://localhost',\n         traces_exporter_port=otlp_receiver_port,\n     ).add(uses=ExecutorTestWithTracing)\n \n\n---\n file path A: tests/k8s_otel/test_k8s_instrumentation.py | file path B: tests/k8s_otel/test_k8s_instrumentation.py\n\n@@ -25,10 +25,10 @@ async def test_flow_resource_labeling(\n         name='test-flow-metrics',\n         port=8080,\n         metrics=True,\n-        metrics_exporter_host=f'otel-collector.{otel_test_namespace}.svc.cluster.local',\n+        metrics_exporter_host=f'http://otel-collector.{otel_test_namespace}.svc.cluster.local',\n         metrics_exporter_port=4317,\n         tracing=True,\n-        traces_exporter_host=f'jaeger.{otel_test_namespace}.svc.cluster.local',\n+        traces_exporter_host=f'http://jaeger.{otel_test_namespace}.svc.cluster.local',\n         traces_exporter_port=4317,\n     ).add(\n         name='instrumentation',\n\n---\n file path A: tests/unit/serve/instrumentation/test_gateway_metric_labels.py | file path B: tests/unit/serve/instrumentation/test_gateway_metric_labels.py\n\n@@ -17,7 +17,7 @@ def test_gateway_metric_labels(monkeypatch_metric_exporter):\n     with Flow(\n         tracing=False,\n         metrics=True,\n-        metrics_exporter_host='localhost',\n+        metrics_exporter_host='http://localhost',\n         metrics_exporter_port=4317,\n         port=12345,\n     ).add(name='first_exec', uses=FirstExec).add(\n@@ -105,7 +105,7 @@ def test_merge_with_no_reduce(monkeypatch_metric_exporter):\n         Flow(\n             tracing=False,\n             metrics=True,\n-            metrics_exporter_host='localhost',\n+            metrics_exporter_host='http://localhost',\n             metrics_exporter_port=4317,\n             port=12345,\n         )\n\n\n###\n\n", "completion": "fix: provide protocol for traces/metrics exporter host (#<issue-num>)"}
{"prompt": " file path A: None | file path B: Dockerfiles/pip-perf.Dockerfile\n\n@@ -0,0 +1,14 @@\n+ARG PY_VERSION=3.7\n+ARG PIP_TAG\n+\n+FROM python:${PY_VERSION}-slim\n+\n+RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev net-tools procps htop lsof dnsutils\n+\n+COPY . /jina/\n+\n+RUN cd /jina && pip install .\"$PIP_TAG\"\n+RUN cat $HOME/.bashrc\n+RUN grep -Fxq \"# JINA_CLI_BEGIN\" $HOME/.bashrc\n+\n+ENTRYPOINT [\"jina\"]\n\\ No newline at end of file\n\n---\n file path A: Dockerfiles/test-pip.Dockerfile | file path B: Dockerfiles/test-pip.Dockerfile\n\n@@ -3,7 +3,7 @@ ARG PIP_TAG\n \n FROM python:${PY_VERSION}-slim\n \n-RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev\n+RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev net-tools procps htop lsof dnsutils\n \n COPY . /jina/\n \n\n\n###\n\n", "completion": "feat: create new Dockerfile with perf tools (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -93,21 +93,6 @@ def get_fastapi_app(\n             }\n         )\n \n-        from jina.serve.runtimes.gateway.http.models import JinaHealthModel\n-\n-        @app.get(\n-            path='/',\n-            summary='Get the health of Jina Gateway service',\n-            response_model=JinaHealthModel,\n-        )\n-        async def _gateway_health():\n-            \"\"\"\n-            Get the health of this Gateway service.\n-            .. # noqa: DAR201\n-\n-            \"\"\"\n-            return {}\n-\n         from docarray import DocumentArray\n \n         from jina.proto import jina_pb2\n\n---\n file path A: jina/serve/runtimes/gateway/http/fastapi.py | file path B: jina/serve/runtimes/gateway/http/fastapi.py\n\n@@ -131,7 +131,17 @@ def _install_health_check(app: 'FastAPI', logger):\n             )\n \n     if not health_check_exists:\n+        from jina.serve.runtimes.gateway.http.models import JinaHealthModel\n \n-        @app.get('/')\n-        def health_check():\n+        @app.get(\n+            path='/',\n+            summary='Get the health of Jina Gateway service',\n+            response_model=JinaHealthModel,\n+        )\n+        async def _gateway_health():\n+            \"\"\"\n+            Get the health of this Gateway service.\n+            .. # noqa: DAR201\n+\n+            \"\"\"\n             return {}\n\n\n###\n\n", "completion": "fix: suppress warning for http gateway about health check (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/remarks.md | file path B: docs/fundamentals/flow/remarks.md\n\n@@ -132,21 +132,6 @@ Few cases require to use `spawn` start method for multiprocessing.\n     Inline functions, such as nested or lambda functions are not picklable. Use `functools.partial` instead.\n \n \n-(flow-macos-multi-processing-fork)=\n-## Multiprocessing Fork in MacOS\n-\n-Apple has changed the rules for using Objective-C between `fork()` and `exec()` since macOS 10.13.\n-This may break some codes that use `fork()` in MacOS.\n-For example, the Flow may not be able to start properly with error messages similar to:\n-\n-```bash\n-objc[20337]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called.\n-objc[20337]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug.```\n-```\n-\n-You can define the environment variable `OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES` to get around this issue.\n-Read [here](http://sealiesoftware.com/blog/archive/2017/6/5/Objective-C_and_fork_in_macOS_1013.html) for more details.\n-\n \n ## Debugging Executor in a Flow\n \n\n---\n file path A: docs/get-started/install/troubleshooting.md | file path B: docs/get-started/install/troubleshooting.md\n\n@@ -35,19 +35,6 @@ Then you are likely installing Jina on a less-supported system/architecture. For\n \n Unfortunately, `conda install` is not supported on Windows. You can either do `pip install jina` natively on Windows, or use `pip/conda install` under WSL2.\n \n-## On MacOS >= 10.13\n-{ref}`Multiprocessing with fork in MacOS <flow-macos-multi-processing-fork>` requires setting the environment variable \n-`OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES` for versions higher than 10.13.\n-You can set this variable each time you run a python interpreter that uses Jina or configure it by default using the \n-following command:\n-```shell\n-echo \"export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\" >> ~/.zshrc\n-```\n-\n-````{admonition} Caution\n-:class: caution\n-Be aware that the latter method will apply to all tools that use the underlying Objective-C fork method.\n-````\n \n ## Upgrading from Jina 2.x to 3.x\n If you upgraded an existing Jina installation from 2.x to 3.x you may see the following error message:\n\n---\n file path A: setup.py | file path B: setup.py\n\n@@ -4,6 +4,7 @@ from os import path\n \n from setuptools import find_packages, setup\n from setuptools.command.develop import develop\n+from setuptools.command.egg_info import egg_info\n from setuptools.command.install import install\n \n if sys.version_info < (3, 7, 0):\n@@ -89,6 +90,14 @@ class PostInstallCommand(install):\n         register_ac()\n \n \n+class PostEggInfoCommand(egg_info):\n+    \"\"\"Post-installation for egg info mode.\"\"\"\n+\n+    def run(self):\n+        egg_info.run(self)\n+        register_ac()\n+\n+\n def get_extra_requires(path, add_all=True):\n     import re\n     from collections import defaultdict\n@@ -164,6 +173,7 @@ setup(\n     cmdclass={\n         'develop': PostDevelopCommand,\n         'install': PostInstallCommand,\n+        'egg_info': PostEggInfoCommand,\n     },\n     classifiers=[\n         'Development Status :: 5 - Production/Stable',\n\n\n###\n\n", "completion": "fix: add egg info post install command for egg info setup mode (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py | file path B: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py\n\n@@ -101,7 +101,7 @@ def get_template_yamls(\n         'volume_path': volumes[0] if volumes is not None else None,\n     }\n \n-    if gpus:\n+    if gpus and gpus != 'all':\n         template_params['device_plugins'] = {'nvidia.com/gpu': gpus}\n \n     template_name = 'deployment-executor' if name != 'gateway' else 'deployment-gateway'\n\n\n###\n\n", "completion": "fix: do not apply limits when gpus all in K8s (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-docker-build.yml | file path B: .github/workflows/force-docker-build.yml\n\n@@ -34,14 +34,14 @@ jobs:\n       fail-fast: false\n       matrix:\n         pip_tag: [ \"\", \"perf\", \"standard\", \"devel\"]  # default: \"\" = core\n-        py_version: [ \"3.7\", \"3.8\", \"3.9\" ]  # default \"\" = 3.7\n+        py_version: [ \"3.7\", \"3.8\", \"3.9\" , \"3.10\", \"3.11\"]  # default \"\" = 3.7\n     steps:\n       - uses: actions/checkout@v2.5.0\n         with:\n           fetch-depth: 100\n       - name: Set envs and versions\n         run: |\n-          DEFAULT_PY_VERSION=\"3.7\"\n+          DEFAULT_PY_VERSION=\"3.8\"\n           VCS_REF=${{ github.ref }}\n           echo \"VCS_REF=$VCS_REF\" >> $GITHUB_ENV\n           echo \"Will build $VCS_REF\"\n\n---\n file path A: RELEASE.md | file path B: RELEASE.md\n\n@@ -98,9 +98,11 @@ jinaai/jina:{version}{python_version}{extra}\n     - `x.y.z`: the release of a particular version;\n     - `x.y`: the alias to the last `x.y.z` patch release, i.e. `x.y` = `x.y.max(z)`;\n - `{python_version}`: The Python version of the image. Possible values:\n-    - ` `, `-py37`: Python 3.7;\n-    - `-py38` for Python 3.8;\n+    - `-py37`: Python 3.7;\n+    - ` `, `-py38` for Python 3.8;\n     - `-py39` for Python 3.9;\n+    - `-py310` for Python 3.10;\n+    - `-py311` for Python 3.11;\n - `{extra}`: the extra dependency installed along with Jina. Possible values:\n     - ` `: Jina is installed inside the image via `pip install jina`;\n     - `-standard`: Jina is installed inside the image via `pip install jina`. It includes all recommended dependencies;  \n\n---\n file path A: docs/get-started/install/troubleshooting.md | file path B: docs/get-started/install/troubleshooting.md\n\n@@ -6,7 +6,7 @@ This article helps you to solve the installation problems of Jina.\n \n The normal installation of Jina takes 10 seconds. If yours takes longer than this, then it is likely you unnecessarily built wheels from scratch. \n \n-Every upstream dependency of Jina has pre-built wheels exhaustively for x86/arm64, macos/Linux and Python 3.7/3.8/3.9, including `numpy`, `protobuf`, `pyzmq`, `grpcio` etc. This means when you install Jina, your `pip` should directly leverage the pre-built wheels instead of building them from scratch locally. For example, you should expect the install log to contain `-cp38-cp38-macosx_10_15_x86_64.whl` when installing Jina on MacOS with Python 3.8.\n+Every upstream dependency of Jina has pre-built wheels exhaustively for x86/arm64, macos/Linux and Python 3.7/3.8/3.9, including `numpy`, `protobuf`, `grpcio` etc. This means when you install Jina, your `pip` should directly leverage the pre-built wheels instead of building them from scratch locally. For example, you should expect the install log to contain `-cp38-cp38-macosx_10_15_x86_64.whl` when installing Jina on MacOS with Python 3.8.\n \n If you find you are building wheels during installation (see an example below), then it is a sign that you are installing Jina **wrongly**. \n \n\n\n###\n\n", "completion": "ci: build python 3.10 and 3.11 as default jina docker images and make 3.8 the default jina docker image (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/remarks.md | file path B: docs/fundamentals/flow/remarks.md\n\n@@ -132,6 +132,7 @@ Few cases require to use `spawn` start method for multiprocessing.\n     Inline functions, such as nested or lambda functions are not picklable. Use `functools.partial` instead.\n \n \n+(flow-macos-multi-processing-fork)=\n ## Multiprocessing Fork in MacOS\n \n Apple has changed the rules for using Objective-C between `fork()` and `exec()` since macOS 10.13.\n\n---\n file path A: docs/get-started/install/troubleshooting.md | file path B: docs/get-started/install/troubleshooting.md\n\n@@ -35,6 +35,20 @@ Then you are likely installing Jina on a less-supported system/architecture. For\n \n Unfortunately, `conda install` is not supported on Windows. You can either do `pip install jina` natively on Windows, or use `pip/conda install` under WSL2.\n \n+## On MacOS >= 10.13\n+{ref}`Multiprocessing with fork in MacOS <flow-macos-multi-processing-fork>` requires setting the environment variable \n+`OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES` for versions higher than 10.13.\n+You can set this variable each time you run a python interpreter that uses Jina or configure it by default using the \n+following command:\n+```shell\n+echo \"export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\" >> ~/.zshrc\n+```\n+\n+````{admonition} Caution\n+:class: caution\n+Be aware that the latter method will apply to all tools that use the underlying Objective-C fork method.\n+````\n+\n ## Upgrading from Jina 2.x to 3.x\n If you upgraded an existing Jina installation from 2.x to 3.x you may see the following error message:\n \n\n\n###\n\n", "completion": "docs: document needed setup for macos (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -45,6 +45,7 @@ from jina.enums import (\n     FlowInspectType,\n     GatewayProtocolType,\n )\n+from jina import __windows__\n from jina.excepts import (\n     FlowMissingDeploymentError,\n     FlowTopologyError,\n@@ -2373,9 +2374,21 @@ class Flow(\n                 self._stop_event = (\n                     threading.Event()\n                 )  #: this allows `.close` to close the Flow from another thread/proc\n-                self._stop_event.wait()\n+                if not __windows__:\n+                    self._stop_event.wait()\n+                else:\n+                    while True:\n+                        if self._stop_event.is_set():\n+                            break\n+                        time.sleep(0.5)\n             else:\n-                stop_event.wait()\n+                if not __windows__:\n+                    stop_event.wait()\n+                else:\n+                    while True:\n+                        if stop_event.is_set():\n+                            break\n+                        time.sleep(0.5)\n         except KeyboardInterrupt:\n             pass\n \n\n---\n file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -9,7 +9,6 @@ from grpc import RpcError\n \n from jina import __windows__\n from jina.helper import send_telemetry_event\n-from jina.importer import ImportExtensions\n from jina.serve.instrumentation import InstrumentationMixin\n from jina.serve.networking import GrpcConnectionPool\n from jina.serve.runtimes.base import BaseRuntime\n@@ -44,34 +43,23 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, InstrumentationMixin, AB\n         asyncio.set_event_loop(self._loop)\n         self.is_cancel = cancel_event or asyncio.Event()\n \n-        def _cancel(sig):\n-            def _inner_cancel(*args, **kwargs):\n-                self.logger.debug(f'Received signal {sig.name}')\n-                self.is_cancel.set(),\n+        if not __windows__:\n+            def _cancel(sig):\n+                def _inner_cancel(*args, **kwargs):\n+                    self.logger.debug(f'Received signal {sig.name}')\n+                    self.is_cancel.set(),\n \n-            return _inner_cancel\n+                return _inner_cancel\n \n-        if not __windows__:\n-            try:\n-                for sig in HANDLED_SIGNALS:\n-                    self._loop.add_signal_handler(sig, _cancel(sig), sig, None)\n-            except (ValueError, RuntimeError) as exc:\n-                self.logger.warning(\n-                    f' The runtime {self.__class__.__name__} will not be able to handle termination signals. '\n-                    f' {repr(exc)}'\n-                )\n+            for sig in HANDLED_SIGNALS:\n+                self._loop.add_signal_handler(sig, _cancel(sig), sig, None)\n         else:\n-            with ImportExtensions(\n-                    required=True,\n-                    logger=self.logger,\n-                    help_text='''If you see a 'DLL load failed' error, please reinstall `pywin32`.\n-                    If you're using conda, please use the command `conda install -c anaconda pywin32`''',\n-            ):\n-                import win32api\n-\n-            win32api.SetConsoleCtrlHandler(\n-                lambda *args, **kwargs: self.is_cancel.set(), True\n-            )\n+            def _cancel(signum, frame):\n+                self.logger.debug(f'Received signal {signum}')\n+                self.is_cancel.set(),\n+\n+            for sig in HANDLED_SIGNALS:\n+                signal.signal(sig, _cancel)\n \n         self._setup_monitoring()\n         self._setup_instrumentation(\n\n\n###\n\n", "completion": "fix: fix windows signal handling (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/http/fastapi.py | file path B: jina/serve/runtimes/gateway/http/fastapi.py\n\n@@ -1,11 +1,14 @@\n import logging\n import os\n from abc import abstractmethod\n-from typing import Optional\n+from typing import TYPE_CHECKING, Optional\n \n from jina.importer import ImportExtensions\n from jina.serve.gateway import BaseGateway\n \n+if TYPE_CHECKING:\n+    from fastapi import FastAPI\n+\n \n class FastAPIBaseGateway(BaseGateway):\n     \"\"\"Base FastAPI gateway. Implement this abstract class in-case you want to build a fastapi-based Gateway by\n@@ -89,9 +92,12 @@ class FastAPIBaseGateway(BaseGateway):\n             # Filter out healthcheck endpoint `GET /`\n             logging.getLogger(\"uvicorn.access\").addFilter(_EndpointFilter())\n \n+        # app property will generate a new fastapi app each time called\n+        app = self.app\n+        _install_health_check(app, self.logger)\n         self.server = UviServer(\n             config=Config(\n-                app=self.app,\n+                app=app,\n                 host=self.host,\n                 port=self.port,\n                 log_level=os.getenv('JINA_LOG_LEVEL', 'error').lower(),\n@@ -111,3 +117,21 @@ class FastAPIBaseGateway(BaseGateway):\n     async def run_server(self):\n         \"\"\"Run HTTP server forever\"\"\"\n         await self.server.serve()\n+\n+\n+def _install_health_check(app: 'FastAPI', logger):\n+    health_check_exists = False\n+    for route in app.routes:\n+        if getattr(route, 'path', None) == '/' and 'GET' in getattr(\n+            route, 'methods', None\n+        ):\n+            health_check_exists = True\n+            logger.warning(\n+                'endpoint GET on \"/\" is used for health checks, make sure it\\'s still accessible'\n+            )\n+\n+    if not health_check_exists:\n+\n+        @app.get('/')\n+        def health_check():\n+            return {}\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_custom_gateway.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_custom_gateway.py\n\n@@ -99,6 +99,23 @@ def test_flow_custom_gateway_no_executor(uses, uses_with, expected):\n         )\n \n \n+def test_flow_fastapi_default_health_check():\n+\n+    flow = (\n+        Flow()\n+        .config_gateway(\n+            uses=_dummy_fastapi_gateway_yaml_path,\n+            uses_with={'default_health_check': True},\n+        )\n+        .add(uses='ProcessExecutor')\n+    )\n+    with flow:\n+        _validate_dummy_custom_gateway_response(flow.port, {})\n+        _validate_custom_gateway_process(\n+            flow.port, 'hello', {'text': 'helloworld', 'tags': {'processed': True}}\n+        )\n+\n+\n def test_flow_custom_gateway_nested_config():\n \n     flow = Flow.load_config(_flow_with_dummy_gateway_yaml_path)\n\n---\n file path A: tests/unit/yaml/dummy_fastapi_gateway.py | file path B: tests/unit/yaml/dummy_fastapi_gateway.py\n\n@@ -20,12 +20,18 @@ class ProcessedResponseModel(BaseModel):\n \n class DummyFastAPIGateway(FastAPIBaseGateway):\n     def __init__(\n-        self, arg1: str = None, arg2: str = None, arg3: str = 'default-arg3', **kwargs\n+        self,\n+        arg1: str = None,\n+        arg2: str = None,\n+        arg3: str = 'default-arg3',\n+        default_health_check: bool = False,\n+        **kwargs\n     ):\n         super().__init__(**kwargs)\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n+        self.default_health_check = default_health_check\n \n     @property\n     def app(self):\n@@ -35,13 +41,15 @@ class DummyFastAPIGateway(FastAPIBaseGateway):\n             title='Dummy Server',\n         )\n \n-        @app.get(path='/', response_model=DummyResponseModel)\n-        def _get_response():\n-            return {\n-                'arg1': self.arg1,\n-                'arg2': self.arg2,\n-                'arg3': self.arg3,\n-            }\n+        if not self.default_health_check:\n+\n+            @app.get(path='/', response_model=DummyResponseModel)\n+            def _get_response():\n+                return {\n+                    'arg1': self.arg1,\n+                    'arg2': self.arg2,\n+                    'arg3': self.arg3,\n+                }\n \n         @app.get(\n             path='/stream',\n\n\n###\n\n", "completion": "feat: install health check for fast api gateway app by default (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.26.4:    core\n+jina-hubble-sdk>=0.26.10:   core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -353,9 +353,9 @@ class Deployment(BaseDeployment):\n \n         :return: True if this deployment is provided as a sandbox, False otherwise\n         \"\"\"\n+        from hubble.executor.helper import is_valid_sandbox_uri\n         uses = getattr(self.args, 'uses') or ''\n-        is_sandbox = uses.startswith('jinahub+sandbox://') or uses.startswith('jinaai+sandbox://')\n-        return is_sandbox\n+        return is_valid_sandbox_uri(uses)\n \n     @property\n     def _is_docker(self) -> bool:\n@@ -364,9 +364,9 @@ class Deployment(BaseDeployment):\n \n         :return: True if this deployment is to be run in docker\n         \"\"\"\n+        from hubble.executor.helper import is_valid_docker_uri\n         uses = getattr(self.args, 'uses', '')\n-        is_docker = uses.startswith('jinahub+docker://') or uses.startswith('docker://') or uses.startswith('jinaai+docker://')\n-        return is_docker\n+        return is_valid_docker_uri(uses)\n \n     @property\n     def tls_enabled(self):\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.26.4:    core\n+jina-hubble-sdk>=0.26.10:   core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n\n\n###\n\n", "completion": "feat: update hubble-sdk (#<issue-num>)"}
{"prompt": " file path A: jina/checker.py | file path B: jina/checker.py\n\n@@ -51,7 +51,7 @@ class NetworkChecker:\n                 if args.attempts > 0:\n                     time.sleep(1)\n             if total_success < args.attempts:\n-                default_logger.warning(\n+                default_logger.debug(\n                     'message lost %.0f%% (%d/%d) '\n                     % (\n                         (1 - total_success / args.attempts) * 100,\n@@ -60,17 +60,17 @@ class NetworkChecker:\n                     )\n                 )\n             if total_success > 0:\n-                default_logger.info(\n+                default_logger.debug(\n                     'avg. latency: %.0f ms' % (total_time / total_success * 1000)\n                 )\n \n             if total_success >= args.min_successful_attempts:\n-                default_logger.info(\n+                default_logger.debug(\n                     f'readiness check succeeded {total_success} times!!!'\n                 )\n                 exit(0)\n             else:\n-                default_logger.info(\n+                default_logger.debug(\n                     f'readiness check succeeded {total_success} times, less than {args.min_successful_attempts}'\n                 )\n         except KeyboardInterrupt:\n\n---\n file path A: jina_cli/__init__.py | file path B: jina_cli/__init__.py\n\n@@ -10,7 +10,7 @@ def _get_run_args(print_args: bool = True):\n \n     console = get_rich_console()\n \n-    silent_print = {'help', 'hub', 'export', 'auth', 'cloud'}\n+    silent_print = {'help', 'hub', 'export', 'auth', 'cloud', 'ping'}\n \n     parser = get_main_parser()\n     if len(sys.argv) > 1:\n\n---\n file path A: tests/unit/test_cli.py | file path B: tests/unit/test_cli.py\n\n@@ -115,3 +115,24 @@ def test_ping():\n             NetworkChecker(a3)\n \n     assert cm.value.code == 1\n+\n+\n+@pytest.mark.parametrize(\n+    'cmd',\n+    [\n+        ['jina', 'ping', 'flow', '127.0.0.1:8080'],\n+        ['jina', 'help', 'port'],\n+        ['jina', 'hub'],\n+    ],\n+)\n+def test_logo_silence(cmd):\n+    from jina import __resources_path__\n+\n+    with open(os.path.join(__resources_path__, 'jina.logo')) as fp:\n+        logo_str = fp.read()\n+\n+    s = subprocess.run(\n+        cmd,\n+        stdout=subprocess.PIPE,\n+    )\n+    assert logo_str not in s.stdout.decode()\n\n\n###\n\n", "completion": "feat: silence or minimize output of jina ping command (#<issue-num>)"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -112,6 +112,7 @@ class ReplicaList:\n         runtime_name: str,\n         aio_tracing_client_interceptors: Optional[Sequence['ClientInterceptor']] = None,\n         tracing_client_interceptor: Optional['OpenTelemetryClientInterceptor'] = None,\n+        deployment_name: str = ''\n     ):\n         self.runtime_name = runtime_name\n         self._connections = []\n@@ -124,6 +125,7 @@ class ReplicaList:\n         self._destroyed_event = asyncio.Event()\n         self.aio_tracing_client_interceptors = aio_tracing_client_interceptors\n         self.tracing_client_interceptors = tracing_client_interceptor\n+        self._deployment_name = deployment_name\n \n     async def reset_connection(\n         self, address: str, deployment_name: str\n@@ -137,7 +139,7 @@ class ReplicaList:\n         :param deployment_name: Target deployment of this connection\n         :returns: The reset connection or None if there was no connection for the given address\n         \"\"\"\n-        self._logger.debug(f'resetting connection to {address}')\n+        self._logger.debug(f'resetting connection for {deployment_name} to {address}')\n \n         if (\n             address in self._address_to_connection_idx\n@@ -255,12 +257,12 @@ class ReplicaList:\n             if all_connections_unavailable:\n                 if num_retries <= 0:\n                     raise EstablishGrpcConnectionError(\n-                        f'Error while resetting connections {self._connections}. Connections cannot be used.'\n+                        f'Error while resetting connections {self._connections} for {self._deployment_name}. Connections cannot be used.'\n                     )\n             elif connection is None:\n                 # give control back to async event loop so connection resetting can be completed; then retry\n                 self._logger.debug(\n-                    f' No valid connection found, give chance for potential resetting of connection'\n+                    f' No valid connection found for {self._deployment_name}, give chance for potential resetting of connection'\n                 )\n                 try:\n                     await asyncio.wait_for(\n@@ -545,7 +547,7 @@ class GrpcConnectionPool:\n             head: bool,\n             entity_id: Optional[int] = None,\n             increase_access_count: bool = True,\n-        ) -> ReplicaList:\n+        ) -> Optional[ReplicaList]:\n             # returns all replicas of a given deployment, using a given shard\n             if deployment in self._deployments:\n                 type_ = 'heads' if head else 'shards'\n@@ -630,12 +632,13 @@ class GrpcConnectionPool:\n             self._add_deployment(deployment)\n             if entity_id not in self._deployments[deployment][type]:\n                 connection_list = ReplicaList(\n-                    self._metrics,\n-                    self._histograms,\n-                    self._logger,\n-                    self.runtime_name,\n-                    self.aio_tracing_client_interceptors,\n-                    self.tracing_client_interceptor,\n+                    metrics=self._metrics,\n+                    histograms=self._histograms,\n+                    logger=self._logger,\n+                    runtime_name=self.runtime_name,\n+                    aio_tracing_client_interceptors=self.aio_tracing_client_interceptors,\n+                    tracing_client_interceptor=self.tracing_client_interceptor,\n+                    deployment_name=deployment\n                 )\n                 self._deployments[deployment][type][entity_id] = connection_list\n \n@@ -650,7 +653,7 @@ class GrpcConnectionPool:\n                 )\n             else:\n                 self._logger.debug(\n-                    f'ignoring activation of pod, {address} already known'\n+                    f'ignoring activation of pod for deployment {deployment}, {address} already known'\n                 )\n \n         async def remove_head(self, deployment, address, head_id: Optional[int] = 0):\n@@ -830,7 +833,7 @@ class GrpcConnectionPool:\n         shard_id: Optional[int] = None,\n         timeout: Optional[float] = None,\n         retries: Optional[int] = -1,\n-    ) -> asyncio.Task:\n+    ) -> Optional[asyncio.Task]:\n         \"\"\"Sends a discover Endpoint call to target.\n \n         :param deployment: name of the Jina deployment to send the request to\n@@ -863,7 +866,7 @@ class GrpcConnectionPool:\n         endpoint: Optional[str] = None,\n         timeout: Optional[float] = None,\n         retries: Optional[int] = -1,\n-    ) -> asyncio.Task:\n+    ) -> Optional[asyncio.Task]:\n         \"\"\"Send a request to target via only one of the pooled connections\n \n         :param requests: request to send\n@@ -966,7 +969,7 @@ class GrpcConnectionPool:\n         # requests usually gets cancelled when the server shuts down\n         # retries for cancelled requests will hit another replica in K8s\n         self._logger.debug(\n-            f'GRPC call errored, getting error {error} for the {retry_i + 1}th time.'\n+            f'GRPC call to {current_deployment} errored, getting error {error} for the {retry_i + 1}th time.'\n         )\n         if (\n             error.code() != grpc.StatusCode.UNAVAILABLE\n@@ -978,7 +981,7 @@ class GrpcConnectionPool:\n             error.code() == grpc.StatusCode.UNAVAILABLE\n             or error.code() == grpc.StatusCode.DEADLINE_EXCEEDED\n         ) and retry_i >= total_num_tries - 1:  # retries exhausted. if we land here it already failed once, therefore -1\n-            self._logger.debug(f'GRPC call failed, retries exhausted')\n+            self._logger.debug(f'GRPC call for {current_deployment} failed, retries exhausted')\n             from jina.excepts import InternalNetworkError\n \n             # after connection failure the gRPC `channel` gets stuck in a failure state for a few seconds\n@@ -996,7 +999,7 @@ class GrpcConnectionPool:\n             )\n         else:\n             self._logger.debug(\n-                f'GRPC call failed with code {error.code()}, retry attempt {retry_i + 1}/{total_num_tries - 1}.'\n+                f'GRPC call to deployment {current_deployment} failed with code {error.code()}, retry attempt {retry_i + 1}/{total_num_tries - 1}.'\n                 f' Trying next replica, if available.'\n             )\n             return None\n@@ -1448,7 +1451,7 @@ def host_is_local(hostname):\n     import socket\n \n     fqn = socket.getfqdn(hostname)\n-    if fqn in (\"localhost\", \"0.0.0.0\") or hostname == '0.0.0.0':\n+    if fqn in ('localhost', '0.0.0.0') or hostname == '0.0.0.0':\n         return True\n \n     try:\n\n---\n file path A: tests/integration/runtimes/test_network_failures.py | file path B: tests/integration/runtimes/test_network_failures.py\n\n@@ -738,12 +738,12 @@ def _test_custom_retry(gateway_port, error_ports, protocol, retries, capfd):\n     out, err = capfd.readouterr()\n     if retries > 0:  # do as many retries as specified\n         for i in range(retries):\n-            assert f'retry attempt {i+1}/{retries}' in out\n+            assert f'attempt {i+1}/{retries}' in out\n     elif retries == 0:  # do no retries\n-        assert 'retry attempt' not in out\n+        assert 'attempt' not in out\n     elif retries < 0:  # use default retry policy, doing at least 3 retries\n         for i in range(3):\n-            assert f'retry attempt {i+1}' in out\n+            assert f'attempt {i+1}' in out\n \n \n @pytest.mark.parametrize('retries', [-1, 0, 5])\n\n\n###\n\n", "completion": "refactor: add more debug info to prints (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -354,7 +354,7 @@ class Deployment(BaseDeployment):\n         :return: True if this deployment is provided as a sandbox, False otherwise\n         \"\"\"\n         uses = getattr(self.args, 'uses') or ''\n-        is_sandbox = uses.startswith('jinahub+sandbox://')\n+        is_sandbox = uses.startswith('jinahub+sandbox://') or uses.startswith('jinaai+sandbox://')\n         return is_sandbox\n \n     @property\n@@ -365,7 +365,7 @@ class Deployment(BaseDeployment):\n         :return: True if this deployment is to be run in docker\n         \"\"\"\n         uses = getattr(self.args, 'uses', '')\n-        is_docker = uses.startswith('jinahub+docker://') or uses.startswith('docker://')\n+        is_docker = uses.startswith('jinahub+docker://') or uses.startswith('docker://') or uses.startswith('jinaai+docker://')\n         return is_docker\n \n     @property\n\n\n###\n\n", "completion": "fix: adapt to new resource structure (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -399,7 +399,7 @@ jobs:\n       matrix:\n         core: ['', 'true']\n         perf: ['', 'true']\n-        exclude: \n+        exclude:\n           - core: 'true'\n             perf: 'true'\n     steps:\n@@ -421,6 +421,36 @@ jobs:\n       - name: Test import all\n         run: python -c 'from jina import *'\n \n+  install-jina-ecosystem-test:\n+    runs-on: ubuntu-latest\n+    needs: [lint-flake-8, code-injection ]\n+    strategy:\n+      fail-fast: false\n+    steps:\n+      - uses: actions/checkout@v2.5.0\n+      - name: Set up Python 3.7\n+        uses: actions/setup-python@v4\n+        with:\n+          python-version: 3.7\n+      - name: Prepare enviroment\n+        run: |\n+          python -m pip install --upgrade pip\n+          python -m pip install wheel\n+\n+          HUBBLE_VERSION=$(curl -L -s \"https://pypi.org/pypi/jina-hubble-sdk/json\" |  jq  -r '.releases | keys | .[]| select(startswith(\"0.\"))'  | sort -V | tail -1)\n+          DOCARRAY_VERSION=$(curl -L -s \"https://pypi.org/pypi/docarray/json\" |  jq  -r '.releases | keys | .[]| select(startswith(\"0.\"))'  | sort -V | tail -1)\n+          JCLOUD_VERSION=$(curl -L -s \"https://pypi.org/pypi/jcloud/json\" |  jq  -r '.releases | keys | .[]| select(startswith(\"0.\"))'  | sort -V | tail -1)\n+\n+          pip install . jcloud==$JCLOUD_VERSION docarray==$DOCARRAY_VERSION jina-hubble-sdk==$HUBBLE_VERSION\n+        env:\n+          JINA_PIP_INSTALL_CORE: ${{ matrix.core }}\n+          JINA_PIP_INSTALL_PERF: ${{ matrix.perf }}\n+\n+      - name: Test basic import\n+        run: python -c 'from jina import Executor,requests'\n+      - name: Test import all\n+        run: python -c 'from jina import *'\n+\n \n   # just for blocking the merge until all parallel core-test are successful\n   success-all-test:\n\n---\n file path A: .github/workflows/nightly-tests.yml | file path B: .github/workflows/nightly-tests.yml\n\n@@ -72,8 +72,38 @@ jobs:\n           SLACK_WEBHOOK_URL: ${{ secrets.SLACK_NIGHTLY_TESTS_WEBHOOK }}\n           MATRIX_CONTEXT: ${{ toJson(matrix) }}\n \n+  install-jina-ecosystem-test:\n+    runs-on: ubuntu-latest\n+    needs: [lint-flake-8, code-injection ]\n+    strategy:\n+      fail-fast: false\n+    steps:\n+      - uses: actions/checkout@v2.5.0\n+      - name: Set up Python 3.7\n+        uses: actions/setup-python@v4\n+        with:\n+          python-version: 3.7\n+      - name: Prepare enviroment\n+        run: |\n+          python -m pip install --upgrade pip\n+          python -m pip install wheel\n+\n+          HUBBLE_VERSION=$(curl -L -s \"https://pypi.org/pypi/jina-hubble-sdk/json\" |  jq  -r '.releases | keys | .[]| select(startswith(\"0.\"))'  | sort -V | tail -1)\n+          DOCARRAY_VERSION=$(curl -L -s \"https://pypi.org/pypi/docarray/json\" |  jq  -r '.releases | keys | .[]| select(startswith(\"0.\"))'  | sort -V | tail -1)\n+          JCLOUD_VERSION=$(curl -L -s \"https://pypi.org/pypi/jcloud/json\" |  jq  -r '.releases | keys | .[]| select(startswith(\"0.\"))'  | sort -V | tail -1)\n+\n+          pip install . jcloud==$JCLOUD_VERSION docarray==$DOCARRAY_VERSION jina-hubble-sdk==$HUBBLE_VERSION\n+        env:\n+          JINA_PIP_INSTALL_CORE: ${{ matrix.core }}\n+          JINA_PIP_INSTALL_PERF: ${{ matrix.perf }}\n+\n+      - name: Test basic import\n+        run: python -c 'from jina import Executor,requests'\n+      - name: Test import all\n+        run: python -c 'from jina import *'\n+\n   success-all-test:\n-    needs: [prep-testbed, windows-test]\n+    needs: [prep-testbed, windows-test, install-jina-ecosystem-test]\n     if: always()\n     runs-on: ubuntu-latest\n     steps:\n\n\n###\n\n", "completion": "chore: add install ecosystem latest version test to ci (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/grpc/gateway.py | file path B: jina/serve/runtimes/gateway/grpc/gateway.py\n\n@@ -4,7 +4,6 @@ import grpc\n from grpc_health.v1 import health, health_pb2, health_pb2_grpc\n from grpc_reflection.v1alpha import reflection\n \n-from jina import __default_host__\n from jina.helper import get_full_version\n from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.gateway import BaseGateway\n@@ -104,27 +103,21 @@ class GRPCGateway(BaseGateway):\n \n     async def dry_run(self, empty, context) -> jina_pb2.StatusProto:\n         \"\"\"\n-        Process the the call requested by having a dry run call to every Executor in the graph\n+        Process the call requested by having a dry run call to every Executor in the graph\n \n         :param empty: The service expects an empty protobuf message\n         :param context: grpc context\n         :returns: the response request\n         \"\"\"\n-        from docarray import DocumentArray\n+        from docarray import DocumentArray, Document\n \n-        from jina.clients.request import request_generator\n-        from jina.enums import DataInputType\n         from jina.serve.executors import __dry_run_endpoint__\n \n-        da = DocumentArray()\n-\n+        da = DocumentArray([Document()])\n         try:\n-            req_iterator = request_generator(\n-                exec_endpoint=__dry_run_endpoint__,\n-                data=da,\n-                data_type=DataInputType.DOCUMENT,\n-            )\n-            async for _ in self.streamer.stream(request_iterator=req_iterator):\n+            async for _ in self.streamer.stream_docs(\n+                docs=da, exec_endpoint=__dry_run_endpoint__, request_size=1\n+            ):\n                 pass\n             status_message = StatusMessage()\n             status_message.set_code(jina_pb2.StatusProto.SUCCESS)\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/gateway.py | file path B: jina/serve/runtimes/gateway/websocket/gateway.py\n\n@@ -2,7 +2,6 @@ import logging\n import os\n from typing import Optional\n \n-from jina import __default_host__\n from jina.importer import ImportExtensions\n from jina.serve.gateway import BaseGateway\n from jina.serve.runtimes.gateway.websocket.app import get_fastapi_app\n\n---\n file path A: jina/serve/streamer.py | file path B: jina/serve/streamer.py\n\n@@ -137,7 +137,7 @@ class GatewayStreamer:\n     async def stream_docs(\n             self,\n             docs: DocumentArray,\n-            request_size: int,\n+            request_size: int = 100,\n             return_results: bool = False,\n             exec_endpoint: Optional[str] = None,\n             target_executor: Optional[str] = None,\n@@ -170,7 +170,7 @@ class GatewayStreamer:\n                     req.parameters = parameters\n                 yield req\n \n-        async for resp in self._streamer.stream(request_iterator=_req_generator(), results_in_order=results_in_order):\n+        async for resp in self.stream(request_iterator=_req_generator(), results_in_order=results_in_order):\n             if return_results:\n                 yield resp\n             else:\n\n---\n file path A: tests/docker_compose/custom-gateway/dummy_gateway.py | file path B: tests/docker_compose/custom-gateway/dummy_gateway.py\n\n@@ -49,14 +49,13 @@ class DummyGateway(Gateway):\n         )\n         async def _process(text: str):\n             doc = None\n-            async for req in self.streamer.stream(\n-                request_generator(\n-                    exec_endpoint='/debug',\n-                    data=DocumentArray([Document(text=text)]),\n-                )\n+\n+            async for docs in self.streamer.stream_docs(\n+                docs=DocumentArray([Document(text=text)]),\n+                exec_endpoint='/debug',\n             ):\n-                doc = req.to_dict()['data'][0]\n-            return {'text': doc['text'], 'tags': doc['tags']}\n+                doc = docs[0]\n+            return {'text': doc.text, 'tags': doc.tags}\n \n         self.server = Server(Config(app, host=self.host, port=self.port))\n \n\n---\n file path A: tests/k8s/custom-gateway/dummy_gateway.py | file path B: tests/k8s/custom-gateway/dummy_gateway.py\n\n@@ -49,14 +49,12 @@ class DummyGateway(Gateway):\n         )\n         async def _process(text: str):\n             doc = None\n-            async for req in self.streamer.stream(\n-                request_generator(\n-                    exec_endpoint='/debug',\n-                    data=DocumentArray([Document(text=text)]),\n-                )\n+            async for docs in self.streamer.stream_docs(\n+                docs=DocumentArray([Document(text=text)]),\n+                exec_endpoint='/debug',\n             ):\n-                doc = req.to_dict()['data'][0]\n-            return {'text': doc['text'], 'tags': doc['tags']}\n+                doc = docs[0]\n+            return {'text': doc.text, 'tags': doc.tags}\n \n         self.server = Server(Config(app, host=self.host, port=self.port))\n \n\n---\n file path A: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py | file path B: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py\n\n@@ -49,14 +49,12 @@ class DummyGateway(Gateway):\n         )\n         async def _process(text: str):\n             doc = None\n-            async for req in self.streamer.stream(\n-                request_generator(\n-                    exec_endpoint='/',\n-                    data=DocumentArray([Document(text=text)]),\n-                )\n+            async for docs in self.streamer.stream_docs(\n+                docs=DocumentArray([Document(text=text)]),\n+                exec_endpoint='/',\n             ):\n-                doc = req.to_dict()['data'][0]\n-            return {'text': doc['text'], 'tags': doc['tags']}\n+                doc = docs[0]\n+            return {'text': doc.text, 'tags': doc.tags}\n \n         self.server = Server(Config(app, host=self.host, port=self.port))\n \n\n---\n file path A: tests/unit/yaml/dummy_gateway.py | file path B: tests/unit/yaml/dummy_gateway.py\n\n@@ -49,14 +49,12 @@ class DummyGateway(Gateway):\n         )\n         async def _process(text: str):\n             doc = None\n-            async for req in self.streamer.stream(\n-                request_generator(\n-                    exec_endpoint='/',\n-                    data=DocumentArray([Document(text=text)]),\n-                )\n+            async for docs in self.streamer.stream_docs(\n+                docs=DocumentArray([Document(text=text)]),\n+                exec_endpoint='/',\n             ):\n-                doc = req.to_dict()['data'][0]\n-            return {'text': doc['text'], 'tags': doc['tags']}\n+                doc = docs[0]\n+            return {'text': doc.text, 'tags': doc.tags}\n \n         self.server = Server(Config(app, host=self.host, port=self.port))\n \n\n\n###\n\n", "completion": "refactor: use stream_docs from streamer (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/pods/container.py | file path B: jina/orchestrate/pods/container.py\n\n@@ -130,7 +130,11 @@ def _docker_run(\n         del args.gpus\n \n     _args = ArgNamespace.kwargs2list(non_defaults)\n-    ports = {f'{args.port}/tcp': args.port} if not net_mode else None\n+\n+    if args.pod_role == PodRoleType.GATEWAY:\n+        ports = {f'{_port}/tcp': _port for _port in args.port} if not net_mode else None\n+    else:\n+        ports = {f'{args.port}/tcp': args.port} if not net_mode else None\n \n     docker_kwargs = args.docker_kwargs or {}\n     container = client.containers.run(\n\n\n###\n\n", "completion": "fix: fix custom gateway container port (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/executor-args.md | file path B: docs/fundamentals/flow/executor-args.md\n\n@@ -25,8 +25,6 @@\n | `gpus` | This argument allows dockerized Jina Executors to discover local gpu devices.<br>    <br>    Note, <br>    - To access all gpus, use `--gpus all`.<br>    - To access multiple gpus, e.g. make use of 2 gpus, use `--gpus 2`.<br>    - To access specified gpus based on device id, use `--gpus device=[YOUR-GPU-DEVICE-ID]`<br>    - To access specified gpus based on multiple device id, use `--gpus device=[YOUR-GPU-DEVICE-ID1],device=[YOUR-GPU-DEVICE-ID2]`<br>    - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display | `string` | `None` |\n | `disable_auto_volume` | Do not automatically mount a volume for dockerized Executors. | `boolean` | `False` |\n | `host` | The host address of the runtime, by default it is 0.0.0.0. In the case of an external Executor (`--external` or `external=True`) this can be a list of hosts, separated by commas. Then, every resulting address will be considered as one replica of the Executor. | `string` | `0.0.0.0` |\n-| `quiet_remote_logs` | Do not display the streaming of remote logs on local console | `boolean` | `False` |\n-| `upload_files` | The files on the host to be uploaded to the remote<br>workspace. This can be useful when your Deployment has more<br>file dependencies beyond a single YAML file, e.g.<br>Python files, data files.<br><br>Note,<br>- currently only flatten structure is supported, which means if you upload `[./foo/a.py, ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace on the remote, losing all hierarchies.<br>- by default, `--uses` YAML file is always uploaded.<br>- uploaded files are by default isolated across the runs. To ensure files are submitted to the same workspace across different runs, use `--workspace-id` to specify the workspace. | `array` | `None` |\n | `runtime_cls` | The runtime class to run inside the Pod | `string` | `WorkerRuntime` |\n | `timeout_ready` | The timeout in milliseconds of a Pod waits for the runtime to be ready, -1 for waiting forever | `number` | `600000` |\n | `env` | The map of environment variables that are available inside runtime | `object` | `None` |\n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -46,38 +46,6 @@ class BaseDeployment(ExitStack):\n         \"\"\"\n         ...\n \n-    @staticmethod\n-    def _set_upload_files(args):\n-        # sets args.upload_files at the deployment level so that pods inherit from it.\n-        # all pods work under one remote workspace, hence important to have upload_files set for all\n-\n-        def valid_path(path):\n-            try:\n-                complete_path(path)\n-                return True\n-            except FileNotFoundError:\n-                return False\n-\n-        _upload_files = set()\n-        for param in ['uses', 'uses_before', 'uses_after']:\n-            param_value = getattr(args, param, None)\n-            if param_value and valid_path(param_value):\n-                _upload_files.add(param_value)\n-\n-        if getattr(args, 'py_modules', None):\n-            _upload_files.update(\n-                {py_module for py_module in args.py_modules if valid_path(py_module)}\n-            )\n-        if getattr(args, 'upload_files', None):\n-            _upload_files.update(\n-                {\n-                    upload_file\n-                    for upload_file in args.upload_files\n-                    if valid_path(upload_file)\n-                }\n-            )\n-        return list(_upload_files)\n-\n     @property\n     def role(self) -> 'DeploymentRoleType':\n         \"\"\"Return the role of this :class:`BaseDeployment`.\n@@ -247,7 +215,6 @@ class Deployment(BaseDeployment):\n         self, args: Union['Namespace', Dict], needs: Optional[Set[str]] = None\n     ):\n         super().__init__()\n-        args.upload_files = BaseDeployment._set_upload_files(args)\n         self.args = args\n         self.args.polling = (\n             args.polling if hasattr(args, 'polling') else PollingType.ANY\n\n---\n file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -72,7 +72,6 @@ class DockerComposeConfig:\n                 'uses_after',\n                 'workspace',\n                 'workspace_id',\n-                'upload_files',\n                 'noblock_on_start',\n                 'env',\n             }\n\n---\n file path A: jina/orchestrate/deployments/config/helper.py | file path B: jina/orchestrate/deployments/config/helper.py\n\n@@ -89,7 +89,6 @@ def construct_runtime_container_args(cargs, uses_metas, uses_with, pod_type):\n         'uses_before',\n         'uses_after',\n         'workspace_id',\n-        'upload_files',\n         'noblock_on_start',\n         'env',\n     }\n\n---\n file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -69,7 +69,6 @@ class K8sDeploymentConfig:\n                 'uses_after',\n                 'workspace',\n                 'workspace_id',\n-                'upload_files',\n                 'noblock_on_start',\n                 'env',\n             }\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -856,7 +856,6 @@ class Flow(\n         py_modules: Optional[List[str]] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n-        quiet_remote_logs: Optional[bool] = False,\n         replicas: Optional[int] = 1,\n         retries: Optional[int] = -1,\n         runtime_cls: Optional[str] = 'WorkerRuntime',\n@@ -868,7 +867,6 @@ class Flow(\n         traces_exporter_host: Optional[str] = None,\n         traces_exporter_port: Optional[int] = None,\n         tracing: Optional[bool] = False,\n-        upload_files: Optional[List[str]] = None,\n         uses: Optional[Union[str, Type['BaseExecutor'], dict]] = 'BaseExecutor',\n         uses_after: Optional[Union[str, Type['BaseExecutor'], dict]] = None,\n         uses_after_address: Optional[str] = None,\n@@ -947,7 +945,6 @@ class Flow(\n           `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n-        :param quiet_remote_logs: Do not display the streaming of remote logs on local console\n         :param replicas: The number of replicas in the deployment\n         :param retries: Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas)\n         :param runtime_cls: The runtime class to run inside the Pod\n@@ -959,15 +956,6 @@ class Flow(\n         :param traces_exporter_host: If tracing is enabled, this hostname will be used to configure the trace exporter agent.\n         :param traces_exporter_port: If tracing is enabled, this port will be used to configure the trace exporter agent.\n         :param tracing: If set, the sdk implementation of the OpenTelemetry tracer will be available and will be enabled for automatic tracing of requests and customer span creation. Otherwise a no-op implementation will be provided.\n-        :param upload_files: The files on the host to be uploaded to the remote\n-          workspace. This can be useful when your Deployment has more\n-          file dependencies beyond a single YAML file, e.g.\n-          Python files, data files.\n-\n-          Note,\n-          - currently only flatten structure is supported, which means if you upload `[./foo/a.py, ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace on the remote, losing all hierarchies.\n-          - by default, `--uses` YAML file is always uploaded.\n-          - uploaded files are by default isolated across the runs. To ensure files are submitted to the same workspace across different runs, use `--workspace-id` to specify the workspace.\n         :param uses: The config of the executor, it could be one of the followings:\n                   * the string literal of an Executor class name\n                   * an Executor YAML file (.yml, .yaml, .jaml)\n@@ -1101,7 +1089,6 @@ class Flow(\n           `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n-        :param quiet_remote_logs: Do not display the streaming of remote logs on local console\n         :param replicas: The number of replicas in the deployment\n         :param retries: Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas)\n         :param runtime_cls: The runtime class to run inside the Pod\n@@ -1113,15 +1100,6 @@ class Flow(\n         :param traces_exporter_host: If tracing is enabled, this hostname will be used to configure the trace exporter agent.\n         :param traces_exporter_port: If tracing is enabled, this port will be used to configure the trace exporter agent.\n         :param tracing: If set, the sdk implementation of the OpenTelemetry tracer will be available and will be enabled for automatic tracing of requests and customer span creation. Otherwise a no-op implementation will be provided.\n-        :param upload_files: The files on the host to be uploaded to the remote\n-          workspace. This can be useful when your Deployment has more\n-          file dependencies beyond a single YAML file, e.g.\n-          Python files, data files.\n-\n-          Note,\n-          - currently only flatten structure is supported, which means if you upload `[./foo/a.py, ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace on the remote, losing all hierarchies.\n-          - by default, `--uses` YAML file is always uploaded.\n-          - uploaded files are by default isolated across the runs. To ensure files are submitted to the same workspace across different runs, use `--workspace-id` to specify the workspace.\n         :param uses: The config of the executor, it could be one of the followings:\n                   * the string literal of an Executor class name\n                   * an Executor YAML file (.yml, .yaml, .jaml)\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -22,9 +22,6 @@ def set_pod_parser(parser=None):\n     from jina.parsers.orchestrate.runtimes.container import (\n         mixin_container_runtime_parser,\n     )\n-    from jina.parsers.orchestrate.runtimes.distributed import (\n-        mixin_distributed_feature_parser,\n-    )\n     from jina.parsers.orchestrate.runtimes.remote import mixin_remote_runtime_parser\n     from jina.parsers.orchestrate.runtimes.worker import mixin_worker_runtime_parser\n \n@@ -32,7 +29,6 @@ def set_pod_parser(parser=None):\n     mixin_worker_runtime_parser(parser)\n     mixin_container_runtime_parser(parser)\n     mixin_remote_runtime_parser(parser)\n-    mixin_distributed_feature_parser(parser)\n     mixin_pod_parser(parser)\n     mixin_hub_pull_options_parser(parser)\n     mixin_head_parser(parser)\n\n---\n file path A: jina/parsers/orchestrate/runtimes/distributed.py | file path B: None\n\n@@ -1,36 +0,0 @@\n-\"\"\"Argparser module for distributed runtimes\"\"\"\n-\n-from jina.parsers.helper import add_arg_group\n-\n-\n-def mixin_distributed_feature_parser(parser):\n-    \"\"\"Mixing in arguments required by :class:`BaseDeployment` into the given parser.\n-    :param parser: the parser instance to which we add arguments\n-    \"\"\"\n-\n-    gp = add_arg_group(parser, title='Distributed')\n-\n-    gp.add_argument(\n-        '--quiet-remote-logs',\n-        action='store_true',\n-        default=False,\n-        help='Do not display the streaming of remote logs on local console',\n-    )\n-\n-    gp.add_argument(\n-        '--upload-files',\n-        type=str,\n-        nargs='*',\n-        metavar='FILE',\n-        help='''\n-The files on the host to be uploaded to the remote\n-workspace. This can be useful when your Deployment has more\n-file dependencies beyond a single YAML file, e.g.\n-Python files, data files.\n-\n-Note,\n-- currently only flatten structure is supported, which means if you upload `[./foo/a.py, ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace on the remote, losing all hierarchies.\n-- by default, `--uses` YAML file is always uploaded.\n-- uploaded files are by default isolated across the runs. To ensure files are submitted to the same workspace across different runs, use `--workspace-id` to specify the workspace.\n-''',\n-    )\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -50,8 +50,6 @@ ac_table = {\n             '--disable-auto-volume',\n             '--host',\n             '--host-in',\n-            '--quiet-remote-logs',\n-            '--upload-files',\n             '--runtime-cls',\n             '--timeout-ready',\n             '--env',\n@@ -266,8 +264,6 @@ ac_table = {\n             '--disable-auto-volume',\n             '--host',\n             '--host-in',\n-            '--quiet-remote-logs',\n-            '--upload-files',\n             '--runtime-cls',\n             '--timeout-ready',\n             '--env',\n@@ -327,8 +323,6 @@ ac_table = {\n             '--disable-auto-volume',\n             '--host',\n             '--host-in',\n-            '--quiet-remote-logs',\n-            '--upload-files',\n             '--runtime-cls',\n             '--timeout-ready',\n             '--env',\n\n---\n file path A: tests/unit/orchestrate/deployments/test_deployments.py | file path B: tests/unit/orchestrate/deployments/test_deployments.py\n\n@@ -364,92 +364,6 @@ def test_pod_args_remove_uses_ba():\n         assert p.num_pods == 2\n \n \n-@pytest.mark.parametrize('replicas', [1])\n-@pytest.mark.parametrize(\n-    'upload_files',\n-    [[os.path.join(cur_dir, __file__), os.path.join(cur_dir, '__init__.py')]],\n-)\n-@pytest.mark.parametrize(\n-    'uses, uses_before, uses_after, py_modules, expected',\n-    [\n-        (\n-            os.path.join(cur_dir, '../../yaml/dummy_ext_exec.yml'),\n-            '',\n-            '',\n-            [\n-                os.path.join(cur_dir, '../../yaml/dummy_exec.py'),\n-                os.path.join(cur_dir, '__init__.py'),\n-            ],\n-            [\n-                os.path.join(cur_dir, '../../yaml/dummy_ext_exec.yml'),\n-                os.path.join(cur_dir, '../../yaml/dummy_exec.py'),\n-                os.path.join(cur_dir, __file__),\n-                os.path.join(cur_dir, '__init__.py'),\n-            ],\n-        ),\n-        (\n-            os.path.join(cur_dir, '../../yaml/dummy_ext_exec.yml'),\n-            os.path.join(cur_dir, '../../yaml/dummy_exec.py'),\n-            os.path.join(cur_dir, '../../yaml/dummy_ext_exec.yml'),\n-            [\n-                os.path.join(cur_dir, '../../yaml/dummy_exec.py'),\n-                os.path.join(cur_dir, '../../yaml/dummy_ext_exec.yml'),\n-            ],\n-            [\n-                os.path.join(cur_dir, '../../yaml/dummy_ext_exec.yml'),\n-                os.path.join(cur_dir, '../../yaml/dummy_exec.py'),\n-                os.path.join(cur_dir, __file__),\n-                os.path.join(cur_dir, '__init__.py'),\n-            ],\n-        ),\n-        (\n-            'non_existing1.yml',\n-            'non_existing3.yml',\n-            'non_existing4.yml',\n-            ['non_existing1.py', 'non_existing2.py'],\n-            [os.path.join(cur_dir, __file__), os.path.join(cur_dir, '__init__.py')],\n-        ),\n-    ],\n-)\n-def test_pod_upload_files(\n-    replicas,\n-    upload_files,\n-    uses,\n-    uses_before,\n-    uses_after,\n-    py_modules,\n-    expected,\n-):\n-    args = set_deployment_parser().parse_args(\n-        [\n-            '--uses',\n-            uses,\n-            '--uses-before',\n-            uses_before,\n-            '--uses-after',\n-            uses_after,\n-            '--py-modules',\n-            *py_modules,\n-            '--upload-files',\n-            *upload_files,\n-            '--replicas',\n-            str(replicas),\n-        ]\n-    )\n-    pod = Deployment(args)\n-    for k, v in pod.pod_args.items():\n-        if k in ['head', 'tail']:\n-            if v:\n-                pass\n-                # assert sorted(v.upload_files) == sorted(expected)\n-        elif v is not None and k == 'pods':\n-            for shard_id in v:\n-                for pod in v[shard_id]:\n-                    print(sorted(pod.upload_files))\n-                    print(sorted(expected))\n-                    assert sorted(pod.upload_files) == sorted(expected)\n-\n-\n class DynamicPollingExecutor(Executor):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n\n\n###\n\n", "completion": "refactor: remove unused distributed args (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -520,6 +520,10 @@ def random_port() -> Optional[int]:\n         return _random_port()\n \n \n+def random_ports(n_ports):\n+    return [random_port() for _ in range(n_ports)]\n+\n+\n def random_identity(use_uuid1: bool = False) -> str:\n     \"\"\"\n     Generate random UUID.\n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -24,7 +24,7 @@ from jina.helper import (\n )\n from jina.jaml.helper import complete_path\n from jina.orchestrate.pods.factory import PodFactory\n-from jina.parsers.helper import _set_gateway_uses\n+from jina.parsers.helper import _update_gateway_args\n from jina.serve.networking import host_is_local, in_docker\n \n WRAPPED_SLICE_BASE = r'\\[[-\\d:]+\\]'\n@@ -344,7 +344,7 @@ class Deployment(BaseDeployment):\n     def update_pod_args(self):\n         \"\"\"Update args of all its pods based on Deployment args. Including head/tail\"\"\"\n         if self.args.runtime_cls == 'GatewayRuntime':\n-            _set_gateway_uses(self.args)\n+            _update_gateway_args(self.args)\n         if isinstance(self.args, Dict):\n             # This is used when a Deployment is created in a remote context, where pods & their connections are already given.\n             self.pod_args = self.args\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -617,6 +617,9 @@ class Flow(\n         args.default_port = (\n             kwargs.get('port', None) is None and kwargs.get('port_expose', None) is None\n         )\n+\n+        if not args.port:\n+            args.port = helper.random_ports(len(args.protocol))\n         args.noblock_on_start = True\n         args.graph_description = json.dumps(graph_description)\n         args.graph_conditions = json.dumps(graph_conditions)\n\n---\n file path A: jina/orchestrate/pods/__init__.py | file path B: jina/orchestrate/pods/__init__.py\n\n@@ -13,6 +13,7 @@ from jina.helper import typename\n from jina.jaml import JAML\n from jina.logging.logger import JinaLogger\n from jina.orchestrate.pods.helper import ConditionalEvent, _get_event\n+from jina.parsers.helper import _update_gateway_args\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n \n __all__ = ['BasePod', 'Pod']\n@@ -109,8 +110,8 @@ class BasePod(ABC):\n     def __init__(self, args: 'argparse.Namespace'):\n         self.args = args\n \n-        if hasattr(self.args, 'port'):\n-            self.args.port = self.args.port\n+        if self.args.pod_role == PodRoleType.GATEWAY:\n+            _update_gateway_args(self.args)\n         self.args.parallel = getattr(self.args, 'shards', 1)\n         self.name = self.args.name or self.__class__.__name__\n         self.is_forked = False\n\n---\n file path A: jina/orchestrate/pods/helper.py | file path B: jina/orchestrate/pods/helper.py\n\n@@ -7,7 +7,7 @@ from hubble.executor.helper import is_valid_huburi\n from hubble.executor.hubio import HubIO\n \n from jina.enums import PodRoleType\n-from jina.parsers.helper import _set_gateway_uses\n+from jina.parsers.helper import _update_gateway_args\n \n if TYPE_CHECKING:  # pragma: no cover\n     from argparse import Namespace\n@@ -83,7 +83,7 @@ def update_runtime_cls(args, copy=False) -> 'Namespace':\n         _args.uses = HubIO(_hub_args).pull()\n \n     if hasattr(_args, 'protocol') and _args.pod_role == PodRoleType.GATEWAY:\n-        _set_gateway_uses(_args)\n+        _update_gateway_args(_args)\n     if _args.pod_role == PodRoleType.HEAD:\n         _args.runtime_cls = 'HeadRuntime'\n \n\n---\n file path A: jina/parsers/helper.py | file path B: jina/parsers/helper.py\n\n@@ -289,6 +289,14 @@ def _set_gateway_uses(args: 'argparse.Namespace'):\n             )\n \n \n+def _update_gateway_args(args: 'argparse.Namespace'):\n+    from jina.helper import random_ports\n+\n+    if not args.port:\n+        args.port = random_ports(len(args.protocol))\n+    _set_gateway_uses(args)\n+\n+\n class CastToIntAction(argparse.Action):\n     \"\"\"argparse action to cast a list of values to int\"\"\"\n \n@@ -305,7 +313,7 @@ class CastToIntAction(argparse.Action):\n         \"\"\"\n         if isinstance(values, list):\n             d = [_port_to_int(port) for port in values]\n-        else:\n+        elif isinstance(values, str):\n             d = _port_to_int(values)\n         setattr(args, self.dest, d)\n \n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -137,7 +137,7 @@ def mixin_pod_runtime_args_parser(arg_group, pod_type='worker'):\n             action=CastToIntAction,\n             type=str,\n             nargs='+',\n-            default=[helper.random_port()],\n+            default=None,\n             help=port_description,\n         )\n \n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -8,7 +8,7 @@ from jina import __default_host__\n from jina.enums import GatewayProtocolType\n from jina.excepts import PortAlreadyUsed\n from jina.helper import is_port_free\n-from jina.parsers.helper import _set_gateway_uses\n+from jina.parsers.helper import _update_gateway_args\n from jina.serve.gateway import BaseGateway\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n \n@@ -44,7 +44,7 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n         self.timeout_send = args.timeout_send\n         if self.timeout_send:\n             self.timeout_send /= 1e3  # convert ms to seconds\n-        _set_gateway_uses(args)\n+        _update_gateway_args(args)\n         super().__init__(args, cancel_event, **kwargs)\n \n     async def async_setup(self):\n\n---\n file path A: jina_cli/api.py | file path B: jina_cli/api.py\n\n@@ -1,6 +1,6 @@\n from typing import TYPE_CHECKING\n \n-from jina.parsers.helper import _set_gateway_uses\n+from jina.parsers.helper import _update_gateway_args\n \n if TYPE_CHECKING:\n     from argparse import Namespace\n@@ -103,7 +103,7 @@ def gateway(args: 'Namespace'):\n     \"\"\"\n     from jina.serve.runtimes import get_runtime\n \n-    _set_gateway_uses(args)\n+    _update_gateway_args(args)\n \n     runtime_cls = get_runtime('GatewayRuntime')\n \n\n---\n file path A: tests/integration/pods/container/gateway-runtime/runtime.py | file path B: tests/integration/pods/container/gateway-runtime/runtime.py\n\n@@ -1,7 +1,7 @@\n import sys\n \n from jina.parsers import set_gateway_parser\n-from jina.parsers.helper import _set_gateway_uses\n+from jina.parsers.helper import _update_gateway_args\n from jina.serve.runtimes.gateway import GatewayRuntime\n \n \n@@ -10,7 +10,7 @@ def run(*args, **kwargs):\n     print(f' args {args}')\n     runtime_args = set_gateway_parser().parse_args(args)\n     print(f' protocol {runtime_args.protocol}')\n-    _set_gateway_uses(runtime_args)\n+    _update_gateway_args(runtime_args)\n \n     print(f' runtime_cls {runtime_cls}')\n     with runtime_cls(runtime_args) as runtime:\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_multiprotocol.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_multiprotocol.py\n\n@@ -46,6 +46,46 @@ def test_flow_multiprotocol(ports, protocols):\n                 assert doc.text == 'processed'\n \n \n+@pytest.mark.parametrize(\n+    'protocols',\n+    [\n+        list(protocols)\n+        for protocols in itertools.chain(\n+            itertools.combinations(PROTOCOLS, r=3),\n+            itertools.combinations(PROTOCOLS, r=2),\n+        )\n+    ],\n+)\n+def test_flow_multiprotocol_default_random_ports(protocols):\n+    flow = Flow().config_gateway(protocol=protocols).add(uses=MyExecutor)\n+\n+    with flow:\n+        for port, protocol in zip(flow.port, protocols):\n+            client = Client(port=port, protocol=protocol)\n+            docs = client.post('/', inputs=[Document()])\n+            for doc in docs:\n+                assert doc.text == 'processed'\n+\n+\n+@pytest.mark.parametrize(\n+    'protocols',\n+    [\n+        ['grpc'],\n+        ['http'],\n+        ['websocket'],\n+    ],\n+)\n+def test_flow_single_protocol_default_random_port(protocols):\n+    flow = Flow().config_gateway(protocol=protocols).add(uses=MyExecutor)\n+\n+    with flow:\n+        for protocol in protocols:\n+            client = Client(port=flow.port, protocol=protocol)\n+            docs = client.post('/', inputs=[Document()])\n+            for doc in docs:\n+                assert doc.text == 'processed'\n+\n+\n def test_flow_multiprotocol_aliases():\n     ports = [random_port(), random_port(), random_port()]\n     protocols = PROTOCOLS\n\n---\n file path A: tests/unit/parsers/peapods/runtimes/test_port_protocol_parser.py | file path B: tests/unit/parsers/peapods/runtimes/test_port_protocol_parser.py\n\n@@ -63,7 +63,7 @@ def test_pod_port_cast():\n \n def test_default_port_protocol_gateway():\n     args = set_gateway_parser().parse_args([])\n-    assert len(args.port) == 1\n+    assert args.port is None\n     assert args.protocol == [GatewayProtocolType.GRPC]\n \n \n\n\n###\n\n", "completion": "feat: generate random ports for multiple protocol (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/gateway-args.md | file path B: docs/fundamentals/flow/gateway-args.md\n\n@@ -19,7 +19,7 @@\n | `ssl_certfile` | the path to the certificate file | `string` | `None` |\n | `ssl_keyfile` | the path to the key file | `string` | `None` |\n | `expose_graphql_endpoint` | If set, /graphql endpoint is added to HTTP interface. | `boolean` | `False` |\n-| `protocol` | Possible communication protocols between server and client. Depending on your chosen gateway, choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET']. | `array` | `[<GatewayProtocolType.GRPC: 0>]` |\n+| `protocol` | Communication protocol of the server exposed by the Gateway. This can be a single value or a list of protocols, depending on your chosen Gateway. Choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET']. | `array` | `[<GatewayProtocolType.GRPC: 0>]` |\n | `host` | The host address of the runtime, by default it is 0.0.0.0. In the case of an external Executor (`--external` or `external=True`) this can be a list of hosts, separated by commas. Then, every resulting address will be considered as one replica of the Executor. | `string` | `0.0.0.0` |\n | `proxy` | If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy | `boolean` | `False` |\n | `uses` | The config of the gateway, it could be one of the followings:<br>        * the string literal of an Gateway class name<br>        * a Gateway YAML file (.yml, .yaml, .jaml)<br>        * a docker image (must start with `docker://`)<br>        * the string literal of a YAML config (must start with `!` or `jtype: `)<br>        * the string literal of a JSON config<br><br>        When use it under Python, one can use the following values additionally:<br>        - a Python dict that represents the config<br>        - a text file stream has `.read()` interface | `string` | `None` |\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -247,7 +247,7 @@ class Flow(\n         :param prefetch: Number of requests fetched from the client before feeding into the first Executor.\n \n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n-        :param protocol: Possible communication protocols between server and client. Depending on your chosen gateway, choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n+        :param protocol: Communication protocol of the server exposed by the Gateway. This can be a single value or a list of protocols, depending on your chosen Gateway. Choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n         :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n         :param py_modules: The customized python modules need to be imported before loading the gateway\n \n@@ -417,7 +417,7 @@ class Flow(\n         :param prefetch: Number of requests fetched from the client before feeding into the first Executor.\n \n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n-        :param protocol: Possible communication protocols between server and client. Depending on your chosen gateway, choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n+        :param protocol: Communication protocol of the server exposed by the Gateway. This can be a single value or a list of protocols, depending on your chosen Gateway. Choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n         :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n         :param py_modules: The customized python modules need to be imported before loading the gateway\n \n@@ -1332,7 +1332,7 @@ class Flow(\n         :param prefetch: Number of requests fetched from the client before feeding into the first Executor.\n \n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n-        :param protocol: Possible communication protocols between server and client. Depending on your chosen gateway, choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n+        :param protocol: Communication protocol of the server exposed by the Gateway. This can be a single value or a list of protocols, depending on your chosen Gateway. Choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n         :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n         :param py_modules: The customized python modules need to be imported before loading the gateway\n \n@@ -1426,7 +1426,7 @@ class Flow(\n         :param prefetch: Number of requests fetched from the client before feeding into the first Executor.\n \n               Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default)\n-        :param protocol: Possible communication protocols between server and client. Depending on your chosen gateway, choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n+        :param protocol: Communication protocol of the server exposed by the Gateway. This can be a single value or a list of protocols, depending on your chosen Gateway. Choose the convenient protocols from: ['GRPC', 'HTTP', 'WEBSOCKET'].\n         :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n         :param py_modules: The customized python modules need to be imported before loading the gateway\n \n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -124,6 +124,11 @@ def mixin_pod_runtime_args_parser(arg_group, pod_type='worker'):\n             help=port_description,\n         )\n     else:\n+        port_description = (\n+            'The port for input data to bind the gateway server to, by default, random ports between range [49152, 65535] will be assigned. '\n+            'The port argument can be either 1 single value in case only 1 protocol is used or multiple values when '\n+            'many protocols are used.'\n+        )\n         arg_group.add_argument(\n             '--port',\n             '--port-expose',\n\n---\n file path A: jina/parsers/orchestrate/runtimes/remote.py | file path B: jina/parsers/orchestrate/runtimes/remote.py\n\n@@ -161,7 +161,7 @@ def mixin_gateway_protocol_parser(parser):\n         type=GatewayProtocolType.from_string,\n         choices=list(GatewayProtocolType),\n         default=[GatewayProtocolType.GRPC],\n-        help=f'Possible communication protocols between server and client. Depending on your chosen gateway, choose the convenient protocols from: {[protocol.to_string() for protocol in list(GatewayProtocolType)]}.',\n+        help=f'Communication protocol of the server exposed by the Gateway. This can be a single value or a list of protocols, depending on your chosen Gateway. Choose the convenient protocols from: {[protocol.to_string() for protocol in list(GatewayProtocolType)]}.',\n     )\n \n \n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -213,6 +213,7 @@ ac_table = {\n         'cloud login': ['--help'],\n         'cloud logout': ['--help'],\n         'cloud deploy': ['--help'],\n+        'cloud normalize': ['--help'],\n         'cloud list': ['--help', '--phase', '--name'],\n         'cloud status': ['--help', '--verbose'],\n         'cloud remove': ['--help'],\n@@ -225,6 +226,7 @@ ac_table = {\n             'login',\n             'logout',\n             'deploy',\n+            'normalize',\n             'list',\n             'status',\n             'remove',\n\n\n###\n\n", "completion": "docs: fix port and protocol description for the gateway (#<issue-num>)"}
{"prompt": " file path A: docs/correct_some_requirements.sh | file path B: docs/correct_some_requirements.sh\n\n@@ -3,4 +3,5 @@\n grep -rl 'opentelemetry-exporter-prometheus' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-prometheus==1.12.0/opentelemetry-exporter-prometheus==1.12.0rc1/g'\n grep -rl 'opentelemetry-exporter-otlp-proto-grpc' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-otlp-proto-grpc==1.13.0/opentelemetry-exporter-otlp-proto-grpc==1.12.0/g'\n grep -rl 'opentelemetry-sdk' extra-requirements.txt | xargs sed -i 's/opentelemetry-sdk>=1.12.0/opentelemetry-sdk>=1.14.0/g'\n+grep -rl 'opentelemetry-semantic-conventions' extra-requirements.txt | xargs sed -i '/opentelemetry-semantic-conventions/d'\n grep -rl 'pyyaml' extra-requirements.txt | xargs sed -i 's/pyyaml==5.3.1/pyyaml==5.4.1/g'\n\n---\n file path A: docs/correct_some_requirements.sh | file path B: docs/correct_some_requirements.sh\n\n@@ -3,4 +3,5 @@\n grep -rl 'opentelemetry-exporter-prometheus' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-prometheus==1.12.0/opentelemetry-exporter-prometheus==1.12.0rc1/g'\n grep -rl 'opentelemetry-exporter-otlp-proto-grpc' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-otlp-proto-grpc==1.13.0/opentelemetry-exporter-otlp-proto-grpc==1.12.0/g'\n grep -rl 'opentelemetry-sdk' extra-requirements.txt | xargs sed -i 's/opentelemetry-sdk>=1.12.0/opentelemetry-sdk>=1.14.0/g'\n+grep -rl 'opentelemetry-semantic-conventions' extra-requirements.txt | xargs sed -i 'opentelemetry-semantic-conventions/d'\n grep -rl 'pyyaml' extra-requirements.txt | xargs sed -i 's/pyyaml==5.3.1/pyyaml==5.4.1/g'\n\n\n###\n\n", "completion": "ci: change script to build old docs"}
{"prompt": " file path A: docs/correct_some_requirements.sh | file path B: docs/correct_some_requirements.sh\n\n@@ -2,4 +2,5 @@\n \n grep -rl 'opentelemetry-exporter-prometheus' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-prometheus==1.12.0/opentelemetry-exporter-prometheus==1.12.0rc1/g'\n grep -rl 'opentelemetry-exporter-otlp-proto-grpc' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-otlp-proto-grpc==1.13.0/opentelemetry-exporter-otlp-proto-grpc==1.12.0/g'\n+grep -rl 'opentelemetry-sdk' extra-requirements.txt | xargs sed -i 's/opentelemetry-sdk>=1.12.0/opentelemetry-sdk>=1.14.0/g'\n grep -rl 'pyyaml' extra-requirements.txt | xargs sed -i 's/pyyaml==5.3.1/pyyaml==5.4.1/g'\n\n\n###\n\n", "completion": "chore: fix old docs script (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -39,7 +39,7 @@ opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n uvloop:                     perf,standard,devel\n prometheus_client>=0.12.0:          perf,standard,devel\n-opentelemetry-sdk>=1.12.0:   perf,standard,devel\n+opentelemetry-sdk>=1.14.0:   perf,standard,devel\n opentelemetry-exporter-otlp>=1.12.0:  perf,standard,devel\n opentelemetry-exporter-prometheus>=1.12.0rc1:  perf,standard,devel\n opentelemetry-instrumentation-aiohttp-client>=0.33b0:    perf,standard,devel\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -39,7 +39,7 @@ opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n uvloop:                     perf,standard,devel\n prometheus_client>=0.12.0:          perf,standard,devel\n-opentelemetry-sdk>=1.12.0:   perf,standard,devel\n+opentelemetry-sdk>=1.14.0:   perf,standard,devel\n opentelemetry-exporter-otlp>=1.12.0:  perf,standard,devel\n opentelemetry-exporter-prometheus>=1.12.0rc1:  perf,standard,devel\n opentelemetry-instrumentation-aiohttp-client>=0.33b0:    perf,standard,devel\n\n\n###\n\n", "completion": "fix: cap opentelemetry-instrumentation-aiohttp-client incompatible wh\u2026 (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -42,7 +42,6 @@ prometheus_client>=0.12.0:          perf,standard,devel\n opentelemetry-sdk>=1.12.0:   perf,standard,devel\n opentelemetry-exporter-otlp>=1.12.0:  perf,standard,devel\n opentelemetry-exporter-prometheus>=1.12.0rc1:  perf,standard,devel\n-opentelemetry-semantic-conventions>=0.33b0:    perf,standard,devel\n opentelemetry-instrumentation-aiohttp-client>=0.33b0:    perf,standard,devel\n opentelemetry-instrumentation-fastapi>=0.33b0: perf,standard,devel\n opentelemetry-exporter-otlp-proto-grpc>=1.13.0: perf,standrad,devel\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -42,7 +42,6 @@ prometheus_client>=0.12.0:          perf,standard,devel\n opentelemetry-sdk>=1.12.0:   perf,standard,devel\n opentelemetry-exporter-otlp>=1.12.0:  perf,standard,devel\n opentelemetry-exporter-prometheus>=1.12.0rc1:  perf,standard,devel\n-opentelemetry-semantic-conventions>=0.33b0:    perf,standard,devel\n opentelemetry-instrumentation-aiohttp-client>=0.33b0:    perf,standard,devel\n opentelemetry-instrumentation-fastapi>=0.33b0: perf,standard,devel\n opentelemetry-exporter-otlp-proto-grpc>=1.13.0: perf,standrad,devel\n\n\n###\n\n", "completion": "ci: remove otel-semantic-convention (#<issue-num>)"}
{"prompt": " file path A: jina/importer.py | file path B: jina/importer.py\n\n@@ -147,8 +147,10 @@ class PathImporter:\n             if not os.path.isfile(path):\n                 try:\n                     importlib.import_module(path)\n-                except:\n+                except ModuleNotFoundError:\n                     not_python_module_paths.append(path)\n+                except:\n+                    raise\n             else:\n                 not_python_module_paths.append(path)\n \n\n---\n file path A: tests/unit/test_importer.py | file path B: tests/unit/test_importer.py\n\n@@ -48,3 +48,15 @@ def test_no_suppress_other_exception():\n     with pytest.raises(Exception):\n         with ImportExtensions(required=True, logger=default_logger):\n             raise Exception\n+\n+\n+def test_path_importer(tmpdir):\n+    tmpmodule = f'package.py'\n+    with open(tmpdir / tmpmodule, 'w') as f:\n+        f.write(\"raise ImportError\")\n+\n+    from jina.importer import PathImporter\n+    with pytest.raises(ImportError):\n+        PathImporter.add_modules(tmpdir / tmpmodule)\n+    with pytest.raises(FileNotFoundError):\n+        PathImporter.add_modules('some_package.py')\n\\ No newline at end of file\n\n\n###\n\n", "completion": "fix: raise exceptions in path importer (#<issue-num>)"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.11.1'\n+__version__ = '3.12.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: update jina version (#<issue-num>)"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -61,16 +61,14 @@ Applications built with Jina enjoy the following features out of the box:\n </thead>\n <tbody>\n   <tr>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udcd7 What is Jina?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#relation-to-mlops\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd0d Is Jina MLOps for search?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/comparing-alternatives/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udd9a How Jina compares to alternatives?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#why-cloud-native\" target=\"_blank\" rel=\"noopener noreferrer\">\u2601\ufe0f What is Cloud-Native?</a></td>\n+    <td><a href=\"https://jina.ai/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udcd7 What is Jina?</a></td>\n+    <td><a href=\"https://jina.ai/news/five-most-trending-open-source-mlops-tools-of-2022/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd0d Is Jina MLOps for search?</a></td>\n+    <td><a href=\"https://jina.ai/news/cloud-native-helps-you-build-multimodal-ai-in-production-here-is-how/\" target=\"_blank\" rel=\"noopener noreferrer\">\u2601\ufe0f What is Cloud-Native?</a></td>\n   </tr>\n   <tr>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd2e What is cross-modal and multimodal\uff1f</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#neural-search\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83e\uddec What is neural search?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#creative-ai\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udfa8 What is creative AI?</a></td>\n-    <td></td>\n+    <td><a href=\"https://jina.ai/news/what-is-multimodal-deep-learning-and-what-are-the-applications/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd2e What is cross-modal and multimodal\uff1f</a></td>\n+    <td><a href=\"https://jina.ai/news/what-is-neural-search-and-learn-to-build-a-neural-search-engine/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83e\uddec What is neural search?</a></td>\n+    <td><a href=\"https://jina.ai/news/paradigm-shift-towards-multimodal-ai/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udfa8 What is creative AI?</a></td>\n   </tr>\n </tbody>\n </table>\n\n\n###\n\n", "completion": "chore: update README (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -2113,7 +2113,9 @@ class Flow(\n         if GATEWAY_NAME in self._deployment_nodes:\n             res = self._deployment_nodes[GATEWAY_NAME].port\n         else:\n-            res = self._gateway_kwargs.get('port', None)\n+            res = self._gateway_kwargs.get('port', None) or self._gateway_kwargs.get(\n+                'ports', None\n+            )\n         if not isinstance(res, list):\n             return res\n         elif len(res) == 1:\n@@ -2399,7 +2401,11 @@ class Flow(\n \n         :return: the protocol of this Flow, if only 1 protocol is supported otherwise returns the list of protocols\n         \"\"\"\n-        v = self._gateway_kwargs.get('protocol', [GatewayProtocolType.GRPC])\n+        v = (\n+            self._gateway_kwargs.get('protocol', None)\n+            or self._gateway_kwargs.get('protocols', None)\n+            or [GatewayProtocolType.GRPC]\n+        )\n         if not isinstance(v, list):\n             v = [v]\n         v = GatewayProtocolType.from_string_list(v)\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow.py\n\n@@ -620,6 +620,17 @@ def test_load_flow_with_custom_gateway(tmpdir):\n         _validate_flow(f)\n \n \n+@pytest.mark.slow\n+def test_flow_multi_protocol_aliases():\n+    f = Flow(ports=[12345, 12345, 12345], protocols=['http', 'grpc', 'websocket'])\n+    assert f.port == [12345, 12345, 12345]\n+    assert f.protocol == [\n+        GatewayProtocolType.HTTP,\n+        GatewayProtocolType.GRPC,\n+        GatewayProtocolType.WEBSOCKET,\n+    ]\n+\n+\n def _validate_flow(f):\n     graph_dict = f._get_graph_representation()\n     addresses = f._get_deployments_addresses()\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_multiprotocol.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_multiprotocol.py\n\n@@ -46,6 +46,19 @@ def test_flow_multiprotocol(ports, protocols):\n                 assert doc.text == 'processed'\n \n \n+def test_flow_multiprotocol_aliases():\n+    ports = [random_port(), random_port(), random_port()]\n+    protocols = PROTOCOLS\n+    flow = Flow().config_gateway(ports=ports, protocols=protocols).add(uses=MyExecutor)\n+\n+    with flow:\n+        for port, protocol in zip(ports, protocols):\n+            client = Client(port=port, protocol=protocol)\n+            docs = client.post('/', inputs=[Document()])\n+            for doc in docs:\n+                assert doc.text == 'processed'\n+\n+\n def test_flow_multiprotocol_yaml():\n     flow = Flow.load_config(os.path.join(cur_dir, 'yaml/multi-protocol.yml'))\n \n\n\n###\n\n", "completion": "fix: fix multi protocol gateway when using ports and protocols aliases (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -137,7 +137,46 @@ with:\n ```\n \n ````\n+## Serve multiple protocols at the same time:\n+You can use multiple protocols in the same gateway, serve your Flow using multiple protocols and bind it \n+to several ports:\n \n+````{tab} Python\n+```{code-block} python\n+---\n+emphasize-lines: 2\n+---\n+from jina import Flow\n+flow = Flow(port=[12345, 12344, 12343], protocol=['grpc', 'http', 'websocket'])\n+with flow:\n+    flow.block()\n+```\n+````\n+\n+````{tab} YAML\n+```{code-block yaml}\n+jtype: Flow\n+with:\n+  protocol:\n+    - 'grpc'\n+    - 'http'\n+    - 'websocket'\n+  port:\n+    - 12345\n+    - 12344\n+    - 12343\n+```\n+````\n+\n+```{figure} multi-protocol-flow.png\n+:width: 70%\n+```\n+\n+```{admonition} Important\n+:class: important\n+\n+In case you want to serve a Flow using multiple protocols, make sure to specify as much ports as protocols used. \n+```\n \n (custom-http)=\n ## Customize HTTP interface\n\n---\n file path A: docs/fundamentals/gateway/multi-protocol-flow.png | file path B: docs/fundamentals/gateway/multi-protocol-flow.png\n\nBinary files /dev/null and b/docs/fundamentals/gateway/multi-protocol-flow.png differ\n\n---\n file path A: jina/parsers/helper.py | file path B: jina/parsers/helper.py\n\n@@ -262,18 +262,30 @@ class _ColoredHelpFormatter(argparse.ArgumentDefaultsHelpFormatter):\n         return lines\n \n \n-def _set_gateway_uses(args: 'argparse.Namespace'):\n+def _get_gateway_class(protocol):\n+    from jina.serve.runtimes.gateway.grpc import GRPCGateway\n+    from jina.serve.runtimes.gateway.http import HTTPGateway\n+    from jina.serve.runtimes.gateway.websocket import WebSocketGateway\n+\n     gateway_dict = {\n-        GatewayProtocolType.GRPC: 'GRPCGateway',\n-        GatewayProtocolType.WEBSOCKET: 'WebSocketGateway',\n-        GatewayProtocolType.HTTP: 'HTTPGateway',\n+        GatewayProtocolType.GRPC: GRPCGateway,\n+        GatewayProtocolType.WEBSOCKET: WebSocketGateway,\n+        GatewayProtocolType.HTTP: HTTPGateway,\n     }\n+    return gateway_dict[protocol]\n+\n+\n+def _set_gateway_uses(args: 'argparse.Namespace'):\n     if not args.uses:\n-        if len(args.protocol) == 1:\n-            args.uses = gateway_dict[args.protocol[0]]\n+        if len(args.protocol) == 1 and len(args.port) == 1:\n+            args.uses = _get_gateway_class(args.protocol[0]).__name__\n+        elif len(args.protocol) == len(args.port):\n+            from jina.serve.runtimes.gateway.composite import CompositeGateway\n+\n+            args.uses = CompositeGateway.__name__\n         else:\n             raise ValueError(\n-                'You need to specify exactly 1 protocol if you want to use a jina built-in gateway'\n+                'You need to specify as much protocols as ports if you want to use a jina built-in gateway'\n             )\n \n \n\n---\n file path A: jina/serve/gateway.py | file path B: jina/serve/gateway.py\n\n@@ -145,6 +145,13 @@ class BaseGateway(JAMLCompatible, metaclass=GatewayType):\n         \"\"\"\n         return self.runtime_args.port\n \n+    @property\n+    def protocols(self):\n+        \"\"\"Gets all the list of protocols from the runtime_args as a list.\n+        :return: The lists of protocols to be exposed\n+        \"\"\"\n+        return self.runtime_args.protocol\n+\n     @property\n     def host(self):\n         \"\"\"Gets the host from the runtime_args\n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -17,6 +17,7 @@ if TYPE_CHECKING:  # pragma: no cover\n     import threading\n \n # Keep these imports even if not used, since YAML parser needs to find them in imported modules\n+from jina.serve.runtimes.gateway.composite import CompositeGateway\n from jina.serve.runtimes.gateway.grpc import GRPCGateway\n from jina.serve.runtimes.gateway.http import HTTPGateway\n from jina.serve.runtimes.gateway.websocket import WebSocketGateway\n\n---\n file path A: None | file path B: jina/serve/runtimes/gateway/composite/__init__.py\n\n@@ -0,0 +1,3 @@\n+from jina.serve.runtimes.gateway.composite.gateway import CompositeGateway\n+\n+__all__ = ['CompositeGateway']\n\n---\n file path A: None | file path B: jina/serve/runtimes/gateway/composite/gateway.py\n\n@@ -0,0 +1,54 @@\n+import copy\n+from typing import List, Optional\n+\n+from jina.serve.gateway import BaseGateway\n+\n+\n+class CompositeGateway(BaseGateway):\n+    \"\"\"GRPC Gateway implementation\"\"\"\n+\n+    def __init__(\n+        self,\n+        **kwargs,\n+    ):\n+        \"\"\"Initialize the gateway\n+        :param kwargs: keyword args\n+        \"\"\"\n+        super().__init__(**kwargs)\n+\n+        from jina.parsers.helper import _get_gateway_class\n+\n+        self.gateways: List[BaseGateway] = []\n+        for port, protocol in zip(self.ports, self.protocols):\n+            gateway_cls = _get_gateway_class(protocol)\n+            runtime_args = copy.deepcopy(self.runtime_args)\n+            runtime_args.port = [port]\n+            runtime_args.protocol = [protocol]\n+            gateway_kwargs = copy.deepcopy(kwargs)\n+            gateway_kwargs['runtime_args'] = dict(vars(runtime_args))\n+            gateway = gateway_cls(**gateway_kwargs)\n+            self.gateways.append(gateway)\n+\n+    async def setup_server(self):\n+        \"\"\"\n+        setup GRPC server\n+        \"\"\"\n+        for gateway in self.gateways:\n+            await gateway.setup_server()\n+\n+    async def shutdown(self):\n+        \"\"\"Free other resources allocated with the server, e.g, gateway object, ...\"\"\"\n+        for gateway in self.gateways:\n+            await gateway.shutdown()\n+\n+    async def run_server(self):\n+        \"\"\"Run GRPC server forever\"\"\"\n+        for gateway in self.gateways:\n+            await gateway.run_server()\n+\n+    @property\n+    def _should_exit(self) -> bool:\n+        should_exit_values = [\n+            getattr(gateway.server, 'should_exit', True) for gateway in self.gateways\n+        ]\n+        return all(should_exit_values)\n\n---\n file path A: tests/integration/multiple_protocol_gateway/test_multiple_protocols_gateway.py | file path B: tests/integration/multiple_protocol_gateway/test_multiple_protocols_gateway.py\n\n@@ -51,14 +51,3 @@ def test_multiple_protocols_gateway(multi_port_gateway_docker_image_built, uses)\n         resp = requests.get(f'http://localhost:{http_port}').json()\n         assert resp['protocol'] == 'http'\n         assert AsyncNewLoopRuntime.is_ready(f'localhost:{grpc_port}')\n-\n-\n-def test_multiple_protocol_disallowed_for_builtin_gateways():\n-    flow = Flow().config_gateway(protocol=['http', 'grpc'])\n-    with pytest.raises(ValueError) as error_info:\n-        with flow:\n-            pass\n-    assert (\n-        'You need to specify exactly 1 protocol if you want to use a jina built-in gateway'\n-        in str(error_info.value)\n-    )\n\n---\n file path A: None | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_multiprotocol.py\n\n@@ -0,0 +1,67 @@\n+import itertools\n+import os.path\n+\n+import pytest\n+from docarray import Document, DocumentArray\n+\n+from jina import Client, Executor, Flow, requests\n+from jina.helper import random_port\n+\n+PROTOCOLS = ['grpc', 'http', 'websocket']\n+cur_dir = os.path.dirname(__file__)\n+\n+\n+class MyExecutor(Executor):\n+    @requests\n+    def foo(self, docs: DocumentArray, **kwargs):\n+        for doc in docs:\n+            doc.text = 'processed'\n+\n+\n+@pytest.mark.parametrize(\n+    'ports,protocols',\n+    [\n+        *[\n+            ([random_port(), random_port(), random_port()], list(protocols))\n+            for protocols in itertools.combinations(PROTOCOLS, r=3)\n+        ],\n+        *[\n+            ([random_port(), random_port()], list(protocols))\n+            for protocols in itertools.combinations(PROTOCOLS, r=2)\n+        ],\n+        *[\n+            ([random_port()], list(protocols))\n+            for protocols in itertools.combinations(PROTOCOLS, r=1)\n+        ],\n+    ],\n+)\n+def test_flow_multiprotocol(ports, protocols):\n+    flow = Flow().config_gateway(port=ports, protocol=protocols).add(uses=MyExecutor)\n+\n+    with flow:\n+        for port, protocol in zip(ports, protocols):\n+            client = Client(port=port, protocol=protocol)\n+            docs = client.post('/', inputs=[Document()])\n+            for doc in docs:\n+                assert doc.text == 'processed'\n+\n+\n+def test_flow_multiprotocol_yaml():\n+    flow = Flow.load_config(os.path.join(cur_dir, 'yaml/multi-protocol.yml'))\n+\n+    with flow:\n+        for port, protocol in zip([12345, 12344, 12343], ['grpc', 'http', 'websocket']):\n+            client = Client(port=port, protocol=protocol)\n+            client.post('/', inputs=[Document()])\n+\n+\n+def test_flow_multiprotocol_ports_protocols_mismatch():\n+    flow = Flow().config_gateway(port=[random_port()], protocol=['grpc', 'http'])\n+    with pytest.raises(ValueError) as err_info:\n+        with flow:\n+            pass\n+\n+    assert (\n+        'You need to specify as much protocols as ports if you want to use a jina built-in gateway'\n+        in err_info.value.args[0]\n+    )\n\n---\n file path A: None | file path B: tests/unit/orchestrate/flow/flow-construct/yaml/multi-protocol.yml\n\n@@ -0,0 +1,10 @@\n+jtype: Flow\n+with:\n+  protocol:\n+    - 'grpc'\n+    - 'http'\n+    - 'websocket'\n+  port:\n+    - 12345\n+    - 12344\n+    - 12343\n\n\n###\n\n", "completion": "feat: add builtin multiprotocol gateway (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/graph/topology_graph.py | file path B: jina/serve/runtimes/gateway/graph/topology_graph.py\n\n@@ -147,7 +147,7 @@ class TopologyGraph:\n \n                     # avoid sending to executor which does not bind to this endpoint\n                     if endpoint is not None and executor_endpoint_mapping is not None:\n-                        if (\n+                        if (self.name in executor_endpoint_mapping and\n                             endpoint not in executor_endpoint_mapping[self.name]\n                             and __default_endpoint__\n                             not in executor_endpoint_mapping[self.name]\n\n---\n file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -7,6 +7,7 @@ import grpc.aio\n from docarray import DocumentArray\n from jina.excepts import InternalNetworkError\n from jina.helper import GATEWAY_NAME\n+from jina.logging.logger import JinaLogger\n from jina.serve.networking import GrpcConnectionPool\n from jina.serve.runtimes.gateway.graph.topology_graph import TopologyGraph\n from jina.serve.runtimes.helper import _is_param_for_specific_executor\n@@ -35,10 +36,12 @@ class GatewayRequestHandler(MonitoringRequestMixin):\n         metrics_registry: Optional['CollectorRegistry'] = None,\n         meter: Optional['Meter'] = None,\n         runtime_name: Optional[str] = None,\n+        logger: Optional[JinaLogger] = None,\n     ):\n         super().__init__(metrics_registry, meter, runtime_name)\n         self._executor_endpoint_mapping = None\n         self._gathering_endpoints = False\n+        self.logger = logger or JinaLogger(self.__class__.__name__)\n \n     def handle_request(\n         self, graph: 'TopologyGraph', connection_pool: 'GrpcConnectionPool'\n@@ -63,11 +66,14 @@ class GatewayRequestHandler(MonitoringRequestMixin):\n                 if err_code == grpc.StatusCode.UNAVAILABLE:\n                     err._details = (\n                         err.details()\n-                        + f' |Gateway: Communication error with deployment at address(es) {err.dest_addr}. Head or worker(s) may be down.'\n+                        + f' |Gateway: Communication error while gathering endpoints with deployment at address(es) {err.dest_addr}. Head or worker(s) may be down.'\n                     )\n                     raise err\n                 else:\n                     raise\n+            except Exception as exc:\n+                self.logger.error(f' Error gathering endpoints: {exc}')\n+                raise exc\n \n             self._executor_endpoint_mapping = {}\n             for node, (endp, _) in zip(nodes, endpoints):\n@@ -205,7 +211,7 @@ class GatewayRequestHandler(MonitoringRequestMixin):\n             :return: Returns a request to be returned to the client\n             \"\"\"\n             for route in result.routes:\n-                if route.executor == 'gateway':\n+                if route.executor == GATEWAY_NAME:\n                     route.end_time.GetCurrentTime()\n \n             self._update_end_request_metrics(result)\n\n\n###\n\n", "completion": "fix: protect when deployment not in gathering endpoints dictionary (#<issue-num>)"}
{"prompt": " file path A: docs/index.md | file path B: docs/index.md\n\n@@ -116,14 +116,6 @@ Check out more in-depth tutorials on the advanced usages of Jina.\n :end-before: <!-- end support-pitch -->\n ```\n \n-```{toctree}\n-:caption: Introduction\n-:hidden:\n-\n-get-started/what-is-cross-modal-multi-modal\n-get-started/what-is-jina\n-get-started/comparing-alternatives\n-```\n \n ```{toctree}\n :caption: Get Started\n@@ -144,15 +136,14 @@ fundamentals/gateway/index\n fundamentals/client/client\n fundamentals/k8s\n fundamentals/docaray-dependency/index\n-jina-ai-cloud/index\n how-to/index\n-\n ```\n \n ```{toctree}\n :caption: Cloud Native\n :hidden:\n \n+jina-ai-cloud/index\n cloud-nativeness/k8s\n cloud-nativeness/docker-compose\n cloud-nativeness/opentelemetry\n\n\n###\n\n", "completion": "docs: remove 3 off-topic articles"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -50,7 +50,6 @@ fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n-cryptography:               standard,devel\n filelock:                   standard,devel\n requests:                   standard,devel\n websockets:                 standard,devel\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -50,7 +50,6 @@ fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n-cryptography:               standard,devel\n filelock:                   standard,devel\n requests:                   standard,devel\n websockets:                 standard,devel\n\n\n###\n\n", "completion": "chore: test ci without crypto dependency (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/k8slib/kubernetes_tools.py | file path B: jina/orchestrate/deployments/config/k8slib/kubernetes_tools.py\n\n@@ -59,7 +59,7 @@ def _get_configmap_yaml(template: str, params: Dict):\n     config_map['metadata']['namespace'] = params.get('namespace')\n     if params.get('data'):\n         for key, value in params['data'].items():\n-            config_map['data'][key] = value\n+            config_map['data'][key] = str(value)\n     return config_map\n \n \n\n\n###\n\n", "completion": "fix: dump env vars as str to k8s (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.24.1:    core\n+jina-hubble-sdk>=0.26.4:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.24.1:    core\n+jina-hubble-sdk>=0.26.4:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.35b0:  core \n\n\n###\n\n", "completion": "chore: bump hubble sdk (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/graph/topology_graph.py | file path B: jina/serve/runtimes/gateway/graph/topology_graph.py\n\n@@ -13,6 +13,7 @@ from jina.serve.networking import GrpcConnectionPool\n from jina.serve.runtimes.helper import _parse_specific_params\n from jina.serve.runtimes.worker.request_handling import WorkerRequestHandler\n from jina.types.request.data import DataRequest\n+from jina.logging.logger import JinaLogger\n \n \n class TopologyGraph:\n@@ -39,6 +40,7 @@ class TopologyGraph:\n             reduce: bool = True,\n             timeout_send: Optional[float] = None,\n             retries: Optional[int] = -1,\n+            logger: Optional[JinaLogger] = None,\n         ):\n             self.name = name\n             self.outgoing_nodes = []\n@@ -54,6 +56,7 @@ class TopologyGraph:\n             self._timeout_send = timeout_send\n             self._retries = retries\n             self.result_in_params_returned = None\n+            self.logger = logger or JinaLogger(self.__class__.__name__)\n \n         @property\n         def leaf(self):\n@@ -180,6 +183,9 @@ class TopologyGraph:\n                         self.parts_to_send.clear()\n                     except InternalNetworkError as err:\n                         self._handle_internalnetworkerror(err)\n+                    except Exception as err:\n+                        self.logger.error(f' Exception sending requests to {self.name}: {err}')\n+                        raise err\n \n                     self.end_time = datetime.utcnow()\n                     if metadata and 'is-error' in metadata:\n@@ -329,9 +335,11 @@ class TopologyGraph:\n         deployments_no_reduce: List[str] = [],\n         timeout_send: Optional[float] = 1.0,\n         retries: Optional[int] = -1,\n+        logger: Optional[JinaLogger] = None,\n         *args,\n         **kwargs,\n     ):\n+        self.logger = logger or JinaLogger(self.__class__.__name__)\n         num_parts_per_node = defaultdict(int)\n         if 'start-gateway' in graph_representation:\n             origin_node_names = graph_representation['start-gateway']\n@@ -364,6 +372,7 @@ class TopologyGraph:\n                 reduce=node_name not in deployments_no_reduce,\n                 timeout_send=timeout_send,\n                 retries=retries,\n+                logger=self.logger\n             )\n \n         for node_name, outgoing_node_names in graph_representation.items():\n\n---\n file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -92,7 +92,15 @@ class RequestStreamer:\n                     r.header.request_id = err.request_id\n                 yield r\n             else:  # HTTP and WS need different treatment further up the stack\n+                self.logger.error(\n+                    f'Error while getting responses from deployments: {err.details()}'\n+                )\n                 raise\n+        except Exception as err:  # HTTP and WS need different treatment further up the stack\n+            self.logger.error(\n+                f'Error while getting responses from deployments: {err}'\n+            )\n+            raise err\n \n     async def _stream_requests(\n             self,\n\n---\n file path A: jina/serve/streamer.py | file path B: jina/serve/streamer.py\n\n@@ -68,6 +68,7 @@ class GatewayStreamer:\n             deployments_no_reduce=deployments_no_reduce,\n             timeout_send=timeout_send,\n             retries=retries,\n+            logger=logger,\n         )\n \n         self.runtime_name = runtime_name\n\n\n###\n\n", "completion": "chore: add more prints of exceptions (#<issue-num>)"}
{"prompt": " file path A: Dockerfiles/test-pip.Dockerfile | file path B: Dockerfiles/test-pip.Dockerfile\n\n@@ -12,4 +12,5 @@ RUN cat $HOME/.bashrc\n RUN grep -Fxq \"# JINA_CLI_BEGIN\" $HOME/.bashrc\n \n ENV JINA_OPTOUT_TELEMETRY='true'\n+ENV GRPC_ENABLE_FORK_SUPPORT='0'\n ENTRYPOINT [\"jina\"]\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -589,7 +589,7 @@ class Flow(\n     @allowed_levels([FlowBuildLevel.EMPTY])\n     def _add_gateway(\n         self,\n-        needs: str,\n+        needs: Union[str, Set[str]],\n         graph_description: Dict[str, List[str]],\n         deployments_addresses: Dict[str, List[str]],\n         deployments_metadata: Dict[str, Dict[str, str]],\n\n\n###\n\n", "completion": "test: try to make tests more reliable in K8s (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.24.1:    core\n+jina-hubble-sdk>=0.24.1:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.24.1:    core\n+jina-hubble-sdk>=0.24.1:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n\n###\n\n", "completion": "fix: unpin hubble sdk version (#<issue-num>)"}
{"prompt": " file path A: jina/serve/gateway.py | file path B: jina/serve/gateway.py\n\n@@ -138,6 +138,27 @@ class BaseGateway(JAMLCompatible, metaclass=GatewayType):\n             tracing_client_interceptor=tracing_client_interceptor,\n         )\n \n+    @property\n+    def port(self):\n+        \"\"\"Gets the first port of the port list argument. To be used in the regular case where a Gateway exposes a single port\n+        :return: The first port to be exposed\n+        \"\"\"\n+        return self.runtime_args.port[0]\n+\n+    @property\n+    def ports(self):\n+        \"\"\"Gets all the list of ports from the runtime_args as a list.\n+        :return: The lists of ports to be exposed\n+        \"\"\"\n+        return self.runtime_args.port\n+\n+    @property\n+    def host(self):\n+        \"\"\"Gets the host from the runtime_args\n+        :return: The host where to bind the gateway\n+        \"\"\"\n+        return self.runtime_args.host\n+\n     @abc.abstractmethod\n     async def setup_server(self):\n         \"\"\"Setup server\"\"\"\n@@ -158,8 +179,3 @@ class BaseGateway(JAMLCompatible, metaclass=GatewayType):\n \n     def __exit__(self, exc_type, exc_val, exc_tb):\n         pass\n-\n-    def _set_single_port_protocol(self):\n-        if len(self.runtime_args.port) < 1 or len(self.runtime_args.protocol) < 1:\n-            raise ValueError(f'{self.__class__} expects at least 1 port and 1 protcol')\n-        self.port = self.runtime_args.port[0]\n\n---\n file path A: jina/serve/runtimes/gateway/grpc/gateway.py | file path B: jina/serve/runtimes/gateway/grpc/gateway.py\n\n@@ -29,8 +29,6 @@ class GRPCGateway(BaseGateway):\n         :param kwargs: keyword args\n         \"\"\"\n         super().__init__(**kwargs)\n-        self._set_single_port_protocol()\n-        self.host = self.runtime_args.host\n         self.grpc_server_options = grpc_server_options\n         self.ssl_keyfile = ssl_keyfile\n         self.ssl_certfile = ssl_certfile\n\n---\n file path A: jina/serve/runtimes/gateway/http/gateway.py | file path B: jina/serve/runtimes/gateway/http/gateway.py\n\n@@ -45,8 +45,6 @@ class HTTPGateway(BaseGateway):\n         :param kwargs: keyword args\n         \"\"\"\n         super().__init__(**kwargs)\n-        self._set_single_port_protocol()\n-        self.host = self.runtime_args.host\n         self.title = title\n         self.description = description\n         self.no_debug_endpoints = no_debug_endpoints\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/gateway.py | file path B: jina/serve/runtimes/gateway/websocket/gateway.py\n\n@@ -28,8 +28,6 @@ class WebSocketGateway(BaseGateway):\n         :param kwargs: keyword args\n         \"\"\"\n         super().__init__(**kwargs)\n-        self._set_single_port_protocol()\n-        self.host = self.runtime_args.host\n         self.ssl_keyfile = ssl_keyfile\n         self.ssl_certfile = ssl_certfile\n         self.uvicorn_kwargs = uvicorn_kwargs\n\n---\n file path A: tests/docker_compose/custom-gateway/dummy_gateway.py | file path B: tests/docker_compose/custom-gateway/dummy_gateway.py\n\n@@ -24,8 +24,6 @@ class DummyGateway(Gateway):\n         self, arg1: str = None, arg2: str = None, arg3: str = 'default-arg3', **kwargs\n     ):\n         super().__init__(**kwargs)\n-        self.port = self.runtime_args.port[0]\n-        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n\n---\n file path A: tests/docker_compose/multiprotocol-gateway/multiprotocol_gateway.py | file path B: tests/docker_compose/multiprotocol-gateway/multiprotocol_gateway.py\n\n@@ -15,8 +15,8 @@ class DummyResponseModel(BaseModel):\n class MultiProtocolGateway(Gateway):\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n-        self.http_port = self.runtime_args.port[0]\n-        self.grpc_port = self.runtime_args.port[1]\n+        self.http_port = self.ports[0]\n+        self.grpc_port = self.ports[1]\n         self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n \n     async def _setup_http_server(self):\n\n---\n file path A: tests/integration/multiple_protocol_gateway/gateway/multiprotocol_gateway.py | file path B: tests/integration/multiple_protocol_gateway/gateway/multiprotocol_gateway.py\n\n@@ -15,8 +15,8 @@ class DummyResponseModel(BaseModel):\n class MultiProtocolGateway(Gateway):\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n-        self.http_port = self.runtime_args.port[0]\n-        self.grpc_port = self.runtime_args.port[1]\n+        self.http_port = self.ports[0]\n+        self.grpc_port = self.ports[1]\n         self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n \n     async def _setup_http_server(self):\n\n---\n file path A: tests/k8s/custom-gateway/dummy_gateway.py | file path B: tests/k8s/custom-gateway/dummy_gateway.py\n\n@@ -24,8 +24,6 @@ class DummyGateway(Gateway):\n         self, arg1: str = None, arg2: str = None, arg3: str = 'default-arg3', **kwargs\n     ):\n         super().__init__(**kwargs)\n-        self.port = self.runtime_args.port[0]\n-        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n\n---\n file path A: tests/k8s/multiprotocol-gateway/multiprotocol_gateway.py | file path B: tests/k8s/multiprotocol-gateway/multiprotocol_gateway.py\n\n@@ -15,8 +15,8 @@ class DummyResponseModel(BaseModel):\n class MultiProtocolGateway(Gateway):\n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n-        self.http_port = self.runtime_args.port[0]\n-        self.grpc_port = self.runtime_args.port[1]\n+        self.http_port = self.ports[0]\n+        self.grpc_port = self.ports[1]\n         self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n \n     async def _setup_http_server(self):\n\n---\n file path A: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py | file path B: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py\n\n@@ -24,8 +24,6 @@ class DummyGateway(Gateway):\n         self, arg1: str = None, arg2: str = None, arg3: str = 'default-arg3', **kwargs\n     ):\n         super().__init__(**kwargs)\n-        self.port = self.runtime_args.port[0]\n-        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n\n---\n file path A: tests/unit/yaml/dummy_gateway.py | file path B: tests/unit/yaml/dummy_gateway.py\n\n@@ -24,8 +24,6 @@ class DummyGateway(Gateway):\n         self, arg1: str = None, arg2: str = None, arg3: str = 'default-arg3', **kwargs\n     ):\n         super().__init__(**kwargs)\n-        self.port = self.runtime_args.port[0]\n-        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n\n\n###\n\n", "completion": "refactor: add properties to gateway (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -888,7 +888,7 @@ class Deployment(BaseDeployment):\n \n         _args = copy.deepcopy(args)\n         _args.pod_role = PodRoleType.WORKER\n-        _args.host = __default_host__\n+        _args.host = _args.host or __default_host__\n         _args.port = helper.random_port()\n \n         if _args.name:\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1764,9 +1764,10 @@ class Flow(\n             self.build(copy_flow=False)\n \n         port_gateway = self._deployment_nodes[GATEWAY_NAME].args.port\n+        host_gateway = self._deployment_nodes[GATEWAY_NAME].args.host\n \n         if not (\n-            is_port_free(__default_host__, port_gateway)\n+            is_port_free(host_gateway, port_gateway)\n         ):  # we check if the port is not used at parsing time as well for robustness\n             raise PortAlreadyUsed(f'port:{port_gateway}')\n \n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -52,7 +52,7 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n \n         Setup the uvicorn server.\n         \"\"\"\n-        if not (is_port_free(__default_host__, self.args.port)):\n+        if not (is_port_free(self.args.host, self.args.port)):\n             raise PortAlreadyUsed(f'port:{self.args.port}')\n \n         uses_with = self.args.uses_with or {}\n@@ -79,6 +79,7 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n                 'name': self.args.name,\n                 'port': self.args.port,\n                 'protocol': self.args.protocol,\n+                'host': self.args.host,\n             },\n             py_modules=self.args.py_modules,\n             extra_search_paths=self.args.extra_search_paths,\n\n---\n file path A: jina/serve/runtimes/gateway/grpc/gateway.py | file path B: jina/serve/runtimes/gateway/grpc/gateway.py\n\n@@ -30,6 +30,7 @@ class GRPCGateway(BaseGateway):\n         \"\"\"\n         super().__init__(**kwargs)\n         self._set_single_port_protocol()\n+        self.host = self.runtime_args.host\n         self.grpc_server_options = grpc_server_options\n         self.ssl_keyfile = ssl_keyfile\n         self.ssl_certfile = ssl_certfile\n@@ -66,7 +67,7 @@ class GRPCGateway(BaseGateway):\n             )\n         reflection.enable_server_reflection(service_names, self.server)\n \n-        bind_addr = f'{__default_host__}:{self.port}'\n+        bind_addr = f'{self.host}:{self.port}'\n \n         if self.ssl_keyfile and self.ssl_certfile:\n             with open(self.ssl_keyfile, 'rb') as f:\n\n---\n file path A: jina/serve/runtimes/gateway/http/gateway.py | file path B: jina/serve/runtimes/gateway/http/gateway.py\n\n@@ -46,6 +46,7 @@ class HTTPGateway(BaseGateway):\n         \"\"\"\n         super().__init__(**kwargs)\n         self._set_single_port_protocol()\n+        self.host = self.runtime_args.host\n         self.title = title\n         self.description = description\n         self.no_debug_endpoints = no_debug_endpoints\n@@ -132,7 +133,7 @@ class HTTPGateway(BaseGateway):\n         self.server = UviServer(\n             config=Config(\n                 app=self.app,\n-                host=__default_host__,\n+                host=self.host,\n                 port=self.port,\n                 log_level=os.getenv('JINA_LOG_LEVEL', 'error').lower(),\n                 **uvicorn_kwargs,\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/gateway.py | file path B: jina/serve/runtimes/gateway/websocket/gateway.py\n\n@@ -29,6 +29,7 @@ class WebSocketGateway(BaseGateway):\n         \"\"\"\n         super().__init__(**kwargs)\n         self._set_single_port_protocol()\n+        self.host = self.runtime_args.host\n         self.ssl_keyfile = ssl_keyfile\n         self.ssl_certfile = ssl_certfile\n         self.uvicorn_kwargs = uvicorn_kwargs\n@@ -101,7 +102,7 @@ class WebSocketGateway(BaseGateway):\n         self.server = UviServer(\n             config=Config(\n                 app=self.app,\n-                host=__default_host__,\n+                host=self.host,\n                 port=self.port,\n                 ws_max_size=1024 * 1024 * 1024,\n                 log_level=os.getenv('JINA_LOG_LEVEL', 'error').lower(),\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -159,7 +159,7 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n             )\n         reflection.enable_server_reflection(service_names, self._grpc_server)\n \n-        bind_addr = f'0.0.0.0:{self.args.port}'\n+        bind_addr = f'{self.args.host}:{self.args.port}'\n         self._grpc_server.add_insecure_port(bind_addr)\n         self.logger.debug(f'start listening on {bind_addr}')\n         await self._grpc_server.start()\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -144,7 +144,7 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n                 service, health_pb2.HealthCheckResponse.SERVING\n             )\n         reflection.enable_server_reflection(service_names, self._grpc_server)\n-        bind_addr = f'0.0.0.0:{self.args.port}'\n+        bind_addr = f'{self.args.host}:{self.args.port}'\n         self.logger.debug(f'start listening on {bind_addr}')\n         self._grpc_server.add_insecure_port(bind_addr)\n         await self._grpc_server.start()\n\n---\n file path A: tests/docker_compose/custom-gateway/dummy_gateway.py | file path B: tests/docker_compose/custom-gateway/dummy_gateway.py\n\n@@ -25,6 +25,7 @@ class DummyGateway(Gateway):\n     ):\n         super().__init__(**kwargs)\n         self.port = self.runtime_args.port[0]\n+        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n@@ -59,7 +60,7 @@ class DummyGateway(Gateway):\n                 doc = req.to_dict()['data'][0]\n             return {'text': doc['text'], 'tags': doc['tags']}\n \n-        self.server = Server(Config(app, host=__default_host__, port=self.port))\n+        self.server = Server(Config(app, host=self.host, port=self.port))\n \n     async def run_server(self):\n         await self.server.serve()\n\n---\n file path A: tests/integration/external_deployment/test_external_deployment.py | file path B: tests/integration/external_deployment/test_external_deployment.py\n\n@@ -424,7 +424,7 @@ def test_external_flow_with_grpc_metadata():\n                 )\n             reflection.enable_server_reflection(service_names, self.server)\n \n-            bind_addr = f'{__default_host__}:{self.port}'\n+            bind_addr = f'{self.host}:{self.port}'\n \n             if self.ssl_keyfile and self.ssl_certfile:\n                 with open(self.ssl_keyfile, 'rb') as f:\n\n---\n file path A: tests/k8s/custom-gateway/dummy_gateway.py | file path B: tests/k8s/custom-gateway/dummy_gateway.py\n\n@@ -25,6 +25,7 @@ class DummyGateway(Gateway):\n     ):\n         super().__init__(**kwargs)\n         self.port = self.runtime_args.port[0]\n+        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n@@ -59,7 +60,7 @@ class DummyGateway(Gateway):\n                 doc = req.to_dict()['data'][0]\n             return {'text': doc['text'], 'tags': doc['tags']}\n \n-        self.server = Server(Config(app, host=__default_host__, port=self.port))\n+        self.server = Server(Config(app, host=self.host, port=self.port))\n \n     async def run_server(self):\n         await self.server.serve()\n\n---\n file path A: tests/unit/orchestrate/deployments/test_deployments.py | file path B: tests/unit/orchestrate/deployments/test_deployments.py\n\n@@ -1,5 +1,6 @@\n import json\n import os\n+import socket\n \n import pytest\n \n@@ -13,6 +14,7 @@ from jina import (\n )\n from jina.clients.request import request_generator\n from jina.enums import PollingType\n+from jina.excepts import RuntimeFailToStart\n from jina.orchestrate.deployments import Deployment\n from jina.parsers import set_deployment_parser, set_gateway_parser\n from jina.serve.networking import GrpcConnectionPool\n@@ -21,6 +23,21 @@ from tests.unit.test_helper import MyDummyExecutor\n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n \n+def get_deployment_args_with_host(hostname, runtime_cls):\n+    args = [\n+        '--name',\n+        'host_args',\n+        '--host',\n+        hostname,\n+        '--runtime-cls',\n+        runtime_cls,\n+    ]\n+    if runtime_cls != 'GatewayRuntime':\n+        return set_deployment_parser().parse_args(args)\n+    else:\n+        return set_gateway_parser().parse_args(args)\n+\n+\n @pytest.fixture(scope='function')\n def pod_args():\n     args = [\n@@ -59,12 +76,27 @@ def test_name(pod_args):\n         assert pod.name == 'test'\n \n \n-def test_host(pod_args):\n-    with Deployment(pod_args) as pod:\n-        assert pod.host == __default_host__\n+@pytest.mark.parametrize(\n+    'runtime_cls', ['GatewayRuntime', 'WorkerRuntime', 'HeadRuntime']\n+)\n+@pytest.mark.parametrize('hostname', ['localhost', '127.0.0.1', '0.0.0.0'])\n+def test_host(hostname, runtime_cls):\n+    with Deployment(get_deployment_args_with_host(hostname, runtime_cls)) as pod:\n+        assert pod.host == hostname\n         assert pod.head_host is None\n \n \n+@pytest.mark.parametrize(\n+    'runtime_cls', ['GatewayRuntime', 'WorkerRuntime', 'HeadRuntime']\n+)\n+def test_wrong_hostname(runtime_cls):\n+    with pytest.raises(RuntimeFailToStart):\n+        with Deployment(\n+            get_deployment_args_with_host('inexisting.hostname.local', runtime_cls)\n+        ) as pod:\n+            pass\n+\n+\n def test_is_ready(pod_args):\n     with Deployment(pod_args) as pod:\n         assert pod.is_ready is True\n\n---\n file path A: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py | file path B: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py\n\n@@ -25,6 +25,7 @@ class DummyGateway(Gateway):\n     ):\n         super().__init__(**kwargs)\n         self.port = self.runtime_args.port[0]\n+        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n@@ -59,7 +60,7 @@ class DummyGateway(Gateway):\n                 doc = req.to_dict()['data'][0]\n             return {'text': doc['text'], 'tags': doc['tags']}\n \n-        self.server = Server(Config(app, host=__default_host__, port=self.port))\n+        self.server = Server(Config(app, host=self.host, port=self.port))\n \n     async def run_server(self):\n         await self.server.serve()\n\n---\n file path A: tests/unit/test_yamlparser.py | file path B: tests/unit/test_yamlparser.py\n\n@@ -3,7 +3,7 @@ import os\n import pytest\n import yaml\n \n-from jina import Gateway, __default_executor__\n+from jina import Gateway, __default_executor__, __default_host__\n from jina.helper import expand_dict, expand_env_var\n from jina.jaml import JAML\n from jina.serve.executors import BaseExecutor\n@@ -172,7 +172,8 @@ def test_load_from_dict():\n \n def test_load_gateway_external_success():\n     with Gateway.load_config(\n-        'yaml/test-custom-gateway.yml', runtime_args={'port': [12345]}\n+        'yaml/test-custom-gateway.yml',\n+        runtime_args={'port': [12345], 'host': __default_host__},\n     ) as gateway:\n         assert gateway.__class__.__name__ == 'DummyGateway'\n         assert gateway.arg1 == 'hello'\n@@ -184,7 +185,7 @@ def test_load_gateway_override_with():\n     with Gateway.load_config(\n         'yaml/test-custom-gateway.yml',\n         uses_with={'arg1': 'arg1', 'arg2': 'arg2', 'arg3': 'arg3'},\n-        runtime_args={'port': [12345]},\n+        runtime_args={'port': [12345], 'host': __default_host__},\n     ) as gateway:\n         assert gateway.__class__.__name__ == 'DummyGateway'\n         assert gateway.arg1 == 'arg1'\n\n---\n file path A: tests/unit/yaml/dummy_gateway.py | file path B: tests/unit/yaml/dummy_gateway.py\n\n@@ -25,6 +25,7 @@ class DummyGateway(Gateway):\n     ):\n         super().__init__(**kwargs)\n         self.port = self.runtime_args.port[0]\n+        self.host = self.runtime_args.host\n         self.arg1 = arg1\n         self.arg2 = arg2\n         self.arg3 = arg3\n@@ -59,7 +60,7 @@ class DummyGateway(Gateway):\n                 doc = req.to_dict()['data'][0]\n             return {'text': doc['text'], 'tags': doc['tags']}\n \n-        self.server = Server(Config(app, host=__default_host__, port=self.port))\n+        self.server = Server(Config(app, host=self.host, port=self.port))\n \n     async def run_server(self):\n         await self.server.serve()\n@@ -67,4 +68,3 @@ class DummyGateway(Gateway):\n     async def shutdown(self):\n         self.server.should_exit = True\n         await self.server.shutdown()\n-\n\n\n###\n\n", "completion": "fix: bind servers to `host` argument isntead of __default_host__ (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-release.yml | file path B: .github/workflows/force-release.yml\n\n@@ -32,7 +32,7 @@ jobs:\n     with:\n       actions: 'all'\n     secrets:\n-      jina_dev_bot: ${{ secrets.JINA_DEV_BOT }}\n+      extended_github_token: ${{ secrets.JINA_DEV_BOT }}\n       jina_auth_token: ${{ secrets.JINA_AUTH_TOKEN }}\n \n   regular-release:\n\n\n###\n\n", "completion": "ci: fix hub-integration parameter (#<issue-num>)"}
{"prompt": " file path A: docs/cloud-nativeness/opentelemetry.md | file path B: docs/cloud-nativeness/opentelemetry.md\n\n@@ -97,6 +97,8 @@ exporters:\n   \n   prometheus:\n     endpoint: \"0.0.0.0:8889\"\n+    resource_to_telemetry_conversion:\n+      enabled: true\n     # can be used to add additional labels\n     const_labels:\n       label1: value1\n\n\n###\n\n", "completion": "docs: enable flag to convert resource labels to metric labels (#<issue-num>)"}
{"prompt": " file path A: jina/serve/gateway.py | file path B: jina/serve/gateway.py\n\n@@ -148,13 +148,9 @@ class BaseGateway(JAMLCompatible, metaclass=GatewayType):\n         \"\"\"Run server forever\"\"\"\n         ...\n \n-    async def teardown(self):\n-        \"\"\"Free other resources allocated with the server, e.g, gateway object, ...\"\"\"\n-        await self.streamer.close()\n-\n     @abc.abstractmethod\n-    async def stop_server(self):\n-        \"\"\"Stop server\"\"\"\n+    async def shutdown(self):\n+        \"\"\"Shutdown the server and free other allocated resources, e.g, streamer object, health check service, ...\"\"\"\n         ...\n \n     def __enter__(self):\n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -110,12 +110,14 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n \n     async def async_teardown(self):\n         \"\"\"Shutdown the server.\"\"\"\n-        await self.gateway.teardown()\n+        await self.gateway.streamer.close()\n+        await self.gateway.shutdown()\n         await self.async_cancel()\n \n     async def async_cancel(self):\n         \"\"\"Stop the server.\"\"\"\n-        await self.gateway.stop_server()\n+        await self.gateway.streamer.close()\n+        await self.gateway.shutdown()\n \n     async def async_run_forever(self):\n         \"\"\"Running method of the server.\"\"\"\n\n---\n file path A: jina/serve/runtimes/gateway/grpc/gateway.py | file path B: jina/serve/runtimes/gateway/grpc/gateway.py\n\n@@ -94,16 +94,10 @@ class GRPCGateway(BaseGateway):\n         self.logger.debug(f'start server bound to {bind_addr}')\n         await self.server.start()\n \n-    async def teardown(self):\n+    async def shutdown(self):\n         \"\"\"Free other resources allocated with the server, e.g, gateway object, ...\"\"\"\n-        await super().teardown()\n-        await self.health_servicer.enter_graceful_shutdown()\n-\n-    async def stop_server(self):\n-        \"\"\"\n-        Stop GRPC server\n-        \"\"\"\n         await self.server.stop(0)\n+        await self.health_servicer.enter_graceful_shutdown()\n \n     async def run_server(self):\n         \"\"\"Run GRPC server forever\"\"\"\n\n---\n file path A: jina/serve/runtimes/gateway/http/gateway.py | file path B: jina/serve/runtimes/gateway/http/gateway.py\n\n@@ -141,18 +141,12 @@ class HTTPGateway(BaseGateway):\n \n         await self.server.setup()\n \n-    async def teardown(self):\n+    async def shutdown(self):\n         \"\"\"\n         Free resources allocated when setting up HTTP server\n         \"\"\"\n-        await super().teardown()\n-        await self.server.shutdown()\n-\n-    async def stop_server(self):\n-        \"\"\"\n-        Stop HTTP server\n-        \"\"\"\n         self.server.should_exit = True\n+        await self.server.shutdown()\n \n     async def run_server(self):\n         \"\"\"Run HTTP server forever\"\"\"\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/gateway.py | file path B: jina/serve/runtimes/gateway/websocket/gateway.py\n\n@@ -111,16 +111,10 @@ class WebSocketGateway(BaseGateway):\n \n         await self.server.setup()\n \n-    async def teardown(self):\n+    async def shutdown(self):\n         \"\"\"Free other resources allocated with the server, e.g, gateway object, ...\"\"\"\n-        await super().teardown()\n-        await self.server.shutdown()\n-\n-    async def stop_server(self):\n-        \"\"\"\n-        Stop WebSocket server\n-        \"\"\"\n         self.server.should_exit = True\n+        await self.server.shutdown()\n \n     async def run_server(self):\n         \"\"\"Run WebSocket server forever\"\"\"\n\n---\n file path A: tests/docker_compose/custom-gateway/dummy_gateway.py | file path B: tests/docker_compose/custom-gateway/dummy_gateway.py\n\n@@ -64,13 +64,6 @@ class DummyGateway(Gateway):\n     async def run_server(self):\n         await self.server.serve()\n \n-    async def teardown(self):\n-        await super().teardown()\n-        await self.server.shutdown()\n-\n-    async def stop_server(self):\n+    async def shutdown(self):\n         self.server.should_exit = True\n-\n-    @property\n-    def should_exit(self) -> bool:\n-        return self.server.should_exit\n+        await self.server.shutdown()\n\n---\n file path A: tests/docker_compose/multiprotocol-gateway/multiprotocol_gateway.py | file path B: tests/docker_compose/multiprotocol-gateway/multiprotocol_gateway.py\n\n@@ -63,15 +63,12 @@ class MultiProtocolGateway(Gateway):\n         await self.http_server.serve()\n         await self.grpc_server.wait_for_termination()\n \n-    async def teardown(self):\n-        await super().teardown()\n-        await self.http_server.shutdown()\n-        self.health_servicer.enter_graceful_shutdown()\n-\n-    async def stop_server(self):\n+    async def shutdown(self):\n         self.http_server.should_exit = True\n         await self.grpc_server.stop(0)\n+        await self.http_server.shutdown()\n+        self.health_servicer.enter_graceful_shutdown()\n \n     @property\n-    def should_exit(self) -> bool:\n+    def _should_exit(self) -> bool:\n         return self.http_server.should_exit\n\n---\n file path A: tests/integration/multiple_protocol_gateway/gateway/multiprotocol_gateway.py | file path B: tests/integration/multiple_protocol_gateway/gateway/multiprotocol_gateway.py\n\n@@ -63,14 +63,11 @@ class MultiProtocolGateway(Gateway):\n         await self.http_server.serve()\n         await self.grpc_server.wait_for_termination()\n \n-    async def teardown(self):\n-        await super().teardown()\n-        await self.http_server.shutdown()\n-        self.health_servicer.enter_graceful_shutdown()\n-\n-    async def stop_server(self):\n+    async def shutdown(self):\n         self.http_server.should_exit = True\n         await self.grpc_server.stop(0)\n+        await self.http_server.shutdown()\n+        self.health_servicer.enter_graceful_shutdown()\n \n     @property\n     def _should_exit(self) -> bool:\n\n---\n file path A: tests/k8s/custom-gateway/dummy_gateway.py | file path B: tests/k8s/custom-gateway/dummy_gateway.py\n\n@@ -64,13 +64,6 @@ class DummyGateway(Gateway):\n     async def run_server(self):\n         await self.server.serve()\n \n-    async def teardown(self):\n-        await super().teardown()\n-        await self.server.shutdown()\n-\n-    async def stop_server(self):\n+    async def shutdown(self):\n         self.server.should_exit = True\n-\n-    @property\n-    def should_exit(self) -> bool:\n-        return self.server.should_exit\n+        await self.server.shutdown()\n\n---\n file path A: tests/k8s/multiprotocol-gateway/multiprotocol_gateway.py | file path B: tests/k8s/multiprotocol-gateway/multiprotocol_gateway.py\n\n@@ -63,15 +63,12 @@ class MultiProtocolGateway(Gateway):\n         await self.http_server.serve()\n         await self.grpc_server.wait_for_termination()\n \n-    async def teardown(self):\n-        await super().teardown()\n-        await self.http_server.shutdown()\n-        self.health_servicer.enter_graceful_shutdown()\n-\n-    async def stop_server(self):\n+    async def shutdown(self):\n         self.http_server.should_exit = True\n         await self.grpc_server.stop(0)\n+        await self.http_server.shutdown()\n+        self.health_servicer.enter_graceful_shutdown()\n \n     @property\n-    def should_exit(self) -> bool:\n-        return self.http_server.should_exit\n+    def _should_exit(self) -> bool:\n+        return self.http_server.should_exit\n\\ No newline at end of file\n\n---\n file path A: tests/unit/jaml/test_gateway_parse.py | file path B: tests/unit/jaml/test_gateway_parse.py\n\n@@ -14,12 +14,9 @@ class MyDummyGateway(Gateway):\n     async def run_server(self):\n         self.logger.info(self.server)\n \n-    async def teardown(self):\n+    async def shutdown(self):\n         pass\n \n-    async def stop_server(self):\n-        self.server = None\n-\n \n def test_cls_from_tag():\n     assert JAML.cls_from_tag('MyDummyGateway') == MyDummyGateway\n\n---\n file path A: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py | file path B: tests/unit/orchestrate/pods/container/custom-gateway/dummy_gateway.py\n\n@@ -64,13 +64,6 @@ class DummyGateway(Gateway):\n     async def run_server(self):\n         await self.server.serve()\n \n-    async def teardown(self):\n-        await super().teardown()\n-        await self.server.shutdown()\n-\n-    async def stop_server(self):\n+    async def shutdown(self):\n         self.server.should_exit = True\n-\n-    @property\n-    def should_exit(self) -> bool:\n-        return self.server.should_exit\n+        await self.server.shutdown()\n\n---\n file path A: tests/unit/yaml/dummy_gateway.py | file path B: tests/unit/yaml/dummy_gateway.py\n\n@@ -64,9 +64,7 @@ class DummyGateway(Gateway):\n     async def run_server(self):\n         await self.server.serve()\n \n-    async def teardown(self):\n-        await super().teardown()\n+    async def shutdown(self):\n+        self.server.should_exit = True\n         await self.server.shutdown()\n \n-    async def stop_server(self):\n-        self.server.should_exit = True\n\n\n###\n\n", "completion": "refactor: unify stop and teardown to shutdown (#<issue-num>)"}
{"prompt": " file path A: jina/serve/gateway.py | file path B: jina/serve/gateway.py\n\n@@ -152,16 +152,6 @@ class BaseGateway(JAMLCompatible, metaclass=GatewayType):\n         \"\"\"Stop server\"\"\"\n         ...\n \n-    # some servers need to set a flag useful in handling termination signals\n-    # e.g, HTTPGateway/ WebSocketGateway\n-    @property\n-    def should_exit(self) -> bool:\n-        \"\"\"\n-        Boolean flag that indicates whether the gateway server should exit or not\n-        :return: boolean flag\n-        \"\"\"\n-        return False\n-\n     def __enter__(self):\n         return self\n \n\n---\n file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -20,6 +20,11 @@ if TYPE_CHECKING:  # pragma: no cover\n     import multiprocessing\n     import threading\n \n+HANDLED_SIGNALS = (\n+    signal.SIGINT,  # Unix signal 2. Sent by Ctrl+C.\n+    signal.SIGTERM,  # Unix signal 15. Sent by `kill <pid>`.\n+)\n+\n \n class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, InstrumentationMixin, ABC):\n     \"\"\"\n@@ -27,25 +32,29 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, InstrumentationMixin, AB\n     \"\"\"\n \n     def __init__(\n-        self,\n-        args: 'argparse.Namespace',\n-        cancel_event: Optional[\n-            Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n-        ] = None,\n-        **kwargs,\n+            self,\n+            args: 'argparse.Namespace',\n+            cancel_event: Optional[\n+                Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n+            ] = None,\n+            **kwargs,\n     ):\n         super().__init__(args, **kwargs)\n         self._loop = asyncio.new_event_loop()\n         asyncio.set_event_loop(self._loop)\n         self.is_cancel = cancel_event or asyncio.Event()\n+\n+        def _cancel(sig):\n+            def _inner_cancel(*args, **kwargs):\n+                self.logger.debug(f'Received signal {sig.name}')\n+                self.is_cancel.set(),\n+\n+            return _inner_cancel\n+\n         if not __windows__:\n-            # TODO: windows event loops don't support signal handlers\n             try:\n-                for signame in {'SIGINT', 'SIGTERM'}:\n-                    self._loop.add_signal_handler(\n-                        getattr(signal, signame),\n-                        lambda *args, **kwargs: self.is_cancel.set(),\n-                    )\n+                for sig in HANDLED_SIGNALS:\n+                    self._loop.add_signal_handler(sig, _cancel(sig), sig, None)\n             except (ValueError, RuntimeError) as exc:\n                 self.logger.warning(\n                     f' The runtime {self.__class__.__name__} will not be able to handle termination signals. '\n@@ -53,10 +62,10 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, InstrumentationMixin, AB\n                 )\n         else:\n             with ImportExtensions(\n-                required=True,\n-                logger=self.logger,\n-                help_text='''If you see a 'DLL load failed' error, please reinstall `pywin32`.\n-                If you're using conda, please use the command `conda install -c anaconda pywin32`''',\n+                    required=True,\n+                    logger=self.logger,\n+                    help_text='''If you see a 'DLL load failed' error, please reinstall `pywin32`.\n+                    If you're using conda, please use the command `conda install -c anaconda pywin32`''',\n             ):\n                 import win32api\n \n@@ -195,11 +204,11 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, InstrumentationMixin, AB\n \n     @classmethod\n     def wait_for_ready_or_shutdown(\n-        cls,\n-        timeout: Optional[float],\n-        ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n-        ctrl_address: str,\n-        **kwargs,\n+            cls,\n+            timeout: Optional[float],\n+            ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n+            ctrl_address: str,\n+            **kwargs,\n     ):\n         \"\"\"\n         Check if the runtime has successfully started\n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -12,11 +12,10 @@ from jina.parsers.helper import _set_gateway_uses\n from jina.serve.gateway import BaseGateway\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     import multiprocessing\n     import threading\n \n-\n # Keep these imports even if not used, since YAML parser needs to find them in imported modules\n from jina.serve.runtimes.gateway.grpc import GRPCGateway\n from jina.serve.runtimes.gateway.http import HTTPGateway\n@@ -33,12 +32,12 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n     \"\"\"\n \n     def __init__(\n-        self,\n-        args: argparse.Namespace,\n-        cancel_event: Optional[\n-            Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n-        ] = None,\n-        **kwargs,\n+            self,\n+            args: argparse.Namespace,\n+            cancel_event: Optional[\n+                Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n+            ] = None,\n+            **kwargs,\n     ):\n         # this order is intentional: The timeout is needed in _create_topology_graph(), called by super\n         self.timeout_send = args.timeout_send\n@@ -101,7 +100,7 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n     async def _wait_for_cancel(self):\n         \"\"\"Do NOT override this method when inheriting from :class:`GatewayPod`\"\"\"\n         # handle terminate signals\n-        while not self.is_cancel.is_set() and not self.gateway.should_exit:\n+        while not self.is_cancel.is_set():\n             await asyncio.sleep(0.1)\n \n         await self.async_cancel()\n@@ -118,6 +117,7 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n     async def async_run_forever(self):\n         \"\"\"Running method of the server.\"\"\"\n         await self.gateway.run_server()\n+        self.is_cancel.set()\n \n     @staticmethod\n     def is_ready(ctrl_address: str, protocol: Optional[str] = 'grpc', **kwargs) -> bool:\n@@ -132,9 +132,9 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n         \"\"\"\n \n         if (\n-            protocol is None\n-            or protocol == GatewayProtocolType.GRPC\n-            or protocol == 'grpc'\n+                protocol is None\n+                or protocol == GatewayProtocolType.GRPC\n+                or protocol == 'grpc'\n         ):\n             res = AsyncNewLoopRuntime.is_ready(ctrl_address)\n         else:\n@@ -147,12 +147,12 @@ class GatewayRuntime(AsyncNewLoopRuntime):\n \n     @classmethod\n     def wait_for_ready_or_shutdown(\n-        cls,\n-        timeout: Optional[float],\n-        ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n-        ctrl_address: str,\n-        protocol: Optional[str] = 'grpc',\n-        **kwargs,\n+            cls,\n+            timeout: Optional[float],\n+            ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n+            ctrl_address: str,\n+            protocol: Optional[str] = 'grpc',\n+            **kwargs,\n     ):\n         \"\"\"\n         Check if the runtime has successfully started\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -22,7 +22,7 @@ def get_fastapi_app(\n     description: str,\n     no_debug_endpoints: bool,\n     no_crud_endpoints: bool,\n-    expose_endpoints: bool,\n+    expose_endpoints: Optional[str],\n     expose_graphql_endpoint: bool,\n     cors: bool,\n     logger: 'JinaLogger',\n\n---\n file path A: jina/serve/runtimes/gateway/http/gateway.py | file path B: jina/serve/runtimes/gateway/http/gateway.py\n\n@@ -101,7 +101,6 @@ class HTTPGateway(BaseGateway):\n                 if not config.loaded:\n                     config.load()\n                 self.lifespan = config.lifespan_class(config)\n-                self.install_signal_handlers()\n                 await self.startup(sockets=sockets)\n                 if self.should_exit:\n                     return\n@@ -160,11 +159,3 @@ class HTTPGateway(BaseGateway):\n     async def run_server(self):\n         \"\"\"Run HTTP server forever\"\"\"\n         await self.server.serve()\n-\n-    @property\n-    def should_exit(self) -> bool:\n-        \"\"\"\n-        Boolean flag that indicates whether the gateway server should exit or not\n-        :return: boolean flag\n-        \"\"\"\n-        return self.server.should_exit\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/gateway.py | file path B: jina/serve/runtimes/gateway/websocket/gateway.py\n\n@@ -70,7 +70,6 @@ class WebSocketGateway(BaseGateway):\n                 if not config.loaded:\n                     config.load()\n                 self.lifespan = config.lifespan_class(config)\n-                self.install_signal_handlers()\n                 await self.startup(sockets=sockets)\n                 if self.should_exit:\n                     return\n@@ -128,11 +127,3 @@ class WebSocketGateway(BaseGateway):\n     async def run_server(self):\n         \"\"\"Run WebSocket server forever\"\"\"\n         await self.server.serve()\n-\n-    @property\n-    def should_exit(self) -> bool:\n-        \"\"\"\n-        Boolean flag that indicates whether the gateway server should exit or not\n-        :return: boolean flag\n-        \"\"\"\n-        return self.server.should_exit\n\n---\n file path A: tests/unit/serve/gateway/test_gateway.py | file path B: tests/unit/serve/gateway/test_gateway.py\n\n@@ -15,6 +15,8 @@ from tests.helper import (\n )\n \n from tests.unit.yaml.dummy_gateway import DummyGateway\n+\n+\n cur_dir = os.path.dirname(os.path.abspath(__file__))\n _dummy_gateway_yaml_path = os.path.join(cur_dir, '../../yaml/test-custom-gateway.yml')\n \n\n---\n file path A: tests/unit/test_gateway.py | file path B: tests/unit/test_gateway.py\n\n@@ -66,7 +66,7 @@ def test_gateway_concurrency(protocol, reraise):\n     assert rate < 0.1\n \n \n-def test_grpc_custom_otpions():\n+def test_grpc_custom_options():\n \n     f = Flow(grpc_server_options={'grpc.max_send_message_length': -1})\n     with f:\n\n---\n file path A: tests/unit/yaml/dummy_gateway.py | file path B: tests/unit/yaml/dummy_gateway.py\n\n@@ -75,7 +75,3 @@ class DummyGateway(Gateway):\n \n     async def stop_server(self):\n         self.server.should_exit = True\n-\n-    @property\n-    def should_exit(self) -> bool:\n-        return self.server.should_exit\n\n\n###\n\n", "completion": "refactor: remove need for should_exit (#<issue-num>)"}
{"prompt": " file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -12,7 +12,7 @@ from jina.logging.profile import ProgressBar\n from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.networking import GrpcConnectionPool\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     from jina.clients.base import CallbackFnType, InputType\n \n \n@@ -95,7 +95,7 @@ class GRPCBaseClient(BaseClient):\n                                     \"maxAttempts\": max_attempts,\n                                     \"initialBackoff\": f\"{initial_backoff}s\",\n                                     \"maxBackoff\": f\"{max_backoff}s\",\n-                                    \"backoffMultiplier\": {backoff_multiplier},\n+                                    \"backoffMultiplier\": backoff_multiplier,\n                                     \"retryableStatusCodes\": [\n                                         \"UNAVAILABLE\",\n                                         \"DEADLINE_EXCEEDED\",\n\n---\n file path A: tests/unit/clients/python/test_client.py | file path B: tests/unit/clients/python/test_client.py\n\n@@ -105,6 +105,34 @@ def test_client_websocket(mocker, flow_with_websocket):\n         on_error_mock.assert_not_called()\n \n \n+# Timeout is necessary to fail in case of hanging client requests\n+@pytest.mark.timeout(60)\n+def test_client_max_attempts(mocker, flow):\n+    with flow:\n+        time.sleep(0.5)\n+        client = Client(\n+            host='localhost',\n+            port=flow.port,\n+        )\n+        # Test that a regular index request triggers the correct callbacks\n+        on_always_mock = mocker.Mock()\n+        on_error_mock = mocker.Mock()\n+        on_done_mock = mocker.Mock()\n+        client.post(\n+            '/',\n+            random_docs(1),\n+            request_size=1,\n+            max_attempts=5,\n+            on_always=on_always_mock,\n+            on_error=on_error_mock,\n+            on_done=on_done_mock,\n+            return_responses=True,\n+        )\n+        on_always_mock.assert_called_once()\n+        on_done_mock.assert_called_once()\n+        on_error_mock.assert_not_called()\n+\n+\n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n def test_client_from_kwargs(protocol):\n     Client(port=12345, host='0.0.0.1', protocol=protocol)\n\n\n###\n\n", "completion": "fix: fix multiplier format when using max attempts (#<issue-num>)"}
{"prompt": " file path A: tests/unit/serve/gateway/test_gateway.py | file path B: tests/unit/serve/gateway/test_gateway.py\n\n@@ -10,12 +10,11 @@ from jina.parsers import set_gateway_parser, set_pod_parser\n from jina.serve.runtimes.gateway import GatewayRuntime\n from jina.serve.runtimes.worker import WorkerRuntime\n from tests.helper import (\n-    ProcessExecutor,\n     _validate_custom_gateway_process,\n     _validate_dummy_custom_gateway_response,\n )\n-from tests.unit.yaml.dummy_gateway import DummyGateway\n \n+from tests.unit.yaml.dummy_gateway import DummyGateway\n cur_dir = os.path.dirname(os.path.abspath(__file__))\n _dummy_gateway_yaml_path = os.path.join(cur_dir, '../../yaml/test-custom-gateway.yml')\n \n\n---\n file path A: tests/unit/test_gateway.py | file path B: tests/unit/test_gateway.py\n\n@@ -6,12 +6,13 @@ import numpy as np\n import pytest\n \n from jina import Client, Document, Flow\n+from jina.helper import random_port\n \n \n @pytest.mark.slow\n @pytest.mark.parametrize('protocol', ['websocket', 'http'])\n def test_gateway_concurrency(protocol, reraise):\n-    port = 12345\n+    port = random_port()\n     CONCURRENCY = 2\n \n     def _validate(req, start, status_codes, durations, index):\n@@ -36,7 +37,7 @@ def test_gateway_concurrency(protocol, reraise):\n             for result in results:\n                 on_done(result)\n \n-    f = Flow(protocol=protocol, port=port).add(parallel=2)\n+    f = Flow(protocol=protocol, port=port).add(replicas=2)\n     with f:\n         threads = []\n         status_codes = [None] * CONCURRENCY\n\n\n###\n\n", "completion": "test: refactor test (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -66,7 +66,6 @@ class DockerComposeConfig:\n             from jina.parsers import set_gateway_parser\n \n             taboo = {\n-                'uses_with',\n                 'uses_metas',\n                 'volumes',\n                 'uses_before',\n\n---\n file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -55,7 +55,7 @@ class K8sDeploymentConfig:\n             self.k8s_deployments_metadata = k8s_deployments_metadata\n \n         def get_gateway_yamls(\n-                self,\n+            self,\n         ) -> List[Dict]:\n             cargs = copy.copy(self.deployment_args)\n             cargs.deployments_addresses = self.k8s_deployments_addresses\n@@ -63,7 +63,6 @@ class K8sDeploymentConfig:\n             from jina.parsers import set_gateway_parser\n \n             taboo = {\n-                'uses_with',\n                 'uses_metas',\n                 'volumes',\n                 'uses_before',\n@@ -131,7 +130,7 @@ class K8sDeploymentConfig:\n             )\n \n         def get_runtime_yamls(\n-                self,\n+            self,\n         ) -> List[Dict]:\n             cargs = copy.copy(self.deployment_args)\n \n@@ -210,7 +209,7 @@ class K8sDeploymentConfig:\n                 gpus=cargs.gpus if hasattr(cargs, 'gpus') else None,\n                 monitoring=cargs.monitoring,\n                 port_monitoring=cargs.port_monitoring,\n-                volumes=getattr(cargs, 'volumes', None)\n+                volumes=getattr(cargs, 'volumes', None),\n             )\n \n     def __init__(\n@@ -350,7 +349,7 @@ class K8sDeploymentConfig:\n         return parsed_args\n \n     def to_kubernetes_yaml(\n-            self,\n+        self,\n     ) -> List[Tuple[str, List[Dict]]]:\n         \"\"\"\n         Return a list of dictionary configurations. One for each deployment in this Deployment\n\n---\n file path A: tests/docker_compose/test_docker_compose.py | file path B: tests/docker_compose/test_docker_compose.py\n\n@@ -342,6 +342,7 @@ async def test_flow_with_custom_gateway(logger, docker_images, tmpdir):\n             port=9090,\n             protocol='http',\n             uses=f'docker://{docker_images[0]}',\n+            uses_with={'arg1': 'overridden-hello'},\n         )\n         .add(\n             name='test_executor',\n@@ -355,7 +356,8 @@ async def test_flow_with_custom_gateway(logger, docker_images, tmpdir):\n     with DockerComposeFlow(dump_path):\n \n         _validate_dummy_custom_gateway_response(\n-            flow.port, {'arg1': 'hello', 'arg2': 'world', 'arg3': 'default-arg3'}\n+            flow.port,\n+            {'arg1': 'overridden-hello', 'arg2': 'world', 'arg3': 'default-arg3'},\n         )\n         _validate_custom_gateway_process(\n             flow.port,\n\n---\n file path A: tests/k8s/test_k8s.py | file path B: tests/k8s/test_k8s.py\n\n@@ -882,6 +882,7 @@ async def test_flow_with_custom_gateway(logger, docker_images, tmpdir):\n             port=9090,\n             protocol='http',\n             uses=f'docker://{docker_images[0]}',\n+            uses_with={'arg1': 'overridden-hello'},\n         )\n         .add(\n             name='test_executor',\n@@ -925,7 +926,8 @@ async def test_flow_with_custom_gateway(logger, docker_images, tmpdir):\n         namespace, gateway_pod_name, flow.port, flow.port, config_path\n     ):\n         _validate_dummy_custom_gateway_response(\n-            flow.port, {'arg1': 'hello', 'arg2': 'world', 'arg3': 'default-arg3'}\n+            flow.port,\n+            {'arg1': 'overridden-hello', 'arg2': 'world', 'arg3': 'default-arg3'},\n         )\n         import requests\n \n\n\n###\n\n", "completion": "fix: dump uses_with for gateway in k8s and docker compose (#<issue-num>)"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -1,9 +1,9 @@\n import contextlib\n+import copy\n import inspect\n import multiprocessing\n import os\n import threading\n-import copy\n import warnings\n from types import SimpleNamespace\n from typing import TYPE_CHECKING, Any, Dict, Optional, Type, Union\n@@ -14,7 +14,10 @@ from jina.helper import ArgNamespace, T, iscoroutinefunction, typename\n from jina.importer import ImportExtensions\n from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n from jina.logging.logger import JinaLogger\n-from jina.serve.executors.decorators import avoid_concurrent_lock_cls, _init_requests_by_class\n+from jina.serve.executors.decorators import (\n+    _init_requests_by_class,\n+    avoid_concurrent_lock_cls,\n+)\n from jina.serve.executors.metas import get_executor_taboo\n from jina.serve.helper import store_init_kwargs, wrap_func\n from jina.serve.instrumentation import MetricsTimer\n@@ -57,7 +60,7 @@ class ExecutorType(type(JAMLCompatible), type):\n             arg_spec = inspect.getfullargspec(cls.__init__)\n \n             if not arg_spec.varkw and not __args_executor_init__.issubset(\n-                    arg_spec.args\n+                arg_spec.args\n             ):\n                 raise TypeError(\n                     f'{cls.__init__} does not follow the full signature of `Executor.__init__`, '\n@@ -117,12 +120,12 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n     \"\"\"\n \n     def __init__(\n-            self,\n-            metas: Optional[Dict] = None,\n-            requests: Optional[Dict] = None,\n-            runtime_args: Optional[Dict] = None,\n-            workspace: Optional[str] = None,\n-            **kwargs,\n+        self,\n+        metas: Optional[Dict] = None,\n+        requests: Optional[Dict] = None,\n+        runtime_args: Optional[Dict] = None,\n+        workspace: Optional[str] = None,\n+        **kwargs,\n     ):\n         \"\"\"`metas` and `requests` are always auto-filled with values from YAML config.\n \n@@ -160,12 +163,12 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n \n     def _init_monitoring(self):\n         if (\n-                hasattr(self.runtime_args, 'metrics_registry')\n-                and self.runtime_args.metrics_registry\n+            hasattr(self.runtime_args, 'metrics_registry')\n+            and self.runtime_args.metrics_registry\n         ):\n             with ImportExtensions(\n-                    required=True,\n-                    help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n+                required=True,\n+                help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n             ):\n                 from prometheus_client import Summary\n \n@@ -296,7 +299,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                 if not hasattr(target, k):\n                     if isinstance(v, str):\n                         if not (\n-                                env_var_regex.findall(v) or internal_var_regex.findall(v)\n+                            env_var_regex.findall(v) or internal_var_regex.findall(v)\n                         ):\n                             setattr(target, k, v)\n                         else:\n@@ -348,10 +351,10 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             return await self.__acall_endpoint__(__default_endpoint__, **kwargs)\n \n     async def __acall_endpoint__(\n-            self, req_endpoint, tracing_context: Optional['Context'], **kwargs\n+        self, req_endpoint, tracing_context: Optional['Context'], **kwargs\n     ):\n         async def exec_func(\n-                summary, histogram, histogram_metric_labels, tracing_context\n+            summary, histogram, histogram_metric_labels, tracing_context\n         ):\n             with MetricsTimer(summary, histogram, histogram_metric_labels):\n                 if iscoroutinefunction(func):\n@@ -379,7 +382,9 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         }\n \n         if self.tracer:\n-            with self.tracer.start_span(req_endpoint, context=tracing_context) as _:\n+            with self.tracer.start_as_current_span(\n+                req_endpoint, context=tracing_context\n+            ):\n                 from opentelemetry.propagate import extract\n                 from opentelemetry.trace.propagation.tracecontext import (\n                     TraceContextTextMapPropagator,\n@@ -409,10 +414,10 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         :return: returns the workspace of the current shard of this Executor.\n         \"\"\"\n         workspace = (\n-                getattr(self.runtime_args, 'workspace', None)\n-                or getattr(self.metas, 'workspace')\n-                or self._init_workspace\n-                or __cache_path__\n+            getattr(self.runtime_args, 'workspace', None)\n+            or getattr(self.metas, 'workspace')\n+            or self._init_workspace\n+            or __cache_path__\n         )\n         if workspace:\n             complete_workspace = os.path.join(workspace, self.metas.name)\n@@ -435,13 +440,13 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n \n     @classmethod\n     def from_hub(\n-            cls: Type[T],\n-            uri: str,\n-            context: Optional[Dict[str, Any]] = None,\n-            uses_with: Optional[Dict] = None,\n-            uses_metas: Optional[Dict] = None,\n-            uses_requests: Optional[Dict] = None,\n-            **kwargs,\n+        cls: Type[T],\n+        uri: str,\n+        context: Optional[Dict[str, Any]] = None,\n+        uses_with: Optional[Dict] = None,\n+        uses_metas: Optional[Dict] = None,\n+        uses_requests: Optional[Dict] = None,\n+        **kwargs,\n     ) -> T:\n         \"\"\"Construct an Executor from Hub.\n \n@@ -493,12 +498,12 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n \n     @classmethod\n     def serve(\n-            cls,\n-            uses_with: Optional[Dict] = None,\n-            uses_metas: Optional[Dict] = None,\n-            uses_requests: Optional[Dict] = None,\n-            stop_event: Optional[Union[threading.Event, multiprocessing.Event]] = None,\n-            **kwargs,\n+        cls,\n+        uses_with: Optional[Dict] = None,\n+        uses_metas: Optional[Dict] = None,\n+        uses_requests: Optional[Dict] = None,\n+        stop_event: Optional[Union[threading.Event, multiprocessing.Event]] = None,\n+        **kwargs,\n     ):\n         \"\"\"Serve this Executor in a temporary Flow. Useful in testing an Executor in remote settings.\n \n@@ -531,16 +536,16 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n \n     @staticmethod\n     def to_kubernetes_yaml(\n-            uses: str,\n-            output_base_path: str,\n-            k8s_namespace: Optional[str] = None,\n-            executor_type: Optional[\n-                StandaloneExecutorType\n-            ] = StandaloneExecutorType.EXTERNAL,\n-            uses_with: Optional[Dict] = None,\n-            uses_metas: Optional[Dict] = None,\n-            uses_requests: Optional[Dict] = None,\n-            **kwargs,\n+        uses: str,\n+        output_base_path: str,\n+        k8s_namespace: Optional[str] = None,\n+        executor_type: Optional[\n+            StandaloneExecutorType\n+        ] = StandaloneExecutorType.EXTERNAL,\n+        uses_with: Optional[Dict] = None,\n+        uses_metas: Optional[Dict] = None,\n+        uses_requests: Optional[Dict] = None,\n+        **kwargs,\n     ):\n         \"\"\"\n         Converts the Executor into a set of yaml deployments to deploy in Kubernetes.\n@@ -568,23 +573,23 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             output_base_path=output_base_path,\n             k8s_namespace=k8s_namespace,\n             include_gateway=executor_type\n-                            == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n+            == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n         )\n \n     to_k8s_yaml = to_kubernetes_yaml\n \n     @staticmethod\n     def to_docker_compose_yaml(\n-            uses: str,\n-            output_path: Optional[str] = None,\n-            network_name: Optional[str] = None,\n-            executor_type: Optional[\n-                StandaloneExecutorType\n-            ] = StandaloneExecutorType.EXTERNAL,\n-            uses_with: Optional[Dict] = None,\n-            uses_metas: Optional[Dict] = None,\n-            uses_requests: Optional[Dict] = None,\n-            **kwargs,\n+        uses: str,\n+        output_path: Optional[str] = None,\n+        network_name: Optional[str] = None,\n+        executor_type: Optional[\n+            StandaloneExecutorType\n+        ] = StandaloneExecutorType.EXTERNAL,\n+        uses_with: Optional[Dict] = None,\n+        uses_metas: Optional[Dict] = None,\n+        uses_requests: Optional[Dict] = None,\n+        **kwargs,\n     ):\n         \"\"\"\n         Converts the Executor into a yaml file to run with `docker-compose up`\n@@ -609,11 +614,11 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             output_path=output_path,\n             network_name=network_name,\n             include_gateway=executor_type\n-                            == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n+            == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n         )\n \n     def monitor(\n-            self, name: Optional[str] = None, documentation: Optional[str] = None\n+        self, name: Optional[str] = None, documentation: Optional[str] = None\n     ) -> Optional[MetricsTimer]:\n         \"\"\"\n         Get a given prometheus metric, if it does not exist yet, it will create it and store it in a buffer.\n\n---\n file path A: tests/integration/instrumentation/test_flow_instrumentation.py | file path B: tests/integration/instrumentation/test_flow_instrumentation.py\n\n@@ -192,10 +192,10 @@ def test_flow_metrics(\n     )\n     assert len(receiving_request_seconds_metrics) > 0\n     assert receiving_request_seconds_exported_jobs == {\n-            'gateway/rep-0',\n-            'executor0/head',\n-            'executor0/shard-0/rep-0',\n-            'executor0/shard-1/rep-0',\n+        'gateway/rep-0',\n+        'executor0/head',\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n     }\n \n     (\n@@ -224,10 +224,10 @@ def test_flow_metrics(\n     )\n     assert len(sent_response_bytes_metrics) > 0\n     assert sent_response_bytes_exported_jobs == {\n-            'gateway/rep-0',\n-            'executor0/shard-0/rep-0',\n-            'executor0/shard-1/rep-0',\n-            'executor0/head'\n+        'gateway/rep-0',\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n+        'executor0/head',\n     }\n \n     (\n@@ -237,7 +237,10 @@ def test_flow_metrics(\n         prometheus_client, 'jina_number_of_pending_requests'\n     )\n     assert len(number_of_pending_requests_metrics) > 0\n-    assert number_of_pending_requests_exported_jobs == {'gateway/rep-0', 'executor0/head'}\n+    assert number_of_pending_requests_exported_jobs == {\n+        'gateway/rep-0',\n+        'executor0/head',\n+    }\n \n     (\n         failed_requests_metrics,\n@@ -245,10 +248,10 @@ def test_flow_metrics(\n     ) = get_metrics_and_exported_jobs_by_name(prometheus_client, 'jina_failed_requests')\n     assert len(failed_requests_metrics) > 0\n     assert failed_requests_exported_jobs == {\n-            'gateway/rep-0',\n-            'executor0/head',\n-            'executor0/shard-0/rep-0',\n-            'executor0/shard-1/rep-0',\n+        'gateway/rep-0',\n+        'executor0/head',\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n     }\n \n     (\n@@ -258,7 +261,12 @@ def test_flow_metrics(\n         prometheus_client, 'jina_successful_requests'\n     )\n     assert len(successful_requests_metrics) > 0\n-    assert successful_requests_exported_jobs == {'gateway/rep-0', 'executor0/shard-0/rep-0', 'executor0/shard-1/rep-0', 'executor0/head'}\n+    assert successful_requests_exported_jobs == {\n+        'gateway/rep-0',\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n+        'executor0/head',\n+    }\n \n     (\n         received_request_bytes_metrics,\n@@ -267,7 +275,12 @@ def test_flow_metrics(\n         prometheus_client, 'jina_received_request_bytes'\n     )\n     assert len(received_request_bytes_metrics) > 0\n-    assert received_request_bytes_exported_jobs == {'gateway/rep-0', 'executor0/shard-0/rep-0', 'executor0/shard-1/rep-0', 'executor0/head'}\n+    assert received_request_bytes_exported_jobs == {\n+        'gateway/rep-0',\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n+        'executor0/head',\n+    }\n \n     (\n         process_requests_seconds_metrics,\n@@ -276,7 +289,10 @@ def test_flow_metrics(\n         prometheus_client, 'jina_process_request_seconds'\n     )\n     assert len(process_requests_seconds_metrics) > 0\n-    assert process_requests_seconds_exported_jobs == {'executor0/shard-0/rep-0', 'executor0/shard-1/rep-0'}\n+    assert process_requests_seconds_exported_jobs == {\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n+    }\n \n     # filter by attributes/labels\n     (\n@@ -288,7 +304,10 @@ def test_flow_metrics(\n         {'executor_endpoint': '/search'},\n     )\n     assert len(process_requests_seconds_search_endpoint) > 0\n-    assert process_requests_seconds_search_endpoint_exported_jobs == {'executor0/shard-0/rep-0', 'executor0/shard-1/rep-0'}\n+    assert process_requests_seconds_search_endpoint_exported_jobs == {\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n+    }\n \n     (\n         process_requests_seconds_executor,\n@@ -299,7 +318,10 @@ def test_flow_metrics(\n         {'executor': 'ExecutorFailureWithTracing'},\n     )\n     assert len(process_requests_seconds_executor) > 0\n-    assert process_requests_seconds_executor_exported_jobs == {'executor0/shard-0/rep-0', 'executor0/shard-1/rep-0'}\n+    assert process_requests_seconds_executor_exported_jobs == {\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n+    }\n \n     (\n         process_requests_seconds_runtime,\n\n---\n file path A: None | file path B: tests/integration/instrumentation/test_worker_instrumentation.py\n\n@@ -0,0 +1,43 @@\n+import time\n+\n+from jina import Flow\n+from tests.integration.instrumentation import ExecutorTestWithTracing, get_traces\n+\n+\n+def test_span_order(jaeger_port, otlp_collector, otlp_receiver_port):\n+    f = Flow(\n+        tracing=True,\n+        traces_exporter_host='localhost',\n+        traces_exporter_port=otlp_receiver_port,\n+    ).add(uses=ExecutorTestWithTracing)\n+\n+    with f:\n+        from jina import DocumentArray\n+\n+        f.post(f'/search', DocumentArray.empty(), continue_on_error=True)\n+        # give some time for the tracing and metrics exporters to finish exporting.\n+        # the client is slow to export the data\n+        time.sleep(8)\n+\n+    traces = get_traces(jaeger_port, 'executor0/rep-0')\n+    process_single_data_span_ids = set()\n+    search_request_parent_span_ids = set()\n+    for trace in traces:\n+        for span in trace['spans']:\n+            if (\n+                span['operationName']\n+                == '/jina.JinaSingleDataRequestRPC/process_single_data'\n+            ):\n+                process_single_data_span_ids.add(span['spanID'])\n+\n+            if span['operationName'] == '/search':\n+                references = span.get('references', [])\n+                for ref in references:\n+                    search_request_parent_span_ids.add(ref.get('spanID', ''))\n+\n+    assert any(\n+        [\n+            search_span in process_single_data_span_ids\n+            for search_span in search_request_parent_span_ids\n+        ]\n+    )\n\n\n###\n\n", "completion": "fix: use start_as_current_span to maintain tracing operation chain (#<issue-num>)"}
{"prompt": " file path A: jina/serve/instrumentation/__init__.py | file path B: jina/serve/instrumentation/__init__.py\n\n@@ -2,7 +2,7 @@ import functools\n from timeit import default_timer\n from typing import TYPE_CHECKING, Dict, Optional, Sequence\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     from grpc.aio._interceptor import ClientInterceptor, ServerInterceptor\n     from opentelemetry.instrumentation.grpc._client import (\n         OpenTelemetryClientInterceptor,\n@@ -147,7 +147,9 @@ class MetricsTimer:\n         self._histogram_metric_labels = histogram_metric_labels\n \n     def _new_timer(self):\n-        return self.__class__(self._summary_metric, self._histogram, self._histogram_metric_labels)\n+        return self.__class__(\n+            self._summary_metric, self._histogram, self._histogram_metric_labels\n+        )\n \n     def __enter__(self):\n         self._start = default_timer()\n\n---\n file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -16,7 +16,7 @@ from jina.serve.runtimes.base import BaseRuntime\n from jina.serve.runtimes.monitoring import MonitoringMixin\n from jina.types.request.data import DataRequest\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     import multiprocessing\n     import threading\n \n\n---\n file path A: jina/serve/runtimes/gateway/grpc/gateway.py | file path B: jina/serve/runtimes/gateway/grpc/gateway.py\n\n@@ -35,7 +35,7 @@ class GRPCGateway(BaseGateway):\n         self.grpc_server_options = grpc_server_options\n         self.ssl_keyfile = ssl_keyfile\n         self.ssl_certfile = ssl_certfile\n-        self.health_servicer = health.HealthServicer(experimental_non_blocking=True)\n+        self.health_servicer = health.aio.HealthServicer()\n \n     async def setup_server(self):\n         \"\"\"\n@@ -63,7 +63,9 @@ class GRPCGateway(BaseGateway):\n         health_pb2_grpc.add_HealthServicer_to_server(self.health_servicer, self.server)\n \n         for service in service_names:\n-            self.health_servicer.set(service, health_pb2.HealthCheckResponse.SERVING)\n+            await self.health_servicer.set(\n+                service, health_pb2.HealthCheckResponse.SERVING\n+            )\n         reflection.enable_server_reflection(service_names, self.server)\n \n         bind_addr = f'{__default_host__}:{self.port}'\n@@ -97,7 +99,7 @@ class GRPCGateway(BaseGateway):\n     async def teardown(self):\n         \"\"\"Free other resources allocated with the server, e.g, gateway object, ...\"\"\"\n         await super().teardown()\n-        self.health_servicer.enter_graceful_shutdown()\n+        await self.health_servicer.enter_graceful_shutdown()\n \n     async def stop_server(self):\n         \"\"\"\n@@ -118,6 +120,7 @@ class GRPCGateway(BaseGateway):\n         :returns: the response request\n         \"\"\"\n         from docarray import DocumentArray\n+\n         from jina.clients.request import request_generator\n         from jina.enums import DataInputType\n         from jina.serve.executors import __dry_run_endpoint__\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -36,7 +36,7 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n         :param args: args from CLI\n         :param kwargs: keyword args\n         \"\"\"\n-        self._health_servicer = health.HealthServicer(experimental_non_blocking=True)\n+        self._health_servicer = health.aio.HealthServicer()\n \n         super().__init__(args, **kwargs)\n         if args.name is None:\n@@ -154,7 +154,9 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n         )\n \n         for service in service_names:\n-            self._health_servicer.set(service, health_pb2.HealthCheckResponse.SERVING)\n+            await self._health_servicer.set(\n+                service, health_pb2.HealthCheckResponse.SERVING\n+            )\n         reflection.enable_server_reflection(service_names, self._grpc_server)\n \n         bind_addr = f'0.0.0.0:{self.args.port}'\n@@ -174,7 +176,7 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n \n     async def async_teardown(self):\n         \"\"\"Close the connection pool\"\"\"\n-        self._health_servicer.enter_graceful_shutdown()\n+        await self._health_servicer.enter_graceful_shutdown()\n         await self.async_cancel()\n         await self.connection_pool.close()\n \n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -32,7 +32,7 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         :param args: args from CLI\n         :param kwargs: keyword args\n         \"\"\"\n-        self._health_servicer = health.HealthServicer(experimental_non_blocking=True)\n+        self._health_servicer = health.aio.HealthServicer()\n         super().__init__(args, **kwargs)\n \n     async def async_setup(self):\n@@ -140,7 +140,9 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         )\n \n         for service in service_names:\n-            self._health_servicer.set(service, health_pb2.HealthCheckResponse.SERVING)\n+            await self._health_servicer.set(\n+                service, health_pb2.HealthCheckResponse.SERVING\n+            )\n         reflection.enable_server_reflection(service_names, self._grpc_server)\n         bind_addr = f'0.0.0.0:{self.args.port}'\n         self.logger.debug(f'start listening on {bind_addr}')\n@@ -162,7 +164,7 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n \n     async def async_teardown(self):\n         \"\"\"Close the data request handler\"\"\"\n-        self._health_servicer.enter_graceful_shutdown()\n+        await self._health_servicer.enter_graceful_shutdown()\n         await self.async_cancel()\n         self._request_handler.close()\n \n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -210,10 +210,9 @@ ac_table = {\n         'hub': ['--help', 'new', 'push', 'pull', 'status', 'list'],\n         'cloud login': ['--help'],\n         'cloud logout': ['--help'],\n-        'cloud deploy': ['--help', '--name', '--workspace', '--env-file'],\n-        'cloud list': ['--help', '--status'],\n-        'cloud logs': ['--help', '--executor'],\n-        'cloud status': ['--help'],\n+        'cloud deploy': ['--help'],\n+        'cloud list': ['--help', '--phase', '--name'],\n+        'cloud status': ['--help', '--verbose'],\n         'cloud remove': ['--help'],\n         'cloud new': ['--help'],\n         'cloud survey': ['--help'],\n@@ -225,7 +224,6 @@ ac_table = {\n             'logout',\n             'deploy',\n             'list',\n-            'logs',\n             'status',\n             'remove',\n             'new',\n\n---\n file path A: None | file path B: tests/integration/conftest.py\n\n@@ -0,0 +1,25 @@\n+import os\n+import time\n+\n+import pytest\n+\n+\n+@pytest.fixture()\n+def docker_image_name():\n+    return 'jina/replica-exec'\n+\n+\n+@pytest.fixture()\n+def docker_image_built(docker_image_name):\n+    cur_dir = os.path.dirname(os.path.abspath(__file__))\n+    import docker\n+\n+    client = docker.from_env()\n+    client.images.build(\n+        path=os.path.join(cur_dir, 'replica-exec'), tag=docker_image_name\n+    )\n+    client.close()\n+    yield\n+    time.sleep(2)\n+    client = docker.from_env()\n+    client.containers.prune()\n\n---\n file path A: tests/integration/container_runtime_args/test_container_get_args.py | file path B: tests/integration/container_runtime_args/test_container_get_args.py\n\n@@ -5,31 +5,16 @@ import pytest\n \n from jina import Client, Document, DocumentArray, Flow\n \n-cur_dir = os.path.dirname(os.path.abspath(__file__))\n-\n-img_name = 'jina/replica-exec'\n-\n-\n-@pytest.fixture(scope='function')\n-def docker_image_built():\n-    import docker\n-\n-    client = docker.from_env()\n-    client.images.build(path=os.path.join(cur_dir, 'replica-exec'), tag=img_name)\n-    client.close()\n-    yield\n-    time.sleep(2)\n-    client = docker.from_env()\n-    client.containers.prune()\n-\n \n @pytest.mark.parametrize('shards', [1, 2])\n @pytest.mark.parametrize('replicas', [1, 3, 4])\n-def test_containerruntime_args(docker_image_built, shards, replicas, port_generator):\n+def test_containerruntime_args(\n+    docker_image_name, docker_image_built, shards, replicas, port_generator\n+):\n     exposed_port = port_generator()\n     f = Flow(port=exposed_port).add(\n         name='executor_container',\n-        uses=f'docker://{img_name}',\n+        uses=f'docker://{docker_image_name}',\n         replicas=replicas,\n         shards=shards,\n         polling='ANY',\n\n---\n file path A: tests/integration/external_deployment/test_external_deployment.py | file path B: tests/integration/external_deployment/test_external_deployment.py\n\n@@ -419,7 +419,7 @@ def test_external_flow_with_grpc_metadata():\n             )\n \n             for service in service_names:\n-                self.health_servicer.set(\n+                await self.health_servicer.set(\n                     service, health_pb2.HealthCheckResponse.SERVING\n                 )\n             reflection.enable_server_reflection(service_names, self.server)\n\n---\n file path A: None | file path B: tests/integration/instrumentation/test_container_instrumentation.py\n\n@@ -0,0 +1,50 @@\n+import os\n+import time\n+\n+import pytest\n+\n+from jina import Flow\n+from tests.integration.instrumentation import (\n+    get_exported_jobs,\n+    get_flow_metric_labels,\n+    get_services,\n+)\n+\n+\n+def test_docker_instrumentation(\n+    jaeger_port,\n+    otlp_collector,\n+    otlp_receiver_port,\n+    docker_image_name,\n+    docker_image_built,\n+    prometheus_client,\n+    expected_flow_metric_labels,\n+):\n+    f = Flow(\n+        tracing=True,\n+        traces_exporter_host='localhost',\n+        traces_exporter_port=otlp_receiver_port,\n+        metrics=True,\n+        metrics_exporter_host='localhost',\n+        metrics_exporter_port=otlp_receiver_port,\n+    ).add(uses=f'docker://{docker_image_name}')\n+\n+    with f:\n+        from jina import DocumentArray\n+\n+        f.post(f'/search', DocumentArray.empty(), continue_on_error=True)\n+        # give some time for the tracing and metrics exporters to finish exporting.\n+        # the client is slow to export the data\n+        time.sleep(3)\n+\n+    services = get_services(jaeger_port)\n+    assert set(services) == {'executor0/rep-0', 'gateway/rep-0'}\n+\n+    exported_jobs = get_exported_jobs(prometheus_client)\n+    assert exported_jobs == {\n+        'gateway/rep-0',\n+        'executor0/rep-0',\n+    }\n+\n+    flow_metric_labels = get_flow_metric_labels(prometheus_client)\n+    assert flow_metric_labels.issubset(expected_flow_metric_labels)\n\n---\n file path A: tests/integration/container_runtime_args/replica-exec/Dockerfile | file path B: tests/integration/replica-exec/Dockerfile\n\n\n---\n file path A: tests/integration/container_runtime_args/replica-exec/__init__.py | file path B: tests/integration/replica-exec/__init__.py\n\n\n---\n file path A: tests/integration/container_runtime_args/replica-exec/config.yml | file path B: tests/integration/replica-exec/config.yml\n\n\n\n###\n\n", "completion": "fix: health check exception with opentelemetry tracing interceptors (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/client/third-party-client.md | file path B: docs/fundamentals/client/third-party-client.md\n\n@@ -9,7 +9,11 @@ Our [Go Client](https://github.com/jina-ai/client-go) supports gRPC, HTTP and We\n \n ## PHP\n \n-A big thanks to our community member at [Jonathan Rowley](https://jina-ai.slack.com/team/U03973EA7BN) for developing a [PHP Client](https://github.com/Dco-ai/php-jina) for Jina!\n+A big thanks to our community member [Jonathan Rowley](https://jina-ai.slack.com/team/U03973EA7BN) for developing a [PHP client](https://github.com/Dco-ai/php-jina) for Jina!\n+\n+## Kotlin\n+\n+A big thanks to our community member [Peter Willemsen](https://jina-ai.slack.com/team/U03R0KNBK98) for developing a [Kotlin client](https://github.com/peterwilli/JinaKotlin) for Jina!\n \n ## HTTP\n \n\n\n###\n\n", "completion": "docs: add reference to kotlin client by community (#<issue-num>)"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -1033,6 +1033,8 @@ class GrpcConnectionPool:\n                     )\n                     if error:\n                         return error\n+                except Exception as e:\n+                    return e\n \n         return asyncio.create_task(task_wrapper())\n \n\n---\n file path A: jina/serve/runtimes/head/request_handling.py | file path B: jina/serve/runtimes/head/request_handling.py\n\n@@ -155,6 +155,7 @@ class HeaderRequestHandler(MonitoringRequestMixin):\n                 retries=retries,\n             )\n             if issubclass(type(result), BaseException):\n+                self._update_end_failed_requests_metrics()\n                 raise result\n             else:\n                 response_request, uses_after_metadata = result\n\n\n###\n\n", "completion": "fix: decrement requests count in case of exception inside HeadRuntime (#<issue-num>)"}
{"prompt": " file path A: scripts/get-openapi-schemas.py | file path B: scripts/get-openapi-schemas.py\n\n@@ -15,13 +15,13 @@ logger = JinaLogger('')\n graph_description = json.loads(args.graph_description)\n graph_conditions = json.loads(args.graph_conditions)\n deployments_addresses = json.loads(args.deployments_addresses)\n-deployments_disable_reduce = json.loads(args.deployments_disable_reduce)\n+deployments_no_reduce = json.loads(args.deployments_no_reduce)\n \n streamer = GatewayStreamer(\n     graph_representation=graph_description,\n     executor_addresses=deployments_addresses,\n     graph_conditions=graph_conditions,\n-    deployments_disable_reduce=deployments_disable_reduce,\n+    deployments_no_reduce=deployments_no_reduce,\n     timeout_send=args.timeout_send,\n     retries=args.retries,\n     compression=args.compression,\n\n\n###\n\n", "completion": "chore: fix cd (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/remarks.md | file path B: docs/fundamentals/flow/remarks.md\n\n@@ -105,7 +105,7 @@\n \n \n \n-## multiprocessing Spawn\n+## Multiprocessing Spawn\n \n Few cases require to use `spawn` start method for multiprocessing. \n (e.g.- Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method)\n@@ -132,6 +132,20 @@ Few cases require to use `spawn` start method for multiprocessing.\n     Inline functions, such as nested or lambda functions are not picklable. Use `functools.partial` instead.\n \n \n+## Multiprocessing Fork in MacOS\n+\n+Apple has changed the rules for using Objective-C between `fork()` and `exec()` since macOS 10.13.\n+This may break some codes that use `fork()` in MacOS.\n+For example, the Flow may not be able to start properly with error messages similar to:\n+\n+```bash\n+objc[20337]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called.\n+objc[20337]: +[__NSCFConstantString initialize] may have been in progress in another thread when fork() was called. We cannot safely call it or ignore it in the fork() child process. Crashing instead. Set a breakpoint on objc_initializeAfterForkError to debug.```\n+```\n+\n+You can define the environment variable `OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES` to get around this issue.\n+Read [here](http://sealiesoftware.com/blog/archive/2017/6/5/Objective-C_and_fork_in_macOS_1013.html) for more details.\n+\n \n ## Debugging Executor in a Flow\n \n\n\n###\n\n", "completion": "docs: add tips for using multiprocessing fork in macos (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.23.3:    core\n+jina-hubble-sdk==0.24.1:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.23.3:    core\n+jina-hubble-sdk==0.24.1:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n\n###\n\n", "completion": "chore: bump hubble sdk (#<issue-num>)"}
{"prompt": " file path A: jina/types/request/data.py | file path B: jina/types/request/data.py\n\n@@ -310,7 +310,6 @@ class DataRequest(Request):\n         \"\"\"\n         route_proto = jina_pb2.RouteProto()\n         route_proto.executor = executor_name\n-        print(f' type {type(self.proto_wo_data.routes)}')\n         self.proto_wo_data.routes.append(route_proto)\n \n     @property\n\n\n###\n\n", "completion": "chore: remove useless print (#<issue-num>)"}
{"prompt": " file path A: conda/meta.yaml | file path B: conda/meta.yaml\n\n@@ -1,5 +1,5 @@\n {% set name = \"jina\" %}\n-{% set version = \"3.0.0\" %}\n+{% set version = \"3.11.0\" %}\n \n package:\n   name: {{ name|lower }}-split\n@@ -7,7 +7,7 @@ package:\n \n source:\n   url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n-  sha256: d8c033d34f31a7086385242087fd8d1d567699eddad67f401ef8b216c9636cff\n+  sha256: 49a7fec74b3b0927143d73ce787c7e3fe5e52fa2a1079323248a20590d2bf49f\n \n build:\n   number: 0\n@@ -36,10 +36,16 @@ outputs:\n       run:\n         - __unix\n         - python >=3.7\n-        - docarray >=0.6.3\n-        - grpcio >=1.33.1\n+        - docarray >=0.16.4\n+        - grpcio >=1.46.0,<1.48.1\n+        - grpcio-health-checking >=1.46.0,<1.48.1\n+        - grpcio-reflection >=1.46.0,<1.48.1\n+        - jina-hubble-sdk ==0.23.3\n         - numpy\n-        - protobuf >=3.19.1\n+        - opentelemetry-api >=1.12.0\n+        - opentelemetry-instrumentation-grpc >=0.33b0\n+        - packaging >=20.0\n+        - protobuf >=3.20.0\n         - pyyaml >=5.3.1\n   - name: jina-perf\n     test:\n@@ -64,12 +70,22 @@ outputs:\n       run:\n         - __unix\n         - python >=3.7\n-        - docarray >=0.6.3\n-        - grpcio >=1.33.1\n-        - lz4 <3.1.2\n+        - docarray >=0.16.4\n+        - grpcio >=1.46.0,<1.48.1\n+        - grpcio-health-checking >=1.46.0,<1.48.1\n+        - grpcio-reflection >=1.46.0,<1.48.1\n+        - jina-hubble-sdk ==0.23.3\n         - numpy\n-        - protobuf >=3.19.1\n-        - python-kubernetes >=18.20.0\n+        - opentelemetry-api >=1.12.0\n+        - opentelemetry-exporter-otlp >=1.12.0\n+        - opentelemetry-instrumentation-aiohttp-client >=0.33b0\n+        - opentelemetry-instrumentation-fastapi >=0.33b0\n+        - opentelemetry-instrumentation-grpc >=0.33b0\n+        - opentelemetry-sdk >=1.12.0\n+        - opentelemetry-semantic-conventions >=0.33b0\n+        - packaging >=20.0\n+        - prometheus_client\n+        - protobuf >=3.20.0\n         - pyyaml >=5.3.1\n         - uvloop\n   - name: jina\n@@ -97,22 +113,31 @@ outputs:\n         - aiohttp\n         - aiostream\n         - cryptography\n-        - docarray >=0.6.3\n+        - docarray >=0.16.4\n         - docker-py\n-        - fastapi\n+        - fastapi >=0.76.0\n         - filelock\n-        - grpcio >=1.33.1\n-        - lz4 <3.1.2\n+        - grpcio >=1.46.0,<1.48.1\n+        - grpcio-health-checking >=1.46.0,<1.48.1\n+        - grpcio-reflection >=1.46.0,<1.48.1\n+        - jina-hubble-sdk ==0.23.3\n         - numpy\n+        - opentelemetry-api >=1.12.0\n+        - opentelemetry-exporter-otlp >=1.12.0\n+        - opentelemetry-instrumentation-aiohttp-client >=0.33b0\n+        - opentelemetry-instrumentation-fastapi >=0.33b0\n+        - opentelemetry-instrumentation-grpc >=0.33b0\n+        - opentelemetry-sdk >=1.12.0\n+        - opentelemetry-semantic-conventions >=0.33b0\n+        - packaging >=20.0\n         - pathspec\n-        - protobuf >=3.19.1\n+        - prometheus_client\n+        - protobuf >=3.20.0\n         - pydantic\n-        - python-kubernetes >=18.20.0\n         - python-multipart\n         - pyyaml >=5.3.1\n         - requests\n-        - rich\n-        - uvicorn >=0.14.0,<=0.16.0\n+        - uvicorn\n         - uvloop\n         - websockets\n \n@@ -121,12 +146,11 @@ about:\n   license: Apache-2.0\n   license_family: Apache\n   license_file: LICENSE\n-  summary: Build cross-modal and multi-modal applications on the cloud\n+  summary: \"Build cross-modal and multi-modal applications on the cloud \\xB7 Neural Search \\xB7 Creative AI \\xB7 Cloud Native\"\n   doc_url: https://docs.jina.ai\n \n extra:\n   recipe-maintainers:\n-    - tadejsv\n     - JoanFM\n     - nan-wang\n     - hanxiao\n\n---\n file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -48,7 +48,6 @@ opentelemetry-instrumentation-fastapi>=0.33b0: perf,standard,devel\n opentelemetry-exporter-otlp-proto-grpc>=1.13.0: perf,standrad,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n-docarray[common]>=0.16.3:   standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n@@ -87,4 +86,4 @@ jsonschema:                 cicd\n portforward>=0.2.4:         cicd\n tensorflow>=2.0:            cicd\n opentelemetry-test-utils>=0.33b0:  test\n-prometheus-api-client>=0.5.1:  test\n\\ No newline at end of file\n+prometheus-api-client>=0.5.1:  test\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -935,8 +935,14 @@ def get_full_version() -> Optional[Tuple[Dict, Dict]]:\n     import yaml\n     from google.protobuf.internal import api_implementation\n     from grpc import _grpcio_metadata\n-    from hubble import __version__ as __hubble_version__\n-    from jcloud import __version__ as __jcloud_version__\n+    try:\n+        from hubble import __version__ as __hubble_version__\n+    except:\n+        __hubble_version__ = 'not-available'\n+    try:\n+        from jcloud import __version__ as __jcloud_version__\n+    except:\n+        __jcloud_version__ = 'not-available'\n \n     from jina import (\n         __docarray_version__,\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -48,7 +48,6 @@ opentelemetry-instrumentation-fastapi>=0.33b0: perf,standard,devel\n opentelemetry-exporter-otlp-proto-grpc>=1.13.0: perf,standrad,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n-docarray[common]>=0.16.3:   standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n@@ -87,4 +86,4 @@ jsonschema:                 cicd\n portforward>=0.2.4:         cicd\n tensorflow>=2.0:            cicd\n opentelemetry-test-utils>=0.33b0:  test\n-prometheus-api-client>=0.5.1:  test\n\\ No newline at end of file\n+prometheus-api-client>=0.5.1:  test\n\n---\n file path A: scripts/create-conda-recipe.py | file path B: scripts/create-conda-recipe.py\n\n@@ -71,6 +71,7 @@ class RecipeDumper(yaml.SafeDumper):\n # Get requirements from the extra-requirements.txt file\n #######################################################\n \n+NON_EXISTING_CONDA_PACKAGES = ['jcloud', 'opentelemetry-exporter-otlp-proto-grpc', 'opentelemetry-exporter-prometheus']\n extra_deps = get_extra_requires('extra-requirements.txt')\n reqs = {}\n \n@@ -82,6 +83,17 @@ reqs['standard'] = reqs['perf'].union(extra_deps['standard'])\n \n for key in list(reqs.keys()):\n     reqs[key] = sorted(list(reqs[key]))\n+    ids_to_remove = []\n+    for i, v in enumerate(reqs[key]):\n+        remove = False\n+        for non_existing in NON_EXISTING_CONDA_PACKAGES:\n+            if non_existing in v:\n+                remove = True\n+        if remove:\n+            ids_to_remove.append(i)\n+\n+    for _i in reversed(ids_to_remove):\n+        del reqs[key][_i]\n \n \n ######################################\n\n\n###\n\n", "completion": "chore: update conda recipe script (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -38,7 +38,7 @@ jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n uvloop:                     perf,standard,devel\n-prometheus_client:          perf,standard,devel\n+prometheus_client>=0.12.0:          perf,standard,devel\n opentelemetry-sdk>=1.12.0:   perf,standard,devel\n opentelemetry-exporter-otlp>=1.12.0:  perf,standard,devel\n opentelemetry-exporter-prometheus>=1.12.0rc1:  perf,standard,devel\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -38,7 +38,7 @@ jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n uvloop:                     perf,standard,devel\n-prometheus_client:          perf,standard,devel\n+prometheus_client>=0.12.0:          perf,standard,devel\n opentelemetry-sdk>=1.12.0:   perf,standard,devel\n opentelemetry-exporter-otlp>=1.12.0:  perf,standard,devel\n opentelemetry-exporter-prometheus>=1.12.0rc1:  perf,standard,devel\n\n\n###\n\n", "completion": "chore: add minimum prometheus client version (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -121,7 +121,7 @@ A successful start of a Flow looks like this:\n \n Your addresses and entrypoints can be found in the output. When you enable more features such as monitoring, HTTP gateway, TLS encryption, this display expands to contain more information.\n \n-\n+(multiprocessing-spawn)\n ### Set multiprocessing `spawn` \n \n Some corner cases require forcing a `spawn` start method for multiprocessing, for example if you encounter \"Cannot re-initialize CUDA in forked subprocess\". \n@@ -132,6 +132,11 @@ You can use `JINA_MP_START_METHOD=spawn` before starting the Python script to en\n JINA_MP_START_METHOD=spawn python app.py\n ```\n \n+```{caution}\n+In case you set `JINA_MP_START_METHOD=spawn`, make sure to use Flow as a context manager inside `if __name__ == '__main__'`.\n+The script entrypoint (starting the flow) [needs to be protected when using `spawn` start method](https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods). \n+```\n+\n ````{hint}\n There's no need to set this for Windows, as it only supports spawn method for multiprocessing. \n ````\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -135,4 +135,5 @@ instrumenting-flow\n health-check\n when-things-go-wrong\n yaml-spec\n+remarks\n ```\n\n---\n file path A: None | file path B: docs/fundamentals/flow/remarks.md\n\n@@ -0,0 +1,189 @@\n+# Remarks\n+\n+- Define & start the Flow via an explicit function call inside `if __name__ == '__main__'`, **especially when using `spawn` multiprocessing start method**. For example\n+\n+    ````{tab} \u2705 Do\n+    ```{code-block} python\n+    ---\n+    emphasize-lines: 13, 14\n+    ---\n+\n+    from jina import Flow, Executor, requests\n+\n+    class CustomExecutor(Executor):\n+        @requests\n+        def foo(self, **kwargs):\n+            ...\n+\n+    def main():\n+        f = Flow().add(uses=CustomExecutor)\n+        with f:\n+            ...\n+\n+    if __name__ == '__main__':\n+        main()\n+    ```\n+    ````\n+\n+    ````{tab} \ud83d\ude14 Don't\n+    ```{code-block} python\n+    ---\n+    emphasize-lines: 2\n+    ---\n+\n+    from jina import Flow, Executor, requests\n+\n+    class CustomExecutor(Executor):\n+        @requests\n+        def foo(self, **kwargs):\n+            ...\n+\n+    f = Flow().add(uses=CustomExecutor)\n+    with f:\n+        ...\n+\n+    \"\"\"\n+    # error\n+    This probably means that you are not using fork to start your\n+    child processes and you have forgotten to use the proper idiom\n+    in the main module:\n+\n+        if _name_ == '_main_':\n+            freeze_support()\n+            ...\n+\n+    The \"freeze_support()\" line can be omitted if the program\n+    is not going to be frozen to produce an executable.\n+\n+    \"\"\"\n+    ```\n+\n+    ````\n+\n+- Declare Executors on the top-level of the module \n+\n+    ````{tab} \u2705 Do\n+    ```{code-block} python\n+    ---\n+    emphasize-lines: 1\n+    ---\n+\n+    class CustomExecutor(Executor):\n+        @requests\n+        def foo(self, **kwargs):\n+            ...\n+\n+    def main():\n+        f = Flow().add(uses=Executor)\n+        with f:\n+            ...\n+\n+    ```\n+    ````\n+\n+    ````{tab} \ud83d\ude14 Don't\n+    ```{code-block} python\n+    ---\n+    emphasize-lines: 2\n+    ---\n+\n+    def main():\n+        class CustomExecutor(Executor):\n+            @requests\n+            def foo(self, **kwargs):\n+                ...\n+\n+        f = Flow().add(uses=Executor)\n+        with f:\n+            ...\n+    ```\n+    ````\n+\n+- **Always provide absolute path**\n+\n+    While passing filepaths to different jina arguments (e.g.- `uses`, `py_modules`), always pass the absolute path.\n+\n+\n+\n+## multiprocessing Spawn\n+\n+Few cases require to use `spawn` start method for multiprocessing. \n+(e.g.- Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method)\n+\n+- Please set `JINA_MP_START_METHOD=spawn` before starting the Python script to enable this.\n+\n+    ````{hint}\n+    There's no need to set this for Windows, as it only supports spawn method for multiprocessing. \n+    ````\n+- **Avoid un-picklable objects**\n+\n+    [Here's a list of types that can be pickled in Python](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled). Since `spawn` relies on pickling, we should avoid using code that cannot be pickled.\n+\n+    ````{hint}\n+    Here are a few errors which indicates that you are using some code that is not pickable.\n+\n+    ```bash\n+    pickle.PicklingError: Can't pickle: it's not the same object\n+    AssertionError: can only join a started process\n+    ```\n+\n+    ````\n+\n+    Inline functions, such as nested or lambda functions are not picklable. Use `functools.partial` instead.\n+\n+\n+\n+## Debugging Executor in a Flow\n+\n+Standard Python breakpoints will not work inside `Executor` methods when called inside a Flow context manager. Nevertheless, `import epdb; epdb.set_trace()` will work just as a native python breakpoint. Note that you need to `pip install epdb` to have acces to this type of breakpoints.\n+\n+\n+````{tab} \u2705 Do\n+```{code-block} python\n+---\n+emphasize-lines: 7\n+---\n+from jina import Flow, Executor, requests\n+ \n+class CustomExecutor(Executor):\n+    @requests\n+    def foo(self, **kwargs):\n+        a = 25\n+        import epdb; epdb.set_trace() \n+        print(f'\\n\\na={a}\\n\\n')\n+ \n+def main():\n+    f = Flow().add(uses=CustomExecutor)\n+    with f:\n+        f.post(on='')\n+\n+if __name__ == '__main__':\n+    main()\n+\n+```\n+````\n+\n+````{tab} \ud83d\ude14 Don't\n+```{code-block} python\n+---\n+emphasize-lines: 7\n+---\n+from jina import Flow, Executor, requests\n+ \n+class CustomExecutor(Executor):\n+    @requests\n+    def foo(self, **kwargs):\n+        a = 25\n+        breakpoint()\n+        print(f'\\n\\na={a}\\n\\n')\n+ \n+def main():\n+    f = Flow().add(uses=CustomExecutor)\n+    with f:\n+        f.post(on='')\n+ \n+if __name__ == '__main__':\n+    main()\n+```\n+````\n+\n\n---\n file path A: docs/get-started/install/windows.md | file path B: docs/get-started/install/windows.md\n\n@@ -19,7 +19,9 @@ Once done, you can install Jina as on a native *nix platform.\n \n ### `multiprocessing spawn`\n \n-Jina relies heavily on `multiprocessing` to enable scaling & distribution. Windows only supports [spawn start method for multiprocessing](https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods), which has a few caveats. [Please follow the guidelines here.](../../../fundamentals/flow/remarks#multiprocessing-spawn)\n+Jina relies heavily on `multiprocessing` to enable scaling and distribution. Windows only supports [spawn start method for multiprocessing](https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods), which has a several caveats.\n+\n+{ref}`Please follow the guidelines here.<multiprocessing-spawn>`\n \n ### Compatibility of Executors in the Hub\n \n\n\n###\n\n", "completion": "docs: fix link to multiprocessing spawn section and highlight entrypoint protection (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -110,7 +110,7 @@ jobs:\n         run: exit 1\n \n   docker-image-test:\n-    needs: [commit-lint, code-injection]\n+    needs: [code-injection]\n     runs-on: ubuntu-latest\n     services:\n       registry:\n@@ -150,7 +150,7 @@ jobs:\n \n   hub-test:\n     runs-on: ubuntu-latest\n-    needs: [commit-lint, lint-flake-8, code-injection]\n+    needs: [lint-flake-8, code-injection]\n     if: ${{ !github.event.pull_request.head.repo.fork }}\n     steps:\n #      - name: Cancel Previous Runs\n@@ -171,7 +171,7 @@ jobs:\n           JINAHUB_PASSWORD: ${{ secrets.JINAHUB_PASSWORD }}\n \n   k8s-test:\n-    needs: [commit-lint, lint-flake-8, code-injection]\n+    needs: [lint-flake-8, code-injection]\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -212,7 +212,7 @@ jobs:\n           fail_ci_if_error: false\n \n   k8s-failures-test:\n-    needs: [ commit-lint, lint-flake-8, code-injection ]\n+    needs: [ lint-flake-8, code-injection ]\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -254,7 +254,7 @@ jobs:\n           fail_ci_if_error: false\n \n   docker-compose-test:\n-    needs: [commit-lint, lint-flake-8, code-injection]\n+    needs: [lint-flake-8, code-injection]\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2.5.0\n@@ -292,7 +292,7 @@ jobs:\n \n   prep-testbed:\n     runs-on: ubuntu-latest\n-    needs: [commit-lint, lint-flake-8, code-injection]\n+    needs: [ lint-flake-8, code-injection]\n     steps:\n       - uses: actions/checkout@v2.5.0\n       - id: set-matrix\n@@ -353,7 +353,7 @@ jobs:\n \n   import-test:\n     runs-on: ubuntu-latest\n-    needs: [ commit-lint, lint-flake-8, code-injection ]\n+    needs: [lint-flake-8, code-injection ]\n     strategy:\n       fail-fast: false\n       matrix:\n@@ -385,7 +385,7 @@ jobs:\n   # just for blocking the merge until all parallel core-test are successful\n   success-all-test:\n     runs-on: ubuntu-latest\n-    needs: [core-test, import-test, hub-test, k8s-test, k8s-failures-test, docker-compose-test, docker-image-test, check-docstring, check-black, code-injection]\n+    needs: [commit-lint, core-test, import-test, hub-test, k8s-test, k8s-failures-test, docker-compose-test, docker-image-test, check-docstring, check-black, code-injection]\n     if: always()\n     steps:\n       - uses: technote-space/workflow-conclusion-action@v2\n\n\n###\n\n", "completion": "chore: allow test to pass even if commit name is not good (#<issue-num>)"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -435,14 +435,15 @@ class GrpcConnectionPool:\n \n             timer = self._get_metric_timer()\n             if request_type == DataRequest and len(requests) == 1:\n+                request = requests[0]\n                 if self.single_data_stub:\n+                    self._record_request_bytes_metric(request.nbytes)\n                     call_result = self.single_data_stub.process_single_data(\n-                        requests[0],\n+                        request,\n                         metadata=metadata,\n                         compression=compression,\n                         timeout=timeout,\n                     )\n-                    self._record_request_bytes_metric(requests[0].nbytes)\n                     with timer:\n                         metadata, response = (\n                             await call_result.trailing_metadata(),\n@@ -452,8 +453,7 @@ class GrpcConnectionPool:\n                     return response, metadata\n \n                 elif self.stream_stub:\n-                    for response in requests:\n-                        self._record_request_bytes_metric(response.nbytes)\n+                    self._record_request_bytes_metric(request.nbytes)\n \n                     with timer:\n                         async for response in self.stream_stub.Call(\n@@ -466,9 +466,9 @@ class GrpcConnectionPool:\n                             return response, None\n \n             if request_type == DataRequest and len(requests) > 1:\n-                # TODO: This section of the code has no observability\n-                # TODO: Does this section not need to deal with streaming stubs?\n                 if self.data_list_stub:\n+                    for request in requests:\n+                        self._record_request_bytes_metric(request.nbytes)\n                     call_result = self.data_list_stub.process_data(\n                         requests,\n                         metadata=metadata,\n@@ -480,6 +480,7 @@ class GrpcConnectionPool:\n                             await call_result.trailing_metadata(),\n                             await call_result,\n                         )\n+                        self._record_received_bytes_metric(response.nbytes)\n                     return response, metadata\n                 else:\n                     raise ValueError(\n\n---\n file path A: tests/unit/serve/instrumentation/conftest.py | file path B: tests/unit/serve/instrumentation/conftest.py\n\n@@ -9,6 +9,7 @@ from opentelemetry.sdk.metrics.export import (\n     MetricExporter,\n     MetricExportResult,\n     MetricsData,\n+    PeriodicExportingMetricReader,\n )\n \n \n@@ -54,12 +55,11 @@ class DirMetricExporter(MetricExporter):\n         self.f.close()\n \n \n-@pytest.fixture(scope='session')\n+@pytest.fixture(scope='function')\n def monkeypatch_metric_exporter(\n     tmpdir_factory: pytest.TempdirFactory,\n ) -> Tuple[Callable, Callable]:\n     import opentelemetry.sdk.metrics.export\n-    from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\n     from pathlib import Path\n     import time\n     import os\n@@ -78,7 +78,7 @@ def monkeypatch_metric_exporter(\n             tick_counter = int(f.read())\n         with open(tick_counter_filename, 'w') as f:\n             f.write(str(tick_counter + 1))\n-        time.sleep(1)\n+        time.sleep(2)\n \n     def _get_service_name(otel_measurement):\n         return otel_measurement[0]['resource_metrics'][0]['resource']['attributes'][\n@@ -102,7 +102,7 @@ def monkeypatch_metric_exporter(\n \n             super().__init__(\n                 exporter=self.exporter,\n-                export_interval_millis=1_000,\n+                export_interval_millis=500,\n             )\n \n         def _ticker(self) -> None:\n@@ -115,5 +115,7 @@ def monkeypatch_metric_exporter(\n                     self.collect(timeout_millis=self._export_timeout_millis)\n             self.collect(timeout_millis=self._export_interval_millis)\n \n+    real_reader = opentelemetry.sdk.metrics.export.PeriodicExportingMetricReader\n     opentelemetry.sdk.metrics.export.PeriodicExportingMetricReader = PatchedTextReader\n-    return collect_metrics, read_metrics\n+    yield collect_metrics, read_metrics\n+    opentelemetry.sdk.metrics.export.PeriodicExportingMetricReader = real_reader\n\n---\n file path A: tests/unit/serve/instrumentation/test_gateway_metric_labels.py | file path B: tests/unit/serve/instrumentation/test_gateway_metric_labels.py\n\n@@ -34,81 +34,122 @@ def test_gateway_metric_labels(monkeypatch_metric_exporter):\n             i['name']: i['data']['data_points'] for i in gateway_metrics\n         }\n \n-        assert (\n-            'address'\n-            in gateway_metric_data_point['jina_sending_request_seconds'][0][\n-                'attributes'\n-            ]\n-        )\n-        assert (\n-            'address'\n-            in gateway_metric_data_point['jina_sent_request_bytes'][0]['attributes']\n-        )\n-        assert (\n-            'address'\n-            in gateway_metric_data_point['jina_received_response_bytes'][0][\n-                'attributes'\n-            ]\n-        )\n-        assert (\n-            'address'\n-            in gateway_metric_data_point['jina_sending_request_seconds'][1][\n-                'attributes'\n-            ]\n-        )\n-        assert (\n-            'address'\n-            in gateway_metric_data_point['jina_sent_request_bytes'][1]['attributes']\n-        )\n-        assert (\n-            'address'\n-            in gateway_metric_data_point['jina_received_response_bytes'][1][\n-                'attributes'\n-            ]\n-        )\n+    assert (\n+        'address'\n+        in gateway_metric_data_point['jina_sending_request_seconds'][0][\n+            'attributes'\n+        ]\n+    )\n+    assert (\n+        'address'\n+        in gateway_metric_data_point['jina_sent_request_bytes'][0]['attributes']\n+    )\n+    assert (\n+        'address'\n+        in gateway_metric_data_point['jina_received_response_bytes'][0][\n+            'attributes'\n+        ]\n+    )\n+    assert (\n+        'address'\n+        in gateway_metric_data_point['jina_sending_request_seconds'][1][\n+            'attributes'\n+        ]\n+    )\n+    assert (\n+        'address'\n+        in gateway_metric_data_point['jina_sent_request_bytes'][1]['attributes']\n+    )\n+    assert (\n+        'address'\n+        in gateway_metric_data_point['jina_received_response_bytes'][1][\n+            'attributes'\n+        ]\n+    )\n \n-        assert (\n-            'deployment'\n-            in gateway_metric_data_point['jina_sending_request_seconds'][0][\n-                'attributes'\n-            ]\n-        )\n-        assert (\n-            'deployment'\n-            in gateway_metric_data_point['jina_sent_request_bytes'][0]['attributes']\n-        )\n-        assert (\n-            'deployment'\n-            in gateway_metric_data_point['jina_received_response_bytes'][0][\n-                'attributes'\n-            ]\n-        )\n-        assert (\n-            'deployment'\n-            in gateway_metric_data_point['jina_sending_request_seconds'][1][\n-                'attributes'\n-            ]\n-        )\n-        assert (\n-            'deployment'\n-            in gateway_metric_data_point['jina_sent_request_bytes'][1]['attributes']\n-        )\n-        assert (\n-            'deployment'\n-            in gateway_metric_data_point['jina_received_response_bytes'][1][\n-                'attributes'\n-            ]\n-        )\n+    assert (\n+        'deployment'\n+        in gateway_metric_data_point['jina_sending_request_seconds'][0][\n+            'attributes'\n+        ]\n+    )\n+    assert (\n+        'deployment'\n+        in gateway_metric_data_point['jina_sent_request_bytes'][0]['attributes']\n+    )\n+    assert (\n+        'deployment'\n+        in gateway_metric_data_point['jina_received_response_bytes'][0][\n+            'attributes'\n+        ]\n+    )\n+    assert (\n+        'deployment'\n+        in gateway_metric_data_point['jina_sending_request_seconds'][1][\n+            'attributes'\n+        ]\n+    )\n+    assert (\n+        'deployment'\n+        in gateway_metric_data_point['jina_sent_request_bytes'][1]['attributes']\n+    )\n+    assert (\n+        'deployment'\n+        in gateway_metric_data_point['jina_received_response_bytes'][1][\n+            'attributes'\n+        ]\n+    )\n \n-        assert (\n-            gateway_metric_data_point['jina_received_response_bytes'][0]['attributes'][\n-                'deployment'\n-            ]\n-            == 'first_exec'\n-        )\n-        assert (\n-            gateway_metric_data_point['jina_received_response_bytes'][1]['attributes'][\n-                'deployment'\n-            ]\n-            == 'second_exec'\n+    assert {'first_exec', 'second_exec'} == {\n+        i['attributes']['deployment']\n+        for i in gateway_metric_data_point['jina_received_response_bytes']\n+    }\n+    assert {'first_exec', 'second_exec'} == {\n+        i['attributes']['deployment']\n+        for i in gateway_metric_data_point['jina_sent_request_bytes']\n+    }\n+    assert {'first_exec', 'second_exec'} == {\n+        i['attributes']['deployment']\n+        for i in gateway_metric_data_point['jina_sending_request_seconds']\n+    }\n+\n+\n+def test_merge_with_no_reduce(monkeypatch_metric_exporter):\n+    collect_metrics, read_metrics = monkeypatch_metric_exporter\n+\n+    f = (\n+        Flow(\n+            tracing=False,\n+            metrics=True,\n+            metrics_exporter_host='localhost',\n+            metrics_exporter_port=4317,\n+            port=12345,\n         )\n+        .add(name='name1')\n+        .add(name='name2', needs=['gateway'])\n+        .add(name='name3', needs=['name1', 'name2'], disable_reduce=True)\n+    )\n+    with f:\n+        f.post('/')\n+        collect_metrics()\n+        metrics = read_metrics()\n+\n+        gateway_metrics = metrics['gateway/rep-0'][0]['resource_metrics'][0][\n+            'scope_metrics'\n+        ][0]['metrics']\n+        gateway_metric_data_point = {\n+            i['name']: i['data']['data_points'] for i in gateway_metrics\n+        }\n+\n+    assert {'name1', 'name2', 'name3'} == {\n+        i['attributes']['deployment']\n+        for i in gateway_metric_data_point['jina_received_response_bytes']\n+    }\n+    assert {'name1', 'name2', 'name3'} == {\n+        i['attributes']['deployment']\n+        for i in gateway_metric_data_point['jina_sent_request_bytes']\n+    }\n+    assert {'name1', 'name2', 'name3'} == {\n+        i['attributes']['deployment']\n+        for i in gateway_metric_data_point['jina_sending_request_seconds']\n+    }\n\n---\n file path A: tests/unit/serve/instrumentation/test_instrumentation.py | file path B: tests/unit/serve/instrumentation/test_instrumentation.py\n\n@@ -86,6 +86,7 @@ def test_timer_decorator(metrics_setup):\n         'cat': 'meow',\n         'dog': 'woof',\n     }\n+\n     @MetricsTimer(summary, histogram, labels)\n     def _sleep():\n         time.sleep(0.1)\n\n\n###\n\n", "completion": "fix: missing recording logic in connection stub metrics (#<issue-num>)"}
{"prompt": " file path A: jina/checker.py | file path B: jina/checker.py\n\n@@ -1,6 +1,4 @@\n import argparse\n-import urllib\n-from http import HTTPStatus\n \n from jina.enums import GatewayProtocolType\n from jina.helper import parse_host_scheme\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -54,13 +54,10 @@ from jina.excepts import (\n from jina.helper import (\n     ArgNamespace,\n     CatchAllCleanupContextManager,\n-    _parse_hosts,\n-    _parse_ports,\n     download_mermaid_url,\n     get_internal_ip,\n     get_public_ip,\n     is_port_free,\n-    make_iterable,\n     send_telemetry_event,\n     typename,\n )\n\n---\n file path A: jina/orchestrate/flow/builder.py | file path B: jina/orchestrate/flow/builder.py\n\n@@ -4,7 +4,7 @@ from typing import TYPE_CHECKING, List\n from jina.excepts import FlowBuildLevelError\n \n # noinspection PyUnreachableCode\n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     from jina.enums import FlowBuildLevel\n     from jina.orchestrate.flow.base import Flow\n \n\n---\n file path A: jina/orchestrate/pods/container.py | file path B: jina/orchestrate/pods/container.py\n\n@@ -7,7 +7,7 @@ import re\n import signal\n import threading\n import time\n-from typing import TYPE_CHECKING, Callable, Dict, Optional, Union\n+from typing import TYPE_CHECKING, Dict, Optional, Union\n \n from jina import __docker_host__, __windows__\n from jina.enums import PodRoleType\n\n---\n file path A: jina/orchestrate/pods/factory.py | file path B: jina/orchestrate/pods/factory.py\n\n@@ -9,7 +9,7 @@ from jina.enums import PodRoleType\n from jina.orchestrate.pods import Pod\n from jina.orchestrate.pods.container import ContainerPod\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     from jina.orchestrate.pods import BasePod\n \n \n@@ -36,9 +36,9 @@ class PodFactory:\n             cargs.uses = HubIO(_hub_args).pull()\n \n         if (\n-            cargs.pod_role != PodRoleType.HEAD\n-            and cargs.uses\n-            and cargs.uses.startswith('docker://')\n+                cargs.pod_role != PodRoleType.HEAD\n+                and cargs.uses\n+                and cargs.uses.startswith('docker://')\n         ):\n             return ContainerPod(cargs)\n         else:\n\n---\n file path A: jina/orchestrate/pods/helper.py | file path B: jina/orchestrate/pods/helper.py\n\n@@ -6,16 +6,16 @@ from typing import TYPE_CHECKING\n from hubble.executor.helper import is_valid_huburi\n from hubble.executor.hubio import HubIO\n \n-from jina.enums import GatewayProtocolType, PodRoleType\n+from jina.enums import PodRoleType\n from jina.parsers.helper import _set_gateway_uses\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     from argparse import Namespace\n \n \n def _get_event(obj) -> multiprocessing.Event:\n     if isinstance(obj, multiprocessing.Process) or isinstance(\n-        obj, multiprocessing.context.ForkProcess\n+            obj, multiprocessing.context.ForkProcess\n     ):\n         return multiprocessing.Event()\n     elif isinstance(obj, multiprocessing.context.SpawnProcess):\n\n---\n file path A: jina/parsers/create.py | file path B: jina/parsers/create.py\n\n@@ -1,4 +1,5 @@\n \"\"\"Argparser module for pinging\"\"\"\n+\n from jina.parsers.base import set_base_parser\n \n \n\n---\n file path A: jina/parsers/flow.py | file path B: jina/parsers/flow.py\n\n@@ -1,4 +1,5 @@\n \"\"\"Argparser module for Flow\"\"\"\n+\n from jina.parsers.base import set_base_parser\n from jina.parsers.helper import KVAppendAction, add_arg_group\n from jina.parsers.orchestrate.base import mixin_essential_parser\n\n---\n file path A: jina/parsers/helper.py | file path B: jina/parsers/helper.py\n\n@@ -1,4 +1,5 @@\n \"\"\"Module for helper functions in the parser\"\"\"\n+\n import argparse\n import os\n from typing import Tuple\n\n---\n file path A: jina/parsers/orchestrate/deployment.py | file path B: jina/parsers/orchestrate/deployment.py\n\n@@ -1,7 +1,6 @@\n \"\"\"Argparser module for Deployment runtimes\"\"\"\n import argparse\n \n-from jina import helper\n from jina.enums import DeploymentRoleType\n from jina.parsers.helper import _SHOW_ALL_ARGS, KVAppendAction, add_arg_group\n \n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -1,4 +1,5 @@\n \"\"\"Argparser module for Pod runtimes\"\"\"\n+\n import argparse\n from dataclasses import dataclass\n from typing import Dict\n\n---\n file path A: jina/parsers/orchestrate/runtimes/head.py | file path B: jina/parsers/orchestrate/runtimes/head.py\n\n@@ -1,5 +1,3 @@\n-import argparse\n-\n from jina.parsers.helper import add_arg_group\n \n \n\n---\n file path A: jina/parsers/orchestrate/runtimes/runtime.py | file path B: jina/parsers/orchestrate/runtimes/runtime.py\n\n@@ -1,6 +1,7 @@\n \"\"\"Argparser module for WorkerRuntime\"\"\"\n+\n from jina import __default_host__, helper\n-from jina.parsers.helper import KVAppendAction, add_arg_group\n+from jina.parsers.helper import KVAppendAction\n \n \n def mixin_base_runtime_parser(arg_group):\n\n---\n file path A: jina/parsers/orchestrate/runtimes/worker.py | file path B: jina/parsers/orchestrate/runtimes/worker.py\n\n@@ -1,6 +1,5 @@\n \"\"\"Argparser module for WorkerRuntime\"\"\"\n-from jina import __default_host__, helper\n-from jina.enums import PollingType\n+\n from jina.parsers.helper import KVAppendAction, add_arg_group\n from jina.parsers.orchestrate.runtimes.runtime import mixin_base_runtime_parser\n \n\n---\n file path A: jina/parsers/ping.py | file path B: jina/parsers/ping.py\n\n@@ -1,4 +1,5 @@\n \"\"\"Argparser module for pinging\"\"\"\n+\n from jina.parsers.base import set_base_parser\n \n \n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -7,9 +7,8 @@ from pathlib import Path\n from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Sequence, Union\n \n from jina import __cache_path__\n-from jina.helper import convert_tuple_to_list, iscoroutinefunction\n+from jina.helper import iscoroutinefunction\n from jina.importer import ImportExtensions\n-from jina.serve.executors.metas import get_default_metas\n \n if TYPE_CHECKING: # pragma: no cover\n     from jina import DocumentArray\n\n---\n file path A: jina/serve/gateway.py | file path B: jina/serve/gateway.py\n\n@@ -5,7 +5,6 @@ from typing import TYPE_CHECKING, Optional, Sequence\n from jina.jaml import JAMLCompatible\n from jina.logging.logger import JinaLogger\n from jina.serve.helper import store_init_kwargs, wrap_func\n-from jina.serve.streamer import GatewayStreamer\n \n __all__ = ['BaseGateway']\n \n\n---\n file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -1,6 +1,5 @@\n import argparse\n import asyncio\n-import os\n import signal\n import time\n from abc import ABC, abstractmethod\n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -1,8 +1,6 @@\n import argparse\n import asyncio\n-import os\n import urllib\n-from abc import ABC\n from http import HTTPStatus\n from typing import TYPE_CHECKING, Optional, Union\n \n\n---\n file path A: jina/serve/runtimes/gateway/graph/topology_graph.py | file path B: jina/serve/runtimes/gateway/graph/topology_graph.py\n\n@@ -6,7 +6,6 @@ from datetime import datetime\n from typing import Dict, List, Optional, Tuple\n \n import grpc.aio\n-from grpc.aio import AioRpcError\n \n from jina import __default_endpoint__\n from jina.excepts import InternalNetworkError\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -7,7 +7,6 @@ from collections import defaultdict\n from typing import Dict, List, Optional, Tuple\n \n import grpc\n-from grpc.aio import AioRpcError\n from grpc_health.v1 import health, health_pb2, health_pb2_grpc\n from grpc_reflection.v1alpha import reflection\n \n\n\n###\n\n", "completion": "chore: remove unneeded imports (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/topologies.md | file path B: docs/fundamentals/flow/topologies.md\n\n@@ -147,7 +147,7 @@ You can restrict the visible devices in round-robin assignment using `CUDA_VISIB\n | 0          | 4          |\n \n \n-You can restrict the visible devices in round-robin assignment by assigning a list of devices ids `CUDA_VISIBLE_DEVICES=RR1,3`. This creates the following assignment:\n+You can restrict the visible devices in round-robin assignment by assigning the list of device IDs to `CUDA_VISIBLE_DEVICES=RR1,3`. This creates the following assignment:\n \n | GPU device | Replica ID |\n |------------|------------|\n@@ -157,6 +157,16 @@ You can restrict the visible devices in round-robin assignment by assigning a li\n | 3          | 3          |\n | 1          | 4          |\n \n+You can also refer to GPUs by their UUID. For instance, you could assign a list of device UUIDs `CUDA_VISIBLE_DEVICES=RRGPU-0aaaaaaa-74d2-7297-d557-12771b6a79d5,GPU-0bbbbbbb-74d2-7297-d557-12771b6a79d5,GPU-0ccccccc-74d2-7297-d557-12771b6a79d5,GPU-0ddddddd-74d2-7297-d557-12771b6a79d5`.\n+Check [CUDA Documentation](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars) to see the accepted formats to assign CUDA devices by UUID.\n+\n+| GPU device | Replica ID |\n+|------------|------------|\n+| GPU-0aaaaaaa-74d2-7297-d557-12771b6a79d5          | 0          |\n+| GPU-0bbbbbbb-74d2-7297-d557-12771b6a79d5          | 1          |\n+| GPU-0ccccccc-74d2-7297-d557-12771b6a79d5          | 2          |\n+| GPU-0ddddddd-74d2-7297-d557-12771b6a79d5          | 3          |\n+| GPU-0aaaaaaa-74d2-7297-d557-12771b6a79d5          | 4          |\n \n ## Distributed replicas\n \n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -732,7 +732,7 @@ class Deployment(BaseDeployment):\n         :return: slice\n         \"\"\"\n \n-        all_devices = range(num_devices)\n+        use_uuids = False\n         if re.match(WRAPPED_SLICE_BASE, value):\n             value = value[1:-1]\n \n@@ -742,13 +742,28 @@ class Deployment(BaseDeployment):\n                 parts = value.split(':')\n \n                 if len(parts) == 1:\n-                    # slice(stop)\n+                    try:\n+                        int(parts[0])\n+                    except:\n+                        use_uuids = True\n+                    if use_uuids:\n+                        return parts\n                     parts = [parts[0], str(int(parts[0]) + 1)]\n-                # else: slice(start, stop[, step])\n             else:\n-                return [int(p) for p in parts]\n+                # try to detect if parts are not numbers\n+                try:\n+                    int(parts[0])\n+                except:\n+                    use_uuids = True\n+\n+                if not use_uuids:\n+                    return [int(p) for p in parts]\n+                else:\n+                    return parts\n         else:\n             parts = []\n+\n+        all_devices = range(num_devices)\n         return all_devices[slice(*[int(p) if p else None for p in parts])]\n \n     @staticmethod\n@@ -776,10 +791,11 @@ class Deployment(BaseDeployment):\n \n             selected_devices = []\n             if device_str[2:]:\n-                for device_num in Deployment._parse_devices(\n+\n+                for device in Deployment._parse_devices(\n                     device_str[2:], num_devices\n                 ):\n-                    selected_devices.append(device_num)\n+                    selected_devices.append(device)\n             else:\n                 selected_devices = range(num_devices)\n             _c = cycle(selected_devices)\n\n---\n file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -1,4 +1,3 @@\n-import argparse\n import asyncio\n from typing import (\n     TYPE_CHECKING,\n\n---\n file path A: tests/unit/orchestrate/deployments/test_cuda_assignment.py | file path B: tests/unit/orchestrate/deployments/test_cuda_assignment.py\n\n@@ -27,9 +27,13 @@ def cuda_total_devices(request):\n         ['RR1:', 5, {0: 1, 1: 2, 2: 1, 3: 2, 4: 1}, 3],\n         ['RR0:2', 5, {0: 0, 1: 1, 2: 0, 3: 1, 4: 0}, 3],\n         ['RR1:2', 2, {0: 1, 1: 1}, 3],\n+        ['RR2', 2, {0: 2, 1: 2}, 3],\n+        ['RRUUID1', 2, {0: 'UUID1', 1: 'UUID1'}, 3],\n         ['RR1:2', 1, {0: 1}, 3],\n         ['RR0,2,3', 3, {0: 0, 1: 2, 2: 3}, 4],\n         ['RR0,2,3', 5, {0: 0, 1: 2, 2: 3, 3: 0, 4: 2}, 4],\n+        ['RRUUID1,UUID2,UUID3', 5, {0: 'UUID1', 1: 'UUID2', 2: 'UUID3', 3: 'UUID1', 4: 'UUID2'}, 4],\n+        ['RRGPU-0aaaaaaa-74d2-7297-d557-12771b6a79d5,GPU-0bbbbbbb-74d2-7297-d557-12771b6a79d5,GPU-0ccccccc-74d2-7297-d557-12771b6a79d5,GPU-0ddddddd-74d2-7297-d557-12771b6a79d5', 5, {0: 'GPU-0aaaaaaa-74d2-7297-d557-12771b6a79d5', 1: 'GPU-0bbbbbbb-74d2-7297-d557-12771b6a79d5', 2: 'GPU-0ccccccc-74d2-7297-d557-12771b6a79d5', 3: 'GPU-0ddddddd-74d2-7297-d557-12771b6a79d5', 4: 'GPU-0aaaaaaa-74d2-7297-d557-12771b6a79d5'}, 4],\n     ], indirect=['cuda_total_devices']\n )\n def test_cuda_assignment(device_str, replicas, expected, cuda_total_devices):\n\n\n###\n\n", "completion": "feat: accept UUID in CUDA_VISIBLE_DEVICES round robin assignment (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -803,7 +803,9 @@ class Deployment(BaseDeployment):\n             for replica_id in range(replicas):\n                 _args = copy.deepcopy(args)\n                 _args.shard_id = shard_id\n-                _args.pod_role = PodRoleType.WORKER\n+                # for gateway pods, the pod role shouldn't be changed\n+                if _args.pod_role != PodRoleType.GATEWAY:\n+                    _args.pod_role = PodRoleType.WORKER\n \n                 if cuda_device_map:\n                     _args.env['CUDA_VISIBLE_DEVICES'] = str(cuda_device_map[replica_id])\n\n---\n file path A: jina/orchestrate/pods/__init__.py | file path B: jina/orchestrate/pods/__init__.py\n\n@@ -17,6 +17,8 @@ from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n \n __all__ = ['BasePod', 'Pod']\n \n+from jina.serve.runtimes.gateway import GatewayRuntime\n+\n \n def run(\n     args: 'argparse.Namespace',\n@@ -188,12 +190,21 @@ class BasePod(ABC):\n         :param timeout: The time to wait before readiness or failure is determined\n             .. # noqa: DAR201\n         \"\"\"\n-        return AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n-            timeout=timeout,\n-            ready_or_shutdown_event=self.ready_or_shutdown.event,\n-            ctrl_address=self.runtime_ctrl_address,\n-            timeout_ctrl=self._timeout_ctrl,\n-        )\n+        if self.args.pod_role == PodRoleType.GATEWAY:\n+            return GatewayRuntime.wait_for_ready_or_shutdown(\n+                timeout=timeout,\n+                ready_or_shutdown_event=self.ready_or_shutdown.event,\n+                ctrl_address=self.runtime_ctrl_address,\n+                timeout_ctrl=self._timeout_ctrl,\n+                protocol=self.args.protocol,\n+            )\n+        else:\n+            return AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+                timeout=timeout,\n+                ready_or_shutdown_event=self.ready_or_shutdown.event,\n+                ctrl_address=self.runtime_ctrl_address,\n+                timeout_ctrl=self._timeout_ctrl,\n+            )\n \n     def _fail_start_timeout(self, timeout):\n         \"\"\"\n\n---\n file path A: tests/unit/orchestrate/pods/container/test_container_pod.py | file path B: tests/unit/orchestrate/pods/container/test_container_pod.py\n\n@@ -3,7 +3,7 @@ import time\n \n import pytest\n \n-from jina import __cache_path__\n+from jina import Flow, __cache_path__\n from jina.excepts import RuntimeFailToStart\n from jina.helper import random_port\n from jina.orchestrate.pods.container import ContainerPod\n@@ -281,3 +281,13 @@ def test_container_pod_custom_gateway(dummy_custom_gateway_docker_image_built):\n     client = docker.from_env()\n     containers = client.containers.list()\n     assert container.id not in containers\n+\n+\n+def test_container_pod_with_flow_custom_gateway(\n+    dummy_custom_gateway_docker_image_built,\n+):\n+    flow = Flow(uses='docker://custom-gateway', protocol='http')\n+    with flow:\n+        _validate_dummy_custom_gateway_response(\n+            flow.port, {'arg1': 'hello', 'arg2': 'world', 'arg3': 'default-arg3'}\n+        )\n\n\n###\n\n", "completion": "fix: fix custom gateway container pod (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.23.0:    core\n+jina-hubble-sdk==0.23.3:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.23.0:    core\n+jina-hubble-sdk==0.23.3:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n\n###\n\n", "completion": "chore: bump hubble sdk (#<issue-num>)"}
{"prompt": " file path A: None | file path B: pyproject.toml\n\n@@ -0,0 +1,3 @@\n+[build-system]\n+requires = [\"setuptools>=18.0\", \"wheel\"]\n+build-backend = \"setuptools.build_meta\"\n\n---\n file path A: setup.py | file path B: setup.py\n\n@@ -154,7 +154,6 @@ setup(\n     long_description=_long_description,\n     long_description_content_type='text/markdown',\n     zip_safe=False,\n-    setup_requires=['setuptools>=18.0', 'wheel'],\n     install_requires=list(final_deps),\n     extras_require=all_deps,\n     entry_points={\n\n\n###\n\n", "completion": "fix: move build configs to pyproject (#<issue-num>)"}
{"prompt": " file path A: jina/proto/build-proto.sh | file path B: jina/proto/build-proto.sh\n\n@@ -2,15 +2,20 @@\n set -e\n \n # Do NOT use this directly, use jinaai/protogen image\n-# use jinaai/protogen:3.21 in order to use compiler version == 21 (creates pb/docarray_pb2.py)\n+# use jinaai/protogen:v21 in order to use compiler version == 21 (creates pb/docarray_pb2.py)\n # and use jinaai/protogen:latest to use compiler version <= 20 (creates pb2/docarray_pb2.py)\n-# make sure to use jinaai/protogen:3.21 to avoid overriting the module\n+# make sure to use jinaai/protogen:v21 to avoid overriting the module\n #\n # current dir: jina root (the one with README.md)\n # run the following in bash:\n # docker run -v $(pwd)/jina/proto:/jina/proto jinaai/protogen\n # finally, set back owner of the generated files using: sudo chown -R $(id -u ${USER}):$(id -g ${USER}) ./jina/proto\n \n+# The protogen docker image can also be build locally using:\n+# docker build -f Dockerfiles/protogen.Dockerfile -t jinaai/protogen:local .\n+# or\n+# docker build -f Dockerfiles/protogen-3.21.Dockerfile -t jinaai/protogen-3.21:local .\n+\n SRC_DIR=./\n MODULE=jina\n SRC_NAME=\"${MODULE}.proto\"\n\n\n###\n\n", "completion": "docs: update docker image tags and info to build locally (#<issue-num>)"}
{"prompt": " file path A: jina/serve/instrumentation/__init__.py | file path B: jina/serve/instrumentation/__init__.py\n\n@@ -147,7 +147,7 @@ class MetricsTimer:\n         self._histogram_metric_labels = histogram_metric_labels\n \n     def _new_timer(self):\n-        return self.__class__(self._summary_metric, self._histogram)\n+        return self.__class__(self._summary_metric, self._histogram, self._histogram_metric_labels)\n \n     def __enter__(self):\n         self._start = default_timer()\n\n---\n file path A: tests/unit/serve/instrumentation/test_instrumentation.py | file path B: tests/unit/serve/instrumentation/test_instrumentation.py\n\n@@ -80,3 +80,31 @@ def test_timer_decorator(metrics_setup):\n     )\n     assert 'time_taken_decorator' == histogram_metric['name']\n     assert 1 == histogram_metric['data']['data_points'][0]['count']\n+    assert {} == histogram_metric['data']['data_points'][0]['attributes']\n+\n+    labels = {\n+        'cat': 'meow',\n+        'dog': 'woof',\n+    }\n+    @MetricsTimer(summary, histogram, labels)\n+    def _sleep():\n+        time.sleep(0.1)\n+\n+    _sleep()\n+\n+    # Prometheus samples\n+    summary_count_sample = [\n+        sample.value for sample in list(summary._samples()) if '_count' == sample.name\n+    ]\n+    assert 2.0 == summary_count_sample[0]\n+    # OpenTelemetry samples\n+    histogram_metric = json.loads(\n+        metric_reader.get_metrics_data()\n+        .resource_metrics[0]\n+        .scope_metrics[0]\n+        .metrics[0]\n+        .to_json()\n+    )\n+    assert 'time_taken_decorator' == histogram_metric['name']\n+    assert 1 == histogram_metric['data']['data_points'][0]['count']\n+    assert labels == histogram_metric['data']['data_points'][0]['attributes']\n\n\n###\n\n", "completion": "fix: new timer should keep labels (#<issue-num>)"}
{"prompt": " file path A: docs/jina-ai-cloud/login.md | file path B: docs/jina-ai-cloud/login.md\n\n@@ -76,19 +76,10 @@ Installed along with Jina, you can leverage the `hubble` package to manage login\n ```python\n import hubble\n \n-# Open browser automatically and login via 3rd party.\n-# Token will be saved locally.\n-hubble.login()\n-```\n-\n-#### Login from Jupyter notebook/Google Colab\n-\n-```python\n-import hubble\n-\n-# Use Personal Access Token or browser to login.\n-# Token will be saved locally.\n-hubble.notebook_login()\n+# Log in via browser or PAT. The token is saved locally.\n+# In Jupyter/Google Colab, interactive login is used automatically.\n+# To disable this feature, run `hubble.login(interactive=False)`.\n+hubble.login() \n ```\n \n ### Check login status\n\n---\n file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.22.2:    core\n+jina-hubble-sdk==0.23.0:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.22.2:    core\n+jina-hubble-sdk==0.23.0:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n\n###\n\n", "completion": "chore: bump hubble sdk (#<issue-num>)"}
{"prompt": " file path A: jina/serve/instrumentation/__init__.py | file path B: jina/serve/instrumentation/__init__.py\n\n@@ -138,8 +138,10 @@ class MetricsTimer:\n         self,\n         summary_metric: Optional['Summary'],\n         histogram: Optional['Histogram'],\n-        histogram_metric_labels: Dict[str, str] = {},\n+        histogram_metric_labels: Optional[Dict[str, str]] = None,\n     ) -> None:\n+        if histogram_metric_labels is None:\n+            histogram_metric_labels = {}\n         self._summary_metric = summary_metric\n         self._histogram = histogram\n         self._histogram_metric_labels = histogram_metric_labels\n\n\n###\n\n", "completion": "fix: metric timer initialization with bad default (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/request_handlers/worker_request_handler.py | file path B: jina/serve/runtimes/request_handlers/worker_request_handler.py\n\n@@ -183,25 +183,7 @@ class WorkerRequestHandler:\n             'runtime_name': runtime_name,\n         }\n \n-    async def handle(\n-        self, requests: List['DataRequest'], tracing_context: Optional['Context'] = None\n-    ) -> DataRequest:\n-        \"\"\"Initialize private parameters and execute private loading functions.\n-\n-        :param requests: The messages to handle containing a DataRequest\n-        :param tracing_context: Optional OpenTelemetry tracing context from the originating request.\n-        :returns: the processed message\n-        \"\"\"\n-        # skip executor if endpoints mismatch\n-        if (\n-            requests[0].header.exec_endpoint not in self._executor.requests\n-            and __default_endpoint__ not in self._executor.requests\n-        ):\n-            self.logger.debug(\n-                f'skip executor: mismatch request, exec_endpoint: {requests[0].header.exec_endpoint}, requests: {self._executor.requests}'\n-            )\n-            return requests[0]\n-\n+    def _record_request_size_monitoring(self, requests):\n         for req in requests:\n             if self._request_size_metrics:\n                 self._request_size_metrics.labels(\n@@ -217,44 +199,7 @@ class WorkerRequestHandler:\n                 )\n                 self._request_size_histogram.record(req.nbytes, attributes=attributes)\n \n-        params = self._parse_params(requests[0].parameters, self._executor.metas.name)\n-\n-        docs = WorkerRequestHandler.get_docs_from_request(\n-            requests,\n-            field='docs',\n-        )\n-\n-        # executor logic\n-        return_data = await self._executor.__acall__(\n-            req_endpoint=requests[0].header.exec_endpoint,\n-            docs=docs,\n-            parameters=params,\n-            docs_matrix=WorkerRequestHandler.get_docs_matrix_from_request(\n-                requests,\n-                field='docs',\n-            ),\n-            tracing_context=tracing_context,\n-        )\n-        # assigning result back to request\n-        if return_data is not None:\n-            if isinstance(return_data, DocumentArray):\n-                docs = return_data\n-            elif isinstance(return_data, dict):\n-                params = requests[0].parameters\n-                results_key = self._KEY_RESULT\n-\n-                if not results_key in params.keys():\n-                    params[results_key] = dict()\n-\n-                params[results_key].update({self.args.name: return_data})\n-                requests[0].parameters = params\n-\n-            else:\n-                raise TypeError(\n-                    f'The return type must be DocumentArray / Dict / `None`, '\n-                    f'but getting {return_data!r}'\n-                )\n-\n+    def _record_docs_processed_monitoring(self, requests, docs):\n         if self._document_processed_metrics:\n             self._document_processed_metrics.labels(\n                 requests[0].header.exec_endpoint,\n@@ -269,10 +214,7 @@ class WorkerRequestHandler:\n             )\n             self._document_processed_counter.add(len(docs), attributes=attributes)\n \n-        WorkerRequestHandler.replace_docs(\n-            requests[0], docs, self.args.output_array_type\n-        )\n-\n+    def _record_response_size_monitoring(self, requests):\n         if self._sent_response_size_metrics:\n             self._sent_response_size_metrics.labels(\n                 requests[0].header.exec_endpoint,\n@@ -289,6 +231,76 @@ class WorkerRequestHandler:\n                 requests[0].nbytes, attributes=attributes\n             )\n \n+    def _set_result(self, requests, return_data, docs):\n+        # assigning result back to request\n+        if return_data is not None:\n+            if isinstance(return_data, DocumentArray):\n+                docs = return_data\n+            elif isinstance(return_data, dict):\n+                params = requests[0].parameters\n+                results_key = self._KEY_RESULT\n+\n+                if not results_key in params.keys():\n+                    params[results_key] = dict()\n+\n+                params[results_key].update({self.args.name: return_data})\n+                requests[0].parameters = params\n+\n+            else:\n+                raise TypeError(\n+                    f'The return type must be DocumentArray / Dict / `None`, '\n+                    f'but getting {return_data!r}'\n+                )\n+\n+        WorkerRequestHandler.replace_docs(\n+            requests[0], docs, self.args.output_array_type\n+        )\n+        return docs\n+\n+    async def handle(\n+        self, requests: List['DataRequest'], tracing_context: Optional['Context'] = None\n+    ) -> DataRequest:\n+        \"\"\"Initialize private parameters and execute private loading functions.\n+\n+        :param requests: The messages to handle containing a DataRequest\n+        :param tracing_context: Optional OpenTelemetry tracing context from the originating request.\n+        :returns: the processed message\n+        \"\"\"\n+        # skip executor if endpoints mismatch\n+        if (\n+            requests[0].header.exec_endpoint not in self._executor.requests\n+            and __default_endpoint__ not in self._executor.requests\n+        ):\n+            self.logger.debug(\n+                f'skip executor: mismatch request, exec_endpoint: {requests[0].header.exec_endpoint}, requests: {self._executor.requests}'\n+            )\n+            return requests[0]\n+\n+        self._record_request_size_monitoring(requests)\n+\n+        params = self._parse_params(requests[0].parameters, self._executor.metas.name)\n+        docs = WorkerRequestHandler.get_docs_from_request(\n+            requests,\n+            field='docs',\n+        )\n+\n+        # executor logic\n+        return_data = await self._executor.__acall__(\n+            req_endpoint=requests[0].header.exec_endpoint,\n+            docs=docs,\n+            parameters=params,\n+            docs_matrix=WorkerRequestHandler.get_docs_matrix_from_request(\n+                requests,\n+                field='docs',\n+            ),\n+            tracing_context=tracing_context,\n+        )\n+\n+        docs = self._set_result(requests, return_data, docs)\n+\n+        self._record_docs_processed_monitoring(requests, docs)\n+        self._record_response_size_monitoring(requests)\n+\n         return requests[0]\n \n     @staticmethod\n\n\n###\n\n", "completion": "refactor: put metric collection in helper methods (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -1,5 +1,5 @@\n (jcloud)=\n-# JCloud Hosting\n+# Jina AI Cloud Hosting\n \n \n ```{toctree}\n@@ -18,15 +18,15 @@ yaml-spec\n :width: 0 %\n ```\n \n-After building a Jina project, the next step is to deploy and host it on the cloud. [JCloud](https://cloud.jina.ai/) is Jina's reliable, scalable and production-ready cloud-hosting solution that manages your project lifecycle without surprises or hidden development costs.\n+After building a Jina project, the next step is to deploy and host it on the cloud. [Jina AI Cloud](https://cloud.jina.ai/) is Jina's reliable, scalable and production-ready cloud-hosting solution that manages your project lifecycle without surprises or hidden development costs.\n \n ```{tip}\n-At present, JCloud hosts all your Jina projects and offers computational/storage resources **for free**!\n+At present, Jina AI Cloud hosts all your Jina projects and offers computational/storage resources **for free**!\n ```\n \n ## Basics\n \n-JCloud provides a CLI that you can use via `jina cloud` from the terminal (or `jcloud` or simply `jc` for minimalists.)\n+Jina AI Cloud provides a CLI that you can use via `jina cloud` from the terminal (or `jcloud` or simply `jc` for minimalists.)\n \n ````{hint}\n You can also install just the JCloud CLI without installing the Jina package.\n@@ -195,7 +195,7 @@ jc status 15937a10bd\n \n ### Monitoring\n \n-Basic monitoring is provided to Flows deployed on JCloud.\n+Basic monitoring is provided to Flows deployed on Jina AI Cloud.\n \n To access the [Grafana](https://grafana.com/)-powered dashboard, first get {ref}`the status of the Flow<jcloud-flow-status>`. The `dashboards` link is displayed at the bottom of the pane. Visit the URL to find basic metrics like 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n \n@@ -246,7 +246,7 @@ jc deploy flow.yml --env-file flow.env\n \n #### Project folder\n \n-- You can include your environment variables in the `.env` file in the local project and JCloud manages them.\n+- You can include your environment variables in the `.env` file in the local project and Jina AI Cloud manages them.\n - You can optionally pass a `custom.env`.\n   ```bash\n   jc deploy ./hello --env-file ./hello/custom.env\n\n\n###\n\n", "completion": "docs: renaming to Jina AI Cloud (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/docker-compose.md | file path B: docs/cloud-nativeness/docker-compose.md\n\n@@ -1,5 +1,5 @@\n (docker-compose)=\n-# Deploy with Docker Compose\n+# {fab}`docker` Docker Compose Support\n \n One of the simplest ways to prototype or serve in\n production is to run your {class}`~jina.Flow` with `docker-compose`.\n\n---\n file path A: docs/fundamentals/k8s.md | file path B: docs/cloud-nativeness/k8s.md\n\n@@ -1,5 +1,12 @@\n (kubernetes-docs)=\n-# Kubernetes Support\n+# {fas}`dharmachakra` Kubernetes Support\n+\n+```{toctree}\n+:hidden:\n+\n+kubernetes\n+```\n+\n \n Jina is a cloud-native framework and therefore runs natively and easily on Kubernetes.\n Deploying a Jina Flow on Kubernetes is actually the recommended way to use Jina in production.\n@@ -8,22 +15,6 @@ A {class}`~jina.Flow` is composed of different microservices called {class}`~jin\n \n Deploying a {class}`~jina.Flow` on Kubernetes means wrapping these microservice containers in the appropriate K8s abstraction (Deployment, StatefulSet, and so on), exposing them internally via K8s service and connecting them together by passing the right set of parameters.\n \n-## Deploying on Jina AI Cloud\n-\n-Check out Jina AI Cloud {ref}`jcloud` if you want a **one-click** solution to deploy and host Jina, leveraging a cloud-native stack of Kubernetes, Prometheus and Grafana, **without worrying about provisioning**.\n-\n-:::::{grid} 2\n-:gutter: 3\n-\n-::::{grid-item-card} {octicon}`cpu;1.5em` Deploy a Flow to JCloud\n-:link: /fundamentals/jcloud/index\n-:link-type: doc\n-:class-card: color-gradient-card-2\n-\n-JCloud is a free CPU/GPU hosting platform for Jina projects.\n-::::\n-\n-:::::\n \n ## Automatically translate a Flow to Kubernetes concept\n \n\n---\n file path A: docs/how-to/kubernetes.md | file path B: docs/cloud-nativeness/kubernetes.md\n\n@@ -21,17 +21,6 @@ Check out {ref}`jcloud` if you want a **one-click** solution to deploy and host\n ```\n \n \n-:::::{grid} 2\n-:gutter: 3\n-\n-::::{grid-item-card} {octicon}`cpu;1.5em` Deploy a Flow to JCloud\n-:link: fundamentals/jcloud/index\n-:link-type: doc\n-:class-card: color-gradient-card-2\n-\n-JCloud is a free CPU/GPU hosting platform for Jina projects.\n-::::\n-:::::\n \n ## Preliminaries\n \n\n---\n file path A: docs/how-to/monitoring.md | file path B: docs/cloud-nativeness/monitoring.md\n\n@@ -1,5 +1,5 @@\n (monitoring)=\n-# Monitor with Prometheus and Grafana\n+# Prometheus/Grafana Support (Legacy)\n \n ```{admonition} Deprecated\n :class: caution\n\n---\n file path A: docs/how-to/opentelemetry-migration.md | file path B: docs/cloud-nativeness/opentelemetry-migration.md\n\n@@ -1,5 +1,5 @@\n (opentelemetry-migration)=\n-# Migrate from Prometheus/Grafana to OpenTelemetry/Prometheus/Grafana \n+# Migrate from Prometheus/Grafana to OpenTelemetry\n \n The {ref}`Prometheus/Grafana <monitoring>` based monitoring setup will soon be deprecated in favor of the {ref}`OpenTelemetry setup <opentelemetry>`. This section provides the details required to update/migrate your Prometheus configuration and Grafana dashboard to continue monitoring with OpenTelemetry. Refer to {ref}`Opentelemetry setup <opentelemetry>` for the new setup before proceeding further.\n \n\n---\n file path A: docs/how-to/opentelemetry.md | file path B: docs/cloud-nativeness/opentelemetry.md\n\n@@ -1,5 +1,12 @@\n (opentelemetry)=\n-# Observability and Instrumentation with OpenTelemetry and Jina\n+# {octicon}`telescope-fill` OpenTelemetry Support\n+\n+```{toctree}\n+:hidden:\n+\n+opentelemetry-migration\n+monitoring\n+```\n \n ```{hint}\n Prometheus-only based metrics collection will soon be deprecated. Refer to {ref}`Monitor with Prometheus and Grafana <monitoring>` for the old setup.\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -76,7 +76,7 @@ html_extra_path = ['html_extra']\n html_css_files = [\n     'main.css',\n     'docbot.css',\n-    'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css',\n+    'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css',\n ]\n html_js_files = [\n     'https://cdn.jsdelivr.net/npm/qabot@0.4'\n\n---\n file path A: docs/get-started/what-is-cross-modal-multi-modal.md | file path B: docs/get-started/what-is-cross-modal-multi-modal.md\n\n@@ -1,5 +1,5 @@\n (intro-cm)=\n-# What is Cross-Modal & Multi-Modal?\n+# What is Multimodal?\n \n Jina is the framework for helping you build cross-modal and multi-modal applications on the cloud. But first, what is cross-modal and multi-modal? And what are the applications? This chapter will answer these preliminary questions.\n \n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -147,6 +147,15 @@ jina-ai-cloud/index\n how-to/index\n ```\n \n+```{toctree}\n+:caption: Cloud Native\n+:hidden:\n+\n+cloud-nativeness/k8s\n+cloud-nativeness/docker-compose\n+cloud-nativeness/opentelemetry\n+```\n+\n \n \n ```{toctree}\n\n\n###\n\n", "completion": "docs: restructure docs into cloud-native section (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/k8s.md | file path B: docs/fundamentals/k8s.md\n\n@@ -4,14 +4,28 @@\n Jina is a cloud-native framework and therefore runs natively and easily on Kubernetes.\n Deploying a Jina Flow on Kubernetes is actually the recommended way to use Jina in production.\n \n-\n A {class}`~jina.Flow` is composed of different microservices called {class}`~jina.Executor`s which natively run in containers. This means that Kubernetes can natively take over the lifetime management of Executors. \n \n-Deploying a {class}`~jina.Flow` on Kubernetes means wrapping these microservice containers in the appropriate K8s abstraction (Deployment, StatefulSet, and so on), exposing them internally via K8s service and \n-connecting them together by passing the right set of parameters.\n+Deploying a {class}`~jina.Flow` on Kubernetes means wrapping these microservice containers in the appropriate K8s abstraction (Deployment, StatefulSet, and so on), exposing them internally via K8s service and connecting them together by passing the right set of parameters.\n \n-## Automatically translate a Flow to Kubernetes concept\n+## Deploying on Jina AI Cloud\n+\n+Check out Jina AI Cloud {ref}`jcloud` if you want a **one-click** solution to deploy and host Jina, leveraging a cloud-native stack of Kubernetes, Prometheus and Grafana, **without worrying about provisioning**.\n+\n+:::::{grid} 2\n+:gutter: 3\n \n+::::{grid-item-card} {octicon}`cpu;1.5em` Deploy a Flow to JCloud\n+:link: /fundamentals/jcloud/index\n+:link-type: doc\n+:class-card: color-gradient-card-2\n+\n+JCloud is a free CPU/GPU hosting platform for Jina projects.\n+::::\n+\n+:::::\n+\n+## Automatically translate a Flow to Kubernetes concept\n \n ```{hint}\n Manually building these Kubernetes YAML object is long and cumbersome. Therefore we provide a helper function {meth}`~jina.Flow.to_kubernetes_yaml` that does most of this\n@@ -26,7 +40,6 @@ This helper function can be called from:\n More detail in the {ref}`Flow export documentation <kubernetes-export>`\n ```\n \n-\n ## Extra Kubernetes options\n \n In general, Jina follows a single principle when it comes to deploying in Kubernetes:\n@@ -89,7 +102,6 @@ Instead, you can disable Jina level retries by setting `Flow(retries=0)` in Pyth\n YAML's `with` block.\n ````\n \n-\n (kubernetes-replicas)=\n ## Scaling Executors: Replicas and shards\n \n@@ -125,29 +137,9 @@ To expose your Gateway replicas outside Kubernetes, you can add a load balancer\n You can use a custom Docker image for the Gateway deployment by setting the envrironment variable `JINA_GATEWAY_IMAGE` to the desired image before generating the configuration.\n ````\n \n-\n-## Deploying On Jina AI Cloud\n-\n-Check out Jina AI Cloud {ref}`jcloud` if you want a **one-click** solution to deploy and host Jina, leveraging a cloud-native stack of Kubernetes, Prometheus and Grafana, **without worrying about provisioning**.\n-\n-\n-:::::{grid} 2\n-:gutter: 3\n-\n-::::{grid-item-card} {octicon}`cpu;1.5em` Deploy a Flow to JCloud\n-:link: fundamentals/jcloud/index\n-:link-type: doc\n-:class-card: color-gradient-card-2\n-\n-JCloud is a free CPU/GPU hosting platform for Jina projects.\n-::::\n-:::::\n-\n-\n-\n-## See further\n-- {ref}`Step by Step deployement of a Jina Flow on K8s <kubernetes>`\n-- {ref}`Flow export documentation <kubernetes-export>`\n+## See also\n+- {ref}`Step by step deployment of a Jina Flow on Kubernetes <kubernetes>`\n+- {ref}`Export a Flow to Kubernetes <kubernetes-export>`\n - {meth}`~jina.Flow.to_kubernetes_yaml`\n-- {ref}`Deploy a standalone Executor on K8s <kubernetes-executor>`\n-- [Kubernetes Documentation](https://kubernetes.io/docs/home/)\n\\ No newline at end of file\n+- {ref}`Deploy a standalone Executor on Kubernetes <kubernetes-executor>`\n+- [Kubernetes Documentation](https://kubernetes.io/docs/home/)\n\n\n###\n\n", "completion": "docs(k8s): fix box link; mv jcloud to top; small language fixes (#<issue-num>)"}
{"prompt": " file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -3,6 +3,7 @@ import json\n from typing import TYPE_CHECKING, Optional\n \n import grpc\n+from grpc import RpcError\n \n from jina.clients.base import BaseClient\n from jina.clients.helper import callback_exec\n@@ -51,6 +52,8 @@ class GRPCBaseClient(BaseClient):\n                     self.logger.error(\n                         f'Returned code is not expected! Exception: {response.exception}'\n                     )\n+        except RpcError as e:\n+            self.logger.error(f'RpcError: {e.details()}')\n         except Exception as e:\n             self.logger.error(f'Error while getting response from grpc server {e!r}')\n \n\n\n###\n\n", "completion": "fix: nicer error message for rpc errors (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/request_handlers/worker_request_handler.py | file path B: jina/serve/runtimes/request_handlers/worker_request_handler.py\n\n@@ -8,7 +8,7 @@ from jina.importer import ImportExtensions\n from jina.serve.executors import BaseExecutor\n from jina.types.request.data import DataRequest\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     import argparse\n \n     from opentelemetry import metrics, trace\n@@ -184,12 +184,12 @@ class WorkerRequestHandler:\n         }\n \n     async def handle(\n-        self, requests: List['DataRequest'], tracing_context: 'Context' = None\n+        self, requests: List['DataRequest'], tracing_context: Optional['Context'] = None\n     ) -> DataRequest:\n         \"\"\"Initialize private parameters and execute private loading functions.\n \n         :param requests: The messages to handle containing a DataRequest\n-        :param tracing_context: OpenTelemetry tracing context from the originating request.\n+        :param tracing_context: Optional OpenTelemetry tracing context from the originating request.\n         :returns: the processed message\n         \"\"\"\n         # skip executor if endpoints mismatch\n@@ -269,7 +269,9 @@ class WorkerRequestHandler:\n             )\n             self._document_processed_counter.add(len(docs), attributes=attributes)\n \n-        WorkerRequestHandler.replace_docs(requests[0], docs, self.args.output_array_type)\n+        WorkerRequestHandler.replace_docs(\n+            requests[0], docs, self.args.output_array_type\n+        )\n \n         if self._sent_response_size_metrics:\n             self._sent_response_size_metrics.labels(\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -1,6 +1,6 @@\n import argparse\n from abc import ABC\n-from typing import TYPE_CHECKING, List\n+from typing import TYPE_CHECKING, List, Optional\n \n import grpc\n from grpc_health.v1 import health, health_pb2, health_pb2_grpc\n@@ -13,10 +13,12 @@ from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.instrumentation import MetricsTimer\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n from jina.serve.runtimes.helper import _get_grpc_server_options\n-from jina.serve.runtimes.request_handlers.worker_request_handler import WorkerRequestHandler\n+from jina.serve.runtimes.request_handlers.worker_request_handler import (\n+    WorkerRequestHandler,\n+)\n from jina.types.request.data import DataRequest\n \n-if TYPE_CHECKING: # pragma: no cover\n+if TYPE_CHECKING:  # pragma: no cover\n     from opentelemetry.propagate import Context\n \n \n@@ -190,12 +192,16 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         )\n         return endpointsProto\n \n-    @staticmethod\n-    def _extract_tracing_context(metadata: grpc.aio.Metadata) -> 'Context':\n-        from opentelemetry.propagate import extract\n+    def _extract_tracing_context(\n+        self, metadata: grpc.aio.Metadata\n+    ) -> Optional['Context']:\n+        if self.tracer:\n+            from opentelemetry.propagate import extract\n \n-        context = extract(dict(metadata))\n-        return context\n+            context = extract(dict(metadata))\n+            return context\n+\n+        return None\n \n     async def process_data(self, requests: List[DataRequest], context) -> DataRequest:\n         \"\"\"\n@@ -213,7 +219,7 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n                 if self.logger.debug_enabled:\n                     self._log_data_request(requests[0])\n \n-                tracing_context = WorkerRuntime._extract_tracing_context(\n+                tracing_context = self._extract_tracing_context(\n                     context.invocation_metadata()\n                 )\n                 result = await self._worker_request_handler.handle(\n\n\n###\n\n", "completion": "fix: don't import OpenTelemetry methods if Opentelemetry is not enabled (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/client/third-party-client.md | file path B: docs/fundamentals/client/third-party-client.md\n\n@@ -9,9 +9,7 @@ Our [Go Client](https://github.com/jina-ai/client-go) supports gRPC, HTTP and We\n \n ## PHP\n \n-A big thanks to our community members at [DCO.ai](https://www.dco.ai/) for developing a [PHP Client](https://github.com/Dco-ai/php-jina) for Jina!\n-\n-This contribution was made by [Jonathan Rowley](https://jina-ai.slack.com/team/U03973EA7BN), in our community Slack.\n+A big thanks to our community member at [Jonathan Rowley](https://jina-ai.slack.com/team/U03973EA7BN) for developing a [PHP Client](https://github.com/Dco-ai/php-jina) for Jina!\n \n ## HTTP\n \n\n\n###\n\n", "completion": "ci: remove website in php client section in docs"}
{"prompt": " file path A: docs/fundamentals/client/third-party-client.md | file path B: docs/fundamentals/client/third-party-client.md\n\n@@ -1,17 +1,17 @@\n (third-party-client)=\n # Third-party clients\n \n-This page is about accessing the Flow with other clients, e.g. `curl`, or programming languages other than python.\n+This page is about accessing the Flow with other clients, e.g. `curl`, or programming languages other than Python.\n \n ## Golang\n \n Our [Go Client](https://github.com/jina-ai/client-go) supports gRPC, HTTP and WebSocket protocols, allowing you to connect to Jina from your Go applications.\n \n-\n ## PHP\n \n A big thanks to our community members at [DCO.ai](https://www.dco.ai/) for developing a [PHP Client](https://github.com/Dco-ai/php-jina) for Jina!\n \n+This contribution was made by [Jonathan Rowley](https://jina-ai.slack.com/team/U03973EA7BN), in our community Slack.\n \n ## HTTP\n \n@@ -25,7 +25,6 @@ Apart from using the {ref}`Jina Client <client>`, the most common way of interac\n \n You can always use `post` to interact with a Flow, using the `/post` HTTP endpoint.\n \n-\n With the help of [OpenAPI schema](https://swagger.io/specification/), one can send data requests to a Flow via `cURL`, JavaScript, [Postman](https://www.postman.com/), or any other HTTP client or programming library. \n \n ### Arguments\n@@ -41,7 +40,7 @@ Your HTTP request can include the following parameters:\n \n \n Instead of using the generic `/post` endpoint, you can directly use endpoints like `/index` or `/search` to perform a specific operation.\n-In this case your data request will be sent to the corresponding Executor endpoint, so the parameter `execEndpoint` does not need to be specified.\n+In this case your data request is sent to the corresponding Executor endpoint, so you don't need to specify the parameter `execEndpoint`.\n \n `````{dropdown} Example\n \n@@ -84,7 +83,7 @@ The response you receive includes `data` (an array of [Documents](https://docarr\n \n ```{admonition} See also: Flow REST API\n :class: seealso\n-For a more detailed descripton of the REST API of a generic Flow, including the complete request body schema and request samples, please check\n+For a more detailed descripton of the REST API of a generic Flow, including the complete request body schema and request samples, please check:\n \n 1. [OpenAPI Schema](https://api.jina.ai/rest/latest.json)\n 2. [Redoc UI](https://api.jina.ai/rest/)\n@@ -94,9 +93,9 @@ For a specific deployed Flow, you can get the same overview by accessing the `/r\n \n (swagger-ui)=\n \n-### Use curl\n+### Use cURL\n \n-Here's an example that uses `cURL`.\n+Here's an example that uses `cURL`:\n \n ```bash\n curl --request POST 'http://localhost:12345/post' --header 'Content-Type: application/json' -d '{\"data\": [{\"text\": \"hello world\"}],\"execEndpoint\": \"/search\"}'\n@@ -160,9 +159,9 @@ curl --request POST 'http://localhost:12345/post' --header 'Content-Type: applic\n \n \n \n-### Use Javascript\n+### Use JavaScript\n \n-Sending a request from the front-end JavaScript code is a common use case too. Here's how this would look like:\n+Sending a request from the front-end JavaScript code is a common use case too. Here's how this looks:\n \n ```javascript\n fetch('http://localhost:12345/post', {\n@@ -210,24 +209,24 @@ fetch('http://localhost:12345/post', {\n \n ### Use Swagger UI\n \n-Flows provide a customized [Swagger UI](https://swagger.io/tools/swagger-ui/) which can be used to interact with the Flow\n-visually, through a web browser.\n+Flows provide a customized [Swagger UI](https://swagger.io/tools/swagger-ui/) which you can use to visually interact with the Flow\n+through a web browser.\n \n ```{admonition} Available Protocols\n :class: caution\n Only Flows that have enabled {ref}`CORS <cors>` expose the Swagger UI interface.\n ```\n \n-For a Flow that is exposed on port `PORT`, you can navigate to the Swagger UI via `http://localhost:PORT/docs`:\n+For a Flow that is exposed on port `PORT`, you can navigate to the Swagger UI at `http://localhost:PORT/docs`:\n \n ```{figure} ../../../.github/2.0/swagger-ui.png\n :align: center\n ```\n Here you can see all the endpoints that are exposed by the Flow, such as `/search` and `/index`.\n \n-To send a request, click on the endpoint you want to target, then on `Try it out`.\n+To send a request, click on the endpoint you want to target, then `Try it out`.\n \n-Now you can enter your HTTP request, and send it by clicking on `Execute`.\n+Now you can enter your HTTP request, and send it by clicking `Execute`.\n You can again use the [REST HTTP request schema](https://api.jina.ai/rest/), but do not need to specify `execEndpoint`.\n \n Below, in `Responses`, you can see the reply, together with a visual representation of the returned Documents.\n@@ -236,20 +235,20 @@ Below, in `Responses`, you can see the reply, together with a visual representat\n \n [Postman](https://www.postman.com/) is an application that allows the testing of web APIs from a graphical interface. You can store all the templates for your REST APIs in it, using Collections. \n \n-We provide a suite of templates for the Jina Flow, in this [collection](https://github.com/jina-ai/jina/tree/master/.github/Jina.postman_collection.json). You can import it in Postman in **Collections**, with the **Import** button. It provides templates for the main operations. You need to create an Environment to define the `{{url}}` and `{{port}}` environment variables. These would be the hostname and the port where the Flow is listening. \n+We provide a [suite of templates for Jina Flow](https://github.com/jina-ai/jina/tree/master/.github/Jina.postman_collection.json). You can import it in Postman in **Collections**, with the **Import** button. It provides templates for the main operations. You need to create an Environment to define the `{{url}}` and `{{port}}` environment variables. These would be the hostname and the port where the Flow is listening. \n \n-This contribution was made by [Jonathan Rowley](https://jina-ai.slack.com/archives/C0169V26ATY/p1649689443888779?thread_ts=1649428823.420879&cid=C0169V26ATY), in our [community Slack](slack.jina.ai). \n+This contribution was made by [Jonathan Rowley](https://jina-ai.slack.com/archives/C0169V26ATY/p1649689443888779?thread_ts=1649428823.420879&cid=C0169V26ATY), in our [community Slack](slack.jina.ai).\n \n ## gRPC\n \n-To use the gRPC protocol with a language other than Python you will need to :\n+To use the gRPC protocol with a language other than Python you will need to:\n \n-* Download the two proto definition files: `jina.proto` and `docarray.proto` from [github](https://github.com/jina-ai/jina/tree/master/jina/proto) (be sure to use the latest release branch)\n-* Compile them with [protoc](https://grpc.io/docs/protoc-installation/) and precise to which programming language you want to compile them.\n-* Add the generated files to your project and import them in your code. \n+* Download the two proto definition files: `jina.proto` and `docarray.proto` from [GitHub](https://github.com/jina-ai/jina/tree/master/jina/proto) (be sure to use the latest release branch)\n+* Compile them with [protoc](https://grpc.io/docs/protoc-installation/) and specify which programming language you want to compile them with.\n+* Add the generated files to your project and import them into your code.\n \n You should finally be able to communicate with your Flow using the gRPC protocol. You can find more information on the gRPC\n-`message` and `service` that you can use to communicate in the  [Protobuf documentation](../../proto/docs.md).\n+`message` and `service` that you can use to communicate in the [Protobuf documentation](../../proto/docs.md).\n \n (flow-graphql)=\n ## GraphQL\n@@ -258,15 +257,15 @@ You should finally be able to communicate with your Flow using the gRPC protocol\n :class: seealso\n \n This article does not serve as the introduction to GraphQL.\n-If you are not already familiar with GraphQL, we recommend you learn more about GraphQL from the official [GraphQL documentation](https://graphql.org/learn/).\n+If you are not already familiar with GraphQL, we recommend you learn more about GraphQL from the [official documentation](https://graphql.org/learn/).\n You may also want to learn about [Strawberry](https://strawberry.rocks/), the library that powers Jina's GraphQL support.\n ````\n Jina Flows that use the HTTP protocol can also provide a GraphQL API, which is located behind the `/graphql` endpoint.\n-GraphQL has the advantage of letting the user define their own response schema, which means that only the fields that are required\n-will be sent over the wire.\n-This is especially useful when the user does not need potentially large fields, like image tensors.\n+GraphQL has the advantage of letting you define your own response schema, which means that only the fields you require\n+are sent over the wire.\n+This is especially useful when you don't need potentially large fields, like image tensors.\n \n-You can access the Flow from any GraphQL client, like for example, `sgqlc`.\n+You can access the Flow from any GraphQL client, like `sgqlc`.\n \n ```python\n from sgqlc.endpoint.http import HTTPEndpoint\n@@ -291,7 +290,7 @@ response = endpoint(mut)\n The Flow GraphQL API exposes the mutation `docs`, which sends its inputs to the Flow's Executors,\n just like HTTP `post` as described {ref}`above <http-interface>`.\n \n-A GraphQL mutation takes same set of arguments used in [HTTP](#arguments). \n+A GraphQL mutation takes the same set of arguments used in [HTTP](#arguments). \n \n The response from GraphQL can include all fields available on a DocumentArray.\n \n@@ -299,7 +298,7 @@ The response from GraphQL can include all fields available on a DocumentArray.\n :class: seealso\n \n For more details on the GraphQL format of Document and DocumentArray, see the [documentation page](https://docarray.jina.ai/advanced/graphql-support/)\n-or the [developer reference](https://docarray.jina.ai/api/docarray.document.mixins.strawberry/).\n+or [developer reference](https://docarray.jina.ai/api/docarray.document.mixins.strawberry/).\n ````\n \n \n@@ -310,29 +309,28 @@ The available fields in the GraphQL API are defined by the [Document Strawberry\n Essentially, you can ask for any property of a Document, including `embedding`, `text`, `tensor`, `id`, `matches`, `tags`,\n and more.\n \n-## Websocket\n+## WebSocket\n \n-Websocket uses persistent connections between the client & Flow, hence allowing streaming use cases. \n-While you can always use the Python client to stream requests like any other protocol, websocket allows streaming JSON from anywhere (CLI / Postman / any other programming language). \n-The same set of arguments as [HTTP](#arguments) can be used in the payload.\n+WebSocket uses persistent connections between the client and Flow, hence allowing streaming use cases. \n+While you can always use the Python client to stream requests like any other protocol, WebSocket allows streaming JSON from anywhere (CLI / Postman / any other programming language). \n+You can use the same set of arguments as [HTTP](#arguments) in the payload.\n \n We use [subprotocols](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers#subprotocols) to separate streaming JSON vs bytes. \n-The Flow defaults to `json` when a subprotocol is not passed during connection establishment (Our Python client uses `bytes` streaming by using [jina.proto](../../proto/docs.md) definition).\n+The Flow defaults to `json` if you don't specify a sub-protocol while establishing the connection (Our Python client uses `bytes` streaming by using [jina.proto](../../proto/docs.md) definition).\n \n \n ````{Hint}\n \n-- Choose Websocket over HTTP if you want to stream requests. \n-- Choose Websocket over gRPC if\n-  - you want to stream using JSON, not bytes\n-  - your client language doesn't support gRPC\n-  - you don't want to compile the [Protobuf definitions](../../proto/docs.md) for your gRPC client\n+- Choose WebSocket over HTTP if you want to stream requests. \n+- Choose WebSocket over gRPC if\n+  - you want to stream using JSON, not bytes.\n+  - your client language doesn't support gRPC.\n+  - you don't want to compile the [Protobuf definitions](../../proto/docs.md) for your gRPC client.\n \n ````\n \n-\n-## See further\n+## See also\n \n - {ref}`Access a Flow with the Client <client>`\n-- {ref}`Configure Flow <flow>`\n-- [Flow REST API reference](https://api.jina.ai/rest/)\n\\ No newline at end of file\n+- {ref}`Configure a Flow <flow>`\n+- [Flow REST API reference](https://api.jina.ai/rest/)\n\n\n###\n\n", "completion": "docs: add contributor acknowledgement, clean up language (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/client/third-party-client.md | file path B: docs/fundamentals/client/third-party-client.md\n\n@@ -3,6 +3,16 @@\n \n This page is about accessing the Flow with other clients, e.g. `curl`, or programming languages other than python.\n \n+## Golang\n+\n+Our [Go Client](https://github.com/jina-ai/client-go) supports gRPC, HTTP and WebSocket protocols, allowing you to connect to Jina from your Go applications.\n+\n+\n+## PHP\n+\n+A big thanks to our community members at [DCO.ai](https://www.dco.ai/) for developing a [PHP Client](https://github.com/Dco-ai/php-jina) for Jina!\n+\n+\n ## HTTP\n \n ```{admonition} Available Protocols\n\n\n###\n\n", "completion": "docs: add links to go and php clients (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-docker-build.yml | file path B: .github/workflows/force-docker-build.yml\n\n@@ -77,14 +77,14 @@ jobs:\n             if [[ \"${{ matrix.py_version }}\" == \"$DEFAULT_PY_VERSION\" ]]; then\n               echo \"TAG_ALIAS=\\\n                               jinaai/jina:master${PY_TAG}${PIP_TAG}, \\\n-                              jinaai/jina:master${PIP_TAG} \\\n-                              jinaai/jina:${JINA_VERSION}${PRE_VERSION}${PIP_TAG} \\\n+                              jinaai/jina:master${PIP_TAG}, \\\n+                              jinaai/jina:${JINA_VERSION}${PRE_VERSION}${PIP_TAG}, \\\n                               jinaai/jina:${JINA_VERSION}${PRE_VERSION}${PY_TAG}${PIP_TAG}\" \\\n                               >> $GITHUB_ENV\n             else\n               # on every CD\n               echo \"TAG_ALIAS=\\\n-                              jinaai/jina:master${PY_TAG}${PIP_TAG} \\\n+                              jinaai/jina:master${PY_TAG}${PIP_TAG}, \\\n                               jinaai/jina:${JINA_VERSION}${PRE_VERSION}${PY_TAG}${PIP_TAG}\" \\\n                               >> $GITHUB_ENV\n             fi\n\n\n###\n\n", "completion": "ci: fix docker build and push (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-docs-build.yml | file path B: .github/workflows/force-docs-build.yml\n\n@@ -86,7 +86,7 @@ jobs:\n       - name: Moving old doc versions\n         run: |\n           cd docs\n-          for i in $(cat _versions.json | jq '.[].version' | tr -d '\"'); do if [ -d \"$i\" ]; then; mv \"$i\" /tmp/gen-html; fi; done\n+          for i in $(cat _versions.json | jq '.[].version' | tr -d '\"'); do if [ -d \"$i\" ]; then mv \"$i\" /tmp/gen-html; fi; done\n       - name: Swap in new docs\n         run: |\n           rm -rf ./docs\n\n\n###\n\n", "completion": "ci: fix move docs that did not exist (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-docs-build.yml | file path B: .github/workflows/force-docs-build.yml\n\n@@ -86,7 +86,7 @@ jobs:\n       - name: Moving old doc versions\n         run: |\n           cd docs\n-          for i in $(cat _versions.json | jq '.[].version' | tr -d '\"'); do mv \"$i\" /tmp/gen-html; done\n+          for i in $(cat _versions.json | jq '.[].version' | tr -d '\"'); do if [ -d \"$i\" ]; then; mv \"$i\" /tmp/gen-html; fi; done\n       - name: Swap in new docs\n         run: |\n           rm -rf ./docs\n\n\n###\n\n", "completion": "ci: fix move docs that did not exist (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/build-old-docs.yml | file path B: .github/workflows/build-old-docs.yml\n\n@@ -74,6 +74,10 @@ jobs:\n           mv ./brand.html ./docs/_templates/sidebar/brand.html\n       - name: Install dependencies\n         run: |\n+          wget https://raw.githubusercontent.com/${{ inputs.repo_owner }}/${{ inputs.package }}/master/docs/pin_requirements.py\n+          wget https://raw.githubusercontent.com/${{ inputs.repo_owner }}/${{ inputs.package }}/master/docs/correct_some_requirements.sh\n+          python pin_requirements.py extra-requirements.txt\n+          bash correct_some_requirements.sh\n           pip install .[devel]\n           cd docs\n           pip install -r requirements.txt\n\n---\n file path A: docs/_versions.json | file path B: docs/_versions.json\n\n@@ -1 +1 @@\n-[{\"version\": \"v3.11.0\"}, {\"version\": \"v3.10.1\"}, {\"version\": \"v3.9.3\"}, {\"version\": \"v3.8.4\"}, {\"version\": \"v3.7.14\"}, {\"version\": \"v3.6.16\"}, {\"version\": \"v3.5.0\"}, {\"version\": \"v3.4.11\"}]\n\\ No newline at end of file\n+[{\"version\": \"v3.11.0\"}, {\"version\": \"v3.10.1\"},  {\"version\": \"v3.10.0\"}, {\"version\": \"v3.9.3\"}, {\"version\": \"v3.9.2\"},{\"version\": \"v3.9.1\"},{\"version\": \"v3.9.0\"}, {\"version\": \"v3.8.4\"}, {\"version\": \"v3.8.3\"}, {\"version\": \"v3.8.2\"}, {\"version\": \"v3.8.1\"}, {\"version\": \"v3.8.0\"}, {\"version\": \"v3.7.14\"}, {\"version\": \"v3.7.13\"},{\"version\": \"v3.7.12\"},{\"version\": \"v3.7.11\"},{\"version\": \"v3.7.10\"},{\"version\": \"v3.7.9\"},{\"version\": \"v3.7.8\"},{\"version\": \"v3.7.7\"},{\"version\": \"v3.7.6\"},{\"version\": \"v3.7.5\"},{\"version\": \"v3.7.4\"},{\"version\": \"v3.7.3\"},{\"version\": \"v3.7.2\"}, {\"version\": \"v3.7.1\"},{\"version\": \"v3.7.0\"}, {\"version\": \"v3.6.16\"}, {\"version\": \"v3.6.15\"},{\"version\": \"v3.6.14\"}, {\"version\": \"v3.6.13\"},{\"version\": \"v3.6.12\"},{\"version\": \"v3.6.11\"},{\"version\": \"v3.6.10\"},{\"version\": \"v3.6.9\"},{\"version\": \"v3.6.8\"},{\"version\": \"v3.6.7\"},{\"version\": \"v3.6.6\"},{\"version\": \"v3.6.5\"},{\"version\": \"v3.6.4\"},{\"version\": \"v3.6.3\"},{\"version\": \"v3.6.2\"}, {\"version\": \"v3.6.1\"},{\"version\": \"v3.6.0\"}, {\"version\": \"v3.5.0\"}, {\"version\": \"v3.4.11\"},{\"version\": \"v3.4.10\"},{\"version\": \"v3.4.9\"},{\"version\": \"v3.4.8\"},{\"version\": \"v3.4.7\"},{\"version\": \"v3.4.6\"},{\"version\": \"v3.4.5\"},{\"version\": \"v3.4.4\"},{\"version\": \"v3.4.3\"},{\"version\": \"v3.4.2\"}, {\"version\": \"v3.4.1\"},{\"version\": \"v3.4.0\"}, {\"version\": \"v3.3.25\"},{\"version\": \"v3.3.24\"},{\"version\": \"v3.3.23\"},{\"version\": \"v3.3.22\"},{\"version\": \"v3.3.21\"},{\"version\": \"v3.3.20\"},{\"version\": \"v3.3.19\"},{\"version\": \"v3.3.18\"},{\"version\": \"v3.3.17\"},{\"version\": \"v3.3.16\"},{\"version\": \"v3.3.15\"},{\"version\": \"v3.3.14\"},{\"version\": \"v3.3.13\"},{\"version\": \"v3.3.7\"},{\"version\": \"v3.3.12\"},{\"version\": \"v3.3.11\"},{\"version\": \"v3.3.10\"},{\"version\": \"v3.3.9\"},{\"version\": \"v3.3.8\"},{\"version\": \"v3.3.7\"},{\"version\": \"v3.3.6\"},{\"version\": \"v3.3.5\"},{\"version\": \"v3.3.4\"},{\"version\": \"v3.3.3\"},{\"version\": \"v3.3.2\"}, {\"version\": \"v3.3.1\"},{\"version\": \"v3.3.0\"}, {\"version\": \"v3.2.10\"},{\"version\": \"v3.2.9\"},{\"version\": \"v3.2.8\"},{\"version\": \"v3.2.7\"},{\"version\": \"v3.2.6\"},{\"version\": \"v3.2.5\"},{\"version\": \"v3.2.4\"},{\"version\": \"v3.2.3\"},{\"version\": \"v3.2.2\"}, {\"version\": \"v3.2.1\"},{\"version\": \"v3.2.0\"}, {\"version\": \"v3.1.6\"},{\"version\": \"v3.1.5\"},{\"version\": \"v3.1.4\"},{\"version\": \"v3.1.3\"},{\"version\": \"v3.1.2\"}, {\"version\": \"v3.1.1\"},{\"version\": \"v3.1.0\"}, {\"version\": \"v3.0.4\"},{\"version\": \"v3.0.3\"},{\"version\": \"v3.0.2\"}, {\"version\": \"v3.0.1\"},{\"version\": \"v3.0.0\"}]\n\n---\n file path A: None | file path B: docs/correct_some_requirements.sh\n\n@@ -0,0 +1,5 @@\n+#!/bin/bash\n+\n+grep -rl 'opentelemetry-exporter-prometheus' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-prometheus==1.12.0/opentelemetry-exporter-prometheus==1.12.0rc1/g'\n+grep -rl 'opentelemetry-exporter-otlp-proto-grpc' extra-requirements.txt | xargs sed -i 's/opentelemetry-exporter-otlp-proto-grpc==1.13.0/opentelemetry-exporter-otlp-proto-grpc==1.12.0/g'\n+grep -rl 'pyyaml' extra-requirements.txt | xargs sed -i 's/pyyaml==5.3.1/pyyaml==5.4.1/g'\n\n---\n file path A: None | file path B: docs/pin_requirements.py\n\n@@ -0,0 +1,15 @@\n+import re\n+import sys\n+file_name = sys.argv[1]\n+with open(file_name, 'r') as f:\n+    input = f.read()\n+\n+\n+# official semver regex: https://semver.org/#is-there-a-suggested-regular-expression-regex-to-check-a-semver-string\n+versions_regex = '(?P<major>0|[1-9]\\d*)\\.(?P<minor>0|[1-9]\\d*)\\.(?P<patch>0|[1-9]\\d*)'\n+\n+output = re.sub(f'(?P<dep>[a-zA-Z0-9]+)(==|>=)(?P<version>{versions_regex}).*:', r'\\g<dep>==\\g<version>:', input)\n+\n+\n+with open(file_name, 'w') as f:\n+    f.write(output)\n\n\n###\n\n", "completion": "ci: add more old versions to be built down to 3.0.0 (#<issue-num>)"}
{"prompt": " file path A: docs/_templates/sidebar/brand.html | file path B: docs/_templates/sidebar/brand.html\n\n@@ -18,7 +18,6 @@\n </a>\n <script>\n   function setPrefix(prefix){\n-    window.sessionStorage.setItem(\"version-select-index\", document.getElementsByClassName(\"version-select\")[0].selectedIndex);\n     window.location.href = prefix\n   }\n </script>\n@@ -26,16 +25,17 @@\n   fetch(`https://${window.location.host}/_versions.json`)\n   .then((resp) => resp.json())\n   .then((data) => {\n-    var versionSelector = document.getElementsByClassName(\"version-select\")[0]\n+    var versionSelector = document.getElementsByClassName(\"version-select\")[0];\n+    var currentPrefix = window.location.href.toString().split(window.location.host)[1].split('/')[1];\n+\n     for(var i = 0; i < data.length; i++){\n       var option = document.createElement(\"option\");\n       option.innerHTML = data[i].version;\n       option.value = \"/\" + data[i].version;\n       versionSelector.appendChild(option);\n-    }\n-\n-    if(window.sessionStorage.getItem('version-select-index')){\n-      versionSelector.selectedIndex = window.sessionStorage.getItem('version-select-index');\n+      if(currentPrefix === data[i].version){\n+        versionSelector.selectedIndex = i + 1;\n+      }\n     }\n   })\n   .catch((err) => console.log(err));\n\n\n###\n\n", "completion": "docs: use url instead of session store in version selector (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -214,7 +214,7 @@ jobs:\n           docker run --privileged --rm tonistiigi/binfmt --uninstall qemu-aarch64\n           docker run --rm --privileged tonistiigi/binfmt --install all\n       - name: Build and test\n-        uses: docker/build-push-action@v3.2.0\n+        uses: docker/build-push-action@v2\n         with:\n           context: .\n           file: Dockerfiles/debianx.Dockerfile\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -137,7 +137,7 @@ jobs:\n           docker run --privileged --rm tonistiigi/binfmt --uninstall qemu-aarch64\n           docker run --rm --privileged tonistiigi/binfmt --install all\n       - name: Build and test\n-        uses: docker/build-push-action@v3.2.0\n+        uses: docker/build-push-action@v2\n         with:\n           context: .\n           file: Dockerfiles/debianx.Dockerfile\n\n---\n file path A: .github/workflows/force-docker-build.yml | file path B: .github/workflows/force-docker-build.yml\n\n@@ -146,7 +146,7 @@ jobs:\n           docker run --privileged --rm tonistiigi/binfmt --uninstall qemu-aarch64\n           docker run --rm --privileged tonistiigi/binfmt --install all\n       - name: Build and push\n-        uses: docker/build-push-action@v3.2.0\n+        uses: docker/build-push-action@v2\n         with:\n           context: .\n           file: Dockerfiles/debianx.Dockerfile\n\n\n###\n\n", "completion": "ci: fix proper build-push version (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -206,7 +206,7 @@ jobs:\n       - uses: actions/checkout@v2.5.0\n       - name: Set up Docker Buildx\n         id: buildx\n-        uses: docker/setup-buildx-action@v2.1.0\n+        uses: docker/setup-buildx-action@v1\n         with:\n           install: true\n           driver-opts: network=host\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -129,7 +129,7 @@ jobs:\n       - uses: actions/checkout@v2.5.0\n       - name: Set up Docker Buildx\n         id: buildx\n-        uses: docker/setup-buildx-action@v2.1.0\n+        uses: docker/setup-buildx-action@v1\n         with:\n           install: true\n           driver-opts: network=host\n\n---\n file path A: .github/workflows/force-docker-build.yml | file path B: .github/workflows/force-docker-build.yml\n\n@@ -132,7 +132,7 @@ jobs:\n \n       - name: Set up Docker Buildx\n         id: buildx\n-        uses: docker/setup-buildx-action@v2.1.0\n+        uses: docker/setup-buildx-action@v1\n         with:\n           install: true\n       - name: Login to DockerHub\n\n\n###\n\n", "completion": "ci: fix proper buildx version (#<issue-num>)"}
{"prompt": " file path A: None | file path B: .github/workflows/build-old-docs.yml\n\n@@ -0,0 +1,124 @@\n+name: Build old docs\n+\n+on:\n+  workflow_dispatch:\n+    inputs:\n+      release_token:\n+        description: 'Your release token'\n+        required: true\n+      triggered_by:\n+        description: 'CD | TAG | MANUAL'\n+        required: false\n+        default: MANUAL\n+      package:\n+        description: The name of the repo to build documentation for.\n+        type: string\n+        default: jina\n+      repo_owner:\n+        description: The owner of the repo to build documentation for. Defaults to 'jina-ai'.\n+        type: string\n+        default: jina-ai\n+      pages_branch:\n+        description: Branch that Github Pages observes\n+        type: string\n+        default: gh-pages\n+      git_config_name:\n+        type: string\n+        default: Jina Dev Bot\n+      git_config_email:\n+        type: string\n+        default: dev-bot@jina.ai\n+\n+jobs:\n+  token-check:\n+    runs-on: ubuntu-latest\n+    steps:\n+      - name: Check release token\n+        id: token-check\n+        run: | \n+          touch SUCCESS\n+        if: inputs.release_token == env.release_token\n+        env:\n+          release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n+      - name: Fail release token\n+        run: |\n+          [[ -f SUCCESS ]]\n+      - name: Get versions\n+        id: get_versions\n+        run: |\n+          printf \"versions=\" >> $GITHUB_OUTPUT\n+          curl https://raw.githubusercontent.com/${{ inputs.repo_owner }}/${{ inputs.package }}/master/docs/_versions.json >> $GITHUB_OUTPUT\n+    outputs:\n+      versions: ${{ steps.get_versions.outputs.versions }}\n+\n+  build-doc:\n+    needs: token-check\n+    runs-on: ubuntu-latest\n+    strategy:\n+      fail-fast: false\n+      matrix:\n+        include: ${{ fromJson(needs.token-check.outputs.versions) }}\n+    steps:\n+      - uses: actions/checkout@v3\n+        with:\n+          fetch-depth: 1\n+          ref: ${{ matrix.version }}\n+      - uses: actions/setup-python@v4\n+        with:\n+          python-version: '3.7'\n+      - name: Get latest templates\n+        run: |\n+          git show --summary\n+          echo \"Get latest sidebar brand template\"\n+          wget https://raw.githubusercontent.com/${{ inputs.repo_owner }}/${{ inputs.package }}/master/docs/_templates/sidebar/brand.html\n+          mv ./brand.html ./docs/_templates/sidebar/brand.html\n+      - name: Install dependencies\n+        run: |\n+          pip install .[devel]\n+          cd docs\n+          pip install -r requirements.txt\n+          pip install --pre -U furo\n+          pip install sphinx-markdown-tables==0.0.17\n+      - name: Sphinx Build\n+        run: |\n+          cd docs\n+          bash makedoc.sh local-only\n+      - name: Package build into artifact\n+        run: |\n+          mv ./docs/_build/dirhtml ./${{ matrix.version }}\n+          zip -r /tmp/build.zip ./${{ matrix.version }}/*\n+      - name: Upload built html\n+        uses: actions/upload-artifact@v3\n+        with:\n+            name: ${{ matrix.version }}\n+            path: /tmp/build.zip\n+            retention-days: 1\n+  \n+  push-docs:\n+    runs-on: ubuntu-latest\n+    needs: build-doc\n+    steps:\n+      - uses: actions/checkout@v3\n+        with:\n+          fetch-depth: 1\n+          ref: ${{ inputs.pages_branch }}\n+      - uses: actions/download-artifact@v3\n+        with:\n+          path: /tmp/artifacts\n+      - name: Clear old builds\n+        run: |\n+          cd docs\n+          for i in $(ls /tmp/artifacts); do git rm -rf \"$i\" || true; done\n+      - name: In with new builds\n+        run: |\n+          cd docs\n+          for i in $(ls /tmp/artifacts); do unzip \"/tmp/artifacts/$i/build.zip\"; done\n+          rm _versions.json || true\n+          wget https://raw.githubusercontent.com/${{ inputs.repo_owner }}/${{ inputs.package }}/master/docs/_versions.json\n+      - name: Push it up!\n+        run: |\n+          git config --local user.email \"${{ inputs.git_config_email }}\"\n+          git config --local user.name \"${{ inputs.git_config_name }}\"\n+          git show --summary\n+          git add . && git commit -m \"chore(docs): update old docs due to ${{github.event_name}} on ${{github.repository}}\"\n+          git push origin\n\n---\n file path A: .github/workflows/force-docs-build.yml | file path B: .github/workflows/force-docs-build.yml\n\n@@ -10,6 +10,28 @@ on:\n         description: 'CD | TAG | MANUAL'\n         required: false\n         default: MANUAL\n+      build_old_docs:\n+        description: 'Whether to build old docs (TRUE | FALSE)'\n+        type: string\n+        default: 'FALSE'\n+      package:\n+        description: The name of the repo to build documentation for.\n+        type: string\n+        default: jina\n+      repo_owner:\n+        description: The owner of the repo to build documentation for. Defaults to 'jina-ai'.\n+        type: string\n+        default: jina-ai\n+      pages_branch:\n+        description: Branch that Github Pages observes\n+        type: string\n+        default: gh-pages\n+      git_config_name:\n+        type: string\n+        default: Jina Dev Bot\n+      git_config_email:\n+        type: string\n+        default: dev-bot@jina.ai\n \n jobs:\n   token-check:\n@@ -26,44 +48,66 @@ jobs:\n         run: |\n           [[ -f SUCCESS ]]\n \n-\n-  regular-release:\n+  build-and-push-latest-docs:\n     needs: token-check\n     runs-on: ubuntu-latest\n     steps:\n-      - uses: actions/checkout@v2.5.0\n+      - uses: actions/checkout@v3\n         with:\n-          fetch-depth: 0\n+          fetch-depth: 1\n       - uses: actions/setup-python@v4\n         with:\n-          python-version: 3.7\n-      - name: Build doc and push to gh-pages\n+          python-version: '3.7'\n+      - name: Install Dependencies\n         run: |\n-          git config --local user.email \"dev-bot@jina.ai\"\n-          git config --local user.name \"Jina Dev Bot\"\n           pip install .[devel]\n-          mkdir gen-html\n           cd docs\n           pip install -r requirements.txt\n           pip install --pre -U furo\n-          export NUM_RELEASES=2\n+          pip install sphinx-markdown-tables==0.0.17\n+      - name: Sphinx Build\n+        run: |\n+          cd docs\n           bash makedoc.sh local-only\n-          cd ./_build/dirhtml/\n-          cp -r ./ ../../../gen-html\n-          cd -  # back to ./docs\n-          cd ..\n-          git checkout -f gh-pages\n-          git rm -rf ./docs\n-          mkdir -p docs\n-          cd gen-html\n-          cp -r ./ ../docs\n-          cd ../docs\n-          ls -la\n-          touch .nojekyll\n-          cp 404/index.html 404.html\n-          sed -i 's/href=\"\\.\\./href=\"/' 404.html # fix asset urls that needs to be updated in 404.html\n-          echo docs.jina.ai > CNAME\n+          mv ./_build/dirhtml /tmp/gen-html\n           cd ..\n-          git status\n-          git add docs && git commit -m \"chore(docs): update docs due to ${{github.event_name}} on ${{github.repository}}\"\n-          git push --force origin gh-pages\n\\ No newline at end of file\n+      - name: Checkout to GH pages branch (${{ inputs.pages_branch }})\n+        run: |\n+          git fetch origin ${{ inputs.pages_branch }}:${{ inputs.pages_branch }} --depth 1\n+          git checkout -f ${{ inputs.pages_branch }}\n+          git reset --hard HEAD\n+      - name: Small config stuff\n+        run: |\n+          touch /tmp/gen-html/.nojekyll\n+          cp ./docs/_versions.json /tmp/gen-html/_versions.json\n+          cp ./docs/CNAME /tmp/gen-html/CNAME\n+          cp /tmp/gen-html/404/index.html /tmp/gen-html/404.html\n+          sed -i 's/href=\"\\.\\./href=\"/' /tmp/gen-html/404.html # fix asset urls that needs to be updated in 404.html\n+      - name: Moving old doc versions\n+        run: |\n+          cd docs\n+          for i in $(cat _versions.json | jq '.[].version' | tr -d '\"'); do mv \"$i\" /tmp/gen-html; done\n+      - name: Swap in new docs\n+        run: |\n+          rm -rf ./docs\n+          mv /tmp/gen-html ./docs\n+      - name: Push it up!\n+        run: |\n+          git config --local user.email \"${{ inputs.git_config_email }}\"\n+          git config --local user.name \"${{ inputs.git_config_name }}\"\n+          git show --summary\n+          git add ./docs && git commit -m \"chore(docs): update docs due to ${{github.event_name}} on ${{github.repository}}\"\n+          git push origin ${{ inputs.pages_branch }}\n+\n+  build-old-docs:\n+    needs: build-and-push-latest-docs\n+    runs-on: ubuntu-latest\n+    if: inputs.build_old_docs == 'TRUE'\n+    steps:\n+      - uses: benc-uk/workflow-dispatch@v1\n+        with:\n+          workflow: Build old docs\n+          token: ${{ secrets.JINA_DEV_BOT }}\n+          inputs: '{ \"release_token\": \"${{ env.release_token }}\", \"triggered_by\": \"TAG\"}'\n+        env:\n+          release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n\n---\n file path A: .github/workflows/tag.yml | file path B: .github/workflows/tag.yml\n\n@@ -66,7 +66,7 @@ jobs:\n         with:\n           workflow: Manual Docs Build\n           token: ${{ secrets.JINA_DEV_BOT }}\n-          inputs: '{ \"release_token\": \"${{ env.release_token }}\", \"triggered_by\": \"TAG\"}'\n+          inputs: '{ \"release_token\": \"${{ env.release_token }}\", \"triggered_by\": \"TAG\", \"build_old_docs\": \"TRUE\"}'\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n \n\n---\n file path A: docs/_templates/sidebar/brand.html | file path B: docs/_templates/sidebar/brand.html\n\n@@ -16,26 +16,33 @@\n   {%- endif %}\n   {% endblock brand_content %}\n </a>\n+<script>\n+  function setPrefix(prefix){\n+    window.sessionStorage.setItem(\"version-select-index\", document.getElementsByClassName(\"version-select\")[0].selectedIndex);\n+    window.location.href = prefix\n+  }\n+</script>\n+<script defer>\n+  fetch(`https://${window.location.host}/_versions.json`)\n+  .then((resp) => resp.json())\n+  .then((data) => {\n+    var versionSelector = document.getElementsByClassName(\"version-select\")[0]\n+    for(var i = 0; i < data.length; i++){\n+      var option = document.createElement(\"option\");\n+      option.innerHTML = data[i].version;\n+      option.value = \"/\" + data[i].version;\n+      versionSelector.appendChild(option);\n+    }\n+\n+    if(window.sessionStorage.getItem('version-select-index')){\n+      versionSelector.selectedIndex = window.sessionStorage.getItem('version-select-index');\n+    }\n+  })\n+  .catch((err) => console.log(err));\n+</script>\n <div class=\"sd-d-flex-row sd-align-major-spaced\">\n   <a class=\"github-button\" href=\"https://github.com/jina-ai/jina\" data-icon=\"octicon-star\" data-show-count=\"true\" aria-label=\"Star jina-ai/jina on GitHub\" style=\"opacity: 0;\">Star</a>\n-  {% if versions %}\n-  <select onChange=\"window.location.href=this.value\" class=\"version-select\">\n-      {%- for item in versions|reverse %}\n-        {% if item.name == latest_jina_version %}\n-          {% set new_url = item.url if current_version.name == latest_jina_version else item.url | replace('/' + latest_jina_version, \"\") %}\n-          {% if current_version.version == item.version %}\n-            <option value=\"{{ new_url }}\" selected=\"selected\" >latest ({{ item.name }})</option>\n-          {% else %}\n-            <option value=\"{{ new_url }}\" >latest({{ item.name }})</option>\n-          {% endif %}\n-        {% else %}\n-          {% if current_version.version == item.version %}\n-            <option value=\"{{ item.url }}\" selected=\"selected\" >{{ item.name }}</option>\n-          {% else %}\n-            <option value=\"{{ item.url }}\" >{{ item.name }}</option>\n-          {% endif %}\n-        {% endif %}\n-      {%- endfor %}\n+  <select onChange=\"setPrefix(this.value)\" class=\"version-select\">\n+    <option value=\"/\">latest</option>\n   </select>\n-  {% endif %}\n-</div>\n+</div>\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/_versions.json\n\n@@ -0,0 +1 @@\n+[{\"version\": \"v3.11.0\"}, {\"version\": \"v3.10.1\"}, {\"version\": \"v3.9.3\"}, {\"version\": \"v3.8.4\"}, {\"version\": \"v3.7.14\"}, {\"version\": \"v3.6.16\"}, {\"version\": \"v3.5.0\"}, {\"version\": \"v3.4.11\"}]\n\\ No newline at end of file\n\n---\n file path A: None | file path B: scripts/prepend_version_json.py\n\n@@ -0,0 +1,21 @@\n+from typing import List\n+import argparse\n+import json\n+\n+parser = argparse.ArgumentParser(prog=\"Prepender docs/_versions.json\")\n+parser.add_argument(\n+    \"--version\",\n+    type=str,\n+    help=\"The version we wish to prepend (e.g. v0.18.0)\",\n+    required=True,\n+)\n+args = parser.parse_args()\n+\n+with open(\"./docs/_versions.json\") as f:\n+    versions: List[dict] = json.load(f)\n+    element = {k: v for k, v in args._get_kwargs()}\n+    if element != versions[0]:\n+        versions.insert(0, element)\n+\n+with open(\"./docs/_versions.json\", \"w\") as f:\n+    json.dump(versions, f)\n\n---\n file path A: scripts/release.sh | file path B: scripts/release.sh\n\n@@ -75,6 +75,10 @@ export RELEASE_VER=$(sed -n '/^__version__/p' $INIT_FILE | cut -d \\' -f2)\n LAST_VER=$(git tag -l | sort -V | tail -n1)\n printf \"last version: \\e[1;32m$LAST_VER\\e[0m\\n\"\n \n+# Update new _versions.json if necessary\n+python ./scripts/prepend_version_json.py --version \"v$RELEASE_VER\"\n+git add ./docs/_versions.json\n+\n if [[ $1 == \"final\" ]]; then\n   printf \"this will be a final release: \\e[1;33m$RELEASE_VER\\e[0m\\n\"\n \n\n\n###\n\n", "completion": "docs: add versioned docs (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-docker-build.yml | file path B: .github/workflows/force-docker-build.yml\n\n@@ -15,10 +15,17 @@ jobs:\n   token-check:\n     runs-on: ubuntu-latest\n     steps:\n-      - run: echo \"success!\"\n-        if: \"${{ github.event.inputs.release_token }} == ${{ env.release_token }}\"\n+      - name: Check release token\n+        id: token-check\n+        run: | \n+          touch SUCCESS\n+        if: inputs.release_token == env.release_token\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n+      - name: Fail release token\n+        run: |\n+          [[ -f SUCCESS ]]\n+\n \n   regular-release:\n     needs: token-check\n\n---\n file path A: .github/workflows/force-docs-build.yml | file path B: .github/workflows/force-docs-build.yml\n\n@@ -15,10 +15,17 @@ jobs:\n   token-check:\n     runs-on: ubuntu-latest\n     steps:\n-      - run: echo \"success!\"\n-        if: \"${{ github.event.inputs.release_token }} == ${{ env.release_token }}\"\n+      - name: Check release token\n+        id: token-check\n+        run: | \n+          touch SUCCESS\n+        if: inputs.release_token == env.release_token\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n+      - name: Fail release token\n+        run: |\n+          [[ -f SUCCESS ]]\n+\n \n   regular-release:\n     needs: token-check\n\n---\n file path A: .github/workflows/force-release.yml | file path B: .github/workflows/force-release.yml\n\n@@ -14,10 +14,17 @@ jobs:\n   token-check:\n     runs-on: ubuntu-latest\n     steps:\n-      - run: echo \"success!\"\n-        if: \"${{ github.event.inputs.release_token }} == ${{ env.release_token }}\"\n+      - name: Check release token\n+        id: token-check\n+        run: | \n+          touch SUCCESS\n+        if: inputs.release_token == env.release_token\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n+      - name: Fail release token\n+        run: |\n+          [[ -f SUCCESS ]]\n+\n \n   hub-integration:\n     needs: token-check\n\n---\n file path A: .github/workflows/update-announcement.yml | file path B: .github/workflows/update-announcement.yml\n\n@@ -17,10 +17,17 @@ jobs:\n   token-check:\n     runs-on: ubuntu-latest\n     steps:\n-      - run: echo \"success!\"\n-        if: \"${{ github.event.inputs.release_token }} == ${{ env.release_token }}\"\n+      - name: Check release token\n+        id: token-check\n+        run: | \n+          touch SUCCESS\n+        if: inputs.release_token == env.release_token\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n+      - name: Fail release token\n+        run: |\n+          [[ -f SUCCESS ]]\n+\n \n   update-announcement:\n     needs: token-check\n\n\n###\n\n", "completion": "ci: fix token check in workflows (#<issue-num>)"}
{"prompt": " file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -102,6 +102,7 @@ extensions = [\n     'sphinx.ext.viewcode',\n     'sphinx.ext.coverage',\n     'sphinxcontrib.apidoc',\n+    'sphinxcontrib.redirects',\n     'sphinxarg.ext',\n     'sphinx_copybutton',\n     'sphinx_sitemap',\n@@ -116,7 +117,7 @@ extensions = [\n intersphinx_mapping = {'docarray': ('https://docarray.jina.ai/', None)}\n myst_enable_extensions = ['colon_fence']\n autosummary_generate = True\n-\n+redirects_file = 'redirects.txt'\n # -- Custom 404 page\n \n # sphinx-notfound-page\n\n---\n file path A: docs/redirects.txt | file path B: docs/redirects.txt\n\n\n---\n file path A: docs/requirements.txt | file path B: docs/requirements.txt\n\n@@ -2,6 +2,7 @@\n sphinx\n sphinx-argparse==0.3.1\n sphinxcontrib-apidoc==0.3.0\n+sphinxcontrib-redirects==0.1.0\n sphinx-autodoc-typehints==1.18.3\n sphinx_copybutton\n sphinx-notfound-page==0.7.1\n\n\n###\n\n", "completion": "docs: support redirects (#<issue-num>)"}
{"prompt": " file path A: .github/2.0/grafana-histogram-metrics.png | file path B: .github/2.0/grafana-histogram-metrics.png\n\nBinary files a/.github/2.0/grafana-histogram-metrics.png and b/.github/2.0/grafana-histogram-metrics.png differ\n\n---\n file path A: .github/readme/grafana-histogram-metrics.png | file path B: .github/readme/grafana-histogram-metrics.png\n\nBinary files a/.github/readme/grafana-histogram-metrics.png and b/.github/readme/grafana-histogram-metrics.png differ\n\n\n###\n\n", "completion": "docs: use grafana screenshot without random text block (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -234,6 +234,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15211,3 +15212,59 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```1810f178```](https://github.com/jina-ai/jina/commit/1810f178ba000cda2a4f6d98d590132c51338f87)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d2760cdd```](https://github.com/jina-ai/jina/commit/d2760cddec14c28693e1bab5926965d1fc3e49d7)] __-__ __version__: the next version will be 3.10.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-11-0></a>\n+## Release Note (`3.11.0`)\n+\n+> Release time: 2022-10-24 14:42:35\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Girish Chandrashekar,  Joan Fontanals,  Han Xiao,  AlaeddineAbdessalem,  felix-wang,  Alex Cureton-Griffiths,  zhangkai,  Andrei Ungureanu,  Anthony Le,  Johannes Messner,  samsja,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```81199a51```](https://github.com/jina-ai/jina/commit/81199a51061b6ecb68b34c0b2781ae11caa06e70)] __-__ add GRPC metadata to Executors and Gateway deployments (#5221) (*felix-wang*)\n+ - [[```287d16a2```](https://github.com/jina-ai/jina/commit/287d16a27c39e3f258897158f2274f2c7cca4df9)] __-__ bump hubble-sdk v0.22.2, show local location of Executors in Hub (#5282) (*zhangkai*)\n+ - [[```6f852dac```](https://github.com/jina-ai/jina/commit/6f852dac58a94e68d365608ab42c7f50ca8274c8)] __-__ dump to StatefulSet in K8s when volumes are passed to Executor (#5265) (*Joan Fontanals*)\n+ - [[```71e42221```](https://github.com/jina-ai/jina/commit/71e422211fe10930d384f2bf679785d3c415f514)] __-__ record existing Prometheus metrics into OpenTelemetry Histograms (#5275) (*Girish Chandrashekar*)\n+ - [[```a8dce571```](https://github.com/jina-ai/jina/commit/a8dce571850da9e9f4e4c7a0306baa94dac5e2d7)] __-__ add default tracing interceptors to Head grpc connection pool (#5271) (*Girish Chandrashekar*)\n+ - [[```107631e9```](https://github.com/jina-ai/jina/commit/107631e955b21db8a4ddb3bee02130de3650d032)] __-__ __instrumentation__: add OpenTelemetry tracing and metrics with basic configurations (#5175) (*Girish Chandrashekar*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```573f6076```](https://github.com/jina-ai/jina/commit/573f60768049d7f0f26f2cca9b051307e83a20ef)] __-__ invalid input raise exception (#5141) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```d2797a5a```](https://github.com/jina-ai/jina/commit/d2797a5a58dda4dc769bf4b1b328fffb7c2defcb)] __-__ docs for OpenTelemetry instrumentation (#5291) (*Girish Chandrashekar*)\n+ - [[```41ea53e8```](https://github.com/jina-ai/jina/commit/41ea53e806cd67e96dcad9b42e09eb0032eb30d3)] __-__ add jina ai cloud restructure jcloud and hub (#5298) (*Han Xiao*)\n+ - [[```c1d9438d```](https://github.com/jina-ai/jina/commit/c1d9438dabad0992318735c4f4f8428f098098dd)] __-__ __jcloud__: standardize naming conventions (#5285) (*Alex Cureton-Griffiths*)\n+ - [[```8d1df1bd```](https://github.com/jina-ai/jina/commit/8d1df1bd57149e65911e2830eec117b029569d9c)] __-__ fix typo in realtime-streaming (#5288) (*Anthony Le*)\n+ - [[```9f7895f0```](https://github.com/jina-ai/jina/commit/9f7895f0024bbb2aa928a2ecf266aa5fce909dd6)] __-__ __flow-switch__: fix broken restructuredtext syntax (#5289) (*Alex Cureton-Griffiths*)\n+ - [[```baba97a1```](https://github.com/jina-ai/jina/commit/baba97a112b8667922c6c38d60b584e49530a1cf)] __-__ __compare-alternatives__: fix english (#5290) (*Alex Cureton-Griffiths*)\n+ - [[```62c5fe91```](https://github.com/jina-ai/jina/commit/62c5fe91e51e00d7f61257582b6e42348c9e39e4)] __-__ __how-to__: tidy up language (#5287) (*Alex Cureton-Griffiths*)\n+ - [[```43a1ebae```](https://github.com/jina-ai/jina/commit/43a1ebae18f9dd8db293a21a9fdb9c45530a8528)] __-__ __jcloud__: tidy up language (#5284) (*Alex Cureton-Griffiths*)\n+ - [[```9981d341```](https://github.com/jina-ai/jina/commit/9981d341e375c428af3b9a945e07f26659f7ed4c)] __-__ fix metrics naming (#5277) (*samsja*)\n+ - [[```bcf17c38```](https://github.com/jina-ai/jina/commit/bcf17c385a38b0dcaf9bc0eb283ce71d969f0f65)] __-__ __flow__: clean up (#5255) (*Alex Cureton-Griffiths*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```8cedfd33```](https://github.com/jina-ai/jina/commit/8cedfd3362d9e0bb19b875f90c00e3b6b0bdba66)] __-__ fix test coverage and pin pytest-cov version (#5297) (*AlaeddineAbdessalem*)\n+ - [[```a3892732```](https://github.com/jina-ai/jina/commit/a3892732ec0ba3bec705378feed5b7e8194adb91)] __-__ update github actions to avoid deprecation warnings (#5296) (*Joan Fontanals*)\n+ - [[```e7e94a4c```](https://github.com/jina-ai/jina/commit/e7e94a4c69d3c2fd11f49610165bc114d6ade3f7)] __-__ codecov ignore some extra large files (#5294) (*Joan Fontanals*)\n+ - [[```9d208783```](https://github.com/jina-ai/jina/commit/9d208783978ad450ac609a148461ca0d4cfea988)] __-__ setup python action bump version v4 (#5293) (*Joan Fontanals*)\n+ - [[```def2cc50```](https://github.com/jina-ai/jina/commit/def2cc50e1e90ba314ba730b32accaa821257cd6)] __-__ fix deprecation of github actions (#5292) (*Joan Fontanals*)\n+ - [[```78c47fec```](https://github.com/jina-ai/jina/commit/78c47fec7b9552aaa431ddb39f3bf1a2b66735db)] __-__ allow release from any branch (#5278) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```2caac49c```](https://github.com/jina-ai/jina/commit/2caac49c14ae1322b4470eac9a87e2afd79f3bf0)] __-__ __version__: bump release version to 3.11.0 (#5304) (*Girish Chandrashekar*)\n+ - [[```f5a362f0```](https://github.com/jina-ai/jina/commit/f5a362f0ffc5070c104c840ab7833689d39b7bdb)] __-__ add pragma no cover to TYPE_CHECKING branch (#5299) (*Joan Fontanals*)\n+ - [[```e071381c```](https://github.com/jina-ai/jina/commit/e071381cfa958f8d31f7078fecb144c0c99a5130)] __-__ remove unused class (#5295) (*Joan Fontanals*)\n+ - [[```6cb9bcd7```](https://github.com/jina-ai/jina/commit/6cb9bcd7615419d80f535af2065b0038b84c5a4f)] __-__ bump hubble sdk (#5279) (*Andrei Ungureanu*)\n+ - [[```5d2d8f1d```](https://github.com/jina-ai/jina/commit/5d2d8f1d501e281579474c4e2d6288897ff95b2f)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```d8c15436```](https://github.com/jina-ai/jina/commit/d8c15436cd1b96322118f4576b7c1be25f453361)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```0b1f2bf6```](https://github.com/jina-ai/jina/commit/0b1f2bf62e2cf8c35578ed070ce3dd6a92b4239f)] __-__ __version__: the next version will be 3.10.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.11.0'\n+__version__ = '3.11.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.11.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.10.2'\n+__version__ = '3.11.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n@@ -106,7 +106,7 @@ __jina_env__ = (\n     'JINA_OPTOUT_TELEMETRY',\n     'JINA_K8S_ACCESS_MODES',\n     'JINA_K8S_STORAGE_CLASS_NAME',\n-    'JINA_K8S_STORAGE_CAPACITY'\n+    'JINA_K8S_STORAGE_CAPACITY',\n )\n \n __default_host__ = _os.environ.get(\n\n\n###\n\n", "completion": "chore(version): bump release version to 3.11.0 (#<issue-num>)"}
{"prompt": " file path A: jina/clients/__init__.py | file path B: jina/clients/__init__.py\n\n@@ -8,7 +8,7 @@ __all__ = ['Client']\n \n from jina.enums import GatewayProtocolType\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING:  # pragma: no cover\n     from jina.clients.grpc import AsyncGRPCClient, GRPCClient\n     from jina.clients.http import AsyncHTTPClient, HTTPClient\n     from jina.clients.websocket import AsyncWebSocketClient, WebSocketClient\n\n---\n file path A: jina/clients/base/__init__.py | file path B: jina/clients/base/__init__.py\n\n@@ -11,7 +11,7 @@ from jina.helper import T, parse_client, send_telemetry_event, typename\n from jina.logging.logger import JinaLogger\n from jina.logging.predefined import default_logger\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.clients.request import GeneratorSourceType\n     from jina.types.request import Request, Response\n \n\n---\n file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -11,7 +11,7 @@ from jina.logging.profile import ProgressBar\n from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.networking import GrpcConnectionPool\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.clients.base import CallbackFnType, InputType\n \n \n\n---\n file path A: jina/clients/base/helper.py | file path B: jina/clients/base/helper.py\n\n@@ -11,7 +11,7 @@ from jina.types.request import Request\n from jina.types.request.data import DataRequest\n from jina.types.request.status import StatusMessage\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from opentelemetry import trace\n \n     from jina.logging.logger import JinaLogger\n\n---\n file path A: jina/clients/base/http.py | file path B: jina/clients/base/http.py\n\n@@ -14,7 +14,7 @@ from jina.serve.stream import RequestStreamer\n from jina.types.request import Request\n from jina.types.request.data import DataRequest\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.clients.base import CallbackFnType, InputType\n \n \n\n---\n file path A: jina/clients/base/websocket.py | file path B: jina/clients/base/websocket.py\n\n@@ -14,7 +14,7 @@ from jina.logging.profile import ProgressBar\n from jina.proto import jina_pb2\n from jina.serve.stream import RequestStreamer\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.clients.base import CallbackFnType, InputType\n     from jina.types.request import Request\n \n\n---\n file path A: jina/clients/mixin.py | file path B: jina/clients/mixin.py\n\n@@ -6,7 +6,7 @@ from typing import TYPE_CHECKING, AsyncGenerator, Dict, List, Optional, Union\n from jina.helper import deprecate_by, get_or_reuse_loop, run_async\n from jina.importer import ImportExtensions\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from docarray import DocumentArray\n \n     from jina.clients.base import CallbackFnType, InputType\n\n---\n file path A: jina/clients/request/__init__.py | file path B: jina/clients/request/__init__.py\n\n@@ -16,7 +16,7 @@ from jina.enums import DataInputType\n from jina.helper import batch_iterator\n from jina.logging.predefined import default_logger\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina import Document\n     from docarray.document import DocumentSourceType\n     from docarray.document.mixins.content import DocumentContentType\n\n---\n file path A: jina/clients/request/asyncio.py | file path B: jina/clients/request/asyncio.py\n\n@@ -8,7 +8,7 @@ from jina.importer import ImportExtensions\n from jina.logging.predefined import default_logger\n from jina.types.request import Request\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.clients.request import GeneratorSourceType\n \n \n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1456,7 +1456,7 @@ def dunder_get(_dict: Any, key: str) -> Any:\n     return dunder_get(result, part2) if part2 else result\n \n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from fastapi import FastAPI\n \n \n\n---\n file path A: jina/jaml/parsers/base.py | file path B: jina/jaml/parsers/base.py\n\n@@ -3,7 +3,7 @@ from abc import ABC\n from functools import reduce\n from typing import TYPE_CHECKING, Any, Dict, Optional, Set, Type, Union\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.orchestrate.flow.base import Flow\n     from jina.serve.executors import BaseExecutor\n \n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -87,7 +87,7 @@ class FlowType(type(ExitStack), type(JAMLCompatible)):\n \n _regex_port = r'(.*?):([0-9]{1,4}|[1-5][0-9]{4}|6[0-4][0-9]{3}|65[0-4][0-9]{2}|655[0-2][0-9]|6553[0-5])$'\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING:  # pragma: no cover\n     from jina.clients.base import BaseClient\n     from jina.orchestrate.flow.asyncio import AsyncFlow\n     from jina.serve.executors import BaseExecutor\n\n---\n file path A: jina/orchestrate/flow/builder.py | file path B: jina/orchestrate/flow/builder.py\n\n@@ -4,7 +4,7 @@ from typing import TYPE_CHECKING, List\n from jina.excepts import FlowBuildLevelError\n \n # noinspection PyUnreachableCode\n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.enums import FlowBuildLevel\n     from jina.orchestrate.flow.base import Flow\n \n\n---\n file path A: jina/orchestrate/pods/container.py | file path B: jina/orchestrate/pods/container.py\n\n@@ -24,7 +24,7 @@ from jina.orchestrate.pods.container_helper import (\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n from jina.serve.runtimes.gateway import GatewayRuntime\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from docker.client import DockerClient\n \n \n\n---\n file path A: jina/orchestrate/pods/container_helper.py | file path B: jina/orchestrate/pods/container_helper.py\n\n@@ -15,7 +15,7 @@ def get_docker_network(client) -> Optional[str]:\n     \"\"\"\n     import docker\n \n-    if TYPE_CHECKING:\n+    if TYPE_CHECKING: # pragma: no cover\n         from docker.models.containers import Container\n \n     container: 'Container' = None\n\n---\n file path A: jina/orchestrate/pods/factory.py | file path B: jina/orchestrate/pods/factory.py\n\n@@ -9,7 +9,7 @@ from jina.enums import PodRoleType\n from jina.orchestrate.pods import Pod\n from jina.orchestrate.pods.container import ContainerPod\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.orchestrate.pods import BasePod\n \n \n\n---\n file path A: jina/orchestrate/pods/helper.py | file path B: jina/orchestrate/pods/helper.py\n\n@@ -9,7 +9,7 @@ from hubble.executor.hubio import HubIO\n from jina.enums import GatewayProtocolType, PodRoleType\n from jina.parsers.helper import _set_gateway_uses\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from argparse import Namespace\n \n \n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -18,7 +18,7 @@ from jina.serve.executors.metas import get_executor_taboo\n from jina.serve.helper import store_init_kwargs, wrap_func\n from jina.serve.instrumentation import MetricsTimer\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from opentelemetry.context.context import Context\n \n __dry_run_endpoint__ = '_jina_dry_run_'\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -11,7 +11,7 @@ from jina.helper import convert_tuple_to_list, iscoroutinefunction\n from jina.importer import ImportExtensions\n from jina.serve.executors.metas import get_default_metas\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina import DocumentArray\n \n \n\n---\n file path A: jina/serve/gateway.py | file path B: jina/serve/gateway.py\n\n@@ -9,7 +9,7 @@ from jina.serve.streamer import GatewayStreamer\n \n __all__ = ['BaseGateway']\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from grpc.aio._interceptor import ClientInterceptor, ServerInterceptor\n     from opentelemetry import trace\n     from opentelemetry.instrumentation.grpc._client import (\n\n---\n file path A: jina/serve/instrumentation/__init__.py | file path B: jina/serve/instrumentation/__init__.py\n\n@@ -2,7 +2,7 @@ import functools\n from timeit import default_timer\n from typing import TYPE_CHECKING, Dict, Optional, Sequence\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from grpc.aio._interceptor import ClientInterceptor, ServerInterceptor\n     from opentelemetry.instrumentation.grpc._client import (\n         OpenTelemetryClientInterceptor,\n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -26,7 +26,7 @@ TLS_PROTOCOL_SCHEMES = ['grpcs', 'https', 'wss']\n \n from typing import TYPE_CHECKING\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from grpc.aio._interceptor import ClientInterceptor\n     from opentelemetry.instrumentation.grpc._client import (\n         OpenTelemetryClientInterceptor,\n\n---\n file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -17,7 +17,7 @@ from jina.serve.runtimes.base import BaseRuntime\n from jina.serve.runtimes.monitoring import MonitoringMixin\n from jina.types.request.data import DataRequest\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     import multiprocessing\n     import threading\n \n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -14,7 +14,7 @@ from jina.parsers.helper import _set_gateway_uses\n from jina.serve.gateway import BaseGateway\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     import multiprocessing\n     import threading\n \n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -10,7 +10,7 @@ from jina.helper import get_full_version\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from opentelemetry import trace\n \n     from jina.serve.streamer import GatewayStreamer\n\n---\n file path A: jina/serve/runtimes/gateway/http/models.py | file path B: jina/serve/runtimes/gateway/http/models.py\n\n@@ -10,7 +10,7 @@ from pydantic import BaseConfig, BaseModel, Field, create_model, root_validator\n \n from jina.proto.jina_pb2 import DataRequestProto, JinaInfoProto, RouteProto, StatusProto\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from google.protobuf.pyext.cpp_message import GeneratedProtocolMessageType\n \n PROTO_TO_PYDANTIC_MODELS = SimpleNamespace()\n\n---\n file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -14,7 +14,7 @@ from jina.serve.runtimes.gateway.graph.topology_graph import TopologyGraph\n from jina.serve.runtimes.helper import _is_param_for_specific_executor\n from jina.serve.runtimes.request_handlers.data_request_handler import DataRequestHandler\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from asyncio import Future\n \n     from opentelemetry.metrics import Meter\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/app.py | file path B: jina/serve/runtimes/gateway/websocket/app.py\n\n@@ -10,7 +10,7 @@ from jina.logging.logger import JinaLogger\n from jina.types.request.data import DataRequest\n from jina.types.request.status import StatusMessage\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from opentelemetry import trace\n \n     from jina.serve.streamer import GatewayStreamer\n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -8,7 +8,7 @@ from jina.importer import ImportExtensions\n from jina.serve.executors import BaseExecutor\n from jina.types.request.data import DataRequest\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     import argparse\n \n     from opentelemetry import metrics, trace\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -16,7 +16,7 @@ from jina.serve.runtimes.helper import _get_grpc_server_options\n from jina.serve.runtimes.request_handlers.data_request_handler import DataRequestHandler\n from jina.types.request.data import DataRequest\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from opentelemetry.propagate import Context\n \n \n\n---\n file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -18,7 +18,7 @@ __all__ = ['RequestStreamer']\n \n from jina.types.request.data import Response\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.types.request import Request\n \n \n\n---\n file path A: jina/serve/streamer.py | file path B: jina/serve/streamer.py\n\n@@ -9,7 +9,7 @@ from jina.serve.stream import RequestStreamer\n \n __all__ = ['GatewayStreamer']\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from grpc.aio._interceptor import ClientInterceptor\n     from opentelemetry.instrumentation.grpc._client import (\n         OpenTelemetryClientInterceptor,\n\n---\n file path A: jina/types/mixin.py | file path B: jina/types/mixin.py\n\n@@ -2,7 +2,7 @@ from typing import Dict\n \n from jina.helper import TYPE_CHECKING, T, deprecate_by, typename\n \n-if TYPE_CHECKING:\n+if TYPE_CHECKING: # pragma: no cover\n     from jina.proto import jina_pb2\n \n \n\n\n###\n\n", "completion": "chore: add pragma no cover to TYPE_CHECKING branch (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -65,7 +65,7 @@ Pillow:                     test\n pytest:                     test\n pytest-timeout:             test\n pytest-mock:                test\n-pytest-cov:                 test\n+pytest-cov==3.0.0:          test\n coverage==6.2:              test\n pytest-repeat:              test\n pytest-asyncio:             test\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -65,7 +65,7 @@ Pillow:                     test\n pytest:                     test\n pytest-timeout:             test\n pytest-mock:                test\n-pytest-cov:                 test\n+pytest-cov==3.0.0:          test\n coverage==6.2:              test\n pytest-repeat:              test\n pytest-asyncio:             test\n\n\n###\n\n", "completion": "ci: fix test coverage and pin pytest-cov version (#<issue-num>)"}
{"prompt": " file path A: jina/jaml/parsers/__init__.py | file path B: jina/jaml/parsers/__init__.py\n\n@@ -23,7 +23,7 @@ def _get_all_parser(cls: Type['JAMLCompatible']):\n     elif issubclass(cls, BaseGateway):\n         return _get_gateway_parser()\n     else:\n-        return _get_default_parser()\n+        raise NotImplementedError(f'No parser exists for cls {cls.__name__}')\n \n \n def _get_flow_parser():\n@@ -44,12 +44,6 @@ def _get_gateway_parser():\n     return [GatewayLegacyParser], GatewayLegacyParser\n \n \n-def _get_default_parser():\n-    from jina.jaml.parsers.default.v1 import V1Parser\n-\n-    return [V1Parser], V1Parser\n-\n-\n def get_parser(\n     cls: Type['JAMLCompatible'], version: Optional[str]\n ) -> 'VersionedYAMLParser':\n\n---\n file path A: jina/jaml/parsers/default/__init__.py | file path B: jina/jaml/parsers/default/__init__.py\n\n\n---\n file path A: jina/jaml/parsers/default/v1.py | file path B: None\n\n@@ -1,51 +0,0 @@\n-from typing import Any, Dict, Optional, Type\n-\n-from jina.jaml import JAML, JAMLCompatible\n-from jina.jaml.parsers.base import VersionedYAMLParser\n-\n-\n-class V1Parser(VersionedYAMLParser):\n-    \"\"\"V1 default parser, used as the default parser for objects.\"\"\"\n-\n-    version = '1'  # the version number this parser designed for\n-\n-    def parse(\n-        self,\n-        cls: Type['JAMLCompatible'],\n-        data: Dict,\n-        runtime_args: Optional[Dict[str, Any]] = None,\n-    ) -> 'JAMLCompatible':\n-        \"\"\"\n-        :param cls: target class type to parse into, must be a :class:`JAMLCompatible` type\n-        :param data: flow yaml file loaded as python dict\n-        :param runtime_args: Optional runtime_args to be directly passed without being parsed into a yaml config\n-        :return: the YAML parser given the syntax version number\n-        \"\"\"\n-        expanded_data = JAML.expand_dict(data, None)\n-        if 'with' in data:\n-            obj = cls(**expanded_data.get('with', {}))\n-        else:\n-            obj = cls(**expanded_data)\n-        return obj\n-\n-    def dump(self, data: 'JAMLCompatible') -> Dict:\n-        \"\"\"\n-        :param data: versioned flow object\n-        :return: the dictionary given a versioned flow object\n-        \"\"\"\n-        a = V1Parser._dump_instance_to_yaml(data)\n-        r = {}\n-        if a:\n-            r['with'] = a\n-        return r\n-\n-    @staticmethod\n-    def _dump_instance_to_yaml(instance):\n-        import inspect\n-\n-        attributes = inspect.getmembers(instance, lambda a: not (inspect.isroutine(a)))\n-        return {\n-            a[0]: a[1]\n-            for a in attributes\n-            if not (a[0].startswith('__') and a[0].endswith('__'))\n-        }\n\n\n###\n\n", "completion": "chore: remove unused class (#<issue-num>)"}
{"prompt": " file path A: .github/codecov.yml | file path B: .github/codecov.yml\n\n@@ -3,6 +3,8 @@ codecov:\n   allow_coverage_offsets: true\n ignore:\n   - \"jina/resources\"\n+  - \"jina/serve/instrumentation/_aio_client.py\"\n+  - \"jina/serve/instrumentation/_aio_server.py\"\n coverage:\n   status:\n     project:\n\n\n###\n\n", "completion": "ci: codecov ignore some extra large files (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/autocommit.yml | file path B: .github/workflows/autocommit.yml\n\n@@ -21,7 +21,7 @@ jobs:\n       - run: |\n           git config --local user.email \"dev-bot@jina.ai\"\n           git config --local user.name \"Jina Dev Bot\"\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Generate TOC\n\n---\n file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -36,7 +36,7 @@ jobs:\n           repository: jina-ai/api\n           path: schema\n           token: ${{ secrets.JINA_DEV_BOT }}\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - uses: actions/setup-node@v2\n@@ -120,7 +120,7 @@ jobs:\n #        with:\n #          submodules: true\n       - name: Set up Python ${{ matrix.python-version }}\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: ${{ matrix.python-version }}\n       - name: Prepare environment\n@@ -173,7 +173,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n@@ -236,7 +236,7 @@ jobs:\n       #          access_token: ${{ github.token }}\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Test hubapp with hubpods\n@@ -253,7 +253,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n@@ -294,7 +294,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n@@ -336,7 +336,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -24,7 +24,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Lint with flake8\n@@ -59,7 +59,7 @@ jobs:\n         with:\n           fetch-depth: 0\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - id: file_changes\n@@ -78,7 +78,7 @@ jobs:\n           token: ${{ secrets.GITHUB_TOKEN }}\n           ref: ${{ github.event.pull_request.head.sha }}\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         if: ${{ !github.event.pull_request.head.repo.fork }}\n         with:\n           python-version: 3.7\n@@ -158,7 +158,7 @@ jobs:\n #          access_token: ${{ github.token }}\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Test hubapp with hubpods\n@@ -175,7 +175,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n@@ -216,7 +216,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n@@ -258,7 +258,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n@@ -315,7 +315,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python ${{ matrix.python-version }}\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: ${{ matrix.python-version }}\n       - name: Prepare environment\n@@ -364,7 +364,7 @@ jobs:\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Prepare enviroment\n\n---\n file path A: .github/workflows/force-docs-build.yml | file path B: .github/workflows/force-docs-build.yml\n\n@@ -27,7 +27,7 @@ jobs:\n       - uses: actions/checkout@v2\n         with:\n           fetch-depth: 0\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - name: Build doc and push to gh-pages\n\n---\n file path A: .github/workflows/force-release.yml | file path B: .github/workflows/force-release.yml\n\n@@ -37,7 +37,7 @@ jobs:\n           token: ${{ secrets.JINA_DEV_BOT }}\n           fetch-depth: 100  # means max contribute history is limited to 100 lines\n #          submodules: true\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n         # https://github.com/actions/checkout#fetch-all-tags\n\n---\n file path A: .github/workflows/label-pr.yml | file path B: .github/workflows/label-pr.yml\n\n@@ -36,7 +36,7 @@ jobs:\n         with:\n           repository: jina-ai/jina\n           ref: ${{ env.BRANCH_NAME }}\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - uses: actions/setup-node@v2\n\n---\n file path A: .github/workflows/nightly-tests.yml | file path B: .github/workflows/nightly-tests.yml\n\n@@ -35,7 +35,7 @@ jobs:\n         with:\n           ref: ${{ github.event.inputs.branch }}\n       - name: Set up Python ${{ matrix.python-version }}\n-        uses: actions/setup-python@v2\n+        uses: actions/setup-python@v4\n         with:\n           python-version: ${{ matrix.python-version }}\n           architecture: x64\n\n---\n file path A: .github/workflows/release.yml | file path B: .github/workflows/release.yml\n\n@@ -19,7 +19,7 @@ jobs:\n           token: ${{ secrets.JINA_DEV_BOT }}\n           fetch-depth: 100  # means max contribute history is limited to 100 lines\n #          submodules: true\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n         # https://github.com/actions/checkout#fetch-all-tags\n\n---\n file path A: .github/workflows/tag.yml | file path B: .github/workflows/tag.yml\n\n@@ -20,7 +20,7 @@ jobs:\n           repository: jina-ai/api\n           path: schema\n           token: ${{ secrets.JINA_DEV_BOT }}\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - uses: actions/setup-node@v2\n@@ -90,7 +90,7 @@ jobs:\n         uses: actions/checkout@v2\n         with:\n           ref: 'master'\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - run: |\n\n---\n file path A: .github/workflows/update-announcement.yml | file path B: .github/workflows/update-announcement.yml\n\n@@ -30,7 +30,7 @@ jobs:\n         with:\n           token: ${{ secrets.JINA_DEV_BOT }}\n           fetch-depth: 0\n-      - uses: actions/setup-python@v2\n+      - uses: actions/setup-python@v4\n         with:\n           python-version: 3.7\n       - run: |\n\n\n###\n\n", "completion": "ci: setup python action bump version v4 (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -102,7 +102,8 @@ jobs:\n       - id: set-matrix\n         run: |\n           sudo apt-get install jq\n-          echo \"::set-output name=matrix::$(bash scripts/get-all-test-paths.sh)\"\n+          export value=$(bash scripts/get-all-test-paths.sh)\n+          echo \"matrix=$value\" >> $GITHUB_OUTPUT\n     outputs:\n       matrix: ${{ steps.set-matrix.outputs.matrix }}\n \n@@ -137,7 +138,7 @@ jobs:\n         run: |\n           pytest --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml --timeout=600 -v -s --ignore-glob='tests/integration/hub_usage/dummyhub*' ${{ matrix.test-path }}\n           echo \"flag it as jina for codeoverage\"\n-          echo \"::set-output name=codecov_flag::jina\"\n+          echo \"codecov_flag=jina\" >> $GITHUB_OUTPUT\n         timeout-minutes: 30\n         env:\n           JINAHUB_USERNAME: ${{ secrets.JINAHUB_USERNAME }}\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -96,7 +96,7 @@ jobs:\n           else\n             git add -u\n             git commit -m \"style: fix overload and cli autocomplete\"\n-            echo '::set-output name=IS_CHANGED::YES'\n+            echo \"IS_CHANGED=YES\" >> $GITHUB_OUTPUT\n           fi\n       - name: Push changes to head ref\n         uses: ad-m/github-push-action@v0.6.0\n@@ -297,7 +297,8 @@ jobs:\n       - id: set-matrix\n         run: |\n           sudo apt-get install jq\n-          echo \"::set-output name=matrix::$(bash scripts/get-all-test-paths.sh)\"\n+          export value=$(bash scripts/get-all-test-paths.sh)\n+          echo \"matrix=$value\" >> $GITHUB_OUTPUT\n     outputs:\n       matrix: ${{ steps.set-matrix.outputs.matrix }}\n \n@@ -331,7 +332,7 @@ jobs:\n           pytest --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml --timeout=600 -v -s --ignore-glob='tests/integration/hub_usage/dummyhub*' ${{ matrix.test-path }}\n \n           echo \"flag it as jina for codeoverage\"\n-          echo \"::set-output name=codecov_flag::jina\"\n+          echo \"codecov_flag=jina\" >> $GITHUB_OUTPUT\n         timeout-minutes: 30\n         env:\n           JINA_AUTH_TOKEN: \"${{ secrets.JINA_AUTH_TOKEN }}\"\n\n---\n file path A: .github/workflows/label-pr.yml | file path B: .github/workflows/label-pr.yml\n\n@@ -21,7 +21,7 @@ jobs:\n           repo-token: \"${{ secrets.GITHUB_TOKEN }}\"\n       - id: docs_updated\n         if: contains( github.event.pull_request.labels.*.name, 'area/docs')\n-        run: echo '::set-output name=docs::true'\n+        run: echo \"docs=true\" >> $GITHUB_OUTPUT\n     outputs:\n       docs: ${{ steps.docs_updated.outputs.docs }}\n \n\n---\n file path A: .github/workflows/nightly-tests.yml | file path B: .github/workflows/nightly-tests.yml\n\n@@ -17,7 +17,8 @@ jobs:\n       - id: set-matrix\n         run: |\n           sudo apt-get install jq\n-          echo \"::set-output name=windows::$(bash scripts/get-all-test-paths.sh windows)\"\n+          export value=$(bash scripts/get-all-test-paths.sh windows)\n+          echo \"windows=$value\" >> $GITHUB_OUTPUT\n     outputs:\n       windows: ${{ steps.set-matrix.outputs.windows }}\n \n\n\n###\n\n", "completion": "ci: fix deprecation of github actions (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -18,26 +18,25 @@ yaml-spec\n :width: 0 %\n ```\n \n-After building a Jina project, the next step is to deploy and host it on the cloud. JCloud simplifies deploying and hosting your Jina projects on Jina Cloud. It provides a simple CLI with five commands to manage the life cycle of your Jina projects.\n+After building a Jina project, the next step is to deploy and host it on the cloud. JCloud is Jina's reliable, scalable and production-ready cloud-hosting solution that manages your project lifecycle without surprises or hidden development costs.\n \n ```{tip}\n-At present, Jina Cloud hosts all your Jina projects and offers computational/storage resources **for free**!\n+At present, JCloud hosts all your Jina projects and offers computational/storage resources **for free**!\n ```\n \n ## Basics\n \n-Jina Cloud provides a CLI that you can use via `jina cloud` from the terminal (or `jcloud` or simply `jc` for minimalists.)\n-\n+JCloud provides a CLI that you can use via `jina cloud` from the terminal (or `jcloud` or simply `jc` for minimalists.)\n \n ````{hint}\n-You can also install just the Jina Cloud CLI without installing the Jina package.\n+You can also install just the JCloud CLI without installing the Jina package.\n \n ```bash\n pip install jcloud\n jc -h\n ```\n \n-If you installed JCloud individually, all of its commands fall under the `jc` or `jcloud` executable.\n+If you installed the JCloud CLI individually, all of its commands fall under the `jc` or `jcloud` executable.\n \n \n In case the command `jc` is already occupied by another tool, use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n@@ -54,7 +53,7 @@ jc login\n \n You can use a Google or GitHub account to register and log in. For all the next steps, logging in is mandatory.\n \n-If you have no access to a web browser in your integration environment, you can set the Environment Variable `JINA_AUTH_TOKEN` using an authentication token before working with JCloud. Authentication tokens can be generated by user login or Personal Access Token (PAT) creation. Please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` already includes `jina-auth`.)\n+If you have no access to a web browser in your integration environment, you can set the environment variable `JINA_AUTH_TOKEN` using an authentication token before working with JCloud. Authentication tokens can be generated by user login or Personal Access Token (PAT) creation. Please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` already includes `jina-auth`.)\n \n ### Deploy\n \n\n\n###\n\n", "completion": "docs(jcloud): standardize naming conventions (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/hub/use-hub-executor.md | file path B: docs/fundamentals/executor/hub/use-hub-executor.md\n\n@@ -151,5 +151,16 @@ jina hub pull jinahub+docker://DummyExecutor/v1.0.0\n jina hub pull jinahub://<UUID>[:<SECRET>][/<TAG>]\n ```\n \n+### List locations of local Executors\n \n-The source code of the Executor will be stored at `~/.jina/hub-packages`.\n+```bash\n+jina hub list\n+```\n+\n+<script id=\"asciicast-z81wi9gwVm7gYjfl5ocBD1RH3\" src=\"https://asciinema.org/a/z81wi9gwVm7gYjfl5ocBD1RH3.js\" async></script>\n+\n+```{tip}\n+To list all the Executors that are in source-code format (i.e. pulled via `jinahub://`), use the command `jina hub list`.\n+\n+To list all the Executors that are in Docker format, use the command `docker images`.\n+```\n\\ No newline at end of file\n\n---\n file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.20.2:    core\n+jina-hubble-sdk==0.22.2:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk==0.20.2:    core\n+jina-hubble-sdk==0.22.2:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n\n###\n\n", "completion": "feat: bump hubble-sdk v0.22.2, show local location of Executors in Hub (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.19.0:    core\n+jina-hubble-sdk==0.20.2:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.4:           core\n-jina-hubble-sdk>=0.19.0:    core\n+jina-hubble-sdk==0.20.2:    core\n jcloud>=0.0.35:             core\n opentelemetry-api>=1.12.0:  core\n opentelemetry-instrumentation-grpc>=0.33b0:  core \n\n\n###\n\n", "completion": "chore: bump hubble sdk (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/realtime-streaming.md | file path B: docs/how-to/realtime-streaming.md\n\n@@ -81,7 +81,7 @@ class VideoChatExecutor(Executor):\n                 d.tensor = np.concatenate(list(self.last_user_frames.values()), axis=0)\n ```\n \n-Save it as `executor.py` and create `executor.yml` with the following content:\n+Save it as `executor.py` and create `config.yml` with the following content:\n \n ```yaml\n jtype: VideoChatExecutor\n\n\n###\n\n", "completion": "docs: fix typo in realtime-streaming (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/flow-switch.md | file path B: docs/how-to/flow-switch.md\n\n@@ -1,7 +1,7 @@\n (flow-switch)=\n # Conditional route request inside a Flow\n \n-This tutorial gives a deeper insight into the {class}`~jina.Flow 's {ref}`filter condition feature<flow-filter>`.\n+This tutorial gives a deeper insight into the {class}`~jina.Flow`'s {ref}`filter condition feature<flow-filter>`.\n \n In a nutshell, this lets any {class}`~jina.Executor` filter Documents that fulfill a specified `condition`, letting you build *selection control* into your Flow.\n \n\n\n###\n\n", "completion": "docs(flow-switch): fix broken restructuredtext syntax (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-docker-build.yml | file path B: .github/workflows/force-docker-build.yml\n\n@@ -61,18 +61,24 @@ jobs:\n           if [ -n \"${PIP_TAG}\" ]; then\n               PIP_TAG=-${PIP_TAG}\n           fi\n+          \n+          LAST_VER_TAG=$(git tag -l | sort -V | tail -n1)\n+          PRE_VERSION=-dev$(git rev-list $LAST_VER_TAG..HEAD --count)\n \n           if [[ \"${{ github.event.inputs.triggered_by }}\" == \"CD\" ]]; then\n \n             if [[ \"${{ matrix.py_version }}\" == \"$DEFAULT_PY_VERSION\" ]]; then\n               echo \"TAG_ALIAS=\\\n                               jinaai/jina:master${PY_TAG}${PIP_TAG}, \\\n-                              jinaai/jina:master${PIP_TAG}\" \\\n+                              jinaai/jina:master${PIP_TAG} \\\n+                              jinaai/jina:${JINA_VERSION}${PRE_VERSION}${PIP_TAG} \\\n+                              jinaai/jina:${JINA_VERSION}${PRE_VERSION}${PY_TAG}${PIP_TAG}\" \\\n                               >> $GITHUB_ENV\n             else\n               # on every CD\n               echo \"TAG_ALIAS=\\\n-                              jinaai/jina:master${PY_TAG}${PIP_TAG}\" \\\n+                              jinaai/jina:master${PY_TAG}${PIP_TAG} \\\n+                              jinaai/jina:${JINA_VERSION}${PRE_VERSION}${PY_TAG}${PIP_TAG}\" \\\n                               >> $GITHUB_ENV\n             fi\n \n\n---\n file path A: .github/workflows/force-release.yml | file path B: .github/workflows/force-release.yml\n\n@@ -57,4 +57,4 @@ jobs:\n         with:\n           github_token: ${{ secrets.JINA_DEV_BOT }}\n           tags: true\n-          branch: master\n+          branch: ${{ github.ref }}\n\n---\n file path A: scripts/release.sh | file path B: scripts/release.sh\n\n@@ -62,11 +62,6 @@ function make_release_note {\n \n BRANCH=$(git rev-parse --abbrev-ref HEAD)\n \n-if [[ \"$BRANCH\" != \"master\" ]]; then\n-  printf \"You are not at master branch, exit\\n\";\n-  exit 1;\n-fi\n-\n LAST_UPDATE=`git show --no-notes --format=format:\"%H\" $BRANCH | head -n 1`\n LAST_COMMIT=`git show --no-notes --format=format:\"%H\" origin/$BRANCH | head -n 1`\n \n\n\n###\n\n", "completion": "ci: allow release from any branch (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -18,62 +18,59 @@ yaml-spec\n :width: 0 %\n ```\n \n-\n-After building a Jina project, the next step is to deploy and host it on Cloud. JCloud simplifies deploying and hosting your Jina projects on Jina Cloud. It provides a simple CLI with five commands to manage the lifecycle of your Jina projects.\n+After building a Jina project, the next step is to deploy and host it on the cloud. JCloud simplifies deploying and hosting your Jina projects on Jina Cloud. It provides a simple CLI with five commands to manage the life cycle of your Jina projects.\n \n ```{tip}\n-At this point, Jina Cloud hosts all your Jina projects and offers computational/storage resources **for free**!\n+At present, Jina Cloud hosts all your Jina projects and offers computational/storage resources **for free**!\n ```\n \n-## Basic\n+## Basics\n \n-Jina Cloud provides a CLI and you can use it simply via `jina cloud` from the terminal, or `jcloud` or simply `jc` for minimalists. \n+Jina Cloud provides a CLI that you can use via `jina cloud` from the terminal (or `jcloud` or simply `jc` for minimalists.)\n \n \n ````{hint}\n-You can also only install Jina Cloud CLI without install `jina` package.\n+You can also install just the Jina Cloud CLI without installing the Jina package.\n \n ```bash\n pip install jcloud\n jc -h\n ```\n \n-If you installed it individually, all of its commands come under the `jc` or `jcloud` executable.\n+If you installed JCloud individually, all of its commands fall under the `jc` or `jcloud` executable.\n \n \n-In case `jc` is already occupied by another tool, please use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n+In case the command `jc` is already occupied by another tool, use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n ````\n \n-For the rest of this section, we will be using `jc` or `jcloud`. But again they are interchangable to `jina cloud`.\n+For the rest of this section, we use `jc` or `jcloud`. But again they are interchangable with `jina cloud`.\n \n \n-### Login\n+### Log in\n \n ```bash\n jc login\n ```\n \n-You can use a Google/GitHub account to register and login. For all the next steps, logging in is mandatory.\n+You can use a Google or GitHub account to register and log in. For all the next steps, logging in is mandatory.\n \n-If you have no access to the web browser in your integration environment, you can set the Environment Variable `JINA_AUTH_TOKEN` using auth token before working with JCloud. Auth token can be generated by user login or Personal Access Token (PAT) creation, please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` includes `jina-auth` already).\n+If you have no access to a web browser in your integration environment, you can set the Environment Variable `JINA_AUTH_TOKEN` using an authentication token before working with JCloud. Authentication tokens can be generated by user login or Personal Access Token (PAT) creation. Please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` already includes `jina-auth`.)\n \n ### Deploy\n \n-In Jina's idiom, a project is a [Flow](https://docs.jina.ai/fundamentals/flow/), which represents an end-to-end task such as indexing, searching or recommending. In this README, we will use \"project\" and \"Flow\" interchangeably.\n+In Jina's idiom, a project is a [Flow](https://docs.jina.ai/fundamentals/flow/), which represents an end-to-end task such as indexing, searching or recommending. In this document, we use \"project\" and \"Flow\" interchangeably.\n \n ```{caution}\n-Flows have a maximal {ref}`lifetime<jcloud-lifetime>` after which they are automatically deleted.\n+Flows have a maximum {ref}`lifetime<jcloud-lifetime>` after which they are automatically deleted.\n ```\n \n A Flow can have two types of file structure: a single YAML file or a project folder.\n \n-#### A single YAML file\n-\n-A self-contained YAML file, consisting of all configs at the [Flow](https://docs.jina.ai/fundamentals/flow/)-level and [Executor](https://docs.jina.ai/fundamentals/executor/)-level.\n+#### Single YAML file\n \n-> All Executors' `uses` must follow the format `jinahub+docker://MyExecutor` (from [Jina Hub](https://hub.jina.ai)) to avoid any local file dependencies.\n+A self-contained YAML file, consisting of all configuration at the [Flow](https://docs.jina.ai/fundamentals/flow/)-level and [Executor](https://docs.jina.ai/fundamentals/executor/)-level.\n \n-e.g.-\n+> All Executors' `uses` must follow the format `jinahub+docker://MyExecutor` (from [Jina Hub](https://hub.jina.ai)) to avoid any local file dependencies:\n \n ```yaml\n # flow.yml\n@@ -83,14 +80,14 @@ executors:\n     uses: jinahub+docker://Sentencizer\n ```\n \n-To deploy,\n+To deploy:\n \n ```bash\n jc deploy flow.yml\n ```\n \n ````{tip}\n-Testing locally before deploying is recommended. You can use \n+We recommend testing locally before deployment:\n \n ```bash\n jina flow --uses flow.yml\n@@ -98,10 +95,10 @@ jina flow --uses flow.yml\n ````\n \n \n-#### A project folder\n+#### Project folder\n \n ````{tip}\n-The best practice of creating a JCloud project is to use\n+The best practice of creating a JCloud project is to use:\n \n ```\n jc new\n@@ -110,7 +107,7 @@ jc new\n This ensures the correct project structure accepted by JCloud.\n ````\n \n-Just like a regular Python project, you can have sub-folders of Executor implementations; and a `flow.yml` on the top-level to connect all Executors together.\n+Just like a regular Python project, you can have sub-folders of Executor implementations and a `flow.yml` on the top-level to connect all Executors together.\n \n You can create an example local project using `jc new hello`. The default structure looks like:\n \n@@ -124,20 +121,19 @@ hello/\n \u2514\u2500\u2500 flow.yml\n ```\n \n-where,\n+Where:\n \n - `hello/` is your top-level project folder.\n-- `executor1` directory has all Executor related code/config. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/executor-files/). Multiple such Executor directories can be created.\n+- `executor1` directory has all Executor related code/configuration. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/executor-files/). Multiple Executor directories can be created.\n - `flow.yml` Your Flow YAML.\n - `.env` All environment variables used during deployment.\n \n-To deploy,\n+To deploy:\n \n ```bash\n jc deploy hello\n ```\n \n-\n The Flow is successfully deployed when you see:\n \n ```{figure} deploy.png\n@@ -146,7 +142,7 @@ The Flow is successfully deployed when you see:\n \n You will get a Flow ID, say `173503c192`. This ID is required to manage, view logs and remove the Flow.\n \n-As this Flow is deployed with default gRPC gateway (feel free to change it to `http` or `websocket`), you can use `jina.Client` to access it:\n+As this Flow is deployed with the default gRPC gateway (feel free to change it to `http` or `websocket`), you can use `jina.Client` to access it:\n \n ```python\n from jina import Client, Document\n@@ -155,11 +151,9 @@ c = Client(host='https://173503c192.wolf.jina.ai')\n print(c.post('/', Document(text='hello')))\n ```\n \n-\n-\n ### View logs\n \n-To watch the logs in realtime:\n+To watch the logs in real time:\n \n ```bash\n jc logs 173503c192\n@@ -173,7 +167,7 @@ jc logs 173503c192 --executor sentencizer\n \n ### Remove Flows\n \n-You can either remove a single Flow, multiple selected Flows or even all Flows by passing different kind of identifiers.\n+You can remove a single Flow, multiple Flows or even all Flows by passing different identifiers.\n \n To remove a single Flow:\n \n@@ -181,7 +175,7 @@ To remove a single Flow:\n jc remove 173503c192\n ```\n \n-To remove multiple selected Flows:\n+To remove multiple Flows:\n \n ```bash\n jc remove 173503c192 887f6313e5 ddb8a2c4ef\n@@ -193,8 +187,7 @@ To remove all Flows:\n jc remove all\n ```\n \n-By default, removing multiple selected / all Flows would be in interactive mode where confirmation will be sent prior to\n-the deletion, to make it non-interactive to better suit your use case, set below environment variable before running the command:\n+By default, removing multiple or all Flows is an interactive process where you must give confirmation before each Flow is deleted. To make it non-interactive, set the below environment variable before running the command:\n \n ```bash\n export JCLOUD_NO_INTERACTIVE=1\n@@ -213,9 +206,10 @@ jc status 15937a10bd\n ```\n \n ### Monitoring\n-Basic monitoring is provided to the Flows deployed on JCloud.\n \n-To access the [Grafana](https://grafana.com/) powered dashboard, get {ref}`the status of the Flow<jcloud-flow-status>` first, at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n+Basic monitoring is provided to Flows deployed on JCloud.\n+\n+To access the [Grafana](https://grafana.com/)-powered dashboard, first get {ref}`the status of the Flow<jcloud-flow-status>`. The `dashboards` link is displayed at the bottom of the pane. Visit the URL to find basic metrics like 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n \n ```{figure} monitoring.png\n :width: 70%\n@@ -223,18 +217,16 @@ To access the [Grafana](https://grafana.com/) powered dashboard, get {ref}`the s\n \n ### List Flows\n \n-To list all the Flows you have:\n+To list all of your \"ALIVE\" Flows:\n+\n ```bash\n jc list\n ```\n \n-You can see the ALIVE Flows deployed by you.\n-\n ```{figure} list.png\n :width: 70%\n ```\n \n-\n You can also filter your Flows by passing a status:\n \n ```bash\n@@ -246,7 +238,7 @@ jc list --status FAILED\n :width: 70%\n ```\n \n-Or see all the flows:\n+Or see all Flows:\n \n ```bash\n jc list --status ALL\n@@ -256,19 +248,17 @@ jc list --status ALL\n :width: 70%\n ```\n \n-\n-\n ### Pass environment variables\n \n-#### A single YAML\n+#### Single YAML\n \n ```bash\n jc deploy flow.yml --env-file flow.env\n ```\n \n-#### A project folder\n+#### Project folder\n \n-- You can include your environment variables in the `.env` file in the local project and JCloud will take care of managing them.\n+- You can include your environment variables in the `.env` file in the local project and JCloud manages them.\n - You can optionally pass a `custom.env`.\n   ```bash\n   jc deploy ./hello --env-file ./hello/custom.env\n@@ -276,30 +266,30 @@ jc deploy flow.yml --env-file flow.env\n   \n ## Troubleshooting\n \n-If your deployment failed, please enable verbose logging and redeploy it. You can add `--loglevel DEBUG` _before_ each CLI subcommand, e.g.\n+If your deployment failed, enable verbose logging and redeploy it. You can add `--loglevel DEBUG` _before_ each CLI subcommand:\n \n ```bash\n jc --loglevel DEBUG deploy flow.yml\n ```\n \n-Alternatively, you can configure it by using environment variable `JCLOUD_LOGLEVEL`, e.g.\n+Alternatively, you can configure it by using environment variable `JCLOUD_LOGLEVEL`:\n \n ```bash\n JCLOUD_LOGLEVEL=DEBUG jc deploy flow.yml\n ```\n \n-If you don't see any obvious errors, please raise an issue in [JCloud](https://github.com/jina-ai/jcloud/issues/new/choose)\n+If you don't see any obvious errors, please raise an issue in [the JCloud repository](https://github.com/jina-ai/jcloud/issues/new/choose).\n \n ## Restrictions\n \n-JCloud scales according to your need. You can demand different resources (GPU / RAM / CPU / Storage / instance-capacity) your Flows & Executors need. We have the following restrictions on its usage. If you have specific resource requirements, please contact us [on Slack](https://slack.jina.ai) or raise a [Github issue](https://github.com/jina-ai/jcloud/issues/new/choose).\n+JCloud scales according to your needs. You can demand different resources (GPU/RAM/CPU/storage/instance-capacity) based on the needs of your Flows and Executors. If you have specific resource requirements, please contact us [on Slack](https://jina.ai/slack) or raise a [GitHub issue](https://github.com/jina-ai/jcloud/issues/new/choose).\n \n \n ```{admonition} Restrictions\n   \n-- Deployments are only supported in `us-east` region.\n-- Each Executor is allowed a maximum of 4G RAM, 2 CPU cores & 10GB of block storage.\n-- 3 Flows can be deployed at a time, out of which there can be 1 Flow using GPU.\n-- A maximum of 2 GPUs are allowed per Flow.\n-- Flows with Executors using GPU are removed after 12hrs, whereas other Flows are removed after 72hrs.\n+- Deployments are only supported in the `us-east` region.\n+- Each Executor is allocated a maximum of 4GB RAM, 2 CPU cores & 10GB of block storage.\n+- Three Flows can be deployed at a time, out of which one Flow can use a GPU.\n+- A maximum of two GPUs are allocated per Flow.\n+- Flows with Executors using GPU are removed after 12 hours, whereas other Flows are removed after 72 hours.\n ```\n\n\n###\n\n", "completion": "docs(jcloud): tidy up language (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/monitoring-flow.md | file path B: docs/fundamentals/flow/monitoring-flow.md\n\n@@ -154,17 +154,17 @@ Because not all Pods have the same role, they expose different kinds of metrics:\n \n ### Gateway Pods\n \n-| Metrics name                        | Metrics type                                                           | Description                                                                                                        |\n-|-------------------------------------|------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------|\n-| `jina_receiving_request_seconds`    | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures time elapsed between receiving a request from the client and sending back the response.               |\n+| Metrics name                        | Metrics type                                                           | Description                                                                                                     |\n+|-------------------------------------|------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|\n+| `jina_receiving_request_seconds`    | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures time elapsed between receiving a request from the client and sending back the response.                |\n | `jina_sending_request_seconds`      | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures time elapsed between sending a downstream request to an Executor/Head and receiving the response back. |\n-| `jina_number_of_pending_requests`   | [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge)       | Counts the number of pending requests.                                                                              |\n-| `jina_successful_requests_total`    | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter)   | Counts the number of successful requests returned by the Gateway.                                                   |\n-| `jina_failed_requests_total`        | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter)   | Counts the number of failed requests returned by the Gateway.                                                       |\n-| `jina_sent_request_bytes`           | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size in bytes of the request sent by the Gateway to the Executor or the Head.                    |\n-| `jina_received_response_bytes`         | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size in bytes of the request returned by the Executor.                                           |\n-| `jina_received_request_bytes`           | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size of the request in bytes received at the Gateway level.                                            |\n-| `jina_sent_response_bytes`  | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size in bytes of the response returned from the Gateway to the Client.                                    |\n+| `jina_number_of_pending_requests`   | [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge)       | Counts the number of pending requests.                                                                          |\n+| `jina_successful_requests`    | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter)   | Counts the number of successful requests returned by the Gateway.                                               |\n+| `jina_failed_requests`        | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter)   | Counts the number of failed requests returned by the Gateway.                                                   |\n+| `jina_sent_request_bytes`           | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size in bytes of the request sent by the Gateway to the Executor or to the Head.                   |\n+| `jina_received_response_bytes`         | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size in bytes of the request returned by the Executor.                                             |\n+| `jina_received_request_bytes`           | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size of the request in bytes received at the Gateway level.                                        |\n+| `jina_sent_response_bytes`  | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)   | Measures the size in bytes of the response returned from the Gateway to the Client.                             |\n \n ```{seealso} \n You can find more information on the different type of metrics in Prometheus [here](https://prometheus.io/docs/concepts/metric_types/#metric-types)\n@@ -174,12 +174,11 @@ You can find more information on the different type of metrics in Prometheus [he\n \n | Metric name                            | Metric type                                                            | Description                                                                                                   |\n |-----------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|\n-| `jina_receiving_request_seconds`        | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the time elapsed between receiving a request from the Gateway and sending back the response.          |\n+| `jina_receiving_request_seconds`        | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the time elapsed between receiving a request from the Gateway and sending back the response.         |\n | `jina_sending_request_seconds`          | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the time elapsed between sending a downstream request to an Executor and receiving the response back. |\n-| `jina_sending_request_bytes`            | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the size of the downstream requests send to an Executor in bytes.                                      |\n-| `jina_failed_requests_total`            | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter)    | Counts the number of failed requests returned by the Gateway.                                                  |\n-| `jina_sent_request_bytes`               | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the size in bytes of the request sent by the Head to the Executor.                                    |\n-| `jina_received_response_bytes`          | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the size in bytes of the response returned by the Executor.                                           |\n+| `jina_sent_request_bytes`            | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the size in bytes of the request sent by the Head to the Executor.                     |\n+| `jina_sent_request_bytes`               | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the size in bytes of the request sent by the Head to the Executor.                                   |\n+| `jina_received_response_bytes`          | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary)    | Measures the size in bytes of the response returned by the Executor.                                          |\n \n ### Executor Pods\n \n@@ -187,9 +186,9 @@ You can find more information on the different type of metrics in Prometheus [he\n |----------------------------------|----------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n | `jina_receiving_request_seconds` | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between receiving a request from the Gateway (or the head) and sending back the response. |\n | `jina_process_request_seconds`   | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time spend calling the requested method                                                         |\n-| `jina_document_processed_total`  | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Counts the number of Documents processed by an Executor                                                     |\n-| `jina_successful_requests_total` | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Total count of successful requests returned by the Executor across all endpoints                            |\n-| `jina_failed_requests_total`     | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Total count of failed requests returned by the Executor across all endpoints                                |\n+| `jina_document_processed`  | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Counts the number of Documents processed by an Executor                                                     |\n+| `jina_successful_requests` | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Total count of successful requests returned by the Executor across all endpoints                            |\n+| `jina_failed_requests`     | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Total count of failed requests returned by the Executor across all endpoints                                |\n | `jina_received_request_bytes`        | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the size in bytes of the request received at the Executor level                                    |\n | `jina_sent_response_bytes`        | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the size in bytes of the response returned from the Executor to the Gateway                           |\n \n\n\n###\n\n", "completion": "docs: fix metrics naming (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -16,7 +16,6 @@ from jina.excepts import InternalNetworkError\n from jina.helper import get_full_version\n from jina.importer import ImportExtensions\n from jina.proto import jina_pb2, jina_pb2_grpc\n-from jina.serve.instrumentation import InstrumentationMixin\n from jina.serve.networking import GrpcConnectionPool\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n from jina.serve.runtimes.helper import _get_grpc_server_options\n@@ -52,6 +51,8 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n             logger=self.logger,\n             compression=args.compression,\n             metrics_registry=self.metrics_registry,\n+            aio_tracing_client_interceptors=self.aio_tracing_client_interceptors(),\n+            tracing_client_interceptor=self.tracing_client_interceptor(),\n         )\n         self._retries = self.args.retries\n \n\n---\n file path A: tests/integration/instrumentation/test_flow_instrumentation.py | file path B: tests/integration/instrumentation/test_flow_instrumentation.py\n\n@@ -90,3 +90,42 @@ def test_executor_instrumentation(otlp_collector):\n \n     trace_ids = get_trace_ids(client_traces)\n     assert len(trace_ids) == 1\n+\n+\n+def test_head_instrumentation(otlp_collector):\n+    f = Flow(\n+        tracing=True,\n+        traces_exporter_host='localhost',\n+        traces_exporter_port=4317,\n+    ).add(uses=ExecutorTestWithTracing, shards=2)\n+\n+    with f:\n+        from jina import DocumentArray\n+\n+        f.post(f'/index', DocumentArray.empty(2), continue_on_error=True)\n+        # give some time for the tracing and metrics exporters to finish exporting.\n+        # the client is slow to export the data\n+        time.sleep(8)\n+\n+    client_type = 'GRPCClient'\n+    client_traces = get_traces(client_type)\n+    (server_spans, client_spans, internal_spans) = partition_spans_by_kind(\n+        client_traces\n+    )\n+    assert len(server_spans) == 9\n+    assert len(client_spans) == 9\n+    assert len(internal_spans) == 2\n+\n+    services = get_services()\n+    expected_services = [\n+        'executor0/shard-0/rep-0',\n+        'executor0/shard-1/rep-0',\n+        'gateway/rep-0',\n+        'executor0/head',\n+        client_type,\n+    ]\n+    assert len(services) == 5\n+    assert set(services).issubset(expected_services)\n+\n+    trace_ids = get_trace_ids(client_traces)\n+    assert len(trace_ids) == 1\n\n\n###\n\n", "completion": "feat: add default tracing interceptors to Head grpc connection pool (#<issue-num>)"}
{"prompt": " file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"fast\">Learn more about Lightning</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/288496227/?isFirstPublish=true\">\n+                <a href=\"fast\">\n                     <!--startmsg-->\n-Join our Office Hour on September 29th at 19:00 CET \n+Learn more about Lightning\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"fast\">Learn more about Lightning</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/288496227/?isFirstPublish=true\">Join our Office Hour on September 29th at 19:00 CET </a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/288131091/?isFirstPublish=true\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/288496227/?isFirstPublish=true\">\n                     <!--startmsg-->\n-Learn more about how to build a Discord bot on Jina's platform on September 13th at 18:00 CET together with Peter Willemsen\n+Join our Office Hour on September 29th at 19:00 CET \n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/288496227/?isFirstPublish=true\">Join our Office Hour on September 29th at 19:00 CET </a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/288131091/?isFirstPublish=true\">Learn more about how to build a Discord bot on Jina's platform on September 13th at 18:00 CET together with Peter Willemsen</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/287738538/?isFirstPublish=true\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/288131091/?isFirstPublish=true\">\n                     <!--startmsg-->\n-Join our Office Hours Special Edition on August 25th at 19:00 CET to talk about Career Development at Jina AI\n+Learn more about how to build a Discord bot on Jina's platform on September 13th at 18:00 CET together with Peter Willemsen\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/288131091/?isFirstPublish=true\">Learn more about how to build a Discord bot on Jina's platform on September 13th at 18:00 CET together with Peter Willemsen</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/287738538/?isFirstPublish=true\">Join our Office Hours Special Edition on August 25th at 19:00 CET to talk about Career Development at Jina AI</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/287432899/\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/287738538/?isFirstPublish=true\">\n                     <!--startmsg-->\n-Learn more about how Neural Search Powered my Application with Ovidiu Ursachi on August 9th at 18:00 CET\n+Join our Office Hours Special Edition on August 25th at 19:00 CET to talk about Career Development at Jina AI\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/287738538/?isFirstPublish=true\">Join our Office Hours Special Edition on August 25th at 19:00 CET to talk about Career Development at Jina AI</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/287432899/\">Learn more about how Neural Search Powered my Application with Ovidiu Ursachi on August 9th at 18:00 CET</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/286917139/\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/287432899/\">\n                     <!--startmsg-->\n-Join our Office Hours on July 28th at 19:00 CET to find answers on all your questions\n+Learn more about how Neural Search Powered my Application with Ovidiu Ursachi on August 9th at 18:00 CET\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/287432899/\">Learn more about how Neural Search Powered my Application with Ovidiu Ursachi on August 9th at 18:00 CET</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/286917139/\">Join our Office Hours on July 28th at 19:00 CET to find answers on all your questions</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/286748566/\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/286917139/\">\n                     <!--startmsg-->\n-Learn more about how basic linear algebra can speed up your data science code together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET\n+Join our Office Hours on July 28th at 19:00 CET to find answers on all your questions\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/286917139/\">Join our Office Hours on July 28th at 19:00 CET to find answers on all your questions</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/286748566/\">Learn more about how basic linear algebra can speed up your data science code together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -20,7 +20,7 @@\n             <p>\n                 <a href=\"https://www.meetup.com/jina-community-meetup/events/286748566/\">\n                     <!--startmsg-->\n-\"Learn more about how basic linear algebra can speed up your data science code\" together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET\n+Learn more about how basic linear algebra can speed up your data science code together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -69,7 +69,7 @@ html_theme_options = {\n     # start-announce\n \n     \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/286748566/\">\"Learn more about how basic linear algebra can speed up your data science code\" together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET</a>\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/286748566/\">Learn more about how basic linear algebra can speed up your data science code together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET</a>\n     ''',\n         \n     # end-announce\n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"basic\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/286748566/\">\n                     <!--startmsg-->\n-Learn more about How\n+\"Learn more about how basic linear algebra can speed up your data science code\" together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/286748566/\">\"Learn more about how basic linear algebra can speed up your data science code\" together with  Jodie Burchell and Jina AI on July 12 at 18:00 CET</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"basic\">Learn more about How</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/286438459/\">\n+                <a href=\"basic\">\n                     <!--startmsg-->\n-Get answers to all your questions at our Office Hour on June 30 at 19:00 CET\n+Learn more about How\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"basic\">Learn more about How</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,10 +68,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/286438459/\">Get answers to all your questions at our Office Hour on June 30 at 19:00 CET</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/286414805/\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/286438459/\">\n                     <!--startmsg-->\n-Learn more about Jina and Wordlift at our Engineering All Hands on June 14th at 18:00 CET\n+Get answers to all your questions at our Office Hour on June 30 at 19:00 CET\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -68,6 +68,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/286438459/\">Get answers to all your questions at our Office Hour on June 30 at 19:00 CET</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,10 +67,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/286414805/\">Learn more about Jina and Wordlift at our Engineering All Hands on June 14th at 18:00 CET</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"Neural\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/286414805/\">\n                     <!--startmsg-->\n-Learn more about the topic When\n+Learn more about Jina and Wordlift at our Engineering All Hands on June 14th at 18:00 CET\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,6 +67,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/286414805/\">Learn more about Jina and Wordlift at our Engineering All Hands on June 14th at 18:00 CET</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,10 +67,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"Neural\">Learn more about the topic When</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/285271110/\">\n+                <a href=\"Neural\">\n                     <!--startmsg-->\n-Learn more about Pet Breed Classification on May 10th at 18:00 CET \n+Learn more about the topic When\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,6 +67,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"Neural\">Learn more about the topic When</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,10 +67,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/285271110/\">Learn more about Pet Breed Classification on May 10th at 18:00 CET </a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/285054198/\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/285271110/\">\n                     <!--startmsg-->\n-Join our Office Hours on April 28th at 19:00 CET \n+Learn more about Pet Breed Classification on May 10th at 18:00 CET \n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,6 +67,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/285271110/\">Learn more about Pet Breed Classification on May 10th at 18:00 CET </a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,10 +67,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/285054198/\">Join our Office Hours on April 28th at 19:00 CET </a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/284604466/\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/285054198/\">\n                     <!--startmsg-->\n-Learn more about Robustness with Nearest Neighbor Search at our Engineering All Hands on April 12 at 16:00 CET\n+Join our Office Hours on April 28th at 19:00 CET \n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,6 +67,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/285054198/\">Join our Office Hours on April 28th at 19:00 CET </a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,10 +67,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/284604466/\">Learn more about Robustness with Nearest Neighbor Search at our Engineering All Hands on April 12 at 16:00 CET</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/284243173/\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/284604466/\">\n                     <!--startmsg-->\n-Join our Office Hours on March 31st at 17:00 CET \n+Learn more about Robustness with Nearest Neighbor Search at our Engineering All Hands on April 12 at 16:00 CET\n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,6 +67,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/284604466/\">Learn more about Robustness with Nearest Neighbor Search at our Engineering All Hands on April 12 at 16:00 CET</a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,10 +67,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/284243173/\">Join our Office Hours on March 31st at 17:00 CET </a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n---\n file path A: .github/images/meetup.svg | file path B: .github/images/meetup.svg\n\n@@ -18,9 +18,9 @@\n             }\n             </style>\n             <p>\n-                <a href=\"https://www.meetup.com/jina-community-meetup/events/284352395\">\n+                <a href=\"https://www.meetup.com/jina-community-meetup/events/284243173/\">\n                     <!--startmsg-->\n-Learn how to build Vehicle Search and Audio Search using Jina at our Engineering All Hands on March 8th\n+Join our Office Hours on March 31st at 17:00 CET \n                     <!--endmsg-->\n                 </a>\n             </p>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,6 +67,10 @@ html_theme_options = {\n \n     # start-announce\n \n+    \"announcement\": '''\n+    <a href=\"https://www.meetup.com/jina-community-meetup/events/284243173/\">Join our Office Hours on March 31st at 17:00 CET </a>\n+    ''',\n+        \n     # end-announce\n }\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -67,10 +67,6 @@ html_theme_options = {\n \n     # start-announce\n \n-    \"announcement\": '''\n-    <a href=\"https://www.meetup.com/jina-community-meetup/events/284352395\">Learn how to build Vehicle Search and Audio Search using Jina at our Engineering All Hands on March 8th</a>\n-    ''',\n-        \n     # end-announce\n }\n \n\n\n###\n\n", "completion": "chore: update announcement in readme and docs"}
{"prompt": " file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -164,6 +164,7 @@ class GRPCBaseClient(BaseClient):\n             self.logger.warning('user cancel the process')\n         except asyncio.CancelledError as ex:\n             self.logger.warning(f'process error: {ex!r}')\n+            raise\n         except:\n             # Not sure why, adding this line helps in fixing a hanging test\n             raise\n\n---\n file path A: jina/clients/base/websocket.py | file path B: jina/clients/base/websocket.py\n\n@@ -72,16 +72,16 @@ class WebSocketBaseClient(BaseClient):\n             return False\n \n     async def _get_results(\n-        self,\n-        inputs: 'InputType',\n-        on_done: 'CallbackFnType',\n-        on_error: Optional['CallbackFnType'] = None,\n-        on_always: Optional['CallbackFnType'] = None,\n-        max_attempts: int = 1,\n-        initial_backoff: float = 0.5,\n-        max_backoff: float = 0.1,\n-        backoff_multiplier: float = 1.5,\n-        **kwargs,\n+            self,\n+            inputs: 'InputType',\n+            on_done: 'CallbackFnType',\n+            on_error: Optional['CallbackFnType'] = None,\n+            on_always: Optional['CallbackFnType'] = None,\n+            max_attempts: int = 1,\n+            initial_backoff: float = 0.5,\n+            max_backoff: float = 0.1,\n+            backoff_multiplier: float = 1.5,\n+            **kwargs,\n     ):\n         \"\"\"\n         :param inputs: the callable\n@@ -110,7 +110,8 @@ class WebSocketBaseClient(BaseClient):\n             proto = 'wss' if self.args.tls else 'ws'\n             url = f'{proto}://{self.args.host}:{self.args.port}/'\n             iolet = await stack.enter_async_context(\n-                WebsocketClientlet(url=url, logger=self.logger, max_attempts=max_attempts, initial_backoff=initial_backoff,\n+                WebsocketClientlet(url=url, logger=self.logger, max_attempts=max_attempts,\n+                                   initial_backoff=initial_backoff,\n                                    max_backoff=max_backoff, backoff_multiplier=backoff_multiplier, **kwargs)\n             )\n \n@@ -149,7 +150,7 @@ class WebSocketBaseClient(BaseClient):\n                 asyncio.create_task(iolet.send_eoi())\n \n             def _request_handler(\n-                request: 'Request',\n+                    request: 'Request',\n             ) -> 'Tuple[asyncio.Future, Optional[asyncio.Future]]':\n                 \"\"\"\n                 For each request in the iterator, we send the `Message` using `iolet.send_message()`.\n@@ -176,6 +177,8 @@ class WebSocketBaseClient(BaseClient):\n \n             receive_task = asyncio.create_task(_receive())\n \n+            exception_raised = None\n+\n             if receive_task.done():\n                 raise RuntimeError('receive task not running, can not send messages')\n             try:\n@@ -191,7 +194,19 @@ class WebSocketBaseClient(BaseClient):\n                     if self.show_progress:\n                         p_bar.update()\n                     yield response\n+            except Exception as ex:\n+                exception_raised = ex\n+                try:\n+                    receive_task.cancel()\n+                except:\n+                    raise ex\n             finally:\n                 if iolet.close_code == status.WS_1011_INTERNAL_ERROR:\n                     raise ConnectionError(iolet.close_message)\n-                await receive_task\n+                try:\n+                    await receive_task\n+                except asyncio.CancelledError:\n+                    if exception_raised is not None:\n+                        raise exception_raised\n+                    else:\n+                        raise\n\n---\n file path A: jina/clients/request/__init__.py | file path B: jina/clients/request/__init__.py\n\n@@ -81,3 +81,4 @@ def request_generator(\n     except Exception as ex:\n         # must be handled here, as grpc channel wont handle Python exception\n         default_logger.critical(f'inputs is not valid! {ex!r}', exc_info=True)\n+        raise\n\n---\n file path A: jina/clients/request/asyncio.py | file path B: jina/clients/request/asyncio.py\n\n@@ -58,3 +58,4 @@ async def request_generator(\n     except Exception as ex:\n         # must be handled here, as grpc channel wont handle Python exception\n         default_logger.critical(f'inputs is not valid! {ex!r}', exc_info=True)\n+        raise\n\n---\n file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -112,6 +112,9 @@ class RequestStreamer:\n         async def end_future():\n             raise self._EndOfStreaming\n \n+        async def exception_raise(exception):\n+            raise exception\n+\n         def callback(future: 'asyncio.Future'):\n             \"\"\"callback to be run after future is completed.\n             1. Put the future in the result queue.\n@@ -187,7 +190,7 @@ class RequestStreamer:\n                 except self._EndOfStreaming:\n                     pass\n \n-        asyncio.create_task(iterate_requests())\n+        iterate_requests_task = asyncio.create_task(iterate_requests())\n         handle_floating_task = asyncio.create_task(handle_floating_responses())\n         self.total_num_floating_tasks_alive += 1\n \n@@ -196,6 +199,14 @@ class RequestStreamer:\n \n         handle_floating_task.add_done_callback(floating_task_done)\n \n+        def iterating_task_done(task):\n+            if task.exception() is not None:\n+                all_requests_handled.set()\n+                future_cancel = asyncio.ensure_future(exception_raise(task.exception()))\n+                result_queue.put_nowait(future_cancel)\n+\n+        iterate_requests_task.add_done_callback(iterating_task_done)\n+\n         while not all_requests_handled.is_set():\n             future = await result_queue.get()\n             try:\n\n---\n file path A: tests/integration/issues/github_5141/__init__.py | file path B: tests/integration/issues/github_5141/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/issues/github_5141/test_invalid_input_raises_exception.py\n\n@@ -0,0 +1,23 @@\n+import pytest\n+from datetime import datetime\n+from jina import Flow, DocumentArray, Document\n+\n+\n+class MyOwnException(Exception):\n+    pass\n+\n+\n+@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+def test_invalid_input_raise(protocol):\n+    f = Flow(protocol=protocol).add()\n+\n+    try:\n+        with f:\n+            da = DocumentArray([Document(text='hello', tags={'date': datetime.now()})])\n+            try:\n+                f.post(on='/', inputs=da)  # process should stop here and raise an exception\n+            except Exception:\n+                raise MyOwnException\n+            assert False\n+    except MyOwnException:\n+        pass\n\\ No newline at end of file\n\n\n###\n\n", "completion": "fix: invalid input raise exception (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -233,6 +233,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15168,3 +15169,44 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```b8957a39```](https://github.com/jina-ai/jina/commit/b8957a392330a7dc9dd19fd50674df8b9c5749d3)] __-__ bump version (#5228) (*Joan Fontanals*)\n  - [[```c838a67d```](https://github.com/jina-ai/jina/commit/c838a67df98866fa01fac2f5214f2de01c1f1b03)] __-__ __version__: the next version will be 3.9.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-10-1></a>\n+## Release Note (`3.10.1`)\n+\n+> Release time: 2022-10-06 15:05:48\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Girish Chandrashekar,  Joan Fontanals,  Johannes Messner,  Alex Cureton-Griffiths,  samsja,  AlaeddineAbdessalem,  Jackmin801,  Jina Dev Bot,  Delgermurun,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```82960f10```](https://github.com/jina-ai/jina/commit/82960f105149c478e4fc88e8b4fef8bbe2454429)] __-__ distributed replicas across different hosts (#5217) (*Johannes Messner*)\n+ - [[```cdaf7f87```](https://github.com/jina-ai/jina/commit/cdaf7f87ececf9e13b517379ca183b17f0d7b007)] __-__ allow passing custom gateway in Flow (#5189) (*AlaeddineAbdessalem*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```c20cbbe3```](https://github.com/jina-ai/jina/commit/c20cbbe31011bad8f5a1c3469f9f32485803e0a2)] __-__ __orchestrate__: enable grpc fork support (#5250) (*Girish Chandrashekar*)\n+ - [[```e083dc88```](https://github.com/jina-ai/jina/commit/e083dc88cca0170e4b170e25627388a5bc082538)] __-__ avoid having a lambda in logger (#5249) (*Joan Fontanals*)\n+ - [[```d2142dc0```](https://github.com/jina-ai/jina/commit/d2142dc0b81f9256140232fe1f7a4f5dd25efdd0)] __-__ disable rich traceback in logging (#5242) (*samsja*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```379a7342```](https://github.com/jina-ai/jina/commit/379a7342a8a220dc155f653ca043ed2c4e5b6031)] __-__ move hubble related code to hubble-sdk (#5227) (*Delgermurun*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```86178f49```](https://github.com/jina-ai/jina/commit/86178f49f68fc120e7df29d97a1fd8bd550a752d)] __-__ polish (2022/10/04) (#5240) (*Alex Cureton-Griffiths*)\n+ - [[```bfdb22e4```](https://github.com/jina-ai/jina/commit/bfdb22e44539ba60027c1f38ddf6cf174bb2a926)] __-__ add note about keeping same jina versions (#5239) (*Joan Fontanals*)\n+ - [[```d6da86bc```](https://github.com/jina-ai/jina/commit/d6da86bc419951ebe95335f5818076b136520a1f)] __-__ __executor__: add missing request numbers in sample code (#5237) (*Jackmin801*)\n+ - [[```58d0e108```](https://github.com/jina-ai/jina/commit/58d0e10825fe1eb78c9adca7582dc46060b83943)] __-__ fix typos (#5236) (*Johannes Messner*)\n+ - [[```d6954ab2```](https://github.com/jina-ai/jina/commit/d6954ab20d895701be04df606c3e8b16a70b65ca)] __-__ explain executor patching in kubernetes (#5235) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```1a0e06b4```](https://github.com/jina-ai/jina/commit/1a0e06b48a7afffdde32830b31d05c9af35bc679)] __-__ docs polish 2022 10 05 (#5244) (*Alex Cureton-Griffiths*)\n+ - [[```fc83fa29```](https://github.com/jina-ai/jina/commit/fc83fa299fcd1cdb7523d38d791c912a31580b25)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```1810f178```](https://github.com/jina-ai/jina/commit/1810f178ba000cda2a4f6d98d590132c51338f87)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d2760cdd```](https://github.com/jina-ai/jina/commit/d2760cddec14c28693e1bab5926965d1fc3e49d7)] __-__ __version__: the next version will be 3.10.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.10.1'\n+__version__ = '3.10.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.10.2"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1381,6 +1381,8 @@ class Flow(\n \n         .. # noqa: DAR401\n         \"\"\"\n+        if multiprocessing.get_start_method().lower() == 'fork':\n+            os.environ['GRPC_ENABLE_FORK_SUPPORT'] = '1'\n \n         op_flow = copy.deepcopy(self) if copy_flow else self\n \n\n\n###\n\n", "completion": "fix(orchestrate): enable grpc fork support (#<issue-num>)"}
{"prompt": " file path A: jina/logging/logger.py | file path B: jina/logging/logger.py\n\n@@ -19,15 +19,15 @@ class _MyLogRender(_LogRender):\n     \"\"\"Override the original rich log record for more compact layout.\"\"\"\n \n     def __call__(\n-        self,\n-        console,\n-        renderables,\n-        log_time=None,\n-        time_format=None,\n-        level=None,\n-        path=None,\n-        line_no=None,\n-        link_path=None,\n+            self,\n+            console,\n+            renderables,\n+            log_time=None,\n+            time_format=None,\n+            level=None,\n+            path=None,\n+            line_no=None,\n+            link_path=None,\n     ):\n         from rich.containers import Renderables\n         from rich.table import Table\n@@ -112,12 +112,12 @@ class JinaLogger:\n     supported = {'FileHandler', 'StreamHandler', 'SysLogHandler', 'RichHandler'}\n \n     def __init__(\n-        self,\n-        context: str,\n-        name: Optional[str] = None,\n-        log_config: Optional[str] = None,\n-        quiet: bool = False,\n-        **kwargs,\n+            self,\n+            context: str,\n+            name: Optional[str] = None,\n+            log_config: Optional[str] = None,\n+            quiet: bool = False,\n+            **kwargs,\n     ):\n \n         log_config = os.getenv(\n@@ -145,7 +145,6 @@ class JinaLogger:\n         }\n \n         self.add_handlers(log_config, **context_vars)\n-        self.success = lambda *x: self.logger.log(LogVerbosity.SUCCESS, *x)\n         self.debug = self.logger.debug\n         self.warning = self.logger.warning\n         self.critical = self.logger.critical\n@@ -154,6 +153,14 @@ class JinaLogger:\n         self._is_closed = False\n         self.debug_enabled = self.logger.isEnabledFor(logging.DEBUG)\n \n+    def success(self, *args):\n+        \"\"\"\n+        Provides an API to print success messages\n+\n+        :param args: the args to be forwarded to the log\n+        \"\"\"\n+        self.logger.log(LogVerbosity.SUCCESS, *args)\n+\n     @property\n     def handlers(self):\n         \"\"\"\n\n\n###\n\n", "completion": "fix: avoid having a lambda in logger (#<issue-num>)"}
{"prompt": " file path A: jina/resources/logging.default.yml | file path B: jina/resources/logging.default.yml\n\n@@ -18,6 +18,6 @@ configs:\n   RichHandler:\n     format: '{name}@%(process)2d %(message)s'\n     markup: false\n-    rich_tracebacks: true\n+    rich_tracebacks: false\n     show_path: false\n     log_time_format: '[%x %X]'\n\\ No newline at end of file\n\n\n###\n\n", "completion": "fix: disable rich traceback in logging (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/docker-compose.md | file path B: docs/how-to/docker-compose.md\n\n@@ -24,21 +24,29 @@ flow = Flow(...).add(...).add(...)\n flow.to_docker_compose_yaml('docker-compose.yml')\n ```\n \n-Jina will generate a `docker-compose.yml` configuration file that you can use directly with \n-`docker-compose` and corresponds to your `Flow`, avoiding the overhead of manually defining all the services needed for the `Flow`.\n+Jina will generate a `docker-compose.yml` configuration file corresponding with your Flow. You can use this directly with \n+Docker Compose, avoiding the overhead of manually defining all the services needed for the Flow.\n \n-```{caution}\n+````{admonition} Use docker based Executors\n+:class: caution\n All Executors in the Flow should be used with `jinahub+docker://...` or `docker://...`.\n-```\n+````\n \n-```{caution}\n-If you are using Executor which rely on docker image built with a jina version prior to 3.1.3, please remove the \n-health check from the dump yaml file as they are only compatible with 3.1.3+ otherwise your docker compose services will \n-always be `unhealthy`\n-```\n+````{admonition} Health check available from 3.1.3\n+:class: caution\n+If you use Executors that rely on Docker images built with a version of Jina prior to 3.1.3, remove the \n+health check from the dumped YAML file, otherwise your Docker Compose services will \n+always be \"unhealthy.\"\n+````\n+\n+````{admonition} Matching jina versions\n+:class: caution\n+If you change the Docker images in your Docker Compose generated file, ensure that all the services included in\n+the gateway are built with the same Jina version to guarantee compatibility.\n+````\n ## Example: Indexing and searching images using CLIPEncoder and ANNLiteIndexer\n \n-To follow this how-to, you should first ensure that [`Docker Compose`](https://docs.docker.com/compose/install/) is installed locally.\n+Install [`Docker Compose`](https://docs.docker.com/compose/install/) locally to follow this how-to.\n \n This example shows how to build and deploy a Flow with Docker Compose, using [`CLIPImageEncoder`](https://hub.jina.ai/executor/0hnlmu3q)\n as an image encoder and [`ANNLiteIndexer`](https://hub.jina.ai/executor/7yypg8qk) as an indexer to perform fast nearest\n\n---\n file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -221,6 +221,11 @@ Instead, you may want to disable Jina level retries by setting `Flow(retries=0)`\n YAML `with` block.\n ````\n \n+````{admonition} Matching jina versions\n+:class: caution\n+If you change the Docker images in your Docker Compose generated file, ensure that all the services included in the gateway are built with the same Jina version to guarantee compatibility.\n+````\n+\n ### Deploy your Flow with shards and replicas\n \n After your service mesh is installed, your cluster is ready to run a Flow with scaled Executors.\n\n\n###\n\n", "completion": "docs: add note about keeping same jina versions (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-methods.md | file path B: docs/fundamentals/executor/executor-methods.md\n\n@@ -452,9 +452,9 @@ class ProcessDocuments(Executor):\n f = Flow().add(uses=ProcessDocuments).add(uses=PrintDocuments)\n \n with f:\n-    f.post(on='/change_in_place', inputs=DocumentArray(Document(text='request')))\n+    f.post(on='/change_in_place', inputs=DocumentArray(Document(text='request1')))\n     f.post(\n-        on='/return_different_docarray', inputs=DocumentArray(Document(text='request'))\n+        on='/return_different_docarray', inputs=DocumentArray(Document(text='request2'))\n     )\n ```\n \n\n\n###\n\n", "completion": "docs(executor): add missing request numbers in sample code (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -355,6 +355,7 @@ print(f\"Matched documents: {len(matches)}\")\n \n In Kubernetes, you can update your Executors by patching the Deployment corresponding to your Executor.\n \n+\n For instance, in the example above, you may want to change set a `batch_size` parameter for the CLIPEncoder.\n \n To do this, change the content of the Deployment inside the `executor.yml` dumped by `.to_kubernetes_yaml`.\n@@ -393,7 +394,8 @@ kubectl apply -R -f ./k8s_flow\n :class: seealso\n \n Within Kubernetes, Executors are ordinary Deployments.\n-This means that you can use other pathing options provided by Kubernetes:\n+This means that you can use other patching options provided by Kubernetes:\n+\n \n - `kubectl replace` to replace an Executor using a complete configuration file\n - `kubectl patch` to patch an Executor using only a partial configuration file\n\n\n###\n\n", "completion": "docs: fix typos (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -351,6 +351,57 @@ matches = queried_docs[0].matches\n print(f\"Matched documents: {len(matches)}\")\n ```\n \n+## Update your Executor in Kubernetes\n+\n+In Kubernetes, you can update your Executors by patching the Deployment corresponding to your Executor.\n+\n+For instance, in the example above, you may want to change set a `batch_size` parameter for the CLIPEncoder.\n+\n+To do this, change the content of the Deployment inside the `executor.yml` dumped by `.to_kubernetes_yaml`.\n+\n+You need to add `--uses_with` and pass the batch size argument to it. This will be passed to the container inside the Deployment:\n+\n+```yaml\n+    spec:\n+      containers:\n+      - args:\n+        - executor\n+        - --name\n+        - encoder\n+        - --k8s-namespace\n+        - custom-namespace\n+        - --uses\n+        - config.yml\n+        - --port\n+        - '8080'\n+        - --uses-metas\n+        - '{}'\n+        - --uses-with\n+        - '{\"batch_size\": 64}'\n+        - --native\n+        command:\n+        - jina\n+```\n+\n+After doing so, you can re-apply your configuration and the new Executor will be deployed without affecting the other unchanged Deployments:\n+\n+```shell script\n+kubectl apply -R -f ./k8s_flow\n+```\n+\n+````{admonition} Other patching options\n+:class: seealso\n+\n+Within Kubernetes, Executors are ordinary Deployments.\n+This means that you can use other pathing options provided by Kubernetes:\n+\n+- `kubectl replace` to replace an Executor using a complete configuration file\n+- `kubectl patch` to patch an Executor using only a partial configuration file\n+- `kubectl edit` to edit an Executor configuration on the fly in your editor\n+\n+You can find more information about these commands in the [official Kubernetes documentation](https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/).\n+````\n+\n ## Key takeaways\n \n To put it succinctly, there are just three key takeaways about deploying a Jina Flow using Kubernetes:\n\n\n###\n\n", "completion": "docs: explain executor patching in kubernetes (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -232,6 +232,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15149,3 +15150,19 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```8c2d0758```](https://github.com/jina-ai/jina/commit/8c2d07589468b2fdf5dfccd04f3a2cbfc6482802)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```139b068e```](https://github.com/jina-ai/jina/commit/139b068ea33b3198f72df36a7ed383478451ab8d)] __-__ __version__: the next version will be 3.9.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-10-0></a>\n+## Release Note (`3.10.0`)\n+\n+> Release time: 2022-09-29 16:50:33\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```b8957a39```](https://github.com/jina-ai/jina/commit/b8957a392330a7dc9dd19fd50674df8b9c5749d3)] __-__ bump version (#5228) (*Joan Fontanals*)\n+ - [[```c838a67d```](https://github.com/jina-ai/jina/commit/c838a67df98866fa01fac2f5214f2de01c1f1b03)] __-__ __version__: the next version will be 3.9.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.10.0'\n+__version__ = '3.10.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.10.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.9.4'\n+__version__ = '3.10.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: bump version (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -231,6 +231,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15092,3 +15093,59 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```f4248ea8```](https://github.com/jina-ai/jina/commit/f4248ea8b7a82f49299076339223cb314511c91c)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```fda5623a```](https://github.com/jina-ai/jina/commit/fda5623aa3b3e4724bfff063b1b43b3be1f3c5e9)] __-__ __version__: the next version will be 3.9.2 (*Jina Dev Bot*)\n \n+<a name=release-note-3-9-3></a>\n+## Release Note (`3.9.3`)\n+\n+> Release time: 2022-09-29 16:05:04\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  AlaeddineAbdessalem,  Michael G\u00fcnther,  Yanlong Wang,  samsja,  Alex Cureton-Griffiths,  Deepankar Mahapatro,  Nikolas Pitsillos,  Han Xiao,  zhangkai,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```11533962```](https://github.com/jina-ai/jina/commit/11533962629d27a05cc677abd4d5a5e1837a3905)] __-__ add gateway option to jina ping and use ping in readinessProbe (#5200) (*Joan Fontanals*)\n+ - [[```d0838d37```](https://github.com/jina-ai/jina/commit/d0838d37de983a687c743fd969b74deea5937b65)] __-__ add multiple attempts options to client.post API (#5176) (*Joan Fontanals*)\n+ - [[```13edf908```](https://github.com/jina-ai/jina/commit/13edf9080e129067a5b2eb4ef7b9092664f9847e)] __-__ use default grpc parameters for grpc connection pool connection (#5211) (*samsja*)\n+ - [[```216b4bf0```](https://github.com/jina-ai/jina/commit/216b4bf080c2695c6f02016a263dcd1ae7af4eba)] __-__ __monitoring__: add monitoring of requests size in bytes at all level (#5111) (*samsja*)\n+ - [[```737875f5```](https://github.com/jina-ai/jina/commit/737875f53751f65e87116c404fa657d442b4809a)] __-__ __logs__: json logging for jcloud (#5201) (*Deepankar Mahapatro*)\n+ - [[```fd4c0347```](https://github.com/jina-ai/jina/commit/fd4c03476d7afd8cb5f311a48befadf380147462)] __-__ support list-like syntax to round robin CUDA devices (#5187) (*Joan Fontanals*)\n+ - [[```9dff4c88```](https://github.com/jina-ai/jina/commit/9dff4c880fae56b9f061047338b5cc8a426579c4)] __-__ add duration info in events (#5157) (*Joan Fontanals*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```3683fccf```](https://github.com/jina-ai/jina/commit/3683fccfd5b9d7c25fd2862f4128eef28d752ac2)] __-__ fix compatibility with protobuf python backend (#5222) (*AlaeddineAbdessalem*)\n+ - [[```e932d6f9```](https://github.com/jina-ai/jina/commit/e932d6f9e042b06771fde2a6bec8f256c223a4d6)] __-__ __hubio.fetch_meta__: move significant params to sequential (#5205) (*Yanlong Wang*)\n+ - [[```60e9b8de```](https://github.com/jina-ai/jina/commit/60e9b8de6f5a6f8927ac16ff67d05d66ebf21a23)] __-__ remove leftover prints (#5199) (*Joan Fontanals*)\n+ - [[```da186a23```](https://github.com/jina-ai/jina/commit/da186a233c5feeeb8470cdeabac71343e7083b6c)] __-__ provide logger and streamer (#5188) (*AlaeddineAbdessalem*)\n+ - [[```7b5c0316```](https://github.com/jina-ai/jina/commit/7b5c0316aca5c91f7b8db2bf6604e483c0598937)] __-__ fix get-openapi-schemas script (#5185) (*AlaeddineAbdessalem*)\n+ - [[```caf4a3d6```](https://github.com/jina-ai/jina/commit/caf4a3d65372d5c0b62dc46efaab0a9ef496e780)] __-__ fix missing secret when logged-in user  with --force-update and \u2026 (#5180) (*zhangkai*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```9a6079ef```](https://github.com/jina-ai/jina/commit/9a6079ef71dfe106d68c9540dfcdb4b0711497d1)] __-__ separate gateway and asyncio runtime readiness checks (#5224) (*AlaeddineAbdessalem*)\n+ - [[```243639dd```](https://github.com/jina-ai/jina/commit/243639dd2b953fab8654747cbfdf6a0953b95578)] __-__ extract gateway app logic into custom gateway class (#5153) (*AlaeddineAbdessalem*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```147317db```](https://github.com/jina-ai/jina/commit/147317db8d5f1eeed0d780cd293ba5c4e9f6c8df)] __-__ change setenv into environ (#5223) (*Michael G\u00fcnther*)\n+ - [[```ad37bdd2```](https://github.com/jina-ai/jina/commit/ad37bdd23f7bc8c8fe3e64bacf92765c2f7e8c2f)] __-__ mention prefetch (#5220) (*Joan Fontanals*)\n+ - [[```b9c8e44e```](https://github.com/jina-ai/jina/commit/b9c8e44e7683fa31b5380b7baf9b40f1890f777e)] __-__ fix install instructions docker (#5213) (*Joan Fontanals*)\n+ - [[```7cbf3471```](https://github.com/jina-ai/jina/commit/7cbf3471478bac48e33fe7a962d302fb322fb4a3)] __-__ __what-is-jina__: fix grammar, wording, punctuation (#5209) (*Alex Cureton-Griffiths*)\n+ - [[```7c7d2cb0```](https://github.com/jina-ai/jina/commit/7c7d2cb04e28173a1f770354bdbcf2b65c0dfef2)] __-__ __what-is-modality__: fix grammar, punctuation (#5208) (*Alex Cureton-Griffiths*)\n+ - [[```1399e36c```](https://github.com/jina-ai/jina/commit/1399e36cea5d29621c0d180726685c1aa8a14657)] __-__ clarify exec endpoint usage in http (#5202) (*Joan Fontanals*)\n+ - [[```842a585b```](https://github.com/jina-ai/jina/commit/842a585b373e6a381828d2477c22d68468cba5c5)] __-__ document grpc client limitation (#5193) (*AlaeddineAbdessalem*)\n+ - [[```96c5e7c1```](https://github.com/jina-ai/jina/commit/96c5e7c1e5760ca1142f7f654a75dc0786f40afa)] __-__ __jcloud__: update faq and lifetime (#5191) (*Nikolas Pitsillos*)\n+ - [[```c17e6416```](https://github.com/jina-ai/jina/commit/c17e6416d6f04c8f971f5b097a533435b8828d49)] __-__ improve warning about config file in custom docker (#5190) (*Joan Fontanals*)\n+ - [[```22330fcb```](https://github.com/jina-ai/jina/commit/22330fcb3118b0eefb231ee9eeffed5e5f80a2fe)] __-__ clarify __return__ behavior in parameters (#5179) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```b5977f47```](https://github.com/jina-ai/jina/commit/b5977f47801a9d841cd803581ea34d3c735a5b2f)] __-__ update contributing to remove labeling (#5225) (*Joan Fontanals*)\n+ - [[```45c7c6e1```](https://github.com/jina-ai/jina/commit/45c7c6e1cb408d63f1a55ae6a7a30d5afe39dc31)] __-__ update pull request template link (#5214) (*Joan Fontanals*)\n+ - [[```1eab9ce6```](https://github.com/jina-ai/jina/commit/1eab9ce6602cd02eae154c4b7297db1b4d70ba40)] __-__ fix doc template (*Han Xiao*)\n+ - [[```8c2d0758```](https://github.com/jina-ai/jina/commit/8c2d07589468b2fdf5dfccd04f3a2cbfc6482802)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```139b068e```](https://github.com/jina-ai/jina/commit/139b068ea33b3198f72df36a7ed383478451ab8d)] __-__ __version__: the next version will be 3.9.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.9.3'\n+__version__ = '3.9.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.9.4"}
{"prompt": " file path A: .github/github-issue-label-guide.md | file path B: None\n\n@@ -1,93 +0,0 @@\n-# Jina Issue Labeling\n-\n-## Scope\n-These guidelines serve as a primary document for explaining how GitHub issues are labeled in Jina repos. For community members reading this document, it should explain how a label was assigned to your issue, and what that label means. For Jina maintainers, it describes how to assign labels correctly.\n-\n-**Note:** These guideline only apply to the following repos; [Jina](https://github.com/jina-ai/jina), [Jina-hub](https://github.com/jina-ai/jina-hub), [Dashboard](https://github.com/jina-ai/dashboard), [docs](https://github.com/jina-ai/docs), [cloud-ops](https://github.com/jina-ai/cloud-ops),  [Jinabox.js](https://github.com/jina-ai/jinabox.js)\n-\n-## Why is labeling important?\n-* Labels provide a good starting point for community members to contribute to Jina.\n-* Labels provide status for both community members and Jina maintainers on ongoing workstreams and feature requests.\n-* Labels provide an overview of the development status of Jina, highlighting areas of issue that need attention. They can be used as metrics of productivity and health of the project.\n-\n-\n-## How labels are used in Jina repos.\n-\n-Labels added by community members are automatically assigned the label `needs-triage`. A Jina maintainers member should then read the issue and assign it to the correct labels.\n-\n-An issue added by a Jina maintainers member can skip triage and directly be assigned a type, priority, status and area label.\n-\n-All issues are assigned a type label. Some issues may be assigned a priority, status, and area label.\n-**An issue should only ever have one type label, one status label, one priority label, and one area label.**\n-\n-This is an example of a correctly labelled issue\n-![alt text](images/github_issue_label.png)\n-\n-\n-\n-## How to assign: a step-by-step flow\n-This aims to walk you through a standard triaging process.\n-\n-#### 1. Assign one type label:\n-You should only assign one type label at a time. If an issue applies to many types, choose the most relevant type. If an issue contains both a feature request and a separate question, you should suggest they open two separate issues.\n-\n-| Label | Description and action to be taken  |\n-|--|--|\n-|`type/irrelevant` | This issue is completely unrelated to Jina and should be closed.|\n-|`type/question` | This is a question about Jina. It should be answered and closed after 20 days. |\n-|`type/duplicate` |This issue is a duplicate of an existing issue. It should be linked to the original issue, the user should notified and the issue closed.|\n-|`triage/needs-information` |This issue needs more info added by the author to be correctly triaged. Reply to the user and request more info.  |\n-|`type/bug`|This issue describes an error, flaw or fault in a Jina that causes it to produce an incorrect or unexpected result, or to behave in unintended ways.|\n-|`type/feature-request` | This issue describes a new feature or behaviour a user or users desires.|\n-|`type/maintenance`|This issue is not a bug or a feature_request.|\n-\n-#### 2. Assign a priority label:\n-*Only issues of type bug - feature_request - maintenance are assigned a priority label.*\n-\n-|Label  |Description |\n-|--|--|\n-|`priority/critical`| Team leaders are responsible for making sure that these issues (in their area) are being actively worked on\u2014i.e., drop what you're doing. Stuff is burning. These should be fixed before the next release.|\n-|`priority/important-soon`|Must be maintainersed and worked on either currently or very soon\u2014ideally in time for the next release.|\n-|`priority/important-longterm`|Important over the long term, but may not be currently maintainersed and/or may require multiple releases to complete.|\n-|`priority/backlog`|General agreement that this is a nice-to-have, but no one's available to work on it anytime soon. Community contributions would be most welcome in the meantime.|\n-|`priority/research`|Possibly useful, but not yet enough research to actually get it done.|\n-\n-#### 3.  Assign a status label:\n-*Only issues of type bug - feature_request - maintenance are assigned a status label.*\n-\n-| Label | Description |\n-|--|--|\n-|`status/available`| The issue is available for someone to begin working on. |\n-|`status/in-progess`|This issue is activity being worked on.|\n-|`status/blocked-upstream`|This issue is blocked by an upstream issue.|\n-|`status/blocked-internal`|This issue is blocked by another internal issue.|\n-|`status/blocked-help_needed`| This issue is blocked and needs support. Likely used by a community member who needs support from a Jina professional maintainers.|\n-|`status/done`|This issue is complete.|\n-\n-\n-#### 4. Assign an area label:\n-Only one area label should be assigned. If an issue applies to many area, choose the most relevant area.\n-\n-Area labels are similar to epics in Jira. They group similar issues by workstream. For example, all issues that affect CRUD operations should be assigned the `area/crud` label.\n-\n-Area labels will be specific to each repo, and created by PMs and team leads on an organic basis.\n-\n-#### 5. [if applicable] assign good first issue\n-The `good_first_issue` label allows a smooth onboarding to the Jina open source project on GitHub. It encourages new developers to join the developer community.\n-\n-####  What makes a \u2018good first issue\u2019?\n-\n-**Priority**\n-\n-The Jina community has five different levels of issue priority. Only issues of type `priority/backlog` and `priority/important-longterm` should be assigned a `good_first_issue` label.\n-\n-**Technical complexity**\n-\n-These issues should not require detailed knowledge of Jina architecture or design patterns. They should be bug or feature requests that are pretty easy to code.\n-\n-**Specifications**\n-The issue should naturally explain what the problem is. It should also include some tips and starting point for how to solve the problem. For example, link to the relevant pages on the documentation site that someone might read to understand how to begin fixing the problem.\n-\n-**Acceptance Criteria**\n-\n-The issue should include a list of acceptance criteria. These are requirements that must be met for the issue to be marked done. By adding clear and understandable acceptance criteria, it helps the community members work towards an end goal.\n\n---\n file path A: CONTRIBUTING.md | file path B: CONTRIBUTING.md\n\n@@ -35,8 +35,6 @@ There are also a couple of nice to haves:\n * **Environment:** You can find this with ``jina -vf``\n * **Screenshots:** If they're relevant\n \n-To understand how our issues are labeled, check out our [issue label guide](.github/github-issue-label-guide.md).\n-\n <a name=\"-making-your-first-submission\"></a>\n ## \ud83e\udd47 Making Your First Submission\n \n\n\n###\n\n", "completion": "chore: update contributing to remove labeling (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -27,12 +27,12 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n     \"\"\"\n \n     def __init__(\n-            self,\n-            args: 'argparse.Namespace',\n-            cancel_event: Optional[\n-                Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n-            ] = None,\n-            **kwargs,\n+        self,\n+        args: 'argparse.Namespace',\n+        cancel_event: Optional[\n+            Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n+        ] = None,\n+        **kwargs,\n     ):\n         super().__init__(args, **kwargs)\n         self._loop = asyncio.new_event_loop()\n@@ -53,9 +53,9 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n                 )\n         else:\n             with ImportExtensions(\n-                    required=True,\n-                    logger=self.logger,\n-                    help_text='''If you see a 'DLL load failed' error, please reinstall `pywin32`.\n+                required=True,\n+                logger=self.logger,\n+                help_text='''If you see a 'DLL load failed' error, please reinstall `pywin32`.\n                 If you're using conda, please use the command `conda install -c anaconda pywin32`''',\n             ):\n                 import win32api\n@@ -84,7 +84,12 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n         self._loop.close()\n         super().teardown()\n         self._stop_time = time.time()\n-        send_telemetry_event(event='stop', obj=self, duration=self._stop_time - self._start_time, entity_id=self._entity_id)\n+        send_telemetry_event(\n+            event='stop',\n+            obj=self,\n+            duration=self._stop_time - self._start_time,\n+            entity_id=self._entity_id,\n+        )\n \n     async def _wait_for_cancel(self):\n         \"\"\"Do NOT override this method when inheriting from :class:`GatewayPod`\"\"\"\n@@ -163,12 +168,13 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n         except RpcError:\n             return False\n \n-    @staticmethod\n+    @classmethod\n     def wait_for_ready_or_shutdown(\n-            timeout: Optional[float],\n-            ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n-            ctrl_address: str,\n-            **kwargs,\n+        cls,\n+        timeout: Optional[float],\n+        ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n+        ctrl_address: str,\n+        **kwargs,\n     ):\n         \"\"\"\n         Check if the runtime has successfully started\n@@ -182,9 +188,7 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n         timeout_ns = 1000000000 * timeout if timeout else None\n         now = time.time_ns()\n         while timeout_ns is None or time.time_ns() - now < timeout_ns:\n-            if ready_or_shutdown_event.is_set() or AsyncNewLoopRuntime.is_ready(\n-                    ctrl_address\n-            ):\n+            if ready_or_shutdown_event.is_set() or cls.is_ready(ctrl_address, **kwargs):\n                 return True\n             time.sleep(0.1)\n         return False\n@@ -200,6 +204,7 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n     @property\n     def _entity_id(self):\n         import uuid\n+\n         if hasattr(self, '_entity_id_'):\n             return self._entity_id_\n         self._entity_id_ = uuid.uuid1().hex\n\n---\n file path A: jina/serve/runtimes/gateway/__init__.py | file path B: jina/serve/runtimes/gateway/__init__.py\n\n@@ -1,5 +1,7 @@\n import argparse\n+import urllib\n from abc import ABC\n+from http import HTTPStatus\n from typing import TYPE_CHECKING, Optional, Union\n \n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n@@ -28,3 +30,52 @@ class GatewayRuntime(AsyncNewLoopRuntime, ABC):\n         if self.timeout_send:\n             self.timeout_send /= 1e3  # convert ms to seconds\n         super().__init__(args, cancel_event, **kwargs)\n+\n+    @staticmethod\n+    def is_ready(ctrl_address: str, protocol: Optional[str] = 'grpc', **kwargs) -> bool:\n+        \"\"\"\n+        Check if status is ready.\n+\n+        :param ctrl_address: the address where the control request needs to be sent\n+        :param protocol: protocol of the gateway runtime\n+        :param kwargs: extra keyword arguments\n+\n+        :return: True if status is ready else False.\n+        \"\"\"\n+\n+        if protocol is None or protocol == 'grpc':\n+            res = super().is_ready(ctrl_address)\n+        else:\n+            try:\n+                conn = urllib.request.urlopen(url=f'http://{ctrl_address}')\n+                res = conn.code == HTTPStatus.OK\n+            except:\n+                res = False\n+        return res\n+\n+    @classmethod\n+    def wait_for_ready_or_shutdown(\n+        cls,\n+        timeout: Optional[float],\n+        ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n+        ctrl_address: str,\n+        protocol: Optional[str] = 'grpc',\n+        **kwargs,\n+    ):\n+        \"\"\"\n+        Check if the runtime has successfully started\n+\n+        :param timeout: The time to wait before readiness or failure is determined\n+        :param ctrl_address: the address where the control message needs to be sent\n+        :param ready_or_shutdown_event: the multiprocessing event to detect if the process failed or is ready\n+        :param protocol: protocol of the gateway runtime\n+        :param kwargs: extra keyword arguments\n+\n+        :return: True if is ready or it needs to be shutdown\n+        \"\"\"\n+        return super().wait_for_ready_or_shutdown(\n+            timeout=timeout,\n+            ready_or_shutdown_event=ready_or_shutdown_event,\n+            ctrl_address=ctrl_address,\n+            protocol=protocol,\n+        )\n\n\n###\n\n", "completion": "refactor: separate gateway and asyncio runtime readiness checks (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/health-check.md | file path B: docs/fundamentals/flow/health-check.md\n\n@@ -125,7 +125,7 @@ import os\n \n PROTOCOL = 'grpc'  # it could also be http or websocket\n \n-os.setenv[\n+os.environ[\n     'JINA_LOG_LEVEL'\n ] = 'DEBUG'  # this way we can check what is the PID of the Executor\n \n@@ -330,4 +330,4 @@ curl http://localhost:12345\n And you will get a valid empty response indicating the Gateway's ability to serve.\n ```json\n {}\n-```\n\\ No newline at end of file\n+```\n\n\n###\n\n", "completion": "docs: change setenv into environ (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/http/models.py | file path B: jina/serve/runtimes/gateway/http/models.py\n\n@@ -2,15 +2,17 @@ from collections import defaultdict\n from datetime import datetime\n from enum import Enum\n from types import SimpleNamespace\n-from typing import Callable, Dict, List, Optional, Union\n+from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Union\n \n from docarray.document.pydantic_model import PydanticDocument, PydanticDocumentArray\n from google.protobuf.descriptor import Descriptor, FieldDescriptor\n-from google.protobuf.pyext.cpp_message import GeneratedProtocolMessageType\n from pydantic import BaseConfig, BaseModel, Field, create_model, root_validator\n \n from jina.proto.jina_pb2 import DataRequestProto, JinaInfoProto, RouteProto, StatusProto\n \n+if TYPE_CHECKING:\n+    from google.protobuf.pyext.cpp_message import GeneratedProtocolMessageType\n+\n PROTO_TO_PYDANTIC_MODELS = SimpleNamespace()\n PROTOBUF_TO_PYTHON_TYPE = {\n     FieldDescriptor.TYPE_INT32: int,\n@@ -97,7 +99,7 @@ def _get_oneof_setter(oneof_fields: List, oneof_key: str) -> Callable:\n \n \n def protobuf_to_pydantic_model(\n-    protobuf_model: Union[Descriptor, GeneratedProtocolMessageType]\n+    protobuf_model: Union[Descriptor, 'GeneratedProtocolMessageType']\n ) -> BaseModel:\n     \"\"\"\n     Converts Protobuf messages to Pydantic model for jsonschema creation/validattion\n\n\n###\n\n", "completion": "fix: fix compatibility with protobuf python backend (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -470,7 +470,7 @@ When working with very slow executors and a big amount of data, you must set `pr\n ```python\n from jina import Flow\n \n-f = Flow(protocol='http', cors=True)\n+f = Flow(protocol='http', cors=True, prefetch=10)\n ```\n ````\n \n@@ -479,7 +479,8 @@ f = Flow(protocol='http', cors=True)\n jtype: Flow\n with:\n   protocol: 'http'\n-  cors: True, \n+  cors: True,\n+  prefetch: 10\n ```\n ````\n \n\n\n###\n\n", "completion": "docs: mention prefetch (#<issue-num>)"}
{"prompt": " file path A: .github/pull_request_template.md | file path B: .github/pull_request_template.md\n\n@@ -11,4 +11,4 @@\n \n - ...\n - ...\n-- [ ] check and update documentation. See [guide](https://github.com/jina-ai/jina/CONTRIBUTING.md#documentation-guidelines) and ask the team.\n+- [ ] check and update documentation. See [guide](https://github.com/jina-ai/jina/blob/master/CONTRIBUTING.md#-contributing-documentation) and ask the team.\n\n\n###\n\n", "completion": "chore: update pull request template link (#<issue-num>)"}
{"prompt": " file path A: docs/index.md | file path B: docs/index.md\n\n@@ -27,16 +27,26 @@ docker pull jinaai/jina:latest\n \n Now that you\u2019re set up, let\u2019s create a project:\n \n+````{tab} In host\n ```shell\n jina new hello-jina\n cd hello-jina\n jina flow --uses flow.yml\n-python client.py\n ```\n+````\n+````{tab} Inside Docker\n+```shell\n+docker run -it --entrypoint=/bin/bash jinaai/jina:latest -p 54321:54321\n+jina new hello-jina\n+cd hello-jina\n+jina flow --uses flow.yml\n+```\n+````\n \n-And observe the result from your terminal.\n+Run the client on your machine and observe the results from your terminal.\n \n ```shell\n+python client.py\n ['hello, world!', 'goodbye, world!']\n ```\n \n\n\n###\n\n", "completion": "docs: fix install instructions docker (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -411,7 +411,9 @@ metas:\n         new_task_id = push_task.get('_id')\n         if new_task_id:\n \n-            dump_secret(work_path, form_data.get('id'), form_data.get('secret'), new_task_id)\n+            dump_secret(\n+                work_path, form_data.get('id'), form_data.get('secret'), new_task_id\n+            )\n             self._prettyprint_status_usage(console, work_path, new_task_id)\n             st.update(f'Async Uploaded!')\n \n@@ -421,7 +423,9 @@ metas:\n                 # `new_secret` is always None\n                 new_uuid8, new_secret = self._prettyprint_result(console, image)\n                 if new_uuid8 != form_data.get('id'):\n-                    dump_secret(work_path, new_uuid8, form_data.get('secret'), new_task_id)\n+                    dump_secret(\n+                        work_path, new_uuid8, form_data.get('secret'), new_task_id\n+                    )\n \n             else:\n                 raise Exception(f'Unknown Error, session_id: {session_id}')\n@@ -959,10 +963,10 @@ metas:\n     def fetch_meta(\n         name: str,\n         tag: str,\n-        *,\n-        secret: Optional[str] = None,\n         image_required: bool = True,\n         rebuild_image: bool = True,\n+        *,\n+        secret: Optional[str] = None,\n         force: bool = False,\n     ) -> HubExecutor:\n         \"\"\"Fetch the executor meta info from Jina Hub.\n@@ -976,7 +980,7 @@ metas:\n         :return: meta of executor\n \n         .. note::\n-            The `name` and `tag` should be passed via ``args`` and `force` and `secret` as ``kwargs``, otherwise,\n+            The significant parameters like `name` and `tag` should be passed via ``args`` and `force` and `secret` as ``kwargs``, otherwise,\n             cache does not work.\n         \"\"\"\n         with ImportExtensions(required=True):\n@@ -1010,7 +1014,7 @@ metas:\n         images = resp['package'].get('containers', [])\n         image_name = images[0] if images else None\n         if image_required and not image_name:\n-            raise Exception(\n+            raise RuntimeError(\n                 f'No image found for executor \"{name}\", '\n                 f'tag: {tag}, commit: {resp.get(\"commit\", {}).get(\"id\")}, '\n                 f'session_id: {req_header.get(\"jinameta-session-id\")}'\n@@ -1175,8 +1179,8 @@ metas:\n                 executor, from_cache = HubIO.fetch_meta(\n                     name,\n                     tag,\n+                    image_required,\n                     secret=secret,\n-                    image_required=image_required,\n                     force=need_pull,\n                 )\n \n@@ -1248,8 +1252,8 @@ metas:\n                                 executor, _ = HubIO.fetch_meta(\n                                     name,\n                                     tag,\n+                                    image_required,\n                                     secret=secret,\n-                                    image_required=False,\n                                     force=True,\n                                 )\n \n\n---\n file path A: tests/integration/hub_usage/test_hub_usage.py | file path B: tests/integration/hub_usage/test_hub_usage.py\n\n@@ -62,19 +62,18 @@ def local_hub_executor(tmpdir):\n     )\n \n \n-def test_use_from_local_hub_deployment_level(\n-    mocker, monkeypatch, local_hub_executor\n-):\n+def test_use_from_local_hub_deployment_level(mocker, monkeypatch, local_hub_executor):\n     from jina.hubble.hubio import HubExecutor, HubIO\n \n     mock = mocker.Mock()\n \n     def _mock_fetch(\n         name,\n-        tag=None,\n-        secret=None,\n+        tag,\n         image_required=True,\n         rebuild_image=True,\n+        *,\n+        secret=None,\n         force=False,\n     ):\n         mock(name=name)\n@@ -97,19 +96,18 @@ def test_use_from_local_hub_deployment_level(\n         pass\n \n \n-def test_use_from_local_hub_flow_level(\n-    mocker, monkeypatch, local_hub_executor\n-):\n+def test_use_from_local_hub_flow_level(mocker, monkeypatch, local_hub_executor):\n     from jina.hubble.hubio import HubExecutor, HubIO\n \n     mock = mocker.Mock()\n \n     def _mock_fetch(\n         name,\n-        tag=None,\n-        secret=None,\n+        tag,\n         image_required=True,\n         rebuild_image=True,\n+        *,\n+        secret=None,\n         force=False,\n     ):\n         mock(name=name)\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -896,7 +896,7 @@ def test_fetch_with_no_image(mocker, monkeypatch):\n \n     monkeypatch.setattr(requests, 'post', _mock_post)\n \n-    with pytest.raises(Exception) as exc_info:\n+    with pytest.raises(RuntimeError) as exc_info:\n         HubIO.fetch_meta('dummy_mwu_encoder', tag=None, force=True)\n \n     assert exc_info.match('No image found for executor \"dummy_mwu_encoder\"')\n@@ -973,10 +973,11 @@ def test_pull(mocker, monkeypatch, executor_name, build_env):\n \n     def _mock_fetch(\n         name,\n-        tag=None,\n-        secret=None,\n+        tag,\n         image_required=True,\n         rebuild_image=True,\n+        *,\n+        secret=None,\n         force=False,\n         build_env=build_env,\n     ):\n@@ -1036,6 +1037,8 @@ class MockDockerClient:\n     def pull(self, repository: str, stream: bool = True, decode: bool = True):\n         if self.fail_pull:\n             raise docker.errors.APIError('Failed pulling docker image')\n+        elif not repository:\n+            raise docker.errors.NullResource('Resource ID was not provided')\n         else:\n             yield {}\n \n@@ -1045,25 +1048,32 @@ def test_offline_pull(mocker, monkeypatch, tmpfile):\n \n     fail_meta_fetch = True\n     version = 'v0'\n+    no_image = False\n \n     @disk_cache_offline(cache_file=str(tmpfile))\n     def _mock_fetch(\n         name,\n-        tag=None,\n-        secret=None,\n+        tag,\n         image_required=True,\n         rebuild_image=True,\n+        *,\n+        secret=None,\n         force=False,\n     ):\n         mock(name=name)\n+        fixed_tag = tag or 'latest'\n         if fail_meta_fetch:\n             raise urllib.error.URLError('Failed fetching meta')\n+        elif no_image and image_required:\n+            raise RuntimeError('No image error')\n         else:\n             return HubExecutor(\n                 uuid='dummy_mwu_encoder',\n                 name='alias_dummy',\n-                tag='v0',\n-                image_name=f'jinahub/pod.dummy_mwu_encoder:{version}',\n+                tag=fixed_tag,\n+                image_name=None\n+                if (not image_required or no_image)\n+                else f'jinahub/pod.dummy_mwu_encoder:{fixed_tag}:{version}',\n                 md5sum=None,\n                 visibility=True,\n                 archive_url=None,\n@@ -1097,24 +1107,77 @@ def test_offline_pull(mocker, monkeypatch, tmpfile):\n     monkeypatch.setattr(\n         HubIO, '_load_docker_client', _gen_load_docker_client(fail_pull=False)\n     )\n-    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:v0'\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:latest:v0'\n \n     version = 'v1'\n     # expect successful forced pull because force == True\n-    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:v1'\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:latest:v1'\n \n     # expect successful pull using cached fetch_meta response and saved image\n     fail_meta_fetch = True\n     monkeypatch.setattr(\n         HubIO, '_load_docker_client', _gen_load_docker_client(fail_pull=False)\n     )\n-    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:v1'\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:latest:v1'\n \n     args.force_update = False\n     fail_meta_fetch = False\n     version = 'v2'\n     # expect successful but outdated pull because force == False\n-    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:v1'\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:latest:v1'\n+\n+    # Tagged image should work similarly\n+    args = set_hub_pull_parser().parse_args(\n+        ['jinahub+docker://dummy_mwu_encoder/tagged']\n+    )\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:tagged:v2'\n+\n+    version = 'v3'\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:tagged:v2'\n+\n+    no_image = True\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:tagged:v2'\n+\n+    # Image may be absent, this should throw RuntimeError from fetch_meta\n+    no_image = True\n+    args = set_hub_pull_parser().parse_args(\n+        ['jinahub+docker://dummy_mwu_encoder/tagged2']\n+    )\n+    # This exception is raised from fetch_meta\n+    with pytest.raises(RuntimeError):\n+        HubIO(args).pull()\n+\n+    no_image = False\n+    # The exception should not be cached\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:tagged2:v3'\n+\n+    version = 'v4'\n+    args = set_hub_pull_parser().parse_args(\n+        ['jinahub+sandbox://dummy_mwu_encoder/tagged3']\n+    )\n+    # Expect `jinahub+sandbox` not pull-able, but the fetch_meta should succeed and\n+    # cache should have been saved properly\n+    # So it must raises ValueError instead of RuntimeError\n+    with pytest.raises(ValueError):\n+        HubIO(args).pull()\n+\n+    no_image = True\n+    args = set_hub_pull_parser().parse_args(\n+        ['jinahub+docker://dummy_mwu_encoder/tagged3']\n+    )\n+    # The cache for `jinahub+sandbox` should not work for `jinahub+docker`\n+    # Expect RuntimeError from fetch_meta\n+    with pytest.raises(RuntimeError):\n+        HubIO(args).pull()\n+\n+    # After meta fixed the pull should be successful\n+    no_image = False\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:tagged3:v4'\n+\n+    no_image = True\n+    version = 'v5'\n+    # Cache should work after first success\n+    assert HubIO(args).pull() == 'docker://jinahub/pod.dummy_mwu_encoder:tagged3:v4'\n \n \n def test_pull_with_progress():\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_docker_compose_pod_config.py | file path B: tests/unit/orchestrate/deployments/config/test_docker_compose_pod_config.py\n\n@@ -418,10 +418,11 @@ def test_docker_compose_yaml_regular_deployment(\n ):\n     def _mock_fetch(\n         name,\n-        tag=None,\n-        secret=None,\n+        tag,\n         image_required=True,\n         rebuild_image=True,\n+        *,\n+        secret=None,\n         force=False,\n     ):\n         return (\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_helper.py | file path B: tests/unit/orchestrate/deployments/config/test_helper.py\n\n@@ -47,10 +47,11 @@ def test_get_image_name(mocker, monkeypatch):\n \n     def _mock_fetch(\n         name,\n-        tag=None,\n-        secret=None,\n+        tag,\n         image_required=True,\n         rebuild_image=True,\n+        *,\n+        secret=None,\n         force=False,\n     ):\n         mock(name=name, rebuild_image=rebuild_image)\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py | file path B: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py\n\n@@ -394,10 +394,11 @@ def test_k8s_yaml_regular_deployment(\n ):\n     def _mock_fetch(\n         name,\n-        tag=None,\n-        secret=None,\n+        tag,\n         image_required=True,\n         rebuild_image=True,\n+        *,\n+        secret=None,\n         force=False,\n     ):\n         return (\n\n\n###\n\n", "completion": "fix(hubio.fetch_meta): move significant params to sequential (#<issue-num>)"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -1148,9 +1148,23 @@ class GrpcConnectionPool:\n         Documentation is here https://github.com/grpc/grpc/blob/master/include/grpc/impl/codegen/grpc_types.h\n         :returns: list of tuples defining grpc parameters\n         \"\"\"\n+\n         return [\n             ('grpc.max_send_message_length', -1),\n             ('grpc.max_receive_message_length', -1),\n+            # for the following see this blog post for the choice of default value https://cs.mcgill.ca/~mxia3/2019/02/23/Using-gRPC-in-Production/\n+            ('grpc.keepalive_time_ms', 10000),\n+            # send keepalive ping every 10 second, default is 2 hours.\n+            ('grpc.keepalive_timeout_ms', 5000),\n+            # keepalive ping time out after 5 seconds, default is 20 seconds\n+            ('grpc.keepalive_permit_without_calls', True),\n+            # allow keepalive pings when there's no gRPC calls\n+            ('grpc.http2.max_pings_without_data', 0),\n+            # allow unlimited amount of keepalive pings without data\n+            ('grpc.http2.min_time_between_pings_ms', 10000),\n+            # allow grpc pings from client every 10 seconds\n+            ('grpc.http2.min_ping_interval_without_data_ms', 5000),\n+            # allow grpc pings from client without data every 5 seconds\n         ]\n \n     @staticmethod\n\n\n###\n\n", "completion": "feat: use default grpc parameters for grpc connection pool connection (#<issue-num>)"}
{"prompt": " file path A: docs/get-started/what-is-cross-modal-multi-modal.md | file path B: docs/get-started/what-is-cross-modal-multi-modal.md\n\n@@ -9,26 +9,25 @@ A video version of this chapter is available below.\n \n ## Beyond single modality\n \n-The term \"Modal\" is the shorthand for \"Data Modality\". Data modality can be thought of as the \"type\" of data. For example, a tweet is a modal of type \"text\"; a photo is a modal of type \"image\"; a video is a modal of type \"video\"; etc.\n-\n-In the early days of AI, research was focused on a single modality, such as vision or language. For example, a spam filter is focused on text modality. A photo classifier is focused on image modality. A music recommender is focused on audio modality.  However, it soon became clear that in order to create truly intelligent systems, AI must be able to integrate multiple modalities.As in the real world, data is often multimodal, meaning that it consists of multiple modalities. For example, a tweet often contains not only text, but also images, videos, and links. A video often contains not only video frames, but also audio and text (e.g., subtitles). This led to the development of cross-modality and multi-modality in AI.\n+The term \"Modal\" is shorthand for \"Data Modality\". Data modality can be thought of as the \"type\" of data. For example, a tweet is a modal of type \"text\"; a photo is a modal of type \"image\"; a video is a modal of type \"video\"; etc.\n \n+In the early days of AI, research was focused on a single modality, such as vision or language. For example, a spam filter is focused on text modality. A photo classifier is focused on image modality. A music recommender is focused on audio modality.  However, it soon became clear that in order to create truly intelligent systems, AI must be able to integrate multiple modalities. In the real world, data is often multimodal, meaning that it consists of multiple modalities. For example, a tweet often contains not only text, but also images, videos, and links. A video often contains not only video frames, but also audio and text (e.g. subtitles). This has led to the development of cross-modality and multi-modality in AI.\n \n **Multi-modal** machine learning is a relatively new field that is concerned with the development of algorithms that can learn from multiple modalities of data.\n \n **Cross-modal** machine learning is a subfield of multi-modal machine learning that is concerned with the development of algorithms that can learn from multiple modalities of data that are not necessarily aligned. For example, learning from images and text where the images and text are not necessarily about the same thing.\n \n-Thanks to recent advances in deep neural networks, cross-modal or multi-modal technologies enable advanced intelligence on all kinds of unstructured data, such as images, audio, video, PDF, 3D mesh. \n+Thanks to recent advances in deep neural networks, cross-modal or multi-modal technologies enable advanced intelligence on all kinds of unstructured data, such as images, audio, video, PDF, 3D meshes, and more. \n \n Cross-modality and multi-modality are two terms that are often used interchangeably, but there is a big difference between the two. Multi-modality refers to the ability of a system to use multiple modalities, or input channels, to achieve a desired goal. For example, a human can use both sight and hearing to identify a person or object. In contrast, cross-modality refers to the ability of a system to use information from one modality to improve performance in another modality. For example, if you see a picture of a dog, you might be able to identify it by its bark when you hear it.\n \n AI systems that are designed to work with multiple modalities are said to be \"multi-modal.\" However, the term \"cross-modality\" is more accurate when referring to AI systems that use information from one modality to improve performance in another.\n \n-In general, cross-modal and multi-modal technologies allow for a more holistic understanding of the data, as well as increased accuracy and efficiency.\n+In general, cross-modal and multi-modal technologies allow for a more holistic understanding of data, as well as increased accuracy and efficiency.\n \n ## Applications\n \n-There are many potential applications of cross-modal & multi-modal machine learning. For example, a cross-modal machine learning algorithm could be used to automatically generate descriptions of images (e.g., for blind people). A search system could use a cross-modal machine learning algorithm to search for images by text queries (e.g., \"find me a picture of a dog\"). A text-to-image generation system could use a cross-modal machine learning algorithm to generate images from text descriptions (e.g., \"generate an image of a dog\").\n+There are many potential applications of cross-modal and multi-modal machine learning. For example, a cross-modal machine learning algorithm could be used to automatically generate descriptions of images (e.g. for blind people). A search system could use a cross-modal machine learning algorithm to search for images by text queries (e.g. \"find me a picture of a dog\"). A text-to-image generation system could use a cross-modal machine learning algorithm to generate images from text descriptions (e.g. \"generate an image of a dog\").\n \n Cross-modal AI systems have the potential to greatly improve the performance of AI systems by making them more flexible and robust. For example, a cross-modal system could be used to improve the accuracy of facial recognition algorithms by using information from other modalities such as body language or voice. Another potential application is using information from one modality to compensate for the limitations of another. For example, if an image recognition algorithm is having difficulty identifying an object due to poor lighting conditions, information from another modality such as sound could be used to help identify the object.\n \n@@ -38,8 +37,7 @@ Under this big umbrella sits two families of applications: neural search and cre\n \n One of the most promising applications of cross-modal machine learning is neural search. The core idea of neural search is to leverage state-of-the-art deep neural networks to build every component of a search system. In short, **neural search is deep neural network-powered information retrieval**. In academia, it\u2019s often called neural IR.\n \n-\n-Below is an example of image embedding space generated by [DocArray](https://github.com/jina-ai/docarray)(the data structure behind Jina) and used for content-based image retrieval. Notice how similar images are mapped together in the embedding space.\n+Below is an example of image embedding space generated by [DocArray](https://github.com/jina-ai/docarray) (the data structure behind Jina) and used for content-based image retrieval. Notice how similar images are mapped together in the embedding space.\n \n ```{figure} https://github.com/jina-ai/docarray/raw/main/.github/README-img/tsne.gif?raw=true\n ```\n@@ -64,7 +62,7 @@ left/02262.jpg right/04520.jpg 0.16477376\n ...\n ```\n \n-Neural search is particularly well suited to cross-modal search tasks, because it can learn to map the features of one modality (e.g., text) to the features of another modality (e.g., images). This enables neural search engines to search for documents and images by text queries, and to search for text documents by image queries.\n+Neural search is particularly well suited to cross-modal search tasks, because it can learn to map the features of one modality (e.g. text) to the features of another modality (e.g. images). This enables neural search engines to search for documents and images by text queries, and to search for text documents by image queries.\n \n \n #### Think outside the (search) box\n@@ -81,9 +79,9 @@ Neural search creates a new way to comprehend the world. It is creating new door\n \n ### Creative AI\n \n-Another potential application of cross-modal machine learning is creative AI. Creative AI systems use artificial intelligence to generate new content, such as images, videos, or text. For example, Open AI GPT3 is a machine learning platform that can generate text. The system is trained on a large corpus of text, such as books, articles, and websites. Once trained, the system can generate new text that is similar to the training data. This can be used to generate new articles, stories, or even poems.\n+Another potential application of cross-modal machine learning is creative AI. Creative AI systems use artificial intelligence to generate new content, such as images, videos, or text. For example, Open AI GPT-3 is a machine learning platform that can generate text. The system is trained on a large corpus of text, such as books, articles, and websites. Once trained, the system can generate new text that is similar to the training data. This can be used to generate new articles, stories, or even poems.\n \n-Open AI DALLE is another example of a creative AI system. This system generates images from textual descriptions. For example, given the text \"a black cat with green eyes\", the system will generate an image of a black cat with green eyes. Below is an example of generating images from a text prompt using [DALL\u00b7E Flow](https://github.com/jina-ai/dalle-flow)(a text-to-image system built on top of Jina).\n+OpenAI's DALL\u00b7E is another example of a creative AI system. This system generates images from textual descriptions. For example, given the text \"a black cat with green eyes\", the system will generate an image of a black cat with green eyes. Below is an example of generating images from a text prompt using [DALL\u00b7E Flow](https://github.com/jina-ai/dalle-flow) (a text-to-image system built on top of Jina).\n \n \n ```python\n@@ -104,10 +102,10 @@ da.plot_image_sprites(fig_size=(10, 10), show_index=True)\n \n Creative AI holds great potential for the future.  It has the potential to revolutionize how we interact with machines, helping us create more personalized experiences, e.g.:\n \n-- create realistic 3D images and videos of people and objects, which can be used in movies, video games, and other visual media.\n-- generate realistic and natural-sounding dialogue, which can be used in movies, video games, and other forms of entertainment.\n-- create new and innovative designs for products, which can be used in manufacturing and other industries.\n-- create new and innovative marketing campaigns, which can be used in advertising and other industries.\n+- Create realistic 3D images and videos of people and objects, which can be used in movies, video games, and other visual media.\n+- Generate realistic and natural-sounding dialogue, which can be used in movies, video games, and other forms of entertainment.\n+- Create new and innovative designs for products, which can be used in manufacturing and other industries.\n+- Create new and innovative marketing campaigns, which can be used in advertising and other industries.\n \n ## Relationship is the key \n \n@@ -115,7 +113,7 @@ So what ties neural search and creative AI together?\n \n **The \"relationship\" between or within modalities.**\n \n-What is the \"relationship\" are we talking about now? Let's see the following illustration , where we managed to represent text \"cat\", \"dog\", \"human\", \"ape\" and their images into one embedding space:\n+What is this \"relationship\" are we talking about now? Let's see the following illustration, where we managed to represent text \"cat\", \"dog\", \"human\", \"ape\" and their images into one embedding space:\n \n ```{figure} relationship.svg\n :scale: 80%\n@@ -129,14 +127,14 @@ The \"relationship\" encodes the following information:\n - The image embedding of \"cat\" is closer to the image embedding of \"dog\" (same modality);\n - etc.\n \n-Don't underestimate the power of this relationship. It is the foundation of neural search and creative AI. It is like the DNA of species. Once mastered, it can be used to find the closest match to any other species, and create new species!\n+Don't underestimate the power of this relationship. It is the foundation of neural search and creative AI. It is like the DNA of a species. Once mastered, it can be used to find the closest match to any other species, and create new species!\n \n ```{figure} dna.png\n :width: 80%\n ```\n \n-In summary, the key of cross-modal and multi-modal application is to understand the relationship between modalities. With the relationship, one can use it to **find existing data**, which is **neural search**; or use it to **make new data**, which is **creative AI**.\n+In summary, the key of cross-modal and multi-modal applications is to understand the relationship between modalities. With this relationship, one can use it to **find existing data**, which is **neural search**; or use it to **make new data**, which is **creative AI**.\n \n-In the {ref}`next chapter<what-is-jina>`, we will see how Jina is the proper tool for building cross-modal and multi-modal applications on the cloud.\n+In the {ref}`next chapter<what-is-jina>`, we will see how Jina is the ideal tool for building cross-modal and multi-modal applications on the cloud.\n \n \n\n\n###\n\n", "completion": "docs(what-is-modality): fix grammar, punctuation (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -205,6 +205,26 @@ with:\n         - fine-tuning\n ```\n ````\n+\n+However, if you want to send requests to a different Executor endpoint, you can still do it without exposing it in the HTTP endpoint, by sending an HTTP request to the `/post` HTTP endpoint while setting  \n+`execEndpoint` in the request.\n+\n+```text\n+curl --request POST \\\n+'http://localhost:12345/post' \\\n+--header 'Content-Type: application/json' -d '{\"data\": [{\"text\": \"hello world\"}], \"execEndpoint\": \"/foo\"}'\n+```\n+\n+The above cURL command is equivalent to passing the `on` parameter to `client.post` as follows:\n+\n+```python\n+from docarray import DocumentArray, Document\n+from jina import Client\n+\n+client = Client(port=12345, protocol='http')\n+client.post(on='/foo', inputs=DocumentArray([Document(text='hello world')]))\n+```\n+\n ### Hide default endpoints\n \n It is possible to hide the default CRUD and debug endpoints in production. This might be useful when the context is not applicable.\n\n\n###\n\n", "completion": "docs: clarify exec endpoint usage in http (#<issue-num>)"}
{"prompt": " file path A: jina/logging/logger.py | file path B: jina/logging/logger.py\n\n@@ -120,11 +120,10 @@ class JinaLogger:\n         **kwargs,\n     ):\n \n-        if not log_config:\n-            log_config = os.getenv(\n-                'JINA_LOG_CONFIG',\n-                'default',\n-            )\n+        log_config = os.getenv(\n+            'JINA_LOG_CONFIG',\n+            log_config or 'default',\n+        )\n \n         if quiet or os.getenv('JINA_LOG_CONFIG', None) == 'QUIET':\n             log_config = 'quiet'\n\n---\n file path A: None | file path B: jina/resources/logging.json.yml\n\n@@ -0,0 +1,7 @@\n+handlers:\n+  - StreamHandler\n+level: INFO\n+configs:\n+  StreamHandler:\n+    format: '%(asctime)s:{name:>15}@%(process)2d[%(levelname).1s]:%(message)s'\n+    formatter: JsonFormatter\n\n\n###\n\n", "completion": "feat(logs): json logging for jcloud (#<issue-num>)"}
{"prompt": " file path A: jina/jaml/helper.py | file path B: jina/jaml/helper.py\n\n@@ -188,7 +188,6 @@ def parse_config_source(\n     ):\n         # possible module.class name\n         module_name, cls_name = path.rsplit('.', maxsplit=1)\n-        print(module_name, cls_name)\n         PathImporter.add_modules(module_name)\n         return io.StringIO(f'!{cls_name}'), None\n     elif allow_json and isinstance(path, str):\n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -657,7 +657,6 @@ class Deployment(BaseDeployment):\n         :param replicas: the number of replicas\n         :return: a map from replica id to device id\n         \"\"\"\n-        print(f' device_str {device_str}')\n         if (\n             device_str\n             and isinstance(device_str, str)\n@@ -679,7 +678,6 @@ class Deployment(BaseDeployment):\n                     selected_devices.append(device_num)\n             else:\n                 selected_devices = range(num_devices)\n-            print(f' selected devices {selected_devices}')\n             _c = cycle(selected_devices)\n             return {j: next(_c) for j in range(replicas)}\n \n\n\n###\n\n", "completion": "fix: remove leftover prints (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/client/client.md | file path B: docs/fundamentals/client/client.md\n\n@@ -128,7 +128,7 @@ Client(host='my.awesome.flow', port=1234, protocol='grpc', tls=True)\n ````\n \n \n-You can also use a mixe of both:\n+You can also use a mix of both:\n \n ```python\n from jina import Client\n@@ -148,6 +148,15 @@ Client(host='https://my.awesome.flow:1234', port=4321)\n ```\n ````\n \n+````{admonition} Caution\n+:class: caution\n+In case you instanciate a `Client` object using the `grpc` protocol, keep in mind that `grpc` clients cannot be used in \n+a multi-threaded environment (check [this gRPC issue](https://github.com/grpc/grpc/issues/25364) for reference).\n+What you should do, is to rely on asynchronous programming or multi-processing rather than multi-threading.\n+For instance, if you're building a web server, you can introduce multi-processing based parallelism to your app using \n+`gunicorn`: `gunicorn main:app --workers 4 --worker-class uvicorn.workers.UvicornWorker ...`\n+````\n+\n \n \n ## Test readiness of the Flow\n\n\n###\n\n", "completion": "docs: document grpc client limitation (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -61,6 +61,10 @@ If you have no access to the web browser in your integration environment, you ca\n \n In Jina's idiom, a project is a [Flow](https://docs.jina.ai/fundamentals/flow/), which represents an end-to-end task such as indexing, searching or recommending. In this README, we will use \"project\" and \"Flow\" interchangeably.\n \n+```{caution}\n+Flows have a maximal {ref}`lifetime<jcloud-lifetime>` after which they are automatically deleted.\n+```\n+\n A Flow can have two types of file structure: a single YAML file or a project folder.\n \n #### A single YAML file\n@@ -286,17 +290,16 @@ JCLOUD_LOGLEVEL=DEBUG jc deploy flow.yml\n \n If you don't see any obvious errors, please raise an issue in [JCloud](https://github.com/jina-ai/jcloud/issues/new/choose)\n \n-## FAQ\n-\n-- **Is everything free?**\n-\n-  Yes at the moment! We just need your feedback - use `jc survey` to help us understand your needs.\n+## Restrictions\n \n-- **How powerful is JCloud?**\n+JCloud scales according to your need. You can demand different resources (GPU / RAM / CPU / Storage / instance-capacity) your Flows & Executors need. We have the following restrictions on its usage. If you have specific resource requirements, please contact us [on Slack](https://slack.jina.ai) or raise a [Github issue](https://github.com/jina-ai/jcloud/issues/new/choose).\n \n-  JCloud scales according to your need. You can demand all the resources (GPU / RAM / CPU / Storage / instance-capacity) your Flows & Executors need. If there's anything particular you'd be looking for, you can contact us [on Slack](https://slack.jina.ai) or let us know via `jc survey`.\n \n-- **What restrictions are there on JCloud?**\n-\n-  - Deployments are only supported in `us-east` region.\n-  - Each Executor is allowed a maximum of 4 GPUs, 16G RAM, 16 CPU cores & 10GB of block storage.\n+```{admonition} Restrictions\n+  \n+- Deployments are only supported in `us-east` region.\n+- Each Executor is allowed a maximum of 4G RAM, 2 CPU cores & 10GB of block storage.\n+- 3 Flows can be deployed at a time, out of which there can be 1 Flow using GPU.\n+- A maximum of 2 GPUs are allowed per Flow.\n+- Flows with Executors using GPU are removed after 12hrs, whereas other Flows are removed after 72hrs.\n+```\n\n---\n file path A: docs/fundamentals/jcloud/yaml-spec.md | file path B: docs/fundamentals/jcloud/yaml-spec.md\n\n@@ -40,7 +40,7 @@ By default, `0.1 (1/10 of a core)` CPU is allocated to each Executor. You can us\n \n JCloud offers the general Intel Xeon processor (Skylake 8175M or Cascade Lake 8259CL) by default. \n \n-```{note}\n+```{hint}\n Maximum of 16 cores is allowed per Executor.\n ```\n \n@@ -62,8 +62,8 @@ JCloud supports GPU workloads with two different usages: `shared` or `dedicated`\n \n If GPU is enabled, JCloud will provide NVIDIA A10G Tensor Core GPUs with 24G memory for workloads in both usage types.\n \n-```{note}\n-When using GPU resources, it may take few extra mins until all Executors ready to serve traffic.\n+```{hint}\n+When using GPU resources, it may take a few extra minutes before all Executors are ready to serve traffic.\n ```\n \n #### Shared GPU\n@@ -116,7 +116,7 @@ executors:\n \n By default, `100M` of RAM is allocated to each Executor. You can use `memory` arg under `resources` to customise it.\n \n-```{note}\n+```{hint}\n Maximum of 16G RAM is allowed per Executor.\n ```\n \n@@ -135,7 +135,7 @@ executors:\n \n JCloud supports 2 kinds of Storage types [efs](https://aws.amazon.com/efs/) (default) and [ebs](https://aws.amazon.com/ebs/). The former one is a network file storage, whereas the latter is a block device.\n \n-````{note}\n+````{hint}\n \n By default, we attach an `efs` to all the Executors in a Flow. The benefits of doing so are\n \n@@ -193,7 +193,7 @@ executors:\n \n JCloud autoscaling leverages [Knative](https://knative.dev/docs/) behind the scenes, and `jinahub+serverless` uses a set of Knative configurations as defaults.\n \n-```{note}\n+```{hint}\n For more information about the Knative Autoscaling configurations, please visit [Knative Autoscaling](https://knative.dev/docs/serving/autoscaling/).\n ```\n \n@@ -221,7 +221,7 @@ executors:\n Below are the defaults and requirements for the configurations:\n \n | Name   | Default     | Allowed                  | Description                                     |\n-|--------|-------------|--------------------------|-------------------------------------------------|\n+| ------ | ----------- | ------------------------ | ----------------------------------------------- |\n | min    | 1           | int                      | Minimum number of replicas (0 means serverless) |\n | max    | 2           | int, up to 5             | Maximum number of replicas                      |\n | metric | concurrency | `concurrency`  /   `rps` | Metric for scaling                              |\n@@ -237,8 +237,8 @@ To expose users' Flows to the public Internet with TLS, JCloud provides support\n \n In JCloud. We use [Let's Encrypt](https://letsencrypt.org/) for TLS.\n \n-```{note}\n-The JCloud gateway is different from Jina's Gateway. In JCloud, a gateway works as a proxy to distribute internet traffic between Flows, each of which has a Jina Gateway (which is responsible to manage external gRPC/HTTP/Websocket traffic to your Executors)\n+```{hint}\n+The JCloud gateway is different from Jina's Gateway. In JCloud, a gateway works as a proxy to distribute internet traffic between Flows, each of which has a Jina Gateway (which is responsible for managing external gRPC/HTTP/Websocket traffic to your Executors)\n ```\n \n ### Set timeout\n@@ -341,7 +341,7 @@ executors:\n     uses: jinahub+docker://Executor1\n ```\n \n-```{note}\n+```{hint}\n \n Keys in `labels` have the following restrictions.\n   - Must be 63 characters or less.\n@@ -351,27 +351,3 @@ Keys in `labels` have the following restrictions.\n     - jina-version\n     - retention-days\n ```\n-\n-\n-### Lifetime\n-\n-A Flow that receives no traffic in 24 hours will be automatically deleted by default.\n-\n-To ignore the lifetime reclaim policy of a Flow, you can use the `retention_days` parameter in the Flow yaml. `retention_days` will keep the flow alive for `x` days (0<x<365). flows is going to be removed after `x` days regardless of above reclaim policy. `-1` is to keep the flow alive regardless of the reclaim policy.\n-\n-```{note}\n-- If {ref}`retention-days <retention-days>` argument configured as `x` (0<x<365). Flows will be removed after `retention-days`, regradless of the usage.\n-\n-- If {ref}`retention-days <retention-days>` argument configured as `-1`. Flows will not be removed, regradless of the usage.\n-\n-- If {ref}`retention-days <retention-days>` argument not configured, or set to `0`. We will detect if flows are idle daily, they will be terminated if they are not serving requests for the last 24hrs.\n-```\n-\n-```yaml\n-jtype: Flow\n-jcloud:\n-  retention_days: 7\n-executors:\n-  - name: executor1\n-    uses: jinahub+docker://Executor1\n-```\n\\ No newline at end of file\n\n\n###\n\n", "completion": "docs(jcloud): update faq and lifetime (#<issue-num>)"}
{"prompt": " file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -141,16 +141,12 @@\n                             </div>\n                             <div class=\"title\">{{ next.title }}</div>\n                         </div>\n-                        <svg>\n-                            <use href=\"#svg-arrow-right\"></use>\n-                        </svg>\n+                        <svg class=\"furo-related-icon\"><use href=\"#svg-arrow-right\"></use></svg>\n                     </a>\n                     {%- endif %}\n                     {% if prev -%}\n                     <a class=\"prev-page\" href=\"{{ prev.link }}\">\n-                        <svg>\n-                            <use href=\"#svg-arrow-right\"></use>\n-                        </svg>\n+                        <svg class=\"furo-related-icon\"><use href=\"#svg-arrow-right\"></use></svg>\n                         <div class=\"page-info\">\n                             <div class=\"context\">\n                                 <span>{{ _(\"Previous\") }}</span>\n\n\n###\n\n", "completion": "chore: fix doc template"}
{"prompt": " file path A: docs/fundamentals/flow/topologies.md | file path B: docs/fundamentals/flow/topologies.md\n\n@@ -149,6 +149,17 @@ You can also restrict the visible devices in round-robin assignment by `CUDA_VIS\n | 0          | 4          |\n \n \n+You can also restrict the visible devices in round-robin assignment by assigning a list of devices ids `CUDA_VISIBLE_DEVICES=RR1,3`. This will create the following assignment:\n+\n+| GPU device | Replica ID |\n+|------------|------------|\n+| 1          | 0          |\n+| 3          | 1          |\n+| 1          | 2          |\n+| 3          | 3          |\n+| 1          | 4          |\n+\n+\n (partition-data-by-using-shards)=\n ## Partition data with shards\n \n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -622,25 +622,32 @@ class Deployment(BaseDeployment):\n         return is_ready\n \n     @staticmethod\n-    def _parse_slice(value: str):\n-        \"\"\"Parses a `slice()` from string, like `start:stop:step`.\n+    def _parse_devices(value: str, num_devices: int):\n+        \"\"\"Parses a list of devices from string, like `start:stop:step` or 'num1,num2,num3` or combination of both.\n \n         :param value: a string like\n+        :param num_devices: total number of devices\n         :return: slice\n         \"\"\"\n+\n+        all_devices = range(num_devices)\n         if re.match(WRAPPED_SLICE_BASE, value):\n             value = value[1:-1]\n \n         if value:\n-            parts = value.split(':')\n+            parts = value.split(',')\n             if len(parts) == 1:\n-                # slice(stop)\n-                parts = [parts[0], str(int(parts[0]) + 1)]\n-            # else: slice(start, stop[, step])\n+                parts = value.split(':')\n+\n+                if len(parts) == 1:\n+                    # slice(stop)\n+                    parts = [parts[0], str(int(parts[0]) + 1)]\n+                # else: slice(start, stop[, step])\n+            else:\n+                return [int(p) for p in parts]\n         else:\n-            # slice()\n             parts = []\n-        return slice(*[int(p) if p else None for p in parts])\n+        return all_devices[slice(*[int(p) if p else None for p in parts])]\n \n     @staticmethod\n     def _roundrobin_cuda_device(device_str: str, replicas: int):\n@@ -650,6 +657,7 @@ class Deployment(BaseDeployment):\n         :param replicas: the number of replicas\n         :return: a map from replica id to device id\n         \"\"\"\n+        print(f' device_str {device_str}')\n         if (\n             device_str\n             and isinstance(device_str, str)\n@@ -665,11 +673,14 @@ class Deployment(BaseDeployment):\n                 if num_devices == 0:\n                     return\n \n-            all_devices = list(range(num_devices))\n+            selected_devices = []\n             if device_str[2:]:\n-                all_devices = all_devices[Deployment._parse_slice(device_str[2:])]\n-\n-            _c = cycle(all_devices)\n+                for device_num in Deployment._parse_devices(device_str[2:], num_devices):\n+                    selected_devices.append(device_num)\n+            else:\n+                selected_devices = range(num_devices)\n+            print(f' selected devices {selected_devices}')\n+            _c = cycle(selected_devices)\n             return {j: next(_c) for j in range(replicas)}\n \n     @staticmethod\n\n---\n file path A: tests/unit/orchestrate/deployments/test_cuda_assignment.py | file path B: tests/unit/orchestrate/deployments/test_cuda_assignment.py\n\n@@ -5,21 +5,33 @@ import pytest\n from jina.orchestrate.deployments import Deployment\n \n \n+@pytest.fixture()\n+def cuda_total_devices(request):\n+    old_cuda_total_devices = os.environ.get('CUDA_TOTAL_DEVICES', None)\n+    os.environ['CUDA_TOTAL_DEVICES'] = str(request.param)\n+    yield\n+    if old_cuda_total_devices is not None:\n+        os.environ['CUDA_TOTAL_DEVICES'] = old_cuda_total_devices\n+    else:\n+        os.unsetenv('CUDA_TOTAL_DEVICES')\n+\n+\n @pytest.mark.parametrize(\n-    'device_str, replicas, expected',\n+    'device_str, replicas, expected, cuda_total_devices',\n     [\n-        ['1', 1, None],  # wont trigger device RB\n-        ['1', 2, None],  # wont trigger device RB\n-        ['1,2', 2, None],  # wont trigger device RB\n-        ['RR', 2, {0: 0, 1: 1}],\n-        ['RR', 5, {0: 0, 1: 1, 2: 2, 3: 0, 4: 1}],\n-        ['RR1:', 5, {0: 1, 1: 2, 2: 1, 3: 2, 4: 1}],\n-        ['RR0:2', 5, {0: 0, 1: 1, 2: 0, 3: 1, 4: 0}],\n-        ['RR1:2', 2, {0: 1, 1: 1}],\n-        ['RR1:2', 1, {0: 1}],\n-    ],\n+        ['1', 1, None, 3],  # wont trigger device RB\n+        ['1', 2, None, 3],  # wont trigger device RB\n+        ['1,2', 2, None, 3],  # wont trigger device RB\n+        ['RR', 2, {0: 0, 1: 1}, 3],\n+        ['RR', 5, {0: 0, 1: 1, 2: 2, 3: 0, 4: 1}, 3],\n+        ['RR1:', 5, {0: 1, 1: 2, 2: 1, 3: 2, 4: 1}, 3],\n+        ['RR0:2', 5, {0: 0, 1: 1, 2: 0, 3: 1, 4: 0}, 3],\n+        ['RR1:2', 2, {0: 1, 1: 1}, 3],\n+        ['RR1:2', 1, {0: 1}, 3],\n+        ['RR0,2,3', 3, {0: 0, 1: 2, 2: 3}, 4],\n+        ['RR0,2,3', 5, {0: 0, 1: 2, 2: 3, 3: 0, 4: 2}, 4],\n+    ], indirect=['cuda_total_devices']\n )\n-def test_cuda_assignment(device_str, replicas, expected):\n-    os.environ['CUDA_TOTAL_DEVICES'] = str(3)\n+def test_cuda_assignment(device_str, replicas, expected, cuda_total_devices):\n     actual = Deployment._roundrobin_cuda_device(device_str, replicas)\n     assert actual == expected\n\n\n###\n\n", "completion": "feat: support list-like syntax to round robin CUDA devices (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/containerize-executor.md | file path B: docs/fundamentals/executor/containerize-executor.md\n\n@@ -64,8 +64,10 @@ the basic entrypoint of the image calls `jina executor` {ref}`CLI <../api/jina_c\n ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n ```\n \n-```{tip}\n-We **strongly encourage** you to name the Executor YAML as `config.yml`, otherwise using your containerize Executor with Kubernetes will require extra step.\n+```{note}\n+We **strongly encourage** you to name the Executor YAML as `config.yml`, otherwise using your containerize Executor with Kubernetes will require extra step. \n+When using {meth}`~jina.serve.executors.BaseExecutor.to_kubernetes_yaml()` or {meth}`~jina.serve.executors.BaseExecutor.to_docker_compose_yaml()`, Jina will add `--uses config.yml` in the entrypoint. \n+In order to change that, you will need to manually alter the generated files.\n ```\n \n ## Example: Dockerized Executor\n\n\n###\n\n", "completion": "docs: improve warning about config file in custom docker (#<issue-num>)"}
{"prompt": " file path A: scripts/get-openapi-schemas.py | file path B: scripts/get-openapi-schemas.py\n\n@@ -3,6 +3,7 @@ import json\n from jina.logging.logger import JinaLogger\n from jina.parsers import set_gateway_parser\n from jina.serve.runtimes.gateway.http.app import get_fastapi_app\n+from jina.serve.streamer import GatewayStreamer\n \n JINA_LOGO_URL = 'https://api.jina.ai/logo/logo-product/jina-core/horizontal-layout/colored/Product%20logo_Core_vertical_colorful%402x-margin.png'\n GATEWAY_SCHEMA_FILENAME = 'gateway.json'\n@@ -10,7 +11,27 @@ GATEWAY_SCHEMA_FILENAME = 'gateway.json'\n \n args = set_gateway_parser().parse_args([])\n logger = JinaLogger('')\n+\n+graph_description = json.loads(args.graph_description)\n+graph_conditions = json.loads(args.graph_conditions)\n+deployments_addresses = json.loads(args.deployments_addresses)\n+deployments_disable_reduce = json.loads(args.deployments_disable_reduce)\n+\n+streamer = GatewayStreamer(\n+    graph_representation=graph_description,\n+    executor_addresses=deployments_addresses,\n+    graph_conditions=graph_conditions,\n+    deployments_disable_reduce=deployments_disable_reduce,\n+    timeout_send=args.timeout_send,\n+    retries=args.retries,\n+    compression=args.compression,\n+    runtime_name=args.name,\n+    prefetch=args.prefetch,\n+    logger=logger,\n+)\n+\n gateway_app = get_fastapi_app(\n+    streamer=streamer,\n     title=args.title,\n     description=args.description,\n     no_debug_endpoints=args.no_debug_endpoints,\n@@ -18,7 +39,7 @@ gateway_app = get_fastapi_app(\n     expose_endpoints=args.expose_endpoints,\n     expose_graphql_endpoint=args.expose_graphql_endpoint,\n     cors=args.cors,\n-    logger=args.logger,\n+    logger=logger,\n )\n gateway_schema = gateway_app.openapi()\n gateway_schema['info']['x-logo'] = {'url': JINA_LOGO_URL}\n\n\n###\n\n", "completion": "fix: provide logger and streamer (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1654,10 +1654,11 @@ def _parse_ports(port: str) -> Union[int, List]:\n     return port\n \n \n-def send_telemetry_event(event: str, obj: Any) -> None:\n+def send_telemetry_event(event: str, obj: Any, **kwargs) -> None:\n     \"\"\"Sends in a thread a request with telemetry for a given event\n     :param event: Event leading to the telemetry entry\n     :param obj: Object to be tracked\n+    :param kwargs: Extra kwargs to be passed to the data sent\n     \"\"\"\n \n     if 'JINA_OPTOUT_TELEMETRY' in os.environ:\n@@ -1671,7 +1672,7 @@ def send_telemetry_event(event: str, obj: Any) -> None:\n             metas, _ = get_full_version()\n             data = base64.urlsafe_b64encode(\n                 json.dumps(\n-                    {**metas, 'event': f'{obj.__class__.__name__}.{event}'}\n+                    {**metas, 'event': f'{obj.__class__.__name__}.{event}', **kwargs}\n                 ).encode('utf-8')\n             )\n \n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1438,6 +1438,14 @@ class Flow(\n \n         self._build_level = FlowBuildLevel.EMPTY\n \n+        self._stop_time = time.time()\n+        send_telemetry_event(\n+            event='stop',\n+            obj=self,\n+            entity_id=self._entity_id,\n+            duration=self._stop_time - self._start_time,\n+            exc_type=str(exc_type),\n+        )\n         self.logger.debug('flow is closed!')\n         self.logger.close()\n \n@@ -1455,7 +1463,7 @@ class Flow(\n \n         :return: this instance\n         \"\"\"\n-\n+        self._start_time = time.time()\n         if self._build_level.value < FlowBuildLevel.GRAPH.value:\n             self.build(copy_flow=False)\n \n@@ -1479,7 +1487,7 @@ class Flow(\n \n         self._build_level = FlowBuildLevel.RUNNING\n \n-        send_telemetry_event(event='start', obj=self)\n+        send_telemetry_event(event='start', obj=self, entity_id=self._entity_id)\n \n         return self\n \n@@ -2407,3 +2415,12 @@ class Flow(\n             )\n \n         return obj\n+\n+    @property\n+    def _entity_id(self) -> str:\n+        import uuid\n+\n+        if hasattr(self, '_entity_id_'):\n+            return self._entity_id_\n+        self._entity_id_ = uuid.uuid1().hex\n+        return self._entity_id_\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -13,7 +13,6 @@ from jina.helper import (\n     ArgNamespace,\n     T,\n     iscoroutinefunction,\n-    send_telemetry_event,\n     typename,\n )\n from jina.importer import ImportExtensions\n@@ -151,7 +150,6 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             )\n         if type(self) == BaseExecutor:\n             self.requests[__default_endpoint__] = self._dry_run_func\n-        send_telemetry_event(event='start', obj=self)\n \n     def _dry_run_func(self, *args, **kwargs):\n         pass\n\n---\n file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -27,12 +27,12 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n     \"\"\"\n \n     def __init__(\n-        self,\n-        args: 'argparse.Namespace',\n-        cancel_event: Optional[\n-            Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n-        ] = None,\n-        **kwargs,\n+            self,\n+            args: 'argparse.Namespace',\n+            cancel_event: Optional[\n+                Union['asyncio.Event', 'multiprocessing.Event', 'threading.Event']\n+            ] = None,\n+            **kwargs,\n     ):\n         super().__init__(args, **kwargs)\n         self._loop = asyncio.new_event_loop()\n@@ -53,9 +53,9 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n                 )\n         else:\n             with ImportExtensions(\n-                required=True,\n-                logger=self.logger,\n-                help_text='''If you see a 'DLL load failed' error, please reinstall `pywin32`.\n+                    required=True,\n+                    logger=self.logger,\n+                    help_text='''If you see a 'DLL load failed' error, please reinstall `pywin32`.\n                 If you're using conda, please use the command `conda install -c anaconda pywin32`''',\n             ):\n                 import win32api\n@@ -65,7 +65,8 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n             )\n \n         self._setup_monitoring()\n-        send_telemetry_event(event='start', obj=self)\n+        send_telemetry_event(event='start', obj=self, entity_id=self._entity_id)\n+        self._start_time = time.time()\n         self._loop.run_until_complete(self.async_setup())\n \n     def run_forever(self):\n@@ -82,6 +83,8 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n         self._loop.stop()\n         self._loop.close()\n         super().teardown()\n+        self._stop_time = time.time()\n+        send_telemetry_event(event='stop', obj=self, duration=self._stop_time - self._start_time, entity_id=self._entity_id)\n \n     async def _wait_for_cancel(self):\n         \"\"\"Do NOT override this method when inheriting from :class:`GatewayPod`\"\"\"\n@@ -162,10 +165,10 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n \n     @staticmethod\n     def wait_for_ready_or_shutdown(\n-        timeout: Optional[float],\n-        ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n-        ctrl_address: str,\n-        **kwargs,\n+            timeout: Optional[float],\n+            ready_or_shutdown_event: Union['multiprocessing.Event', 'threading.Event'],\n+            ctrl_address: str,\n+            **kwargs,\n     ):\n         \"\"\"\n         Check if the runtime has successfully started\n@@ -180,7 +183,7 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n         now = time.time_ns()\n         while timeout_ns is None or time.time_ns() - now < timeout_ns:\n             if ready_or_shutdown_event.is_set() or AsyncNewLoopRuntime.is_ready(\n-                ctrl_address\n+                    ctrl_address\n             ):\n                 return True\n             time.sleep(0.1)\n@@ -193,3 +196,11 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n         self.logger.debug(\n             f'recv DataRequest at {request.header.exec_endpoint} with id: {request.header.request_id}'\n         )\n+\n+    @property\n+    def _entity_id(self):\n+        import uuid\n+        if hasattr(self, '_entity_id_'):\n+            return self._entity_id_\n+        self._entity_id_ = uuid.uuid1().hex\n+        return self._entity_id_\n\n\n###\n\n", "completion": "feat: add duration info in events (#<issue-num>)"}
{"prompt": " file path A: scripts/get-openapi-schemas.py | file path B: scripts/get-openapi-schemas.py\n\n@@ -11,8 +11,14 @@ GATEWAY_SCHEMA_FILENAME = 'gateway.json'\n args = set_gateway_parser().parse_args([])\n logger = JinaLogger('')\n gateway_app = get_fastapi_app(\n-    args,\n-    logger=logger,\n+    title=args.title,\n+    description=args.description,\n+    no_debug_endpoints=args.no_debug_endpoints,\n+    no_crud_endpoints=args.no_crud_endpoints,\n+    expose_endpoints=args.expose_endpoints,\n+    expose_graphql_endpoint=args.expose_graphql_endpoint,\n+    cors=args.cors,\n+    logger=args.logger,\n )\n gateway_schema = gateway_app.openapi()\n gateway_schema['info']['x-logo'] = {'url': JINA_LOGO_URL}\n\n\n###\n\n", "completion": "fix: fix get-openapi-schemas script (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-methods.md | file path B: docs/fundamentals/executor/executor-methods.md\n\n@@ -346,8 +346,8 @@ class DummyExecutor(Executor):\n Every Executor method can `return` in 3 ways: \n \n - If you return a `DocumentArray` object, then it will be sent over to the next Executor.\n-- If you return `None` or if you don't have a `return` in your method, then the original `doc` object (potentially mutated by your function) will be sent over to the next Executor.\n-- If you return a `dict` object, then it will be considered as a result and passed on behind `parameters['__results__']`. The original `doc` object (potentially mutated by your function) will be sent over to the next Executor.\n+- If you return `None` or if you don't have a `return` in your method, then the original `docs` object (potentially mutated by your function) will be sent over to the next Executor.\n+- If you return a `dict` object, then it will be considered as a result and returned on `parameters['__results__']` to the client. `__results__` key will not be available in subsequent Executors. The original `docs` object (potentially mutated by your function) will be sent over to the next Executor.\n \n \n ```python\n\n\n###\n\n", "completion": "docs: clarify __return__ behavior in parameters (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -364,8 +364,6 @@ metas:\n         content,\n         form_data,\n         work_path,\n-        uuid8,\n-        secret,\n         task_id,\n     ):\n \n@@ -377,11 +375,9 @@ metas:\n \n             if image:\n                 new_uuid8 = image['id']\n-                new_secret = image.get('secret')\n                 form_data['id'] = new_uuid8\n \n-                if new_uuid8 != uuid8 or new_secret != secret:\n-                    dump_secret(work_path, new_uuid8, new_secret or '', task_id)\n+                dump_secret(work_path, new_uuid8, form_data.get('secret'), task_id)\n             else:\n                 raise Exception(f'Unknown Error, session_id: {session_id}')\n \n@@ -415,16 +411,17 @@ metas:\n         new_task_id = push_task.get('_id')\n         if new_task_id:\n \n-            dump_secret(work_path, None, None, new_task_id)\n+            dump_secret(work_path, form_data.get('id'), form_data.get('secret'), new_task_id)\n             self._prettyprint_status_usage(console, work_path, new_task_id)\n             st.update(f'Async Uploaded!')\n \n             image = self._status_with_progress(console, st, new_task_id, False, verbose)\n             if image:\n-                new_uuid8, new_secret = self._prettyprint_result(console, image)\n \n-                if new_uuid8 != uuid8 or new_secret != secret or task_id != new_task_id:\n-                    dump_secret(work_path, new_uuid8, new_secret or '', new_task_id)\n+                # `new_secret` is always None\n+                new_uuid8, new_secret = self._prettyprint_result(console, image)\n+                if new_uuid8 != form_data.get('id'):\n+                    dump_secret(work_path, new_uuid8, form_data.get('secret'), new_task_id)\n \n             else:\n                 raise Exception(f'Unknown Error, session_id: {session_id}')\n@@ -637,8 +634,6 @@ metas:\n                         content,\n                         form_data,\n                         work_path,\n-                        uuid8,\n-                        secret,\n                         task_id,\n                     )\n \n@@ -857,9 +852,11 @@ metas:\n                         st.update(f'Cloud pending ... [dim]: {t} ({status})[/dim]')\n \n                 elif status == 'failed':\n-                    error = stream_msg.get('message')\n+                    error = stream_msg.get('error', {})\n+                    msg = error.get('message')\n+                    message = stream_msg.get('message')\n                     raise Exception(\n-                        f'{ error or \"Unknown Error\"} session_id: {session_id}'\n+                        f'{ msg or message or \"Unknown Error\"} session_id: {session_id}'\n                     )\n \n                 elif status == 'waiting':\n\n\n###\n\n", "completion": "fix: fix missing secret when logged-in user  with --force-update and \u2026 (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -230,6 +230,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15052,3 +15053,41 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```0a71009b```](https://github.com/jina-ai/jina/commit/0a71009bd71b8e52bd1974032c75d84add7af782)] __-__ __version__: the next version will be 3.9.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-9-2></a>\n+## Release Note (`3.9.2`)\n+\n+> Release time: 2022-09-15 14:00:36\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Girish Chandrashekar,  zhangkai,  AlaeddineAbdessalem,  Joan Fontanals,  Jina Dev Bot,  Andrei Ungureanu,  Deepankar Mahapatro,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```c51f9014```](https://github.com/jina-ai/jina/commit/c51f9014a0ec7e0d75db94a0aef71aaedd6328bc)] __-__ hubble async push (#5129) (*zhangkai*)\n+ - [[```3f39ed46```](https://github.com/jina-ai/jina/commit/3f39ed46f8d8da96e6ed13a30b03d6d8d1f21708)] __-__ __runtime__: add argument to specify exceptions that will exit the runtime (#5165) (*Girish Chandrashekar*)\n+ - [[```27e1f779```](https://github.com/jina-ai/jina/commit/27e1f7799debdabcf5b4c2fe4b23c63c0098572f)] __-__ __hubio__: display warning messages from hubble request (jina hub push) (#5156) (*Andrei Ungureanu*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```29ad1750```](https://github.com/jina-ai/jina/commit/29ad1750d94011a3c8f7d72c60acb4c638d6a4b9)] __-__ exit on exception args only applies to executors (#5169) (*AlaeddineAbdessalem*)\n+ - [[```55188165```](https://github.com/jina-ai/jina/commit/55188165883ce738346e7687f058b86581fb7b7a)] __-__ pin docarray version for new column syntax (#5171) (*Joan Fontanals*)\n+ - [[```fa83955c```](https://github.com/jina-ai/jina/commit/fa83955cead6fb8ee13f594f69d7b7bea3c808fc)] __-__ increase minimum protobuf version (#5166) (*AlaeddineAbdessalem*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```28aeac8e```](https://github.com/jina-ai/jina/commit/28aeac8e9ac282e7707b69faf443e01c5d9b6972)] __-__ add section for exit_on_exceptions argument (#5172) (*Girish Chandrashekar*)\n+ - [[```33891c46```](https://github.com/jina-ai/jina/commit/33891c46c6786c0e548ea6d9d6fa79ae3ef28977)] __-__ __jcloud__: labels in flow yaml (#5164) (*Deepankar Mahapatro*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```b59d0450```](https://github.com/jina-ai/jina/commit/b59d04500e8a749e2d12b35887f4a2dcb5ae3ab4)] __-__ add jina auth token (#5167) (*AlaeddineAbdessalem*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```76dca020```](https://github.com/jina-ai/jina/commit/76dca0205bf1f74581ef01112d904eaf8a468c8e)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```f4248ea8```](https://github.com/jina-ai/jina/commit/f4248ea8b7a82f49299076339223cb314511c91c)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```fda5623a```](https://github.com/jina-ai/jina/commit/fda5623aa3b3e4724bfff063b1b43b3be1f3c5e9)] __-__ __version__: the next version will be 3.9.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.9.2'\n+__version__ = '3.9.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.9.3"}
{"prompt": " file path A: docs/fundamentals/flow/when-things-go-wrong.md | file path B: docs/fundamentals/flow/when-things-go-wrong.md\n\n@@ -19,6 +19,17 @@ If the gRPC or WebSocket protocols are used, the networking stream is not interr\n \n In all cases, the {ref}`Jina Client <client>` will raise an Exception.\n \n+## Exit on exceptions\n+\n+Some exceptions like network errors or request timeouts can be transient and can recover automatically. In some cases there\n+can be fatal errors or user defined errors that can put the Executor in an unuseable state. The executor can be restarted to recover from such a \n+state. Locally the flow must to be re-run manually to restore the Executor availability. \n+\n+On Kubernetes deployments, the process can be automated by terminating the Exeuctor process which will cause the pod to terminate. The availability\n+ is restored by the autoscaler by creating a new pod to replace the terminated pod. The termination can be enabled for one or more errors by using the `exit_on_exceptions` argument when creating the Executor in a Flow. Upon matching the caught exception, the Executor will perform a gracefull termination.\n+ \n+A sample Flow can be `Flow().add(uses=MyExecutor, exit_on_exceptions: ['Exception', 'RuntimeException'])`. The `exit_on_exceptions` argument accepts a list of python or user defined custom Exception or Error class names.\n+\n ## Network errors\n \n When an {ref}`Executor or Head <architecture-overview>` can't be reached by the {class}`~jina.Flow`'s gateway, it attempts to re-connect\n\n\n###\n\n", "completion": "docs: add section for exit_on_exceptions argument (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/executor-args.md | file path B: docs/fundamentals/flow/executor-args.md\n\n@@ -7,7 +7,6 @@\n | `quiet_error` | If set, then exception stack information will not be added to the log | `boolean` | `False` |\n | `timeout_ctrl` | The timeout in milliseconds of the control request, -1 for waiting forever | `number` | `60` |\n | `polling` | The polling strategy of the Deployment and its endpoints (when `shards>1`).<br>    Can be defined for all endpoints of a Deployment or by endpoint.<br>    Define per Deployment:<br>    - ANY: only one (whoever is idle) Pod polls the message<br>    - ALL: all Pods poll the message (like a broadcast)<br>    Define per Endpoint:<br>    JSON dict, {endpoint: PollingType}<br>    {'/custom': 'ALL', '/search': 'ANY', '*': 'ANY'} | `string` | `ANY` |\n-| `exit_on_exceptions` | List of exceptions that will cause the Executor to shut down. | `array` | `[]` |\n | `uses` | The config of the executor, it could be one of the followings:<br>        * the string literal of an Executor class name<br>        * an Executor YAML file (.yml, .yaml, .jaml)<br>        * a Jina Hub Executor (must start with `jinahub://` or `jinahub+docker://`)<br>        * a docker image (must start with `docker://`)<br>        * the string literal of a YAML config (must start with `!` or `jtype: `)<br>        * the string literal of a JSON config<br><br>        When use it under Python, one can use the following values additionally:<br>        - a Python dict that represents the config<br>        - a text file stream has `.read()` interface | `string` | `BaseExecutor` |\n | `uses_with` | Dictionary of keyword arguments that will override the `with` configuration in `uses` | `object` | `None` |\n | `uses_metas` | Dictionary of keyword arguments that will override the `metas` configuration in `uses` | `object` | `None` |\n@@ -18,6 +17,7 @@\n | `native` | If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime. | `boolean` | `False` |\n | `output_array_type` | The type of array `tensor` and `embedding` will be serialized to.<br><br>Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which can be found <br>`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.<br>Defaults to retaining whatever type is returned by the Executor. | `string` | `None` |\n | `grpc_server_options` | Dictionary of kwargs arguments that will be passed to the grpc server as options when starting the server, example : {'grpc.max_send_message_length': -1} | `object` | `None` |\n+| `exit_on_exceptions` | List of exceptions that will cause the Executor to shut down. | `array` | `[]` |\n | `entrypoint` | The entrypoint command overrides the ENTRYPOINT in Docker image. when not set then the Docker image ENTRYPOINT takes effective. | `string` | `None` |\n | `docker_kwargs` | Dictionary of kwargs arguments that will be passed to Docker SDK when starting the docker '<br>container. <br><br>More details can be found in the Docker SDK docs:  https://docker-py.readthedocs.io/en/stable/ | `object` | `None` |\n | `volumes` | The path on the host to be mounted inside the container. <br><br>Note, <br>- If separated by `:`, then the first part will be considered as the local host path and the second part is the path in the container system. <br>- If no split provided, then the basename of that directory will be mounted into container's root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into `/my-workspace` inside the container. <br>- All volumes are mounted with read-write mode. | `array` | `None` |\n\n---\n file path A: docs/fundamentals/flow/gateway-args.md | file path B: docs/fundamentals/flow/gateway-args.md\n\n@@ -7,7 +7,6 @@\n | `quiet_error` | If set, then exception stack information will not be added to the log | `boolean` | `False` |\n | `timeout_ctrl` | The timeout in milliseconds of the control request, -1 for waiting forever | `number` | `60` |\n | `polling` | The polling strategy of the Deployment and its endpoints (when `shards>1`).<br>    Can be defined for all endpoints of a Deployment or by endpoint.<br>    Define per Deployment:<br>    - ANY: only one (whoever is idle) Pod polls the message<br>    - ALL: all Pods poll the message (like a broadcast)<br>    Define per Endpoint:<br>    JSON dict, {endpoint: PollingType}<br>    {'/custom': 'ALL', '/search': 'ANY', '*': 'ANY'} | `string` | `ANY` |\n-| `exit_on_exceptions` | List of exceptions that will cause the Executor to shut down. | `array` | `[]` |\n | `uses` | The config of the executor, it could be one of the followings:<br>        * the string literal of an Executor class name<br>        * an Executor YAML file (.yml, .yaml, .jaml)<br>        * a Jina Hub Executor (must start with `jinahub://` or `jinahub+docker://`)<br>        * a docker image (must start with `docker://`)<br>        * the string literal of a YAML config (must start with `!` or `jtype: `)<br>        * the string literal of a JSON config<br><br>        When use it under Python, one can use the following values additionally:<br>        - a Python dict that represents the config<br>        - a text file stream has `.read()` interface | `string` | `BaseExecutor` |\n | `uses_with` | Dictionary of keyword arguments that will override the `with` configuration in `uses` | `object` | `None` |\n | `uses_metas` | Dictionary of keyword arguments that will override the `metas` configuration in `uses` | `object` | `None` |\n@@ -18,6 +17,7 @@\n | `native` | If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime. | `boolean` | `False` |\n | `output_array_type` | The type of array `tensor` and `embedding` will be serialized to.<br><br>Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which can be found <br>`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.<br>Defaults to retaining whatever type is returned by the Executor. | `string` | `None` |\n | `grpc_server_options` | Dictionary of kwargs arguments that will be passed to the grpc server as options when starting the server, example : {'grpc.max_send_message_length': -1} | `object` | `None` |\n+| `exit_on_exceptions` | List of exceptions that will cause the Executor to shut down. | `array` | `[]` |\n | `prefetch` | Number of requests fetched from the client before feeding into the first Executor. <br>    <br>    Used to control the speed of data input into a Flow. 0 disables prefetch (1000 requests is the default) | `number` | `1000` |\n | `title` | The title of this HTTP server. It will be used in automatics docs such as Swagger UI. | `string` | `None` |\n | `description` | The description of this HTTP server. It will be used in automatics docs such as Swagger UI. | `string` | `None` |\n\n---\n file path A: jina/parsers/orchestrate/base.py | file path B: jina/parsers/orchestrate/base.py\n\n@@ -119,11 +119,3 @@ def mixin_base_ppr_parser(parser):\n     \n     ''',\n     )\n-\n-    gp.add_argument(\n-        '--exit-on-exceptions',\n-        type=str,\n-        default=[],\n-        nargs='*',\n-        help='List of exceptions that will cause the Executor to shut down.',\n-    )\n\n---\n file path A: jina/parsers/orchestrate/runtimes/worker.py | file path B: jina/parsers/orchestrate/runtimes/worker.py\n\n@@ -113,3 +113,11 @@ Defaults to retaining whatever type is returned by the Executor.\n         help=\"Dictionary of kwargs arguments that will be passed to the grpc server as options when starting the server, example : {'grpc.max_send_message_length': -1}\",\n         default=None,\n     )\n+\n+    gp.add_argument(\n+        '--exit-on-exceptions',\n+        type=str,\n+        default=[],\n+        nargs='*',\n+        help='List of exceptions that will cause the Executor to shut down.',\n+    )\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -30,7 +30,6 @@ ac_table = {\n             '--timeout-ctrl',\n             '--k8s-namespace',\n             '--polling',\n-            '--exit-on-exceptions',\n             '--uses',\n             '--uses-with',\n             '--uses-metas',\n@@ -41,6 +40,7 @@ ac_table = {\n             '--native',\n             '--output-array-type',\n             '--grpc-server-options',\n+            '--exit-on-exceptions',\n             '--entrypoint',\n             '--docker-kwargs',\n             '--volumes',\n@@ -103,7 +103,6 @@ ac_table = {\n             '--timeout-ctrl',\n             '--k8s-namespace',\n             '--polling',\n-            '--exit-on-exceptions',\n             '--uses',\n             '--uses-with',\n             '--uses-metas',\n@@ -114,6 +113,7 @@ ac_table = {\n             '--native',\n             '--output-array-type',\n             '--grpc-server-options',\n+            '--exit-on-exceptions',\n             '--prefetch',\n             '--title',\n             '--description',\n@@ -223,7 +223,6 @@ ac_table = {\n             '--timeout-ctrl',\n             '--k8s-namespace',\n             '--polling',\n-            '--exit-on-exceptions',\n             '--uses',\n             '--uses-with',\n             '--uses-metas',\n@@ -234,6 +233,7 @@ ac_table = {\n             '--native',\n             '--output-array-type',\n             '--grpc-server-options',\n+            '--exit-on-exceptions',\n             '--entrypoint',\n             '--docker-kwargs',\n             '--volumes',\n@@ -277,7 +277,6 @@ ac_table = {\n             '--timeout-ctrl',\n             '--k8s-namespace',\n             '--polling',\n-            '--exit-on-exceptions',\n             '--uses',\n             '--uses-with',\n             '--uses-metas',\n@@ -288,6 +287,7 @@ ac_table = {\n             '--native',\n             '--output-array-type',\n             '--grpc-server-options',\n+            '--exit-on-exceptions',\n             '--entrypoint',\n             '--docker-kwargs',\n             '--volumes',\n\n\n###\n\n", "completion": "fix: exit on exception args only applies to executors (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -32,7 +32,7 @@ grpcio-reflection>=1.46.0,<1.48.1:  core\n grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray>=0.16.3:           core\n+docarray>=0.16.4:           core\n jina-hubble-sdk>=0.15.1:    core\n jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -32,7 +32,7 @@ grpcio-reflection>=1.46.0,<1.48.1:  core\n grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray>=0.16.3:           core\n+docarray>=0.16.4:           core\n jina-hubble-sdk>=0.15.1:    core\n jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n\n\n###\n\n", "completion": "fix: pin docarray version for new column syntax (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -7,7 +7,7 @@ import json\n import os\n import random\n from pathlib import Path\n-from typing import Dict, Optional, Union\n+from typing import Dict, Optional, Union, List\n from urllib.parse import urljoin\n \n import hubble\n@@ -482,7 +482,7 @@ metas:\n                 )\n \n                 image = None\n-                warning = None\n+                warnings = []\n                 session_id = req_header.get('jinameta-session-id')\n                 for stream_line in resp.iter_lines():\n                     stream_msg = json.loads(stream_line)\n@@ -508,6 +508,9 @@ metas:\n                         raise Exception(\n                             f'{overridden_msg or msg or \"Unknown Error\"} session_id: {session_id}'\n                         )\n+                    elif t == 'warning':\n+                        warnings.append(stream_msg.get('message'))\n+        \n                     if t == 'progress' and subject == 'buildWorkspace':\n                         legacy_message = stream_msg.get('legacyMessage', {})\n                         status = legacy_message.get('status', '')\n@@ -533,7 +536,7 @@ metas:\n \n                 if image:\n                     new_uuid8, new_secret = self._prettyprint_result(\n-                        console, image, warning=warning\n+                        console, image, warnings=warnings\n                     )\n                     if new_uuid8 != uuid8 or new_secret != secret:\n                         dump_secret(work_path, new_uuid8, new_secret or '')\n@@ -549,7 +552,7 @@ metas:\n                 )\n                 raise e\n \n-    def _prettyprint_result(self, console, image, *, warning: Optional[str] = None):\n+    def _prettyprint_result(self, console, image, *, warnings: Optional[List[str]] = None):\n         # TODO: only support single executor now\n \n         from rich import box\n@@ -576,21 +579,23 @@ metas:\n             table.add_row(':lock: Secret', secret)\n             table.add_row(\n                 '',\n-                ':point_up:\ufe0f [bold red]Please keep this token in a safe place!',\n+                '\ud83d\udc46 [bold red]Please keep this token in a safe place!',\n             )\n \n         table.add_row(':eyes: Visibility', visibility)\n \n-        if warning:\n+        if warnings:\n             table.add_row(\n-                ':warning: Warning',\n-                f':exclamation:\ufe0f [bold yellow]{warning}',\n+                ':exclamation: Warnings',\n+                '\ud83d\udc47 [bold yellow]Process finished with warnings!',\n             )\n+            for warning in warnings:\n+                table.add_row('', f'[yellow]\u2022 {warning}')\n \n         p1 = Panel(\n             table,\n             title='Published',\n-            width=80,\n+            width=100,\n             expand=False,\n         )\n         console.print(p1)\n\n\n###\n\n", "completion": "feat(hubio): display warning messages from hubble request (jina hub push) (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -143,6 +143,7 @@ jobs:\n           JINAHUB_USERNAME: ${{ secrets.JINAHUB_USERNAME }}\n           JINAHUB_PASSWORD: ${{ secrets.JINAHUB_PASSWORD }}\n           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n+          JINA_AUTH_TOKEN: \"${{ secrets.JINA_AUTH_TOKEN }}\"\n       - name: Check file existence\n         id: check_files\n         uses: andstor/file-existence-action@v1\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -333,6 +333,8 @@ jobs:\n           echo \"flag it as jina for codeoverage\"\n           echo \"::set-output name=codecov_flag::jina\"\n         timeout-minutes: 30\n+        env:\n+          JINA_AUTH_TOKEN: \"${{ secrets.JINA_AUTH_TOKEN }}\"\n       - name: Check codecov file\n         id: check_files\n         uses: andstor/file-existence-action@v1\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -25,17 +25,6 @@ from jina.parsers.hubble import (\n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n \n-@pytest.fixture(scope='function')\n-def auth_token(tmpdir):\n-    from hubble.utils.config import Config\n-\n-    c = Config()\n-    token = 'test-auth-token'\n-    c.set('auth_token', token)\n-    yield token\n-    c.delete('auth_token')\n-\n-\n class PostMockResponse:\n     def __init__(self, response_code: int = 201):\n         self.response_code = response_code\n@@ -398,7 +387,7 @@ def test_push_wrong_dockerfile(\n \n \n @pytest.mark.parametrize('build_env', ['DOMAIN=github.com DOWNLOAD=download'])\n-def test_push_with_authorization(mocker, monkeypatch, auth_token, build_env):\n+def test_push_with_authorization(mocker, monkeypatch, build_env):\n     mock = mocker.Mock()\n \n     def _mock_post(url, data, headers, stream):\n@@ -419,7 +408,7 @@ def test_push_with_authorization(mocker, monkeypatch, auth_token, build_env):\n \n     _, kwargs = mock.call_args_list[0]\n \n-    assert kwargs['headers'].get('Authorization') == f'token {auth_token}'\n+    assert kwargs['headers'].get('Authorization').startswith('token ')\n \n \n @pytest.mark.parametrize('rebuild_image', [True, False])\n@@ -538,7 +527,7 @@ def test_fetch_with_retry(mocker, monkeypatch):\n     assert mock.call_count == 6  # mock must be called 3+3\n \n \n-def test_fetch_with_authorization(mocker, monkeypatch, auth_token):\n+def test_fetch_with_authorization(mocker, monkeypatch):\n     mock = mocker.Mock()\n \n     def _mock_post(url, json, headers):\n@@ -553,7 +542,7 @@ def test_fetch_with_authorization(mocker, monkeypatch, auth_token):\n \n     _, kwargs = mock.call_args_list[0]\n \n-    assert kwargs['headers'].get('Authorization') == f'token {auth_token}'\n+    assert kwargs['headers'].get('Authorization').startswith('token ')\n \n \n class DownloadMockResponse:\n@@ -851,7 +840,7 @@ def test_new_with_arguments(\n     for file in ['executor.py', 'README.md', 'config.yml']:\n         with open(path / file, 'r') as fp:\n             assert 'argsExecutor' in fp.read()\n-    \n+\n     if advance_configuration or confirm_advance_configuration:\n         with open(path / 'config.yml') as fp:\n             temp = yaml.load(fp, Loader=yaml.FullLoader)\n\n\n###\n\n", "completion": "ci: add jina auth token (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -26,7 +26,7 @@\n \n \n numpy:                      core\n-protobuf>=3.13.0:           core\n+protobuf>=3.20.0:           core\n grpcio>=1.46.0,<1.48.1:     core\n grpcio-reflection>=1.46.0,<1.48.1:  core\n grpcio-health-checking>=1.46.0,<1.48.1:  core\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -26,7 +26,7 @@\n \n \n numpy:                      core\n-protobuf>=3.13.0:           core\n+protobuf>=3.20.0:           core\n grpcio>=1.46.0,<1.48.1:     core\n grpcio-reflection>=1.46.0,<1.48.1:  core\n grpcio-health-checking>=1.46.0,<1.48.1:  core\n\n\n###\n\n", "completion": "fix: increase minimum protobuf version (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/yaml-spec.md | file path B: docs/fundamentals/jcloud/yaml-spec.md\n\n@@ -326,6 +326,32 @@ executors:\n     uses: jinahub+docker://Executor1\n ```\n \n+### Add Labels\n+\n+You can use `labels` (as key-value pairs) to attach metadata to your Flows.\n+\n+```yaml\n+jtype: Flow\n+jcloud:\n+  labels: \n+    username: johndoe\n+    app: fashion-search\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+```\n+\n+```{note}\n+\n+Keys in `labels` have the following restrictions.\n+  - Must be 63 characters or less.\n+  - Must begin and end with an alphanumeric character ([a-z0-9A-Z]) with dashes (-), underscores (_), dots (.), and alphanumerics between.\n+  - Following keys are skipped if passed in the Flow YAML.\n+    - user\n+    - jina-version\n+    - retention-days\n+```\n+\n \n ### Lifetime\n \n\n\n###\n\n", "completion": "docs(jcloud): labels in flow yaml (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -229,6 +229,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15029,3 +15030,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```b49aa212```](https://github.com/jina-ai/jina/commit/b49aa212d92a1ac5f80d632d83696214f44d4b30)] __-__ bump jina version (#5150) (*Joan Fontanals*)\n  - [[```731819a4```](https://github.com/jina-ai/jina/commit/731819a4faffbb58e0caeb1930417e6102a478e3)] __-__ __version__: the next version will be 3.8.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-9-1></a>\n+## Release Note (`3.9.1`)\n+\n+> Release time: 2022-09-08 14:10:44\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```273fda5a```](https://github.com/jina-ai/jina/commit/273fda5a86da0d6bf48f423fa50700e828b40be6)] __-__ merge dryrun into ping (#5151) (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```0a71009b```](https://github.com/jina-ai/jina/commit/0a71009bd71b8e52bd1974032c75d84add7af782)] __-__ __version__: the next version will be 3.9.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.9.1'\n+__version__ = '3.9.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.9.2"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -228,6 +228,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -15008,3 +15009,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```a9b80aec```](https://github.com/jina-ai/jina/commit/a9b80aec484ac6ced21c71dddb285afa40384049)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```1df9b459```](https://github.com/jina-ai/jina/commit/1df9b45919b5d24cd0d61dbcaec633c43c2e02bc)] __-__ __version__: the next version will be 3.8.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-9-0></a>\n+## Release Note (`3.9.0`)\n+\n+> Release time: 2022-09-08 11:53:16\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Andrei Ungureanu,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```40af2f04```](https://github.com/jina-ai/jina/commit/40af2f047388ace9916f512a0a5032e769c9876f)] __-__ __hubio__: add default values for metas when using `jina hub new` (#5149) (*Andrei Ungureanu*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```b49aa212```](https://github.com/jina-ai/jina/commit/b49aa212d92a1ac5f80d632d83696214f44d4b30)] __-__ bump jina version (#5150) (*Joan Fontanals*)\n+ - [[```731819a4```](https://github.com/jina-ai/jina/commit/731819a4faffbb58e0caeb1930417e6102a478e3)] __-__ __version__: the next version will be 3.8.5 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.9.0'\n+__version__ = '3.9.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.9.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.8.5'\n+__version__ = '3.9.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: bump jina version (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -208,9 +208,9 @@ Meta information helps other users to identify, search and reuse your Executor o\n                     f = (\n                         fp.read()\n                         .replace('{{exec_name}}', exec_name)\n-                        .replace('{{exec_description}}', exec_description)\n-                        .replace('{{exec_keywords}}', str(exec_keywords.split(',')))\n-                        .replace('{{exec_url}}', exec_url)\n+                        .replace('{{exec_description}}', exec_description if exec_description != '{{}}' else '')\n+                        .replace('{{exec_keywords}}', str(exec_keywords.split(',')) if exec_keywords != '{{}}' else '[]')\n+                        .replace('{{exec_url}}', exec_url if exec_url != '{{}}' else '')\n                     )\n                     fpw.writelines(f)\n \n@@ -259,9 +259,9 @@ py_modules:\n   - executor.py\n metas:\n   name: {exec_name}\n-  description: {exec_description if exec_description != '{{}}' else 'None'}\n-  url: {exec_url if exec_url != '{{}}' else 'None'}\n-  keywords: {exec_keywords if exec_keywords != '{{}}' else 'None'}\n+  description: {exec_description if exec_description != '{{}}' else ''}\n+  url: {exec_url if exec_url != '{{}}' else ''}\n+  keywords: {exec_keywords if exec_keywords != '{{}}' else '[]'}\n ''',\n                     'yaml',\n                     theme='monokai',\n\n\n###\n\n", "completion": "fix(hubio): add default values for metas when using `jina hub new` (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -227,6 +227,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14969,3 +14970,41 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```47e2cfc3```](https://github.com/jina-ai/jina/commit/47e2cfc3c28465af8f402261341693e28614f034)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```0dbdcaa0```](https://github.com/jina-ai/jina/commit/0dbdcaa048bff6b05fcfb9930f92dbc5a6c5da12)] __-__ __version__: the next version will be 3.8.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-8-4></a>\n+## Release Note (`3.8.4`)\n+\n+> Release time: 2022-09-08 08:51:32\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Deepankar Mahapatro,  AlaeddineAbdessalem,  Joan Fontanals,  Johannes Messner,  Andrei Ungureanu,  samsja,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```d1faf6e6```](https://github.com/jina-ai/jina/commit/d1faf6e6131961cf773e0447c98aefa9eaccf29b)] __-__ pass internal flag to telemetry (#5134) (*Joan Fontanals*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```e501ddfd```](https://github.com/jina-ai/jina/commit/e501ddfdfc86b4309e329f1442ff6f1ad79cae81)] __-__ __version__: adapt to docker hub v2 (#5146) (*Deepankar Mahapatro*)\n+ - [[```d76e69ac```](https://github.com/jina-ai/jina/commit/d76e69ac06ca52c6fbe2512f3224d40fca98b77e)] __-__ fix parsing empty list (#5143) (*AlaeddineAbdessalem*)\n+ - [[```3ec33c08```](https://github.com/jina-ai/jina/commit/3ec33c0851842c89e5f7d76bf91248c016173a3d)] __-__ gpu dockerfile template include now jina install (#5124) (*samsja*)\n+ - [[```e2967f98```](https://github.com/jina-ai/jina/commit/e2967f9889caa1d24445d5e3df2923431dadb16f)] __-__ set minimal docarray dependency (#5133) (*Joan Fontanals*)\n+ - [[```ff803686```](https://github.com/jina-ai/jina/commit/ff803686a929be5f20f646baa05d81ac9721809b)] __-__ linkerd cd (#5131) (*AlaeddineAbdessalem*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```a78612f3```](https://github.com/jina-ai/jina/commit/a78612f3eecb0fc3ee79b301f0775a3590b7ad35)] __-__ manifest config (#5101) (*Andrei Ungureanu*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```ddf90efb```](https://github.com/jina-ai/jina/commit/ddf90efb6b7c430c31de0d51b0741d57053afed4)] __-__ remove outdated test (#5139) (*Johannes Messner*)\n+ - [[```a4ea7215```](https://github.com/jina-ai/jina/commit/a4ea72159c9d9a00862e012310bb34897f5e2fb4)] __-__ increase wait time (#5137) (*AlaeddineAbdessalem*)\n+ - [[```478e53f6```](https://github.com/jina-ai/jina/commit/478e53f63bf8d26023b1327ccece6fdcc0915bc4)] __-__ fix k8s tests return responses params (#5127) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```a9b80aec```](https://github.com/jina-ai/jina/commit/a9b80aec484ac6ced21c71dddb285afa40384049)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```1df9b459```](https://github.com/jina-ai/jina/commit/1df9b45919b5d24cd0d61dbcaec633c43c2e02bc)] __-__ __version__: the next version will be 3.8.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.8.4'\n+__version__ = '3.8.5'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.8.5"}
{"prompt": " file path A: jina/orchestrate/deployments/config/helper.py | file path B: jina/orchestrate/deployments/config/helper.py\n\n@@ -1,4 +1,5 @@\n import os\n+from typing import Dict\n \n from jina import __default_executor__, __version__\n from jina.enums import PodRoleType\n@@ -50,10 +51,9 @@ def get_base_executor_version():\n     import requests\n \n     try:\n-        url = 'https://registry.hub.docker.com/v1/repositories/jinaai/jina/tags'\n-        tags = requests.get(url).json()\n-        name_set = {tag['name'] for tag in tags}\n-        if __version__ in name_set:\n+        url = 'https://registry.hub.docker.com/v2/repositories/jinaai/jina/tags'\n+        result: Dict = requests.get(url, params={'name': __version__}).json()\n+        if result.get('count', 0) > 0:\n             return __version__\n         else:\n             return 'master'\n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_helper.py | file path B: tests/unit/orchestrate/deployments/config/test_helper.py\n\n@@ -1,3 +1,4 @@\n+import json\n import os\n \n import pytest\n@@ -15,13 +16,20 @@ from jina.orchestrate.deployments.config.helper import (\n @pytest.mark.parametrize('is_master', (True, False))\n def test_version(is_master, requests_mock):\n     if is_master:\n-        version = 'v2'\n+        count = 0\n     else:\n         # current version is published already\n-        version = __version__\n+        count = 3\n     requests_mock.get(\n-        'https://registry.hub.docker.com/v1/repositories/jinaai/jina/tags',\n-        text='[{\"name\": \"v1\"}, {\"name\": \"' + version + '\"}]',\n+        'https://registry.hub.docker.com/v2/repositories/jinaai/jina/tags',\n+        text=json.dumps(\n+            {\n+                'count': count,\n+                'next': 'abc',\n+                'previous': 'def',\n+                'results': [{'a': 'b', 'c': 'd'}],\n+            }\n+        ),\n     )\n     v = get_base_executor_version()\n     if is_master:\n\n\n###\n\n", "completion": "fix(version): adapt to docker hub v2 (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -286,9 +286,9 @@ def parse_arg(v: str) -> Optional[Union[bool, int, str, list, float]]:\n \n     if v.startswith('[') and v.endswith(']'):\n         # function args must be immutable tuples not list\n-        tmp = v.replace('[', '').replace(']', '').strip().split(',')\n+        tmp = v.replace('[', '').replace(']', '').strip()\n         if len(tmp) > 0:\n-            return [parse_arg(vv.strip()) for vv in tmp]\n+            return [parse_arg(vv.strip()) for vv in tmp.split(',')]\n         else:\n             return []\n     try:\n\n---\n file path A: tests/unit/test_helper.py | file path B: tests/unit/test_helper.py\n\n@@ -18,6 +18,7 @@ from jina.helper import (\n     get_ci_vendor,\n     is_port_free,\n     is_yaml_filepath,\n+    parse_arg,\n     random_port,\n     reset_ports,\n     retry,\n@@ -367,3 +368,19 @@ def test_run_async():\n )\n def test_parse_port(port, output):\n     assert _parse_ports(port) == output\n+\n+\n+@pytest.mark.parametrize(\n+    'input, expected',\n+    [\n+        ('12', 12),\n+        ('1.5', 1.5),\n+        ('str', 'str'),\n+        ('[]', []),\n+        ('[1, 1.5, 5]', [1, 1.5, 5]),\n+        ('true', True),\n+        ('False', False),\n+    ],\n+)\n+def test_parse_arg(input, expected):\n+    assert parse_arg(input) == expected\n\n\n###\n\n", "completion": "fix: fix parsing empty list (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -966,6 +966,7 @@ def get_full_version() -> Optional[Tuple[Dict, Dict]]:\n             'session-id': str(random_uuid(use_uuid1=True)),\n             'uptime': __uptime__,\n             'ci-vendor': get_ci_vendor() or __unset_msg__,\n+            'internal': 'jina-ai' in os.getenv('GITHUB_ACTION_REPOSITORY', __unset_msg__)\n         }\n \n         env_info = {k: os.getenv(k, __unset_msg__) for k in __jina_env__}\n\n---\n file path A: tests/unit/orchestrate/flow/flow-orchestrate/test_flow_complex_topology.py | file path B: tests/unit/orchestrate/flow/flow-orchestrate/test_flow_complex_topology.py\n\n@@ -1,4 +1,5 @@\n import threading\n+import multiprocessing\n import time\n \n import pytest\n@@ -36,15 +37,14 @@ def test_flow_external_executor_with_gateway():\n     def serve_exec(**kwargs):\n         FooExec.serve(**kwargs)\n \n-    e = threading.Event()\n-    t = threading.Thread(\n+    e = multiprocessing.Event()\n+    t = multiprocessing.Process(\n         name='serve-exec',\n         target=serve_exec,\n-        kwargs={'port_expose': external_gateway_port, 'stop_event': e},\n-        daemon=True,\n+        kwargs={'port': external_gateway_port, 'stop_event': e},\n     )\n     t.start()\n-    time.sleep(3)  # allow exec to start\n+    time.sleep(5)  # allow exec to start\n \n     with Flow().add(\n         name='external_gateway_exec', external=True, port=external_gateway_port\n@@ -53,6 +53,8 @@ def test_flow_external_executor_with_gateway():\n         assert docs.texts == ['foo']\n \n     e.set()\n+    t.terminate()\n+    t.join()\n \n \n class BarExec(Executor):\n\n\n###\n\n", "completion": "feat: pass internal flag to telemetry (#<issue-num>)"}
{"prompt": " file path A: tests/unit/serve/runtimes/worker/test_worker_runtime.py | file path B: tests/unit/serve/runtimes/worker/test_worker_runtime.py\n\n@@ -9,8 +9,8 @@ from threading import Event\n import grpc\n import pytest\n import requests as req\n-\n from docarray import Document\n+\n from jina import DocumentArray, Executor, requests\n from jina.clients.request import request_generator\n from jina.parsers import set_pod_parser\n@@ -191,90 +191,6 @@ def test_error_in_worker_runtime(monkeypatch):\n     assert not AsyncNewLoopRuntime.is_ready(f'{args.host}:{args.port}')\n \n \n-@pytest.mark.slow\n-@pytest.mark.timeout(10)\n-@pytest.mark.asyncio\n-@pytest.mark.skipif(\n-    'GITHUB_WORKFLOW' in os.environ,\n-    reason='Graceful shutdown is not working at the moment',\n-)\n-# TODO: This test should work, it does not\n-async def test_worker_runtime_graceful_shutdown():\n-    args = set_pod_parser().parse_args([])\n-\n-    cancel_event = multiprocessing.Event()\n-    handler_closed_event = multiprocessing.Event()\n-    slow_executor_block_time = 1.0\n-    pending_requests = 5\n-\n-    def start_runtime(args, cancel_event, handler_closed_event):\n-        with WorkerRuntime(args, cancel_event=cancel_event) as runtime:\n-            runtime._data_request_handler.handle = lambda *args, **kwargs: time.sleep(\n-                slow_executor_block_time\n-            )\n-            runtime._data_request_handler.close = (\n-                lambda *args, **kwargs: handler_closed_event.set()\n-            )\n-\n-            runtime.run_forever()\n-\n-    runtime_thread = Process(\n-        target=start_runtime,\n-        args=(args, cancel_event, handler_closed_event),\n-    )\n-    runtime_thread.start()\n-\n-    assert AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n-        timeout=5.0,\n-        ctrl_address=f'{args.host}:{args.port}',\n-        ready_or_shutdown_event=Event(),\n-    )\n-\n-    request_start_time = time.time()\n-\n-    async def task_wrapper(adress, messages_received):\n-        request = _create_test_data_message(len(messages_received))\n-        (\n-            single_data_stub,\n-            data_stub,\n-            control_stub,\n-            channel,\n-        ) = GrpcConnectionPool.create_async_channel_stub(adress)\n-        await data_stub.process_data(request)\n-        await channel.close()\n-        messages_received.append(request)\n-\n-    sent_requests = 0\n-    messages_received = []\n-    tasks = []\n-    for i in range(pending_requests):\n-        tasks.append(\n-            asyncio.create_task(\n-                task_wrapper(f'{args.host}:{args.port}', messages_received)\n-            )\n-        )\n-        sent_requests += 1\n-\n-    await asyncio.sleep(1.0)\n-\n-    runtime_thread.terminate()\n-\n-    assert not handler_closed_event.is_set()\n-    runtime_thread.join()\n-\n-    for future in asyncio.as_completed(tasks):\n-        _ = await future\n-\n-    assert pending_requests == sent_requests\n-    assert sent_requests == len(messages_received)\n-\n-    assert (\n-        time.time() - request_start_time >= slow_executor_block_time * pending_requests\n-    )\n-    assert handler_closed_event.is_set()\n-    assert not WorkerRuntime.is_ready(f'{args.host}:{args.port}')\n-\n-\n class SlowInitExecutor(Executor):\n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n\n\n###\n\n", "completion": "test: remove outdated test (#<issue-num>)"}
{"prompt": " file path A: tests/integration/monitoring/test_manual_flow.py | file path B: tests/integration/monitoring/test_manual_flow.py\n\n@@ -283,7 +283,7 @@ def test_pending_request(port_generator, failure_in_executor, protocol):\n         _assert_pending_value('0.0', runtime_name, port0)\n \n         p_send.start()\n-        time.sleep(1)\n+        time.sleep(3)\n \n         _assert_pending_value('1.0', runtime_name, port0)\n \n\n\n###\n\n", "completion": "test: increase wait time (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/hub/create-hub-executor.md | file path B: docs/fundamentals/executor/hub/create-hub-executor.md\n\n@@ -7,32 +7,29 @@ To create your Hub {class}`~jina.Executor`, you just need to run:\n jina hub new\n ```\n \n+<script id=\"asciicast-T98aWaJLe0r0ul3cXGk7AzqUs\" src=\"https://asciinema.org/a/T98aWaJLe0r0ul3cXGk7AzqUs.js\" async></script>\n \n-```{figure} screenshots/create-new.gif\n-:align: center\n-```\n+For the basic configuration (advanced configuration is optional but rarely necessary), you will be asked for two things: \n \n-For the basic configuration, \n-you will be asked for two things: The Executor\u2019s name and where it should be saved. A more advanced configuration is optional but rarely necessary.\n+- Name of your Executor \n+- Path to the folder where it should be saved. \n \n After running the command, a project with the following structure will be generated:\n \n ```text\n MyExecutor/\n-\u251c\u2500\u2500 Dockerfile\t        # Advanced configuration will generate this file\n-\u251c\u2500\u2500 manifest.yml\n+\u251c\u2500\u2500 executor.py\n \u251c\u2500\u2500 config.yml\n \u251c\u2500\u2500 README.md\n \u251c\u2500\u2500 requirements.txt\n-\u2514\u2500\u2500 executor.py\n+\u2514\u2500\u2500 Dockerfile\n ```\n \n-- `manifest.yml` should contain the Executor's annotations for getting better exposure on Jina Hub. {ref}`Its specification can be found here<manifest-yaml>`.\n-- `config.yml` is the Executor's configuration file, where you can define **__init__** arguments using **with** keyword.\n-- `requirements.txt` describes the Executor's Python dependencies.\n - `executor.py` should contain your Executor's main logic.\n+- `config.yml` is the Executor's {ref}`configuration <executor-yaml-spec>` file, where you can define `__init__` arguments using `with` keyword. You can also define meta annotations relevant to the executor, for getting better exposer on Jina Hub.\n+- `requirements.txt` describes the Executor's Python dependencies.\n - `README.md` should describe how to use your Executor.\n-\n+- `Dockerfile` will only be generated once you request advanced configuration.\n \n \n ## Tips\n@@ -47,8 +44,7 @@ structure.\n \n * No need to write Dockerfile manually \n \n-  Most of the time, you do not need to create `Dockerfile` manually, {abbr}`Hubble (Hubble is the Jina Hub building system)` will generate a well-optimized Dockerfile according to your Executor \n-    package.\n+  Most of the time, you do not need to create `Dockerfile` manually. Build system will generate a well-optimized Dockerfile according to your Executor package.\n \n \n ```{tip}\n@@ -58,11 +54,9 @@ In the wizard of `jina hub new`, you can choose from four Dockerfile templates:\n \n * No need to bump Jina version\n \n-  Hub executors are version-agnostic. When you pull an Executor from Hub, Hubble will always select the right Jina \n-version for you. No worries about Jina version upgrade!\n+  Hub executors are version-agnostic. When you pull an Executor from Hub, Hubble will always select the right Jina version for you. No worries about Jina version upgrade!\n \n \n-* Fill in `manifest.yml` correctly. \n+* Fill in metadata of your Executor correctly\n \n-  Information you include in `manifest.yml` will be displayed on our website.\n-Want to make your Executor eye-catching on our website? Fill all fields in `manifest.yml` with heart & love! {ref}`Its specification can be found here<manifest-yaml>`.\n+  Information you include under the `metas` key, in `config.yml`, will be displayed on our website. Want to make your Executor eye-catching on our website? Fill all `metas` fields in `config.yml` with heart & love! {ref}`Its specification can be found here<config.yml>`.\n\n---\n file path A: docs/fundamentals/executor/hub/push-executor.md | file path B: docs/fundamentals/executor/hub/push-executor.md\n\n@@ -14,10 +14,7 @@ There are two types of sharing:\n jina hub push [--public/--private] <path_to_executor_folder>\n ```\n \n-```{figure} screenshots/hub-push.gif\n-:align: center\n-```\n-\n+<script id=\"asciicast-tpvuZ9u0lU2IumRyLlly3JI93\" src=\"https://asciinema.org/a/tpvuZ9u0lU2IumRyLlly3JI93.js\" async></script>\n \n It will return `NAME` & `SECRET`, which you will need to use (if the Executor is private) or update the Executor. **Please keep them carefully.**\n \n\n---\n file path A: docs/fundamentals/executor/hub/screenshots/create-new.gif | file path B: docs/fundamentals/executor/hub/screenshots/create-new.gif\n\nBinary files a/docs/fundamentals/executor/hub/screenshots/create-new.gif and /dev/null differ\n\n---\n file path A: docs/fundamentals/executor/hub/screenshots/hub-push.gif | file path B: docs/fundamentals/executor/hub/screenshots/hub-push.gif\n\nBinary files a/docs/fundamentals/executor/hub/screenshots/hub-push.gif and /dev/null differ\n\n---\n file path A: docs/fundamentals/executor/hub/yaml-spec.md | file path B: None\n\n@@ -1,15 +0,0 @@\n-(manifest-yaml)=\n-# {octicon}`file-code` YAML specification\n-\n-`manifest.yml` is an optional file that shipped with your Executor bundle. It annotates your Executor with meta information so that it can be better managed by the Hub system. \n-\n-To get better appealing on Jina Hub, you may want to \n-carefully set `manifest.yml` to the correct values:\n-\n-| Key                | Description                                                                                | Default |\n-| ---                | ---                                                                                        | ---     |\n-| `manifest_version` | The version of the manifest protocol                                                       | `1`     |\n-| `name`             | Human-readable title of the Executor                                                       | None    |\n-| `description`      | Human-readable description of the Executor                                                 | None    |\n-| `url`              | URL to find more information about the Executor, normally the GitHub repo URL              | None    |\n-| `keywords`         | A list of strings to help users filter and locate your package                             | None    |\n\n---\n file path A: docs/fundamentals/executor/yaml-spec.md | file path B: docs/fundamentals/executor/yaml-spec.md\n\n@@ -20,6 +20,8 @@ py_modules:\n metas:\n   name: Indexer\n   description: Indexes all documents\n+  url: https://github.com/janedoe/indexer\n+  keywords: [\"indexer\", \"executor\"]\n ```\n \n ## Keywords\n@@ -36,6 +38,9 @@ List of strings defining the Python dependencies of the Executor. Most notably t\n ### `metas`\n Collection containing meta information about the Executor.\n \n-- **`name`**: String that defines the name of the Executor.\n-- **`description`**: String that describes the Executor.\n+Your executor will also be annoted with this information when publishing to Jina Hub. To get better appeal on Jina Hub, you may want to carefully set the `metas` fields to the correct values:\n \n+- **`name`**: Human-readable name of the Executor.\n+- **`description`**: Human-readable description of the Executor. \n+- **`url`**: URL of where to find more information about the Executor, normally a GitHub repo URL.\n+- **`keywords`**: A list of strings to help users filter and locate your package.\n\\ No newline at end of file\n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -22,7 +22,7 @@ hello-jina/\n - `config.yml` is the config file for the {class}`~jina.Executor`. It\u2019s where you keep metadata for your Executor, as well as dependencies.\n - `client.py` is the entrypoint of your Jina project. You can run it via `python app.py`.\n \n-There may be some other files like `README.md`, `manifest.yml`  `requirements.txt` to provide extra metadata about that {class}`~jina.Executor`. More information {ref}`can be found here<create-executor>`.\n+There may be some other files like `README.md`, `requirements.txt` to provide extra metadata about that {class}`~jina.Executor`. More information {ref}`can be found here<create-executor>`.\n \n \n Now run it and observe the output of the server and client.\n\n---\n file path A: docs/yaml-spec.md | file path B: docs/yaml-spec.md\n\n@@ -17,14 +17,6 @@ Executor level YAML is placed inside the Executor directory, as a part of Execut\n Define the argument of `__init__`, Python module dependencies and other settings of an Executor. \n ::::\n \n-::::{grid-item-card} Hub Manifest YAML\n-:link: fundamentals/executor/hub/yaml-spec\n-:link-type: doc\n-\n-Define meta information about how the Executor appears in Jina Hub.\n-\n-::::\n-\n \n :::::\n \n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -217,7 +217,6 @@ Meta information helps other users to identify, search and reuse your Executor o\n         Path(exec_path).mkdir(parents=True, exist_ok=True)\n         pkg_files = [\n             'executor.py',\n-            'manifest.yml',\n             'README.md',\n             'requirements.txt',\n             'config.yml',\n@@ -243,7 +242,8 @@ Meta information helps other users to identify, search and reuse your Executor o\n         # adding the columns in order of `ls` output\n         table.add_row(\n             'config.yml',\n-            'The YAML config file of the Executor. You can define [bold]__init__[/bold] arguments using [bold]with[/bold] keyword.',\n+            'The YAML config file of the Executor. You can define [bold]__init__[/bold] arguments using [bold]with[/bold] keyword.' +\\\n+            '\\nYou can also define metadata for the executor, for better appeal on Jina Hub.',\n         )\n \n         table.add_row(\n@@ -256,7 +256,13 @@ with:\n   foo: 1\n   bar: hello\n py_modules:\n-  - executor.py''',\n+  - executor.py\n+metas:\n+  name: {exec_name}\n+  description: {exec_description if exec_description != '{{}}' else 'None'}\n+  url: {exec_url if exec_url != '{{}}' else 'None'}\n+  keywords: {exec_keywords if exec_keywords != '{{}}' else 'None'}\n+''',\n                     'yaml',\n                     theme='monokai',\n                     line_numbers=True,\n@@ -275,27 +281,6 @@ py_modules:\n             )\n \n         table.add_row('executor.py', 'The main logic file of the Executor.')\n-        table.add_row(\n-            'manifest.yml',\n-            'Metadata for the Executor, for better appeal on Jina Hub.',\n-        )\n-\n-        manifest_fields_table = Table(box=box.SIMPLE)\n-        manifest_fields_table.add_column('Field', style='cyan', no_wrap=True)\n-        manifest_fields_table.add_column('Description', no_wrap=True)\n-        manifest_fields_table.add_row('name', 'Human-readable title of the Executor')\n-        manifest_fields_table.add_row(\n-            'description', 'Human-readable description of the Executor'\n-        )\n-        manifest_fields_table.add_row(\n-            'url',\n-            'URL to find more information on the Executor (e.g. GitHub repo URL)',\n-        )\n-        manifest_fields_table.add_row(\n-            'keywords', 'Keywords that help user find the Executor'\n-        )\n-\n-        table.add_row('', manifest_fields_table)\n         table.add_row('README.md', 'A usage guide of the Executor.')\n         table.add_row('requirements.txt', 'The Python dependencies of the Executor.')\n \n\n---\n file path A: jina/resources/executor-template/config.yml | file path B: jina/resources/executor-template/config.yml\n\n@@ -1,3 +1,8 @@\n jtype: {{exec_name}}\n py_modules:\n-  - executor.py\n\\ No newline at end of file\n+  - executor.py\n+metas:\n+  name: {{exec_name}}\n+  description: {{exec_description}}\n+  url: {{exec_url}}\n+  keywords: {{exec_keywords}}\n\\ No newline at end of file\n\n---\n file path A: jina/resources/executor-template/manifest.yml | file path B: None\n\n@@ -1,5 +0,0 @@\n-manifest_version: 1\n-name: {{exec_name}}\n-description: {{exec_description}}\n-url: {{exec_url}}\n-keywords: {{exec_keywords}}\n\\ No newline at end of file\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -768,7 +768,6 @@ def test_new_without_arguments(monkeypatch, tmpdir, add_dockerfile):\n \n     pkg_files = [\n         'executor.py',\n-        'manifest.yml',\n         'README.md',\n         'requirements.txt',\n         'config.yml',\n@@ -781,7 +780,6 @@ def test_new_without_arguments(monkeypatch, tmpdir, add_dockerfile):\n         assert (path / file).exists()\n     for file in [\n         'executor.py',\n-        'manifest.yml',\n         'README.md',\n         'config.yml',\n     ]:\n@@ -836,7 +834,6 @@ def test_new_with_arguments(\n \n     pkg_files = [\n         'executor.py',\n-        'manifest.yml',\n         'README.md',\n         'requirements.txt',\n         'config.yml',\n@@ -851,16 +848,17 @@ def test_new_with_arguments(\n     for file in pkg_files:\n         assert (path / file).exists()\n \n-    for file in ['executor.py', 'manifest.yml', 'README.md', 'config.yml']:\n+    for file in ['executor.py', 'README.md', 'config.yml']:\n         with open(path / file, 'r') as fp:\n             assert 'argsExecutor' in fp.read()\n+    \n     if advance_configuration or confirm_advance_configuration:\n-        with open(path / 'manifest.yml') as fp:\n+        with open(path / 'config.yml') as fp:\n             temp = yaml.load(fp, Loader=yaml.FullLoader)\n-            assert temp['name'] == 'argsExecutor'\n-            assert temp['description'] == 'args description'\n-            assert temp['keywords'] == ['args', 'keywords']\n-            assert temp['url'] == 'args url'\n+            assert temp['metas']['name'] == 'argsExecutor'\n+            assert temp['metas']['description'] == 'args description'\n+            assert temp['metas']['keywords'] == ['args', 'keywords']\n+            assert temp['metas']['url'] == 'args url'\n \n \n class SandboxGetMockResponse:\n\n\n###\n\n", "completion": "refactor: manifest config (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -212,10 +212,6 @@ Meta information helps other users to identify, search and reuse your Executor o\n                         .replace('{{exec_keywords}}', str(exec_keywords.split(',')))\n                         .replace('{{exec_url}}', exec_url)\n                     )\n-\n-                    f = [\n-                        v + '\\n' for v in f.split('\\n') if not ('{{' in v or '}}' in v)\n-                    ]\n                     fpw.writelines(f)\n \n         Path(exec_path).mkdir(parents=True, exist_ok=True)\n\n\n###\n\n", "completion": "fix: gpu dockerfile template include now jina install (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -32,14 +32,14 @@ grpcio-reflection>=1.46.0,<1.48.1:  core\n grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray>=0.16.1:           core\n+docarray>=0.16.3:           core\n jina-hubble-sdk>=0.15.1:    core\n jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n-docarray[common]>=0.16.1:   standard,devel\n+docarray[common]>=0.16.3:   standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -32,14 +32,14 @@ grpcio-reflection>=1.46.0,<1.48.1:  core\n grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray>=0.16.1:           core\n+docarray>=0.16.3:           core\n jina-hubble-sdk>=0.15.1:    core\n jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n-docarray[common]>=0.16.1:   standard,devel\n+docarray[common]>=0.16.3:   standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n\n\n###\n\n", "completion": "fix: set minimal docarray dependency (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -266,6 +266,7 @@ jobs:\n           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n       - name: Test k8s\n         run: |\n+          export LINKERD2_VERSION=stable-2.11.4\n           curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh\n           pytest -v -s --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml ./tests/k8s/test_k8s.py ./tests/k8s/test_graceful_request_handling.py\n         timeout-minutes: 30\n\n\n###\n\n", "completion": "fix: linkerd cd (#<issue-num>)"}
{"prompt": " file path A: tests/k8s/test_k8s.py | file path B: tests/k8s/test_k8s.py\n\n@@ -128,7 +128,6 @@ async def run_test(flow, core_client, namespace, endpoint, n_docs=10, request_si\n         client_kwargs = dict(\n             host='localhost',\n             port=flow.port,\n-            return_responses=True,\n             asyncio=True,\n         )\n         client_kwargs.update(flow._common_kwargs)\n@@ -140,6 +139,7 @@ async def run_test(flow, core_client, namespace, endpoint, n_docs=10, request_si\n             endpoint,\n             inputs=[Document() for _ in range(n_docs)],\n             request_size=request_size,\n+            return_responses=True,\n         ):\n             responses.append(resp)\n \n\n---\n file path A: tests/k8s/test_k8s_failures.py | file path B: tests/k8s/test_k8s_failures.py\n\n@@ -140,7 +140,6 @@ async def run_test_until_event(\n         client_kwargs = dict(\n             host='localhost',\n             port=flow.port,\n-            return_responses=True,\n             asyncio=True,\n         )\n         client_kwargs.update(flow._common_kwargs)\n@@ -166,6 +165,7 @@ async def run_test_until_event(\n             endpoint,\n             inputs=functools.partial(async_inputs, sent_ids, sleep_time),\n             request_size=1,\n+            return_responses=True\n         ):\n             responses.append(resp)\n \n\n\n###\n\n", "completion": "test: fix k8s tests return responses params (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -226,6 +226,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14947,3 +14948,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```d124d9af```](https://github.com/jina-ai/jina/commit/d124d9af8680f53bf087271e693bcaff15801ffc)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```0df7cd8a```](https://github.com/jina-ai/jina/commit/0df7cd8aab71b9ccee9f7654b108dacb6811d5e5)] __-__ __version__: the next version will be 3.8.2 (*Jina Dev Bot*)\n \n+<a name=release-note-3-8-3></a>\n+## Release Note (`3.8.3`)\n+\n+> Release time: 2022-09-05 14:48:30\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ AlaeddineAbdessalem,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```7b7eecc5```](https://github.com/jina-ai/jina/commit/7b7eecc538cb5d07663a7922ac1729ed990e2517)] __-__ cap grpc version (#5122) (*AlaeddineAbdessalem*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```47e2cfc3```](https://github.com/jina-ai/jina/commit/47e2cfc3c28465af8f402261341693e28614f034)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```0dbdcaa0```](https://github.com/jina-ai/jina/commit/0dbdcaa048bff6b05fcfb9930f92dbc5a6c5da12)] __-__ __version__: the next version will be 3.8.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.8.3'\n+__version__ = '3.8.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.8.4"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -27,9 +27,9 @@\n \n numpy:                      core\n protobuf>=3.13.0:           core\n-grpcio>=1.46.0:             core\n-grpcio-reflection>=1.46.0:  core\n-grpcio-health-checking>=1.46.0:  core\n+grpcio>=1.46.0,<1.48.1:     core\n+grpcio-reflection>=1.46.0,<1.48.1:  core\n+grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.1:           core\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -27,9 +27,9 @@\n \n numpy:                      core\n protobuf>=3.13.0:           core\n-grpcio>=1.46.0:             core\n-grpcio-reflection>=1.46.0:  core\n-grpcio-health-checking>=1.46.0:  core\n+grpcio>=1.46.0,<1.48.1:     core\n+grpcio-reflection>=1.46.0,<1.48.1:  core\n+grpcio-health-checking>=1.46.0,<1.48.1:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.16.1:           core\n\n\n###\n\n", "completion": "fix: cap grpc version (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -225,6 +225,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14907,3 +14908,41 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```1ad06216```](https://github.com/jina-ai/jina/commit/1ad06216b3d92501e6292fdabd542ed59b388284)] __-__ __docs__: fix retention days description (*Han Xiao*)\n  - [[```9f5f5879```](https://github.com/jina-ai/jina/commit/9f5f58796481bbc0fc7f6985721ba726ef121860)] __-__ __version__: the next version will be 3.8.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-8-2></a>\n+## Release Note (`3.8.2`)\n+\n+> Release time: 2022-09-03 15:56:11\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Zac Li,  samsja,  AlaeddineAbdessalem,  Jina Dev Bot,  tarrantro,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```e794c06c```](https://github.com/jina-ai/jina/commit/e794c06c919ab1d04fe99136851c897ce64b8e5c)] __-__ expose grpc parameters and add production ready keepalive parameters (#5092) (*samsja*)\n+ - [[```6205ffc9```](https://github.com/jina-ai/jina/commit/6205ffc9ff0ef9e35a16fb1bcdde70aa48175d1a)] __-__ add gpu dockerfile support to jina hub new (#5104) (*AlaeddineAbdessalem*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```9293698b```](https://github.com/jina-ai/jina/commit/9293698bdd09686ab4f7905930a7f4e78af453a7)] __-__ rewrite flow add (*Han Xiao*)\n+ - [[```115bc0fa```](https://github.com/jina-ai/jina/commit/115bc0fabd5533116b994b9e3468edbc83228fd5)] __-__ rewrite flow add (#5120) (*Han Xiao*)\n+ - [[```22fdbcee```](https://github.com/jina-ai/jina/commit/22fdbceeb2492143653071a70ebf60474e88b1da)] __-__ __jcloud__: fix jc status link (#5116) (*Zac Li*)\n+ - [[```4dfe6dfb```](https://github.com/jina-ai/jina/commit/4dfe6dfb4f7aa3919e1164e8a88fe75114a06684)] __-__ __jcloud__: fix docs for gateway resource customization (#5114) (*Zac Li*)\n+ - [[```6b24bf69```](https://github.com/jina-ai/jina/commit/6b24bf698b907e2104ad4b4d7dc093bfab0b6518)] __-__ correct jcloud retention days (#5109) (*tarrantro*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```587f6268```](https://github.com/jina-ai/jina/commit/587f626800d830dd570b7b22e92d37fff0d376b3)] __-__ fix test  concurrent async flow (#5115) (*AlaeddineAbdessalem*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```763f6773```](https://github.com/jina-ai/jina/commit/763f67732cbf4319c81af520ad309225b9fd8b02)] __-__ update readme (*Han Xiao*)\n+ - [[```2651c506```](https://github.com/jina-ai/jina/commit/2651c506a5acd21ca2f7542237e731d5fe6a88d5)] __-__ disable hub-integration (*Han Xiao*)\n+ - [[```3590c385```](https://github.com/jina-ai/jina/commit/3590c3856681eeccbf8f148a1377dc735883f69a)] __-__ fix readme (*Han Xiao*)\n+ - [[```8303fb25```](https://github.com/jina-ai/jina/commit/8303fb25df97aa5122dd19394eaa8cbe4c5864c4)] __-__ __docs__: improve docs on jcloud k8s (*Han Xiao*)\n+ - [[```a34edc62```](https://github.com/jina-ai/jina/commit/a34edc62c46df778bc477a39a2fb3ecc4fea38df)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```d124d9af```](https://github.com/jina-ai/jina/commit/d124d9af8680f53bf087271e693bcaff15801ffc)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```0df7cd8a```](https://github.com/jina-ai/jina/commit/0df7cd8aab71b9ccee9f7654b108dacb6811d5e5)] __-__ __version__: the next version will be 3.8.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.8.2'\n+__version__ = '3.8.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.8.3"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -21,30 +21,6 @@\n \n Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n-<sup>\n-<table align=center>\n-<thead>\n-  <tr>\n-    <th colspan=\"4\">Understand Jina better</th>\n-  </tr>\n-</thead>\n-<tbody>\n-  <tr>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udcd7 What is Jina?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#relation-to-mlops\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd0d Is Jina MLOps for search?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/comparing-alternatives/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udd9a How Jina compares to alternatives?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#why-cloud-native\" target=\"_blank\" rel=\"noopener noreferrer\">\u2601\ufe0f What is Cloud-Native?</a></td>\n-  </tr>\n-  <tr>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd2e What is cross-modal and multimodal\uff1f</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#neural-search\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83e\uddec What is neural search?</a></td>\n-    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#creative-ai\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udfa8 What is creative AI?</a></td>\n-    <td></td>\n-  </tr>\n-</tbody>\n-</table>\n-</sup>\n-\n Applications built with Jina enjoy the following features out-of-the-box:\n \n \ud83c\udf0c **Universal**\n@@ -74,8 +50,32 @@ Applications built with Jina enjoy the following features out-of-the-box:\n \n <!-- end jina-description -->\n \n+\n ## [Documentation](https://docs.jina.ai)\n \n+<table align=center>\n+<thead>\n+  <tr>\n+    <th colspan=\"4\">Understand Jina better</th>\n+  </tr>\n+</thead>\n+<tbody>\n+  <tr>\n+    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udcd7 What is Jina?</a></td>\n+    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#relation-to-mlops\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd0d Is Jina MLOps for search?</a></td>\n+    <td><a href=\"https://docs.jina.ai/get-started/comparing-alternatives/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udd9a How Jina compares to alternatives?</a></td>\n+    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#why-cloud-native\" target=\"_blank\" rel=\"noopener noreferrer\">\u2601\ufe0f What is Cloud-Native?</a></td>\n+  </tr>\n+  <tr>\n+    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd2e What is cross-modal and multimodal\uff1f</a></td>\n+    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#neural-search\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83e\uddec What is neural search?</a></td>\n+    <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#creative-ai\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udfa8 What is creative AI?</a></td>\n+    <td></td>\n+  </tr>\n+</tbody>\n+</table>\n+\n+\n ## Install \n \n ```bash\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -23,10 +23,10 @@ Jina is a MLOps framework that empowers anyone to build cross-modal and multi-mo\n \n <sup>\n <sub>\n-<table>\n+<table align=center>\n <thead>\n   <tr>\n-    <th colspan=\"3\">Understand Jina better</th>\n+    <th colspan=\"4\">Understand Jina better</th>\n   </tr>\n </thead>\n <tbody>\n@@ -34,11 +34,13 @@ Jina is a MLOps framework that empowers anyone to build cross-modal and multi-mo\n     <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udcd7 What is Jina?</a></td>\n     <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#relation-to-mlops\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd0d Is Jina MLOps for search?</a></td>\n     <td><a href=\"https://docs.jina.ai/get-started/comparing-alternatives/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udd9a How Jina compares to alternatives?</a></td>\n+    <td><a href=\"https://docs.jina.ai/get-started/what-is-jina/#why-cloud-native\" target=\"_blank\" rel=\"noopener noreferrer\">\u2601\ufe0f What is Cloud-Native?</a></td>\n   </tr>\n   <tr>\n     <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83d\udd2e What is cross-modal and multimodal\uff1f</a></td>\n     <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#neural-search\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83e\uddec What is neural search?</a></td>\n     <td><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/#creative-ai\" target=\"_blank\" rel=\"noopener noreferrer\">\ud83c\udfa8 What is creative AI?</a></td>\n+    <td></td>\n   </tr>\n </tbody>\n </table>\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -12,7 +12,8 @@\n <p align=center>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=Release&style=flat-square\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?&logo=Codecov&logoColor=white&style=flat-square\"></a>\n-<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.1k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n+<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.6k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n+<a href=\"https://pypistats.org/packages/jina\"><img alt=\"PyPI - Downloads from official pypistats\" src=\"https://img.shields.io/pypi/dm/jina?style=flat-square\"></a>\n <a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n </p>\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -5,7 +5,7 @@\n </p>\n \n <p align=\"center\">\n-<b>Build cross-modal and multi-modal applications on the cloud</b>\n+<b>Build cross-modal and multi-modal applications<sup><a href=\"https://docs.jina.ai/get-started/what-is-cross-modal-multi-modal/\">[?]</a></sup> on the cloud</b>\n </p>\n \n \n@@ -18,9 +18,9 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n+Jina is a framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n-<sub><sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/discoart/\">DiscoArt</a>, <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup></sub>\n+<sub><sup><a id=\"example-application\">[?]</a> Example cross-modal/multimodal applications: <a href=\"https://github.com/jina-ai/discoart/\">DiscoArt</a>, <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>, <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.\n \n Applications built with Jina enjoy the following features out-of-the-box:\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -11,9 +11,9 @@\n \n <p align=center>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n-<a href=\"https://hub.docker.com/r/jinaai/jina/tags\"><img src=\"https://img.shields.io/docker/v/jinaai/jina?color=%23099cec&amp;label=Docker&amp;logo=docker&amp;logoColor=white&amp;sort=semver&style=flat-square\" alt=\"Docker Image Version (latest semver)\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n+<a href=\"https://hub.docker.com/r/jinaai/jina/tags\"><img alt=\"Docker Pulls\" src=\"https://img.shields.io/docker/pulls/jinaai/jina?logo=Docker&style=social\"></a>\n </p>\n \n <!-- start jina-description -->\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -10,10 +10,10 @@\n \n \n <p align=center>\n-<a href=\"https://pypi.org/project/jina/\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/badges/python-badge.svg?raw=true\" alt=\"Python 3.7 3.8 3.9\" title=\"Jina supports Python 3.7 and above\"></a>\n-<a href=\"https://pypi.org/project/jina/\"><img src=\"https://img.shields.io/pypi/v/jina?color=%23099cec&amp;label=PyPI&amp;logo=pypi&amp;logoColor=white\" alt=\"PyPI\"></a>\n-<a href=\"https://codecov.io/gh/jina-ai/jina\"><img src=\"https://codecov.io/gh/jina-ai/jina/branch/master/graph/badge.svg\" alt=\"codecov\"></a>\n-<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white\"></a>\n+<a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n+<a href=\"https://hub.docker.com/r/jinaai/jina/tags\"><img src=\"https://img.shields.io/docker/v/jinaai/jina?color=%23099cec&amp;label=Docker&amp;logo=docker&amp;logoColor=white&amp;sort=semver&style=flat-square\" alt=\"Docker Image Version (latest semver)\"></a>\n+<a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n+<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n </p>\n \n <!-- start jina-description -->\n\n\n###\n\n", "completion": "chore: update readme"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -22,7 +22,6 @@\n Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n <sup>\n-<sub>\n <table align=center>\n <thead>\n   <tr>\n@@ -44,7 +43,6 @@ Jina is a MLOps framework that empowers anyone to build cross-modal and multi-mo\n   </tr>\n </tbody>\n </table>\n-</sub>\n </sup>\n \n Applications built with Jina enjoy the following features out-of-the-box:\n\n\n###\n\n", "completion": "chore: disable hub integration test"}
{"prompt": " file path A: .github/workflows/force-release.yml | file path B: .github/workflows/force-release.yml\n\n@@ -29,7 +29,7 @@ jobs:\n       jina_auth_token: ${{ secrets.JINA_AUTH_TOKEN }}\n \n   regular-release:\n-    needs: [token-check, hub-integration]\n+    needs: [token-check]\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2\n\n\n###\n\n", "completion": "chore: disable hub-integration"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -22,7 +22,6 @@\n Jina is a MLOps framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n <sup>\n-<sub>\n <table align=center>\n <thead>\n   <tr>\n@@ -44,7 +43,6 @@ Jina is a MLOps framework that empowers anyone to build cross-modal and multi-mo\n   </tr>\n </tbody>\n </table>\n-</sub>\n </sup>\n \n Applications built with Jina enjoy the following features out-of-the-box:\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -38,11 +38,13 @@ Applications built with Jina enjoy the following features out-of-the-box:\n \n \u2601\ufe0f **Cloud-native**\n   - Seamless Docker container integration: sharing, exploring, sandboxing, versioning and dependency control via [Jina Hub](https://hub.jina.ai).\n-  - Fast deployment to Kubernetes, Docker Compose and [Jina Cloud](https://docs.jina.ai/fundamentals/jcloud/).\n   - Full observability via Prometheus and Grafana.\n+  - Fast deployment to Kubernetes, Docker Compose.\n \n \ud83c\udf71 **Ecosystem**\n   - Improved engineering efficiency thanks to the Jina AI ecosystem, so you can focus on innovating with the data applications you build.\n+  - Free CPU/GPU hosting via [Jina Cloud](https://docs.jina.ai/fundamentals/jcloud/).\n+\n \n <p align=\"center\">\n <a href=\"#\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/core-tree-graph.svg?raw=true\" alt=\"Jina in Jina AI neural search ecosystem\" width=\"100%\"></a>\n@@ -58,7 +60,7 @@ Applications built with Jina enjoy the following features out-of-the-box:\n pip install jina\n ```\n \n-[More install options can be found in the docs](https://docs.jina.ai/get-started/install/).\n+[More install options on Apple Silicon and Windows can be found here](https://docs.jina.ai/get-started/install/).\n \n \n ## Get Started\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -20,7 +20,7 @@\n \n Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n-<sub><sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/discoart/\">DiscoArt</a> <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup></sub>\n+<sub><sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/discoart/\">DiscoArt</a>, <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup></sub>\n \n Applications built with Jina enjoy the following features out-of-the-box:\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -20,7 +20,7 @@\n \n Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n-<sub><sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup></sub>\n+<sub><sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/discoart/\">DiscoArt</a> <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup></sub>\n \n Applications built with Jina enjoy the following features out-of-the-box:\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -10,7 +10,7 @@\n \n \n <p align=center>\n-<a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=Release&logo=Python&logoColor=white&style=flat-square\"></a>\n+<a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=Release&style=flat-square\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?&logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.1k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n <a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -10,10 +10,10 @@\n \n \n <p align=center>\n-<a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=Release&logo=Python&logoColor=white&style=flat-square\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?&logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.1k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n+<a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n </p>\n \n <!-- start jina-description -->\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -11,8 +11,8 @@\n \n <p align=center>\n <a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n-<a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n-<a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n+<a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=Release&logo=Python&logoColor=white&style=flat-square\"></a>\n+<a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?&logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.1k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n </p>\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -13,7 +13,7 @@\n <a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n-<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.0k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n+<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.1k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n </p>\n \n <!-- start jina-description -->\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -21,6 +21,8 @@\n \n Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a PoC into a production-ready service in just minutes. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n+<sub><sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup></sub>\n+\n Applications built with Jina enjoy the following features out-of-the-box:\n \n \ud83c\udf0c **Universal**\n@@ -42,7 +44,7 @@ Applications built with Jina enjoy the following features out-of-the-box:\n \ud83c\udf71 **Ecosystem**\n   - Improved engineering efficiency thanks to the Jina AI ecosystem, so you can focus on innovating with the data applications you build.\n \n-<sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup>\n+\n \n <!-- end jina-description -->\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -14,7 +14,6 @@\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n-<a href=\"https://hub.docker.com/r/jinaai/jina/tags\"><img alt=\"Docker Pulls\" src=\"https://img.shields.io/docker/pulls/jinaai/jina?logo=Docker&style=social\"></a>\n </p>\n \n <!-- start jina-description -->\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -12,9 +12,8 @@\n <p align=center>\n <a href=\"https://pypi.org/project/jina/\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/badges/python-badge.svg?raw=true\" alt=\"Python 3.7 3.8 3.9\" title=\"Jina supports Python 3.7 and above\"></a>\n <a href=\"https://pypi.org/project/jina/\"><img src=\"https://img.shields.io/pypi/v/jina?color=%23099cec&amp;label=PyPI&amp;logo=pypi&amp;logoColor=white\" alt=\"PyPI\"></a>\n-<a href=\"https://hub.docker.com/r/jinaai/jina/tags\"><img src=\"https://img.shields.io/docker/v/jinaai/jina?color=%23099cec&amp;label=Docker&amp;logo=docker&amp;logoColor=white&amp;sort=semver\" alt=\"Docker Image Version (latest semver)\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img src=\"https://codecov.io/gh/jina-ai/jina/branch/master/graph/badge.svg\" alt=\"codecov\"></a>\n-<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.6k%2B-blueviolet?logo=slack&amp;logoColor=white\"></a>\n+<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white\"></a>\n </p>\n \n <!-- start jina-description -->\n\n\n###\n\n", "completion": "chore: fix readme"}
{"prompt": " file path A: jina/jaml/helper.py | file path B: jina/jaml/helper.py\n\n@@ -181,7 +181,11 @@ def parse_config_source(\n     elif allow_class_type and path.isidentifier():\n         # possible class name\n         return io.StringIO(f'!{path}'), None\n-    elif allow_py_module_class_type and path.split('.')[-1].isidentifier():\n+    elif (\n+        allow_py_module_class_type\n+        and '.' in path\n+        and path.split('.')[-1].isidentifier()\n+    ):\n         # possible module.class name\n         module_name, cls_name = path.rsplit('.', maxsplit=1)\n         print(module_name, cls_name)\n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -185,10 +185,7 @@ class DataRequestHandler:\n                 self.args.name,\n             ).inc(len(docs))\n \n-        if self.args.output_array_type:\n-            DataRequestHandler.replace_docs(\n-                requests[0], docs, self.args.output_array_type\n-            )\n+        DataRequestHandler.replace_docs(requests[0], docs, self.args.output_array_type)\n \n         return requests[0]\n \n\n\n###\n\n", "completion": "docs: rewrite flow add"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -186,7 +186,7 @@ the deletion, to make it non-interactive to better suit your use case, set below\n export JCLOUD_NO_INTERACTIVE=1\n ```\n \n-(jcloud-flow-status)\n+(jcloud-flow-status)=\n ### Get status\n \n To get the status of a Flow:\n@@ -201,7 +201,7 @@ jc status 15937a10bd\n ### Monitoring\n Basic monitoring is provided to the Flows deployed on JCloud.\n \n-To access the [Grafana](https://grafana.com/) powered dashboard, get `{ref} the status of the Flow <jcloud-flow-status>` first, at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n+To access the [Grafana](https://grafana.com/) powered dashboard, get {ref}`the status of the Flow<jcloud-flow-status>` first, at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n \n ```{figure} monitoring.png\n :width: 70%\n\n\n###\n\n", "completion": "docs(jcloud): fix jc status link (#<issue-num>)"}
{"prompt": " file path A: tests/unit/orchestrate/flow/flow-async/test_asyncflow.py | file path B: tests/unit/orchestrate/flow/flow-async/test_asyncflow.py\n\n@@ -93,13 +93,12 @@ class Wait5s(Executor):\n         time.sleep(5)\n \n \n-async def run_async_flow_5s(protocol):\n-    with Flow(protocol=protocol, asyncio=True, timeout_send=6000).add(uses=Wait5s) as f:\n-        async for r in f.index(\n-            from_ndarray(np.random.random([num_docs, 4])),\n-            on_done=validate,\n-        ):\n-            assert isinstance(r, DocumentArray)\n+async def run_async_flow_5s(flow):\n+    async for r in flow.index(\n+        from_ndarray(np.random.random([num_docs, 4])),\n+        on_done=validate,\n+    ):\n+        assert isinstance(r, DocumentArray)\n \n \n async def sleep_print():\n@@ -111,13 +110,18 @@ async def sleep_print():\n \n async def concurrent_main(protocol):\n     # about 5s; but some dispatch cost, can't be just 5s, usually at <7s\n-    await asyncio.gather(run_async_flow_5s(protocol), sleep_print())\n+    with Flow(protocol=protocol, asyncio=True, timeout_send=6000).add(uses=Wait5s) as f:\n+        with TimeContext('concurrent await') as t:\n+            await asyncio.gather(run_async_flow_5s(f), sleep_print())\n+    return t\n \n \n async def sequential_main(protocol):\n     # about 10s; with some dispatch cost , usually at <12s\n-    await run_async_flow_5s(protocol)\n-    await sleep_print()\n+    with Flow(protocol=protocol, asyncio=True, timeout_send=6000).add(uses=Wait5s) as f:\n+        with TimeContext('sequential await') as t:\n+            await run_async_flow_5s(f)\n+            await sleep_print()\n \n \n @pytest.mark.slow\n@@ -134,11 +138,10 @@ async def test_run_async_flow_other_task_sequential(protocol):\n @pytest.mark.asyncio\n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n async def test_run_async_flow_other_task_concurrent(protocol):\n-    with TimeContext('concurrent await') as t:\n-        await concurrent_main(protocol)\n+    t = await concurrent_main(protocol)\n \n-    # some dispatch cost, can't be just 5s, usually at 7~8s, but must <10s\n-    assert t.duration < 10\n+    # some dispatch cost, can't be just 5s, usually between 5 and 6, but must be <7s\n+    assert t.duration < 7\n \n \n @pytest.mark.slow\n\n\n###\n\n", "completion": "test: fix test  concurrent async flow (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/yaml-spec.md | file path B: docs/fundamentals/jcloud/yaml-spec.md\n\n@@ -267,9 +267,8 @@ jtype: Flow\n jcloud:\n   gateway:\n     resources:\n-      requests:\n-        memory: 800M\n-        cpu: 0.4\n+      memory: 800M\n+      cpu: 0.4\n executors:\n   - name: encoder\n     uses: jinahub+docker://Encoder\n\n\n###\n\n", "completion": "docs(jcloud): fix docs for gateway resource customization (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/hub/create-hub-executor.md | file path B: docs/fundamentals/executor/hub/create-hub-executor.md\n\n@@ -51,6 +51,11 @@ structure.\n     package.\n \n \n+```{tip}\n+In the wizard of `jina hub new`, you can choose from four Dockerfile templates: `cpu`, `tf-gpu`, `torch-gpu`, and `jax-gpu`.\n+```\n+\n+\n * No need to bump Jina version\n \n   Hub executors are version-agnostic. When you pull an Executor from Hub, Hubble will always select the right Jina \n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -117,13 +117,49 @@ This guide helps you to create your own Executor in 30 seconds.''',\n         exec_keywords = '{{}}'\n         exec_url = '{{}}'\n \n-        is_dockerfile = False\n+        is_dockerfile = 'none'\n \n         if self.args.advance_configuration or Confirm.ask(\n             '[green]That\\'s all we need to create an Executor![/green]\\n'\n-            ':grey_question: Or do you want to proceed to advanced configuration',\n+            ':grey_question: Or do you want to proceed to advanced configuration [dim](GPU support, meta information on Hub, etc.)[/]',\n             default=False,\n         ):\n+            print(\n+                Panel.fit(\n+                    '''\n+[bold]Dockerfile[/bold] describes how this executor will be built. It is useful when\n+your executor has non-trivial dependencies or must be run under certain environment.\n+\n+- If [bold]Dockerfile[/bold] is not given, Jina Cloud automatically generates one.\n+- If [bold]Dockerfile[/bold] is provided by you, then Jina Cloud will respect it when building the Executor.\n+\n+Here are some Dockerfile templates for you to choose from:\n+- [b]cpu[/b]: CPU-only executor with Jina as base image;\n+- [b]torch-gpu[/b]: GPU enabled executor with PyTorch as the base image;\n+- [b]tf-gpu[/b]: GPU enabled executor with Tensorflow as the base image;\n+- [b]jax-gpu[/b]: GPU enabled executor with JAX installed.\n+''',\n+                    title=':package: [bold]Dockerfile[/bold]',\n+                    width=80,\n+                )\n+            )\n+\n+            is_dockerfile = self.args.dockerfile or Prompt.ask(\n+                ':grey_question: Select how you want to generate the [bold]Dockerfile[/bold] for this Executor?',\n+                choices=['cpu', 'torch-gpu', 'tf-gpu', 'jax-gpu', 'none'],\n+                default='cpu',\n+            )\n+\n+            print(\n+                Panel.fit(\n+                    '''\n+Meta information helps other users to identify, search and reuse your Executor on Jina Cloud.\n+''',\n+                    title=':name_badge: [bold]Meta Info[/bold]',\n+                    width=80,\n+                )\n+            )\n+\n             exec_description = (\n                 self.args.description\n                 if self.args.description\n@@ -157,32 +193,18 @@ This guide helps you to create your own Executor in 30 seconds.''',\n                 )\n             )\n \n-            print(\n-                Panel.fit(\n-                    '''\n-[bold]Dockerfile[/bold] describes how this executor will be built. It is useful when\n-your executor has non-trivial dependencies or must be run under certain environment.\n-\n-- If the [bold]Dockerfile[/bold] is missing, Jina automatically generates one for you.\n-- If you provide one, then Jina will respect the given [bold]Dockerfile[/bold].''',\n-                    title='[Optional] [bold]Dockerfile[/bold]',\n-                    width=80,\n-                )\n-            )\n-\n-            is_dockerfile = self.args.add_dockerfile or Confirm.ask(\n-                ':grey_question: Do you need to write your own [bold]Dockerfile[/bold] instead of the auto-generated one?',\n-                default=False,\n-            )\n             print('[green]That\\'s all we need to create an Executor![/green]')\n \n         def mustache_repl(srcs):\n             for src in track(\n                 srcs, description=f'Creating {exec_name}...', total=len(srcs)\n             ):\n+                dest = src\n+                if dest.endswith('.Dockerfile'):\n+                    dest = 'Dockerfile'\n                 with open(\n                     os.path.join(__resources_path__, 'executor-template', src)\n-                ) as fp, open(os.path.join(exec_path, src), 'w') as fpw:\n+                ) as fp, open(os.path.join(exec_path, dest), 'w') as fpw:\n                     f = (\n                         fp.read()\n                         .replace('{{exec_name}}', exec_name)\n@@ -205,8 +227,16 @@ your executor has non-trivial dependencies or must be run under certain environm\n             'config.yml',\n         ]\n \n-        if is_dockerfile:\n+        if is_dockerfile == 'cpu':\n             pkg_files.append('Dockerfile')\n+        elif is_dockerfile == 'torch-gpu':\n+            pkg_files.append('torch.Dockerfile')\n+        elif is_dockerfile == 'jax-gpu':\n+            pkg_files.append('torch.Dockerfile')\n+        elif is_dockerfile == 'tf-gpu':\n+            pkg_files.append('tf.Dockerfile')\n+        elif is_dockerfile != 'none':\n+            raise ValueError(f'Unknown Dockerfile type: {is_dockerfile}')\n \n         mustache_repl(pkg_files)\n \n@@ -227,11 +257,10 @@ your executor has non-trivial dependencies or must be run under certain environm\n                     f'''\n jtype: {exec_name}\n with:\n-    foo: 1\n-    bar: hello\n+  foo: 1\n+  bar: hello\n py_modules:\n-    - executor.py\n-                ''',\n+  - executor.py''',\n                     'yaml',\n                     theme='monokai',\n                     line_numbers=True,\n@@ -243,7 +272,7 @@ py_modules:\n             ),\n         )\n \n-        if is_dockerfile:\n+        if is_dockerfile != 'none':\n             table.add_row(\n                 'Dockerfile',\n                 'The Dockerfile describes how this executor will be built.',\n@@ -282,7 +311,7 @@ py_modules:\n \n         p0 = Panel(\n             Syntax(\n-                f'cd {exec_path}\\nls',\n+                f'ls {exec_path}',\n                 'console',\n                 theme='monokai',\n                 line_numbers=True,\n@@ -300,6 +329,19 @@ py_modules:\n             expand=False,\n         )\n \n+        p12 = Panel(\n+            Syntax(\n+                f'jina executor --uses {exec_path}/config.yml',\n+                'console',\n+                theme='monokai',\n+                line_numbers=True,\n+                word_wrap=True,\n+            ),\n+            title='3. Test the Executor locally',\n+            width=120,\n+            expand=False,\n+        )\n+\n         p2 = Panel(\n             Syntax(\n                 f'jina hub push {exec_path}',\n@@ -308,14 +350,13 @@ py_modules:\n                 line_numbers=True,\n                 word_wrap=True,\n             ),\n-            title='3. Share it to Jina Hub',\n+            title='4. Share it to Jina Hub',\n             width=120,\n             expand=False,\n         )\n \n-        final_table.add_row(p0)\n-        final_table.add_row(p1)\n-        final_table.add_row(p2)\n+        for _p in [p0, p1, p12, p2]:\n+            final_table.add_row(_p)\n \n         p = Panel(\n             final_table,\n\n---\n file path A: jina/parsers/hubble/new.py | file path B: jina/parsers/hubble/new.py\n\n@@ -45,7 +45,8 @@ def mixin_hub_new_parser(parser):\n     )\r\n \r\n     gp.add_argument(\r\n-        '--add-dockerfile',\r\n-        help='If set, add a Dockerfile to the created Executor bundle',\r\n-        action='store_true',\r\n+        '--dockerfile',\r\n+        help='The Dockerfile template to use for the Executor',\r\n+        type=str,\r\n+        choices=['cpu', 'tf-gpu', 'torch-gpu', 'jax-gpu'],\r\n     )\r\n\n---\n file path A: jina/resources/executor-template/Dockerfile | file path B: jina/resources/executor-template/Dockerfile\n\n@@ -1,11 +1,13 @@\n-FROM jinaai/jina:latest\n+ARG JINA_VERSION=latest\n+\n+FROM jinaai/jina:${JINA_VERSION}\n \n # install requirements before copying the workspace\n COPY requirements.txt /requirements.txt\n RUN pip install --default-timeout=1000 --compile -r requirements.txt\n \n # setup the workspace\n-COPY . /workspace\n-WORKDIR /workspace\n+COPY . /workdir/\n+WORKDIR /workdir\n \n ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n\\ No newline at end of file\n\n---\n file path A: None | file path B: jina/resources/executor-template/jax.Dockerfile\n\n@@ -0,0 +1,27 @@\n+ARG CUDA_VERSION=11.6.0\n+ARG CUDNN_VERSION=8\n+\n+FROM nvidia/cuda:${CUDA_VERSION}-devel-ubuntu20.04\n+\n+# declare the image name\n+ARG JAXLIB_VERSION=0.3.0\n+\n+# install python3-pip\n+RUN apt update && apt install python3-pip -y\n+\n+# install dependencies via pip\n+RUN python3 -m pip install numpy scipy six wheel jaxlib==${JAXLIB_VERSION}+cuda11.cudnn82 -f https://storage.googleapis.com/jax-releases/jax_releases.html jax[cuda11_cudnn82] -f https://storage.googleapis.com/jax-releases/jax_releases.html\n+\n+RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev git\n+\n+ARG JINA_VERSION=\n+\n+RUN python3 -m pip install --no-cache-dir jina${JINA_VERSION:+==${JINA_VERSION}}\n+\n+COPY requirements.txt requirements.txt\n+RUN pip install --default-timeout=1000 --compile -r requirements.txt\n+\n+COPY . /workdir/\n+WORKDIR /workdir\n+\n+ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n\\ No newline at end of file\n\n---\n file path A: None | file path B: jina/resources/executor-template/tf.Dockerfile\n\n@@ -0,0 +1,16 @@\n+ARG TF_PACKAGE_VERSION=latest\n+FROM tensorflow/tensorflow:${TF_PACKAGE_VERSION}-gpu\n+\n+RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev git\n+\n+ARG JINA_VERSION=\n+\n+RUN python3 -m pip install --no-cache-dir jina${JINA_VERSION:+==${JINA_VERSION}}\n+\n+COPY requirements.txt requirements.txt\n+RUN pip install --default-timeout=1000 --compile -r requirements.txt\n+\n+COPY . /workdir/\n+WORKDIR /workdir\n+\n+ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n\\ No newline at end of file\n\n---\n file path A: None | file path B: jina/resources/executor-template/torch.Dockerfile\n\n@@ -0,0 +1,20 @@\n+ARG TORCH_PACKAGE_VERSION=1.12.1\n+ARG CUDA_VERSION=11.3\n+ARG CUDNN_VERSION=8\n+\n+\n+FROM pytorch/pytorch:${TORCH_PACKAGE_VERSION}-cuda${CUDA_VERSION}-cudnn${CUDNN_VERSION}-runtime\n+\n+RUN apt-get update && apt-get install --no-install-recommends -y gcc libc6-dev git\n+\n+ARG JINA_VERSION=\n+\n+RUN python3 -m pip install --no-cache-dir jina${JINA_VERSION:+==${JINA_VERSION}}\n+\n+COPY requirements.txt requirements.txt\n+RUN pip install --default-timeout=1000 --compile -r requirements.txt\n+\n+COPY . /workdir/\n+WORKDIR /workdir\n+\n+ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n\\ No newline at end of file\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -163,7 +163,7 @@ ac_table = {\n             '--description',\n             '--keywords',\n             '--url',\n-            '--add-dockerfile',\n+            '--dockerfile',\n         ],\n         'hub push': [\n             '--help',\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -738,7 +738,7 @@ def test_pull_with_progress():\n     HubIO(args)._pull_with_progress(_log_stream_generator(), console)\n \n \n-@pytest.mark.parametrize('add_dockerfile', [True, False])\n+@pytest.mark.parametrize('add_dockerfile', ['cpu', 'torch-gpu', 'tf-gpu', 'jax-gpu'])\n def test_new_without_arguments(monkeypatch, tmpdir, add_dockerfile):\n     from rich.prompt import Confirm, Prompt\n \n@@ -746,22 +746,21 @@ def test_new_without_arguments(monkeypatch, tmpdir, add_dockerfile):\n         [\n             'DummyExecutor',\n             tmpdir / 'DummyExecutor',\n+            add_dockerfile,\n             'dummy description',\n             'dummy author',\n             'dummy tags',\n         ]\n     )\n \n-    confirms = iter([True, add_dockerfile])\n-\n     def _mock_prompt_ask(*args, **kwargs):\n         return next(prompts)\n \n     def _mock_confirm_ask(*args, **kwargs):\n-        return next(confirms)\n+        return True\n \n-    monkeypatch.setattr(Prompt, 'ask', _mock_prompt_ask)\n     monkeypatch.setattr(Confirm, 'ask', _mock_confirm_ask)\n+    monkeypatch.setattr(Prompt, 'ask', _mock_prompt_ask)\n \n     args = set_hub_new_parser().parse_args([])\n     HubIO(args).new()\n@@ -775,7 +774,7 @@ def test_new_without_arguments(monkeypatch, tmpdir, add_dockerfile):\n         'config.yml',\n     ]\n \n-    if add_dockerfile:\n+    if add_dockerfile != 'none':\n         pkg_files.append('Dockerfile')\n \n     for file in pkg_files:\n@@ -790,7 +789,7 @@ def test_new_without_arguments(monkeypatch, tmpdir, add_dockerfile):\n             assert 'DummyExecutor' in fp.read()\n \n \n-@pytest.mark.parametrize('add_dockerfile', [True, False])\n+@pytest.mark.parametrize('add_dockerfile', ['cpu', 'torch-gpu', 'tf-gpu', 'jax-gpu'])\n @pytest.mark.parametrize('advance_configuration', [True, False])\n @pytest.mark.parametrize('confirm_advance_configuration', [True, False])\n @pytest.mark.parametrize('confirm_add_docker', [True, False])\n@@ -809,6 +808,8 @@ def test_new_with_arguments(\n     _args_list = [\n         '--name',\n         'argsExecutor',\n+        '--dockerfile',\n+        add_dockerfile,\n         '--description',\n         'args description',\n         '--keywords',\n@@ -823,15 +824,8 @@ def test_new_with_arguments(\n     else:\n         temp.append(confirm_advance_configuration)\n \n-    if add_dockerfile:\n-        _args_list.append('--add-dockerfile')\n-    else:\n-        temp.append(confirm_add_docker)\n-\n-    confirms = iter(temp)\n-\n     def _mock_confirm_ask(*args, **kwargs):\n-        return next(confirms)\n+        return True\n \n     monkeypatch.setattr(Confirm, 'ask', _mock_confirm_ask)\n \n\n---\n file path A: tests/unit/parsers/hubble/test_new.py | file path B: tests/unit/parsers/hubble/test_new.py\n\n@@ -13,7 +13,7 @@ def test_new_parser():\n     mixin_hub_new_parser(parser)\n \n     args = parser.parse_args([])\n-    assert not args.add_dockerfile\n+    assert not args.dockerfile\n     assert not args.advance_configuration\n     assert args.name == None\n     assert args.path == None\n@@ -21,8 +21,8 @@ def test_new_parser():\n     assert args.keywords == None\n     assert args.url == None\n \n-    args = parser.parse_args(['--add-dockerfile'])\n-    assert args.add_dockerfile\n+    args = parser.parse_args(['--dockerfile', 'cpu'])\n+    assert args.dockerfile\n \n     args = parser.parse_args(['--advance-configuration'])\n     assert args.advance_configuration\n@@ -41,7 +41,7 @@ def test_new_parser():\n             'Dummy url',\n         ]\n     )\n-    assert not args.add_dockerfile\n+    assert not args.dockerfile\n     assert not args.advance_configuration\n     assert args.name == 'Dummy Executor'\n     assert args.path == 'Dummy Path'\n@@ -64,7 +64,7 @@ def test_new_parser():\n             '--advance-configuration',\n         ]\n     )\n-    assert not args.add_dockerfile\n+    assert not args.dockerfile\n     assert args.advance_configuration\n     assert args.name == 'Dummy Executor'\n     assert args.path == 'Dummy Path'\n@@ -74,7 +74,8 @@ def test_new_parser():\n \n     args = parser.parse_args(\n         [\n-            '--add-dockerfile',\n+            '--dockerfile',\n+            'cpu',\n             '--name',\n             'Dummy Executor',\n             '--path',\n@@ -87,7 +88,7 @@ def test_new_parser():\n             'Dummy url',\n         ]\n     )\n-    assert args.add_dockerfile\n+    assert args.dockerfile\n     assert not args.advance_configuration\n     assert args.name == 'Dummy Executor'\n     assert args.path == 'Dummy Path'\n\n\n###\n\n", "completion": "feat: add gpu dockerfile support to jina hub new (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/yaml-spec.md | file path B: docs/fundamentals/jcloud/yaml-spec.md\n\n@@ -330,9 +330,17 @@ executors:\n \n ### Lifetime\n \n-A Flow that receives no traffic in 24 hours will be automatically deleted.\n+A Flow that receives no traffic in 24 hours will be automatically deleted by default.\n \n-To control the lifetime of a Flow, you can specify the `retention_days: x` parameter in the Flow yaml, which keeps the Flow alive for `x` days. After `x` days, it will be deleted automatically, *regardless* of the traffic.\n+To ignore the lifetime reclaim policy of a Flow, you can use the `retention_days` parameter in the Flow yaml. `retention_days` will keep the flow alive for `x` days (0<x<365). flows is going to be removed after `x` days regardless of above reclaim policy. `-1` is to keep the flow alive regardless of the reclaim policy.\n+\n+```{note}\n+- If {ref}`retention-days <retention-days>` argument configured as `x` (0<x<365). Flows will be removed after `retention-days`, regradless of the usage.\n+\n+- If {ref}`retention-days <retention-days>` argument configured as `-1`. Flows will not be removed, regradless of the usage.\n+\n+- If {ref}`retention-days <retention-days>` argument not configured, or set to `0`. We will detect if flows are idle daily, they will be terminated if they are not serving requests for the last 24hrs.\n+```\n \n ```yaml\n jtype: Flow\n\n\n###\n\n", "completion": "docs: correct jcloud retention days (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -224,6 +224,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14870,3 +14871,38 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```f9c2d8de```](https://github.com/jina-ai/jina/commit/f9c2d8ded6264a82297665d286fdc40ac3b469f9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```2154f98f```](https://github.com/jina-ai/jina/commit/2154f98fddcbeddcfd80790de897f6210b408f87)] __-__ __version__: the next version will be 3.7.15 (*Jina Dev Bot*)\n \n+<a name=release-note-3-8-1></a>\n+## Release Note (`3.8.1`)\n+\n+> Release time: 2022-08-30 19:32:52\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  AlaeddineAbdessalem,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```6df36ce5```](https://github.com/jina-ai/jina/commit/6df36ce5958f3a7998c86e9f2745d897d4c1151e)] __-__ __client__: add profiling function to client and flow (#5105) (*Han Xiao*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```78aae025```](https://github.com/jina-ai/jina/commit/78aae0256da180287fc6b05fc3d5d74b6b7d2e02)] __-__ fix inconsistent docs and tests on py_modules (#5108) (*Han Xiao*)\n+ - [[```a725010d```](https://github.com/jina-ai/jina/commit/a725010d0f41967603dd207ee0a7a5ab6a568e71)] __-__ remove flakyness of monitoring integration tests in CI (#5106) (*samsja*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```90fa81f3```](https://github.com/jina-ai/jina/commit/90fa81f3d0a4c9cb7b4aa3b6303dfb5fd7410b96)] __-__ move port monitoring to pods parsing (#5100) (*samsja*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```95ee283c```](https://github.com/jina-ai/jina/commit/95ee283c510fc52c3b40ef1a6c25c3255215966d)] __-__ fix naming (#5102) (*AlaeddineAbdessalem*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```d528d947```](https://github.com/jina-ai/jina/commit/d528d9476316fb0a9bef712447187659b7829f7d)] __-__ fix cd pipeline (*Han Xiao*)\n+ - [[```57625350```](https://github.com/jina-ai/jina/commit/5762535035b28e358c1ba8e1c777b9575aa8172c)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```1ad06216```](https://github.com/jina-ai/jina/commit/1ad06216b3d92501e6292fdabd542ed59b388284)] __-__ __docs__: fix retention days description (*Han Xiao*)\n+ - [[```9f5f5879```](https://github.com/jina-ai/jina/commit/9f5f58796481bbc0fc7f6985721ba726ef121860)] __-__ __version__: the next version will be 3.8.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.8.1'\n+__version__ = '3.8.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.8.2"}
{"prompt": " file path A: .github/workflows/force-release.yml | file path B: .github/workflows/force-release.yml\n\n@@ -19,7 +19,8 @@ jobs:\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n \n-  hub-integration: \n+  hub-integration:\n+    needs: token-check\n     uses: jina-ai/hub-integration/.github/workflows/main.yml@main\n     with:\n       actions: 'all'\n\n\n###\n\n", "completion": "chore: fix cd pipeline"}
{"prompt": " file path A: docs/fundamentals/architecture-overview.md | file path B: docs/fundamentals/architecture-overview.md\n\n@@ -130,12 +130,10 @@ with:\n executors:\n - uses: FooExec\n   replicas: 3\n-  uses_metas:\n-    py_modules: executor.py\n+  py_modules: executor.py\n - uses: BarExec\n   replicas: 2\n-  uses_metas:\n-    py_modules: executor.py\n+  py_modules: executor.py\n ```\n ````\n \n\n---\n file path A: docs/fundamentals/executor/containerize-executor.md | file path B: docs/fundamentals/executor/containerize-executor.md\n\n@@ -106,9 +106,8 @@ and we can define such a configuration in `config.yml`:\n \n ```yaml\n jtype: ContainerizedEncoder\n-metas:\n-  py_modules:\n-    - my_executor.py\n+py_modules:\n+ - my_executor.py\n ```\n \n ### Write `requirements.txt`\n\n---\n file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -154,7 +154,6 @@ The list of the `metas` are:\n \n - `name`: Name given to the Executor;\n - `description`: Description of the Executor (optional, reserved for future-use in auto-docs);\n-- `py_modules`: List of Python modules needed to import the Executor. It can be Python package path e.g. `foo.bar.package.module` or file path to the modules needed to import the Executor.\n \n \n These can be provided to the Executor via the {ref}`Python or YAML API <executor-api>`.\n\n---\n file path A: docs/fundamentals/executor/executor-files.md | file path B: docs/fundamentals/executor/executor-files.md\n\n@@ -12,9 +12,8 @@ When you are only working with a single python file (let's call it `my_executor.\n \n ```yaml\n jtype: MyExecutor\n-metas:\n-  py_modules:\n-    - my_executor.py\n+py_modules:\n+  - my_executor.py\n ```\n \n ## Multiple Python files + YAML\n@@ -71,9 +70,8 @@ Finally, the contents of `config.yml` - notice that only the `executor/__init__.\n \n ```yaml\n jtype: MyExecutor\n-metas:\n-  py_modules:\n-    - executor/__init__.py\n+py_modules:\n+  - executor/__init__.py\n ```\n \n This was a relatively simple example, but this way of structuring python modules works for any python package structure, however complex. Consider this slightly more complicated example\n\n---\n file path A: docs/fundamentals/flow/add-executors.md | file path B: docs/fundamentals/flow/add-executors.md\n\n@@ -81,12 +81,12 @@ with f:\n ````{admonition} Hint: Load multiple Executors from the same module\n :class: hint\n \n-You can override the `metas` attribute for all Executors in a Flow. This allows you to specify a single Python module\n+You can override the `py_modules` attribute for all Executors in a Flow. This allows you to specify a single Python module\n from which you can then load all of your Executors, without having to specify the module individually for each Executor:\n \n ```yaml\n jtype: Flow\n-metas:\n+with:\n   py_modules:\n     - executors.py\n executors:\n@@ -311,10 +311,10 @@ from jina import Flow\n with Flow().add(\n     uses='MyExecutor',\n     uses_with={\"parameter_1\": \"foo\", \"parameter_2\": \"bar\"},\n+    py_modules=[\"executor.py\"],\n     uses_metas={\n         \"name\": \"MyExecutor\",\n         \"description\": \"MyExecutor does a thing to the stuff in your Documents\",\n-        \"py_modules\": [\"executor.py\"],\n     },\n     uses_requests={\"/index\": \"my_index\", \"/search\": \"my_search\", \"/random\": \"foo\"},\n     workspace=\"some_custom_path\",\n@@ -326,9 +326,9 @@ with Flow().add(\n - `uses_metas` is a key-value map that defines some {ref}`internal attributes<executor-metas>` of the Executor. It contains the following fields:\n     - `name` is a string that defines the name of the executor;\n     - `description` is a string that defines the description of this executor. It will be used in automatic docs UI;\n-    - `py_modules` is a list of strings that defines the Python dependencies of the executor;\n - `uses_requests` is a key-value map that defines the {ref}`mapping from endpoint to class method<executor-requests>`. Useful if one needs to overwrite the default endpoint-to-method mapping defined in the Executor python implementation.\n - `workspace` is a string value that defines the {ref}`workspace <executor-workspace>`.\n+- `py_modules` is a list of strings that defines the Python dependencies of the executor;\n \n \n ### Set `metas` via `uses_metas`\n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -148,9 +148,8 @@ In a new file called `my-exec.yml` we type:\n \n ```yaml\n jtype: MyExecutor\n-metas:\n-  py_modules:\n-    - exec.py\n+py_modules:\n+  - exec.py\n ```\n \n This simply points Jina to our file and Executor class.\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -229,9 +229,8 @@ jtype: {exec_name}\n with:\n     foo: 1\n     bar: hello\n-metas:\n-    py_modules:\n-        - executor.py\n+py_modules:\n+    - executor.py\n                 ''',\n                     'yaml',\n                     theme='monokai',\n\n---\n file path A: tests/docker_compose/executor-merger/config.yml | file path B: tests/docker_compose/executor-merger/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: ExecMerger\n-metas:\n-  py_modules:\n-    - exec_merger.py\n+py_modules:\n+  - exec_merger.py\n\n---\n file path A: tests/docker_compose/reload-executor/config.yml | file path B: tests/docker_compose/reload-executor/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: ReloadExecutor\n-metas:\n-  py_modules:\n-    - reload_executor.py\n+py_modules:\n+  - reload_executor.py\n\n---\n file path A: tests/docker_compose/test-executor/config.yml | file path B: tests/docker_compose/test-executor/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: TestExecutor\n-metas:\n-  py_modules:\n-    - debug_executor.py\n+py_modules:\n+  - debug_executor.py\n\n---\n file path A: tests/integration/container_runtime_args/replica-exec/config.yml | file path B: tests/integration/container_runtime_args/replica-exec/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: ReplicatedExec\n-metas:\n-  py_modules:\n-    - __init__.py\n+py_modules:\n+  - __init__.py\n\n---\n file path A: tests/integration/docker_volumes/filewriter-exec/executor.yml | file path B: tests/integration/docker_volumes/filewriter-exec/executor.yml\n\n@@ -1,5 +1,5 @@\n !FilewriterExec\n metas:\n   name: filewriter-exec\n-  py_modules: executor.py\n   workspace: ./\n+py_modules: executor.py\n\n---\n file path A: tests/integration/hub_usage/dummyhub/config.yml | file path B: tests/integration/hub_usage/dummyhub/config.yml\n\n@@ -1,6 +1,5 @@\n !DummyHubExecutor\n-metas:\n-  py_modules:\n-    # - you can put more dependencies here\n-    - __init__.py\n-    - helper.py\n\\ No newline at end of file\n+py_modules:\n+  # - you can put more dependencies here\n+  - __init__.py\n+  - helper.py\n\\ No newline at end of file\n\n---\n file path A: tests/integration/hub_usage/dummyhub_abs/config.yml | file path B: tests/integration/hub_usage/dummyhub_abs/config.yml\n\n@@ -1,7 +1,6 @@\n !DummyHubExecutorAbs\n with:\n   {}\n-metas:\n-  py_modules:\n-    # - you can put more dependencies here\n-    - __init__.py\n\\ No newline at end of file\n+py_modules:\n+  # - you can put more dependencies here\n+  - __init__.py\n\\ No newline at end of file\n\n---\n file path A: tests/integration/hub_usage/dummyhub_pretrained/config.yml | file path B: tests/integration/hub_usage/dummyhub_pretrained/config.yml\n\n@@ -1,7 +1,6 @@\n !DummyPretrainedExecutor\n with:\n   {}\n-metas:\n-  py_modules:\n-    # - you can put more dependencies here\n-    - __init__.py\n\\ No newline at end of file\n+py_modules:\n+  # - you can put more dependencies here\n+  - __init__.py\n\\ No newline at end of file\n\n---\n file path A: tests/integration/hub_usage/dummyhub_slow/config.yml | file path B: tests/integration/hub_usage/dummyhub_slow/config.yml\n\n@@ -1,7 +1,6 @@\n !DummyHubExecutorSlow\n with:\n   {}\n-metas:\n-  py_modules:\n-    # - you can put more dependencies here\n-    - __init__.py\n\\ No newline at end of file\n+py_modules:\n+  # - you can put more dependencies here\n+  - __init__.py\n\\ No newline at end of file\n\n---\n file path A: tests/integration/hub_usage/hub-mwu/mwu_encoder.yml | file path B: tests/integration/hub_usage/hub-mwu/mwu_encoder.yml\n\n@@ -3,5 +3,5 @@ with:\n   greetings: im from internal yaml!\n metas:\n   name: my-mwu-encoder\n-  py_modules: mwu_encoder.py\n-  workspace: ./\n\\ No newline at end of file\n+  workspace: ./\n+py_modules: mwu_encoder.py\n\\ No newline at end of file\n\n---\n file path A: tests/integration/hub_usage/yaml/test-executor.yml | file path B: tests/integration/hub_usage/yaml/test-executor.yml\n\n@@ -1,4 +1,3 @@\n jtype: TestExecutor\n-metas:\n-  py_modules:\n-    - test_executor.py\n+py_modules:\n+  - test_executor.py\n\n---\n file path A: tests/integration/issues/github_1546/bad1/crafter.yml | file path B: tests/integration/issues/github_1546/bad1/crafter.yml\n\n@@ -1,3 +1,2 @@\n !BadCrafter1\n-metas:\n-  py_modules: custom_crafter.py # I also tried to add helper.py here\n+py_modules: custom_crafter.py # I also tried to add helper.py here\n\n---\n file path A: tests/integration/issues/github_1546/good_new/crafter.yml | file path B: tests/integration/issues/github_1546/good_new/crafter.yml\n\n@@ -1,4 +1,3 @@\n !GoodCrafterNew\n-metas:\n-  py_modules:\n-    - executor/__init__.py\n+py_modules:\n+  - executor/__init__.py\n\n---\n file path A: tests/integration/issues/github_1546/good_old/crafter.yml | file path B: tests/integration/issues/github_1546/good_old/crafter.yml\n\n@@ -1,4 +1,3 @@\n !GoodCrafterOld\n-metas:\n-  py_modules:\n-    - __init__.py\n+py_modules:\n+  - __init__.py\n\n---\n file path A: tests/integration/issues/github_3271/test_python_single_import.py | file path B: tests/integration/issues/github_3271/test_python_single_import.py\n\n@@ -1,4 +1,5 @@\n import pytest\n+\n from jina import Flow\n \n num_calls = 0\n@@ -31,7 +32,7 @@ def test_single_import(patched_path_import):\n def test_single_import_metas(patched_path_import):\n     flow = Flow().add(\n         uses='ExecutorImportedOnce',\n-        uses_metas=dict(py_modules=['executors/executor_fails_import_twice.py']),\n+        py_modules=['executors/executor_fails_import_twice.py'],\n     )\n     with flow:\n         pass\n\n---\n file path A: tests/integration/override_config_params/container/default_config.yml | file path B: tests/integration/override_config_params/container/default_config.yml\n\n@@ -4,6 +4,6 @@ with:\n   param2: 10\n   param1: 10\n metas:\n-  py_modules: [executor.py]\n   name: 'name'\n   workspace: 'predefined_workpace'\n+py_modules: [executor.py]\n\n---\n file path A: tests/integration/override_config_params/worker/default_config.yml | file path B: tests/integration/override_config_params/worker/default_config.yml\n\n@@ -4,6 +4,6 @@ with:\n   param2: 10\n   param1: 10\n metas:\n-  py_modules: [executor.py]\n   name: 'name'\n   workspace: 'predefined_workpace'\n+py_modules: [executor.py]\n\n---\n file path A: tests/jinahub/hub_mwu/mwu_encoder.yml | file path B: tests/jinahub/hub_mwu/mwu_encoder.yml\n\n@@ -3,5 +3,5 @@ with:\n   greetings: im from internal yaml!\n metas:\n   name: my-mwu-encoder\n-  py_modules: mwu_encoder.py\n   workspace: ./\n+py_modules: mwu_encoder.py\n\n---\n file path A: tests/k8s/executor-merger/config.yml | file path B: tests/k8s/executor-merger/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: ExecMerger\n-metas:\n-  py_modules:\n-    - exec_merger.py\n+py_modules:\n+  - exec_merger.py\n\n---\n file path A: tests/k8s/reload-executor/config.yml | file path B: tests/k8s/reload-executor/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: ReloadExecutor\n-metas:\n-  py_modules:\n-    - reload_executor.py\n+py_modules:\n+  - reload_executor.py\n\n---\n file path A: tests/k8s/set-text-executor/config.yml | file path B: tests/k8s/set-text-executor/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: TagTextExecutor\n-metas:\n-  py_modules:\n-    - debug_executor.py\n+py_modules:\n+  - debug_executor.py\n\n---\n file path A: tests/k8s/slow-process-executor/config.yml | file path B: tests/k8s/slow-process-executor/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: SlowProcessExecutor\n-metas:\n-  py_modules:\n-    - debug_executor.py\n+py_modules:\n+  - debug_executor.py\n\n---\n file path A: tests/k8s/test-executor/config.yml | file path B: tests/k8s/test-executor/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: TestExecutor\n-metas:\n-  py_modules:\n-    - debug_executor.py\n+py_modules:\n+  - debug_executor.py\n\n---\n file path A: tests/unit/hubble-executor/config.yml | file path B: tests/unit/hubble-executor/config.yml\n\n@@ -1,8 +1,7 @@\n jtype: MyExecutor\n with:\n   bar: 123\n-metas:\n-  py_modules:\n-    - dep.py\n-    - exec.py\n+py_modules:\n+  - dep.py\n+  - exec.py\n \n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/executor-invalid-import/config.yml | file path B: tests/unit/orchestrate/flow/flow-construct/executor-invalid-import/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: InvalidImportExec\n-metas:\n-  py_modules:\n-    - executor.py\n+py_modules:\n+  - executor.py\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/executor/config.yml | file path B: tests/unit/orchestrate/flow/flow-construct/executor/config.yml\n\n@@ -1,4 +1,3 @@\n jtype: CustomExec\n-metas:\n-  py_modules:\n-    - executor.py\n+py_modules:\n+  - executor.py\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/mwu-encoder/mwu_encoder.yml | file path B: tests/unit/orchestrate/flow/flow-construct/mwu-encoder/mwu_encoder.yml\n\n@@ -3,5 +3,5 @@ with:\n   greetings: hello there!\n metas:\n   name: my-mwu-encoder\n-  py_modules: mwu_encoder.py\n   workspace: ./\n+py_modules: mwu_encoder.py\n\n---\n file path A: tests/unit/orchestrate/pods/container/dummy-exec/executor.yml | file path B: tests/unit/orchestrate/pods/container/dummy-exec/executor.yml\n\n@@ -1,5 +1,5 @@\n !DummyExec\n metas:\n   name: dummy-exec\n-  py_modules: executor.py\n   workspace: ./\n+py_modules: executor.py\n\n---\n file path A: tests/unit/orchestrate/pods/container/env-checker/executor.yml | file path B: tests/unit/orchestrate/pods/container/env-checker/executor.yml\n\n@@ -1,5 +1,5 @@\n !EnvChecker\n metas:\n   name: env-checker\n-  py_modules: executor.py\n   workspace: ./\n+py_modules: executor.py\n\n---\n file path A: tests/unit/orchestrate/pods/container/fail-start/executor.yml | file path B: tests/unit/orchestrate/pods/container/fail-start/executor.yml\n\n@@ -1,5 +1,5 @@\n !FailStart\n metas:\n   name: env-checker\n-  py_modules: executor.py\n   workspace: ./\n+py_modules: executor.py\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -80,9 +80,8 @@ def test_executor_with_pymodule_path():\n         ex = Executor.load_config(\n             '''\n         jtype: BaseExecutor\n-        metas:\n-            py_modules:\n-                - jina.no_valide.executor\n+        py_modules:\n+            - jina.no_valide.executor\n         '''\n         )\n \n@@ -91,9 +90,8 @@ def test_executor_with_pymodule_path():\n     jtype: MyExecutor\n     with:\n         bar: 123\n-    metas:\n-        py_modules:\n-            - unit.serve.executors.dummy_executor\n+    py_modules:\n+        - unit.serve.executors.dummy_executor\n     '''\n     )\n     assert ex.bar == 123\n\n---\n file path A: tests/unit/yaml/dummy_ext_exec_success.yml | file path B: tests/unit/yaml/dummy_ext_exec_success.yml\n\n@@ -1,3 +1,2 @@\n !DummyExternalIndexer\n-metas:\n-  py_modules: dummy_exec.py\n\\ No newline at end of file\n+py_modules: dummy_exec.py\n\\ No newline at end of file\n\n\n###\n\n", "completion": "fix: fix inconsistent docs and tests on py_modules (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/executor-args.md | file path B: docs/fundamentals/flow/executor-args.md\n\n@@ -30,7 +30,7 @@\n | `shards` | The number of shards in the deployment running at the same time. For more details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies | `number` | `1` |\n | `replicas` | The number of replicas in the deployment | `number` | `1` |\n | `monitoring` | If set, spawn an http server with a prometheus endpoint to expose metrics | `boolean` | `False` |\n-| `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n+| `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `string` | `random in [49152, 65535]` |\n | `retries` | Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas) | `number` | `-1` |\n | `floating` | If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one. | `boolean` | `False` |\n | `install_requirements` | If set, install `requirements.txt` in the Hub Executor bundle to local | `boolean` | `False` |\n\n---\n file path A: docs/fundamentals/flow/gateway-args.md | file path B: docs/fundamentals/flow/gateway-args.md\n\n@@ -43,6 +43,6 @@\n | `shards` | The number of shards in the deployment running at the same time. For more details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies | `number` | `1` |\n | `replicas` | The number of replicas in the deployment | `number` | `1` |\n | `monitoring` | If set, spawn an http server with a prometheus endpoint to expose metrics | `boolean` | `False` |\n-| `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n+| `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `string` | `random in [49152, 65535]` |\n | `retries` | Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas) | `number` | `-1` |\n | `floating` | If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one. | `boolean` | `False` |\n\\ No newline at end of file\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -165,7 +165,7 @@ class Flow(\n         output_array_type: Optional[str] = None,\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n-        port_monitoring: Optional[int] = None,\n+        port_monitoring: Optional[str] = None,\n         prefetch: Optional[int] = 1000,\n         protocol: Optional[str] = 'GRPC',\n         proxy: Optional[bool] = False,\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -4,11 +4,10 @@ from jina.parsers.helper import _SHOW_ALL_ARGS\n from jina.parsers.orchestrate.runtimes.head import mixin_head_parser\n \n \n-def set_pod_parser(parser=None, port_monitoring=True):\n+def set_pod_parser(parser=None):\n     \"\"\"Set the parser for the Pod\n \n     :param parser: an optional existing parser to build upon\n-    :param port_monitoring: if to include the port parsing\n     :return: the parser\n     \"\"\"\n     if not parser:\n@@ -33,7 +32,7 @@ def set_pod_parser(parser=None, port_monitoring=True):\n     mixin_container_runtime_parser(parser)\n     mixin_remote_runtime_parser(parser)\n     mixin_distributed_feature_parser(parser)\n-    mixin_pod_parser(parser, port_monitoring=port_monitoring)\n+    mixin_pod_parser(parser)\n     mixin_hub_pull_options_parser(parser)\n     mixin_head_parser(parser)\n \n@@ -51,7 +50,7 @@ def set_deployment_parser(parser=None):\n \n         parser = set_base_parser()\n \n-    set_pod_parser(parser, port_monitoring=False)\n+    set_pod_parser(parser)\n \n     from jina.parsers.orchestrate.deployment import mixin_base_deployment_parser\n \n\n---\n file path A: jina/parsers/orchestrate/deployment.py | file path B: jina/parsers/orchestrate/deployment.py\n\n@@ -60,11 +60,3 @@ def mixin_base_deployment_parser(parser):\n         default=False,\n         help='If set, connect to deployment using tls encryption',\n     )\n-\n-    gp.add_argument(\n-        '--port-monitoring',\n-        type=str,\n-        default=str(helper.random_port()),\n-        dest='port_monitoring',\n-        help=f'The port on which the prometheus server is exposed, default is a random port between [49152, 65535]',\n-    )\n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -6,10 +6,9 @@ from jina.enums import PodRoleType\n from jina.parsers.helper import _SHOW_ALL_ARGS, KVAppendAction, add_arg_group\n \n \n-def mixin_pod_parser(parser, port_monitoring=True):\n+def mixin_pod_parser(parser):\n     \"\"\"Mixing in arguments required by :class:`Pod` into the given parser.\n     :param parser: the parser instance to which we add arguments\n-    :param port_monitoring: if to include the port parsing\n     \"\"\"\n \n     gp = add_arg_group(parser, title='Pod')\n@@ -97,14 +96,13 @@ def mixin_pod_parser(parser, port_monitoring=True):\n         help='If set, spawn an http server with a prometheus endpoint to expose metrics',\n     )\n \n-    if port_monitoring:\n-        gp.add_argument(\n-            '--port-monitoring',\n-            type=int,\n-            default=helper.random_port(),\n-            dest='port_monitoring',\n-            help=f'The port on which the prometheus server is exposed, default is a random port between [49152, 65535]',\n-        )\n+    gp.add_argument(\n+        '--port-monitoring',\n+        type=str,\n+        default=str(helper.random_port()),\n+        dest='port_monitoring',\n+        help=f'The port on which the prometheus server is exposed, default is a random port between [49152, 65535]',\n+    )\n \n     gp.add_argument(\n         '--retries',\n\n---\n file path A: jina/serve/runtimes/monitoring.py | file path B: jina/serve/runtimes/monitoring.py\n\n@@ -17,4 +17,6 @@ class MonitoringMixin:\n \n             from prometheus_client import start_http_server\n \n-            start_http_server(self.args.port_monitoring, registry=self.metrics_registry)\n+            start_http_server(\n+                int(self.args.port_monitoring), registry=self.metrics_registry\n+            )\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -301,6 +301,7 @@ ac_table = {\n             '--replicas',\n             '--port',\n             '--monitoring',\n+            '--port-monitoring',\n             '--retries',\n             '--floating',\n             '--install-requirements',\n@@ -318,7 +319,6 @@ ac_table = {\n             '--external',\n             '--deployment-role',\n             '--tls',\n-            '--port-monitoring',\n         ],\n         'client': [\n             '--help',\n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -139,7 +139,8 @@ def test_monitoring_head_few_port(port_generator, executor):\n             assert resp.status_code == 200\n \n \n-def test_monitoring_replicas_and_shards(port_generator, executor):\n+@pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http', None])\n+def test_monitoring_replicas_and_shards(port_generator, executor, protocol):\n     n_shards = 2\n     n_replicas = 3\n     port_shards_list = [port_generator() for _ in range(n_shards * n_replicas)]\n@@ -147,7 +148,13 @@ def test_monitoring_replicas_and_shards(port_generator, executor):\n     port_monitoring = ','.join([str(port) for port in [port_head] + port_shards_list])\n     port1 = port_generator()\n \n-    f = Flow(monitoring=True, port_monitoring=port1).add(\n+    flow = (\n+        Flow(protocol=protocol, monitoring=True, port_monitoring=port1)\n+        if protocol\n+        else Flow(monitoring=True, port_monitoring=port1)\n+    )\n+\n+    f = flow.add(\n         uses=executor,\n         port_monitoring=port_monitoring,\n         shards=n_shards,\n@@ -186,9 +193,6 @@ def test_monitoring_replicas_and_shards(port_generator, executor):\n         assert f'jina_sending_request_seconds' in str(resp.content)\n \n \n-# GOOD\n-\n-\n def test_document_processed_total(port_generator, executor):\n     port0 = port_generator()\n     port1 = port_generator()\n@@ -309,7 +313,6 @@ def test_requests_size(port_generator, executor):\n         assert measured_request_bytes_sum > measured_request_bytes_sum_init\n \n \n-# GOOD\n def test_failed_successful_request_count(port_generator, failing_executor):\n     port0 = port_generator()\n     port1 = port_generator()\n\n\n###\n\n", "completion": "refactor: move port monitoring to pods parsing (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/monitoring-flow.md | file path B: docs/fundamentals/flow/monitoring-flow.md\n\n@@ -156,13 +156,13 @@ Because not all Pods have the same role, they expose different kinds of metrics:\n \n ### Gateway Pods\n \n-| Metrics name                        | Metrics type                                                         | Description                                                                                                         |\n-|-------------------------------------|----------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|\n-| `jina_receiving_request_seconds`    | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between receiving a request from the client and sending back the response.                |\n-| `jina_sending_request_seconds`      | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between sending a downstream request to an Executor/Head and receiving the response back. |\n-| `jina_number_of_pending_requests`   | [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge)     | Counts the number of pending requests                                                                               |\n-| `jina_successful_requests`          | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Counts the number of successful requests returned by the gateway                                                    |\n-| `jina_failed_requests`              | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Counts the number of failed requests returned by the gateway                                                        |\n+| Metrics name                           | Metrics type                                                         | Description                                                                                                         |\n+|----------------------------------------|----------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|\n+| `jina_receiving_request_seconds`       | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between receiving a request from the client and sending back the response.                |\n+| `jina_sending_request_seconds`         | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between sending a downstream request to an Executor/Head and receiving the response back. |\n+| `jina_number_of_pending_requests`      | [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge)     | Counts the number of pending requests                                                                               |\n+| `jina_successful_requests_total`       | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Counts the number of successful requests returned by the gateway                                                    |\n+| `jina_failed_requests_total`           | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Counts the number of failed requests returned by the gateway                                                        |\n \n ```{seealso} \n You can find more information on the different type of metrics in Prometheus [here](https://prometheus.io/docs/concepts/metric_types/#metric-types)\n\n\n###\n\n", "completion": "docs: fix naming (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -280,7 +280,7 @@ If you don't see any obvious errors, please raise an issue in [JCloud](https://g\n \n - **Is everything free?**\n \n-  Yes! We just need your feedback - use `jc survey` to help us understand your needs.\n+  Yes at the moment! We just need your feedback - use `jc survey` to help us understand your needs.\n \n - **How powerful is JCloud?**\n \n@@ -290,9 +290,3 @@ If you don't see any obvious errors, please raise an issue in [JCloud](https://g\n \n   - Deployments are only supported in `us-east` region.\n   - Each Executor is allowed a maximum of 4 GPUs, 16G RAM, 16 CPU cores & 10GB of block storage.\n-\n-- **How long do you persist my service?**\n-\n-  - If {ref}`retention-days <retention-days>` argument configured. Flows will be removed after `retention-day`, regradless of the usage.\n-\n-  - If {ref}`retention-days <retention-days>` argument not configured, or set to `0`. We will detect if flows are idle daily, they will be terminated if they are not serving requests for the last 24hrs. \n\n---\n file path A: docs/fundamentals/jcloud/yaml-spec.md | file path B: docs/fundamentals/jcloud/yaml-spec.md\n\n@@ -328,15 +328,16 @@ executors:\n ```\n \n \n-(retention-days)=\n-### Retention days\n+### Lifetime\n \n-In JCloud, we have a default life-cycle of 24hrs for Flows, after which they're removed if idle. You can manage the same yourself by passing the right parameter for `retention-days` under `jcloud`. `0` is to use the default life-cycle, `X` (0<X<365), which is meant to keep the Flow alive until X days, and `-1` is for never expired,\n+A Flow that receives no traffic in 24 hours will be automatically deleted.\n+\n+To control the lifetime of a Flow, you can specify the `retention_days: x` parameter in the Flow yaml, which keeps the Flow alive for `x` days. After `x` days, it will be deleted automatically, *regardless* of the traffic.\n \n ```yaml\n jtype: Flow\n jcloud:\n-  retention_days: -1\n+  retention_days: 7\n executors:\n   - name: executor1\n     uses: jinahub+docker://Executor1\n\n---\n file path A: docs/get-started/comparing-alternatives.md | file path B: docs/get-started/comparing-alternatives.md\n\n@@ -189,7 +189,7 @@ When a Jina Flow contains only one Executor, serving this Flow is basically serv\n \n When using Jina on cloud, it makes sense to compare Jina with other MLOps platforms. Note that MLOps is an especially confusing landscape with hundreds of tools available. Platforms have their own specializations and there is no clear line between a tool (with a narrow focus) and a platform (which supports many ML lifecycle activities). Even platforms that have a similar scope have different concepts and strategies, making them hard to compare directly. \n \n-### Based on \"Guide to Evaluating MLOps Platforms\"\n+#### Based on \"Guide to Evaluating MLOps Platforms\"\n \n The figures below illustrate how platforms specialize in particular areas (bottom) and others aim to cover the whole lifecycle with equal focus (top). The original figures are from [the Thoughtworks Guide to MLOps Platforms](https://www.thoughtworks.com/what-we-do/data-and-ai/cd4ml/guide-to-evaluating-mlops-platforms). We add Jina as a new entry to it.\n \n@@ -197,7 +197,7 @@ The figures below illustrate how platforms specialize in particular areas (botto\n ```\n \n \n-### Based on \"MLOps Platforms\"\n+#### Based on \"MLOps Platforms\"\n \n Below we adopt the methodology from [MLOps Platforms](https://github.com/thoughtworks/mlops-platforms) and add Jina as an entry. The chart and tabular data are credited to MLOps Platforms.\n \n\n\n###\n\n", "completion": "chore(docs): fix retention days description"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -223,6 +223,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14819,3 +14820,52 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```0bd289fe```](https://github.com/jina-ai/jina/commit/0bd289fe4f13025b337e4b2586cde9444afad1c0)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```96489914```](https://github.com/jina-ai/jina/commit/96489914a49449cc99e8c97473953318a908ce3a)] __-__ __version__: the next version will be 3.7.14 (*Jina Dev Bot*)\n \n+<a name=release-note-3-8-0></a>\n+## Release Note (`3.8.0`)\n+\n+> Release time: 2022-08-29 16:43:11\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Johannes Messner,  tarrantro,  Han Xiao,  AlaeddineAbdessalem,  samsja,  Jina Dev Bot,  Zac Li,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```527beb85```](https://github.com/jina-ai/jina/commit/527beb85a62eef9ec239406b986e43fcec28c2e7)] __-__ bump protobuf version (#5082) (*AlaeddineAbdessalem*)\n+ - [[```c47cb716```](https://github.com/jina-ai/jina/commit/c47cb71637a9f72dd0f8710a7f93b3e6c6e9b238)] __-__ add failed and successful request number metrics (#5079) (*AlaeddineAbdessalem*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```c81252ac```](https://github.com/jina-ai/jina/commit/c81252aca7ba0c52650f7e915febe367a5e4828f)] __-__ update to protobuf 4.21 new types (#5098) (*Johannes Messner*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```6e51e815```](https://github.com/jina-ai/jina/commit/6e51e815e534a8bf54d6629dc828fd50ace21bc0)] __-__ refactor data request handler monitoring (#5088) (*samsja*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```b3fdb49c```](https://github.com/jina-ai/jina/commit/b3fdb49cf4946796bc8b5fb8e5bc360f6f32bd0c)] __-__ correct jcloud retention days (#5096) (*tarrantro*)\n+ - [[```98fb71f1```](https://github.com/jina-ai/jina/commit/98fb71f188fb71600db18ebd77809a36bfa9909c)] __-__ __jcloud__: adjust jcloud monitoring docs(#5081) (*Zac Li*)\n+ - [[```dbea43f3```](https://github.com/jina-ai/jina/commit/dbea43f3f36fda3e111a7c0d58ea3b56b0146337)] __-__ remove kong/alb from jcloud document (#5080) (*tarrantro*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```27ec3b41```](https://github.com/jina-ai/jina/commit/27ec3b41f8b49507aa5694db2ef020a9161576e7)] __-__ cleanup pip install (#5094) (*AlaeddineAbdessalem*)\n+ - [[```c0c3bf9a```](https://github.com/jina-ai/jina/commit/c0c3bf9a58cf59d6eea0cacabdb479b00d147b99)] __-__ downgrade linkerd version in CI (#5090) (*AlaeddineAbdessalem*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```142c0bb1```](https://github.com/jina-ai/jina/commit/142c0bb1d9c2f3deaf04c60e3f6d3509390851f7)] __-__ __docs__: add streamline value props (*Han Xiao*)\n+ - [[```af7f6763```](https://github.com/jina-ai/jina/commit/af7f6763818cd121c973db5d10f98e3ceab96781)] __-__ fix readme (*Han Xiao*)\n+ - [[```c39714fa```](https://github.com/jina-ai/jina/commit/c39714fae05e7e841574b1203de2781d708c13fb)] __-__ __docs__: add install apple silicon (*Han Xiao*)\n+ - [[```5375b4d3```](https://github.com/jina-ai/jina/commit/5375b4d398425500eb425c93dfc48cedb758a24b)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```53553b14```](https://github.com/jina-ai/jina/commit/53553b1415ca024b0495b9658181b8ca6f227532)] __-__ add security report (*Han Xiao*)\n+ - [[```cfe5dd70```](https://github.com/jina-ai/jina/commit/cfe5dd70fce54f2a6f1f5cecac3aab47d6ce2793)] __-__ update readme (*Han Xiao*)\n+ - [[```e106796c```](https://github.com/jina-ai/jina/commit/e106796c26390f820d0f7d571c97303e3cd2f37f)] __-__ __docs__: update furo deps (*Han Xiao*)\n+ - [[```079d04b0```](https://github.com/jina-ai/jina/commit/079d04b00946e0dbe274d1011f72a44dd65423d3)] __-__ __docs__: add jcloud to first app (*Han Xiao*)\n+ - [[```64de8608```](https://github.com/jina-ai/jina/commit/64de86083f98f930fb87a99c41f1fbc6fb8a9d0d)] __-__ __docs__: add comparing alternatives (*Han Xiao*)\n+ - [[```f9c2d8de```](https://github.com/jina-ai/jina/commit/f9c2d8ded6264a82297665d286fdc40ac3b469f9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```2154f98f```](https://github.com/jina-ai/jina/commit/2154f98fddcbeddcfd80790de897f6210b408f87)] __-__ __version__: the next version will be 3.7.15 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.8.0'\n+__version__ = '3.8.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.8.1"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -32,14 +32,14 @@ grpcio-reflection>=1.46.0:  core\n grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray>=0.13.14:          core\n+docarray>=0.16.1:           core\n jina-hubble-sdk>=0.15.1:    core\n jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n-docarray[common]>=0.13.14:  standard,devel\n+docarray[common]>=0.16.1:   standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.15'\n+__version__ = '3.8.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -32,14 +32,14 @@ grpcio-reflection>=1.46.0:  core\n grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray>=0.13.14:          core\n+docarray>=0.16.1:           core\n jina-hubble-sdk>=0.15.1:    core\n jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n-docarray[common]>=0.13.14:  standard,devel\n+docarray[common]>=0.16.1:   standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n\n---\n file path A: jina/serve/runtimes/gateway/http/models.py | file path B: jina/serve/runtimes/gateway/http/models.py\n\n@@ -114,12 +114,18 @@ def protobuf_to_pydantic_model(\n     oneof_fields = defaultdict(list)\n     oneof_field_validators = {}\n \n-    if isinstance(protobuf_model, Descriptor):\n-        model_name = protobuf_model.name\n-        protobuf_fields = protobuf_model.fields\n-    elif isinstance(protobuf_model, GeneratedProtocolMessageType):\n-        model_name = protobuf_model.DESCRIPTOR.name\n-        protobuf_fields = protobuf_model.DESCRIPTOR.fields\n+    desc = (\n+        protobuf_model\n+        if isinstance(protobuf_model, Descriptor)\n+        else getattr(protobuf_model, 'DESCRIPTOR', None)\n+    )\n+    if desc:\n+        model_name = desc.name\n+        protobuf_fields = desc.fields\n+    else:\n+        raise ValueError(\n+            f'protobuf_model is of type {type(protobuf_model)} and has no attribute \"DESCRIPTOR\"'\n+        )\n \n     if model_name in vars(PROTO_TO_PYDANTIC_MODELS):\n         return PROTO_TO_PYDANTIC_MODELS.__getattribute__(model_name)\n\n\n###\n\n", "completion": "fix: update to protobuf 4.21 new types (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -293,4 +293,6 @@ If you don't see any obvious errors, please raise an issue in [JCloud](https://g\n \n - **How long do you persist my service?**\n \n-  Flows are terminated if they are not serving requests for the last 24hrs. But this is configurable by passing {ref}`retention-days <retention-days>` argument.\n+  - If {ref}`retention-days <retention-days>` argument configured. Flows will be removed after `retention-day`, regradless of the usage.\n+\n+  - If {ref}`retention-days <retention-days>` argument not configured, or set to `0`. We will detect if flows are idle daily, they will be terminated if they are not serving requests for the last 24hrs. \n\n\n###\n\n", "completion": "docs: correct jcloud retention days (#<issue-num>)"}
{"prompt": " file path A: .github/readme/streamline-banner.png | file path B: .github/readme/streamline-banner.png\n\nBinary files /dev/null and b/.github/readme/streamline-banner.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -76,6 +76,74 @@ Document, Executor and Flow are three fundamental concepts in Jina.\n \n [The full glossary is explained here.](https://docs.jina.ai/fundamentals/architecture-overview/)\n \n+\n+---\n+\n+<p align=\"center\">\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/streamline-banner.png?raw=true\" alt=\"Jina: Streamline AI & ML Product Delivery\" width=\"100%\"></a>\n+</p>\n+\n+### Streamline AI & ML Product Delivery\n+\n+A new project starts from local. With Jina, you can easily leverage existing deep learning stacks, improve the quality and quickly build the POC.\n+\n+```python\n+import torch\n+from jina import DocumentArray\n+\n+model = torch.nn.Sequential(\n+    torch.nn.Linear(\n+        in_features=128,\n+        out_features=128,\n+    ),\n+    torch.nn.ReLU(),\n+    torch.nn.Linear(in_features=128, out_features=32),\n+)\n+\n+\n+docs = DocumentArray.from_files('left/*.jpg')\n+docs.embed(model)\n+```\n+\n+Moving to production, Jina enhances the POC with service endpoint, scalability and adds cloud-native features, making it ready for production without refactoring.\n+\n+<table>\n+<tr>\n+<td>\n+\n+```python\n+from jina import DocumentArray, Executor, requests\n+from .embedding import model\n+\n+\n+class MyExec(Executor):\n+    @requests(on='/embed')\n+    async def embed(self, docs: DocumentArray, **kwargs):\n+        docs.embed(model)\n+```\n+\n+</td>\n+<td>\n+    \n+```yaml\n+jtype: Flow\n+with:\n+  port: 12345\n+executors:\n+- uses: MyExec\n+  replicas: 2\n+```\n+</td>\n+</tr>\n+</table>\n+\n+\n+Finally, the project can be easily deployed to the cloud and serve real traffic.\n+\n+```bash\n+jina cloud deploy ./\n+```\n+\n ---\n \n <p align=\"center\">\n\n\n###\n\n", "completion": "chore(docs): add streamline value props"}
{"prompt": " file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -183,7 +183,6 @@ jobs:\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n           python -m pip install --upgrade pip\n           python -m pip install wheel\n-          pip install git+https://github.com/jina-ai/docarray.git@bump-protobuf\n           pip install \".[all]\" --no-cache-dir\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -225,7 +224,6 @@ jobs:\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n           python -m pip install --upgrade pip\n           python -m pip install wheel\n-          pip install git+https://github.com/jina-ai/docarray.git@bump-protobuf\n           pip install \".[all]\" --no-cache-dir\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -268,7 +266,6 @@ jobs:\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n           python -m pip install --upgrade pip\n           python -m pip install wheel\n-          pip install git+https://github.com/jina-ai/docarray.git@bump-protobuf\n           pip install \".[all]\" --no-cache-dir\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -325,7 +322,6 @@ jobs:\n           docker build -f Dockerfiles/test-pip.Dockerfile -t jinaai/jina:test-pip .\n           python -m pip install --upgrade pip\n           python -m pip install wheel\n-          pip install git+https://github.com/jina-ai/docarray.git@bump-protobuf\n           pip install \".[all]\" --no-cache-dir\n           jina\n           export JINA_LOG_LEVEL=\"ERROR\"\n@@ -372,7 +368,6 @@ jobs:\n         run: |\n           python -m pip install --upgrade pip\n           python -m pip install wheel\n-          pip install git+https://github.com/jina-ai/docarray.git@bump-protobuf\n           pip install --no-cache-dir .\n         env:\n           JINA_PIP_INSTALL_CORE: ${{ matrix.core }}\n\n\n###\n\n", "completion": "ci: cleanup pip install (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -22,9 +22,9 @@ if TYPE_CHECKING:\n     from jina.types.request import Request\n \n \n-class RequestHandler:\n+class MonitoringRequestMixin:\n     \"\"\"\n-    Class that handles the requests arriving to the gateway and the result extracted from the requests future.\n+    Mixin for the request handling monitoring\n \n     :param metrics_registry: optional metrics registry for prometheus used if we need to expose metrics from the executor or from the data request handler\n     :param runtime_name: optional runtime_name that will be registered during monitoring\n@@ -35,9 +35,8 @@ class RequestHandler:\n         metrics_registry: Optional['CollectorRegistry'] = None,\n         runtime_name: Optional[str] = None,\n     ):\n+\n         self._request_init_time = {} if metrics_registry else None\n-        self._executor_endpoint_mapping = None\n-        self._gathering_endpoints = False\n \n         if metrics_registry:\n             with ImportExtensions(\n@@ -48,7 +47,7 @@ class RequestHandler:\n \n             self._receiving_request_metrics = Summary(\n                 'receiving_request_seconds',\n-                'Time spent processing request',\n+                'Time spent processing successful request',\n                 registry=metrics_registry,\n                 namespace='jina',\n                 labelnames=('runtime_name',),\n@@ -90,8 +89,10 @@ class RequestHandler:\n         if self._pending_requests_metrics:\n             self._pending_requests_metrics.inc()\n \n-    def _update_end_request_metrics(self, result: 'Request', exc: Exception = None):\n-        if self._receiving_request_metrics:\n+    def _update_end_successful_requests_metrics(self, result: 'Request'):\n+        if (\n+            self._receiving_request_metrics\n+        ):  # this one should only be observed when the metrics is succesful\n             init_time = self._request_init_time.pop(\n                 result.request_id\n             )  # need to pop otherwise it stays in memory forever\n@@ -99,16 +100,42 @@ class RequestHandler:\n \n         if self._pending_requests_metrics:\n             self._pending_requests_metrics.dec()\n-        if (\n-            exc or result.status.code == jina_pb2.StatusProto.ERROR\n-        ) and self._failed_requests_metrics:\n-            self._failed_requests_metrics.inc()\n-        if (\n-            not (exc or result.status.code == jina_pb2.StatusProto.ERROR)\n-            and self._successful_requests_metrics\n-        ):\n+\n+        if self._successful_requests_metrics:\n             self._successful_requests_metrics.inc()\n \n+    def _update_end_failed_requests_metrics(self, result: 'Request'):\n+        if self._pending_requests_metrics:\n+            self._pending_requests_metrics.dec()\n+\n+        if self._failed_requests_metrics:\n+            self._failed_requests_metrics.inc()\n+\n+    def _update_end_request_metrics(self, result: 'Request'):\n+\n+        if result.status.code != jina_pb2.StatusProto.ERROR:\n+            self._update_end_successful_requests_metrics(result)\n+        else:\n+            self._update_end_failed_requests_metrics(result)\n+\n+\n+class RequestHandler(MonitoringRequestMixin):\n+    \"\"\"\n+    Class that handles the requests arriving to the gateway and the result extracted from the requests future.\n+\n+    :param metrics_registry: optional metrics registry for prometheus used if we need to expose metrics from the executor or from the data request handler\n+    :param runtime_name: optional runtime_name that will be registered during monitoring\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        metrics_registry: Optional['CollectorRegistry'] = None,\n+        runtime_name: Optional[str] = None,\n+    ):\n+        super().__init__(metrics_registry, runtime_name)\n+        self._executor_endpoint_mapping = None\n+        self._gathering_endpoints = False\n+\n     def handle_request(\n         self, graph: 'TopologyGraph', connection_pool: 'GrpcConnectionPool'\n     ) -> Callable[['Request'], 'Tuple[Future, Optional[Future]]']:\n@@ -215,7 +242,7 @@ class RequestHandler:\n                     partial_responses = await asyncio.gather(*tasks)\n                 except Exception as e:\n                     # update here failed request\n-                    self._update_end_request_metrics(request, exc=e)\n+                    self._update_end_failed_requests_metrics(request)\n                     raise\n                 partial_responses, metadatas = zip(*partial_responses)\n                 filtered_partial_responses = list(\n\n\n###\n\n", "completion": "refactor: refactor data request handler monitoring (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -306,6 +306,7 @@ jobs:\n           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n       - name: Test k8s\n         run: |\n+          export LINKERD2_VERSION=stable-2.11.4\n           curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh\n           curl --proto '=https' --tlsv1.2 -sSfL https://linkerd.github.io/linkerd-smi/install | sh\n           pytest -v -s --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml ./tests/k8s/test_k8s_failures.py\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -190,6 +190,7 @@ jobs:\n           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n       - name: Test k8s\n         run: |\n+          export LINKERD2_VERSION=stable-2.11.4\n           curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh\n           pytest -v -s --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml ./tests/k8s/test_k8s.py ./tests/k8s/test_graceful_request_handling.py\n         timeout-minutes: 30\n@@ -230,6 +231,7 @@ jobs:\n           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n       - name: Test k8s\n         run: |\n+          export LINKERD2_VERSION=stable-2.11.4\n           curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh\n           curl --proto '=https' --tlsv1.2 -sSfL https://linkerd.github.io/linkerd-smi/install | sh\n           pytest -v -s --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml ./tests/k8s/test_k8s_failures.py\n\n---\n file path A: tests/k8s/conftest.py | file path B: tests/k8s/conftest.py\n\n@@ -1,5 +1,6 @@\n import os\n import subprocess\n+import tempfile\n from pathlib import Path\n \n import docker\n@@ -24,13 +25,26 @@ class KindClusterWrapper:\n         self._install_linkderd(kind_cluster)\n         self._loaded_images = set()\n \n-    def _install_linkderd(self, kind_cluster):\n-        self._log.info('Installing Linkerd to Cluster...')\n-        proc = subprocess.Popen(\n-            [f'{Path.home()}/.linkerd2/bin/linkerd', 'install'],\n-            stdout=subprocess.PIPE,\n+    def _linkerd_install_cmd(self, kind_cluster, cmd, tool_name):\n+        self._log.info(f'Installing {tool_name} to Cluster...')\n+        kube_out = subprocess.check_output(\n+            (str(kind_cluster.kubectl_path), 'version'),\n+            env=os.environ,\n+        )\n+        self._log.info(f'kuberbetes versions: {kube_out}')\n+\n+        # since we need to pipe to commands and the linkerd output can bee too long\n+        # there is a risk of deadlock and hanging tests: https://docs.python.org/3/library/subprocess.html#popen-objects\n+        # to avoid this, the right mechanism is implemented in subprocess.run and subprocess.check_output, but output\n+        # must be piped to a file-like object, not to stdout\n+        proc_stdout = tempfile.TemporaryFile()\n+        proc = subprocess.run(\n+            cmd,\n+            stdout=proc_stdout,\n             env={\"KUBECONFIG\": str(kind_cluster.kubeconfig_path)},\n         )\n+\n+        proc_stdout.seek(0)\n         kube_out = subprocess.check_output(\n             (\n                 str(kind_cluster.kubectl_path),\n@@ -38,16 +52,23 @@ class KindClusterWrapper:\n                 '-f',\n                 '-',\n             ),\n-            stdin=proc.stdout,\n+            stdin=proc_stdout,\n             env=os.environ,\n         )\n-        self._log.info('Poll status of linkerd install')\n-        returncode = proc.poll()\n+\n+        returncode = proc.returncode\n         self._log.info(\n-            f'Installing Linkerd to Cluster returned code {returncode}, kubectl output was {kube_out}'\n+            f'Installing {tool_name} to Cluster returned code {returncode}, kubectl output was {kube_out}'\n         )\n         if returncode is not None and returncode != 0:\n-            raise Exception(f\"Installing linkerd failed with {returncode}\")\n+            raise Exception(f'Installing {tool_name} failed with {returncode}')\n+\n+    def _install_linkderd(self, kind_cluster):\n+        # linkerd < 2.12: only linkerd install is needed\n+        # in later versions, linkerd install --crds will be needed\n+        self._linkerd_install_cmd(\n+            kind_cluster, [f'{Path.home()}/.linkerd2/bin/linkerd', 'install'], 'Linkerd'\n+        )\n \n         self._log.info('check linkerd status')\n         out = subprocess.check_output(\n\n\n###\n\n", "completion": "ci: downgrade linkerd version in CI (#<issue-num>)"}
{"prompt": " file path A: docs/_static/main.css | file path B: docs/_static/main.css\n\n@@ -173,4 +173,8 @@ body[data-theme=\"auto\"] .only-dark-line {\n     text-align: center;\n     max-width: 7em;\n     color: var(--color-foreground-muted);\n+}\n+\n+.highlight .hll {\n+    background-color: #ffffcc85;\n }\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/get-started/install/apple-silicon-m1-m2.md\n\n@@ -0,0 +1,155 @@\n+# On Apple Silicon\n+\n+If you own a MacOS device with an Apple Silicon M1/M2 chip, you can run Jina **natively** on it (instead of running under Rosetta) and enjoy up to 10x faster performance. This chapter summarizes how to install Jina.\n+\n+## Check terminal and device\n+\n+To make sure you are using the right terminal, run\n+\n+```bash\n+uname -m\n+```\n+\n+and it should return\n+\n+```text\n+arm64\n+```\n+\n+\n+## Install Homebrew\n+\n+`brew` is a package manager for macOS. If you already install it you need to confirm it is actually installed for Apple Silicon not for Rosetta. To check that, run\n+\n+```bash\n+which brew\n+```\n+\n+```text\n+/opt/homebrew/bin/brew\n+```\n+\n+If you find it is installed under `/usr/local/` instead of `/opt/homebrew/`, it means your `brew` is installed for Rosetta not for Apple Silicon. You need to reinstall it. [Here is an article on how to do it](https://apple.stackexchange.com/a/410829).\n+\n+```{danger}\n+Reinstalling `brew` can be a destructive operation. Please make sure you have backed up your data before proceeding.\n+```\n+\n+To (re)install brew, run\n+\n+```bash\n+/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n+```\n+\n+You may want to observe the output to check if it contains `/opt/homebrew` to make sure you are installing for Apple Silicon.\n+\n+## Install Python\n+\n+Python has to be installed for Apple Silicon as well. It is possible it is installed for Rosetta, and you are not aware of that. To confirm, run\n+\n+```python\n+import platform\n+\n+platform.machine()\n+```\n+\n+which should give\n+\n+```text\n+'arm64'\n+```\n+\n+If not, then you are using Python under Rosetta, and you need to install Python for Apple Silicon with `brew`.\n+\n+\n+```bash\n+brew install python3\n+```\n+\n+As of Aug 2022, this will install Python 3.10 natively for Apple Silicon.\n+\n+Make sure to note down where `python` and `pip` are installed to. In this example, they are installed to `/opt/homebrew/bin/python3` and `/opt/homebrew/opt/python@3.10/libexec/bin/pip` respectively.\n+\n+## Install dependencies wheels\n+\n+There are some core dependencies that Jina needs to run, whose wheels are not available on PyPI but fortunately are available on wheel. To install them, run\n+\n+```bash\n+brew install protobuf numpy\n+```\n+\n+## Install Jina\n+\n+Now we can install Jina via `pip`. Note you need to use the right one:\n+\n+```bash\n+/opt/homebrew/opt/python@3.10/libexec/bin/pip install jina\n+```\n+\n+`grpcio` requires building the wheels, it will take some time.\n+\n+\n+After all the dependencies are installed, you can run Jina CLI and check the system information.\n+\n+```bash\n+jina -vf\n+```\n+\n+```{code-block} text\n+---\n+emphasize-lines: 13-15\n+---\n+- jina 3.7.14\n+- docarray 0.15.4\n+- jcloud 0.0.35\n+- jina-hubble-sdk 0.15.2\n+- jina-proto 0.1.13\n+- protobuf 3.20.1\n+- proto-backend python\n+- grpcio 1.47.0\n+- pyyaml 6.0\n+- python 3.10.6\n+- platform Darwin\n+- platform-release 21.6.0\n+- platform-version Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n+- architecture arm64\n+- processor arm\n+- uid 94731629138370\n+- session-id 49497356-254e-11ed-9624-56286d1a91c2\n+- uptime 2022-08-26T16:49:28.279723\n+- ci-vendor (unset)\n+* JINA_DEFAULT_HOST (unset)\n+* JINA_DEFAULT_TIMEOUT_CTRL (unset)\n+* JINA_DEPLOYMENT_NAME (unset)\n+* JINA_DISABLE_UVLOOP (unset)\n+* JINA_EARLY_STOP (unset)\n+* JINA_FULL_CLI (unset)\n+* JINA_GATEWAY_IMAGE (unset)\n+* JINA_GRPC_RECV_BYTES (unset)\n+* JINA_GRPC_SEND_BYTES (unset)\n+* JINA_HUB_NO_IMAGE_REBUILD (unset)\n+* JINA_LOG_CONFIG (unset)\n+* JINA_LOG_LEVEL (unset)\n+* JINA_LOG_NO_COLOR (unset)\n+* JINA_MP_START_METHOD (unset)\n+* JINA_OPTOUT_TELEMETRY (unset)\n+* JINA_RANDOM_PORT_MAX (unset)\n+* JINA_RANDOM_PORT_MIN (unset)\n+```\n+\n+\n+Congratulations! You have successfully installed Jina on Apple Silicon.\n+\n+\n+````{tip}\n+\n+To install MPS-enabled PyTorch, run\n+\n+```bash\n+/opt/homebrew/opt/python@3.10/libexec/bin/pip install -U --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n+```\n+````\n+\n+\n+\n+\n\n---\n file path A: docs/get-started/install/index.md | file path B: docs/get-started/install/index.md\n\n@@ -5,6 +5,7 @@\n :hidden:\n \n docker\n+apple-silicon-m1-m2\n windows\n troubleshooting\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/get-started/install/troubleshooting.md | file path B: docs/get-started/install/troubleshooting.md\n\n@@ -31,27 +31,6 @@ pip install -U pip\n \n Then you are likely installing Jina on a less-supported system/architecture. For example, on native Mac M1, Alpine Linux, or Raspberry Pi 2/3 (armv6/7).\n \n-## On Mac M1\n-\n-It is generally recommended using a conda environment on a Mac M1 and installing in particular `grpcio`, `protobuf` and `torch`  using `conda install`. See for more [Issue 4422](https://github.com/jina-ai/jina/issues/4422#issuecomment-1057663345).\n-\n-Some users may have difficulty to install Protobuf on MacOS from `pip`, you may try `brew install protobuf`.\n-\n-In general, some upstream dependencies do not yet have pre-built wheels for the M1 chip, so you are likely to encounter some issues during the install. In this case, you need to configure the development environment using [Rosetta2](https://support.apple.com/en-us/HT211861), including your terminal, `brew` and `python`. They must all be running under Rosetta2 instead of natively on M1.\n-\n-````{tip}\n-You can run the following command in the terminal to check if you are running under Rosetta2 or natively on M1.\n-\n-```shell\n-sysctl -n -i sysctl.proc_translated\n-```\n-\n-Depending on the results:\n-- `0`: for Apple silicon native process\n-- `1`: for Rosetta2 translated process\n-- `\"\"`: in case the OID was not found, you are using an older Mac running Catalina or an earlier version. You don't have the M1 problem in the first place.\n-````\n-\n ## On Windows with `conda`\n \n Unfortunately, `conda install` is not supported on Windows. You can either do `pip install jina` natively on Windows, or use `pip/conda install` under WSL2.\n\n\n###\n\n", "completion": "chore(docs): add install apple silicon"}
{"prompt": " file path A: None | file path B: SECURITY.md\n\n@@ -0,0 +1,20 @@\n+# Security Policy\n+\n+Security is very important for Jina AI and its community. \n+\n+## Supported Versions\n+\n+The latest versions of Jina are supported.\n+\n+All Docker images of Jina are scanned with Snyk. [You can find the report here](https://hub.docker.com/repository/docker/jinaai/jina).\n+\n+<img width=\"811\" alt=\"image\" src=\"https://user-images.githubusercontent.com/2041322/186850148-62b9bea2-dba2-45e1-80c2-94b5f8cbc553.png\">\n+\n+\n+## Reporting a Vulnerability\n+\n+If you think you found a vulnerability, and even if you are not sure about it, please report it right away by sending an email to: security@jina.ai. Please try to be as explicit as possible, describing all the steps and example code to reproduce the security issue.\n+\n+Our team will review it thoroughly and get back to you.\n+\n+Please restrain from publicly discussing a potential security vulnerability on Github issues or in Slack community. \ud83d\ude4a It's better to discuss privately and try to find a solution first, to limit the potential impact as much as possible.\n\n\n###\n\n", "completion": "chore: add security report"}
{"prompt": " file path A: docs/_static/main.css | file path B: docs/_static/main.css\n\n@@ -14,14 +14,6 @@ html.loaded-in-iframe .page .main {\n }\n \n \n-table.docutils {\n-    border: thin;\n-}\n-\n-table.docutils td, table.docutils th {\n-    padding: 1rem 1rem;\n-}\n-\n .highlight {\n     background: #f5f5f5;\n }\n\n\n###\n\n", "completion": "chore(docs): update furo deps"}
{"prompt": " file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -1,4 +1,4 @@\n-# Create First Project\n+# {octicon}`milestone` Create First Project\n \n Let's build a toy application with Jina. To start, we use Jina CLI to make a new project for us:\n \n@@ -64,7 +64,7 @@ In `executor.py`, let's add another endpoint `/get-tensor` as follows:\n \n ```{code-block} python\n ---\n-emphasize-lines: 12-15\n+emphasize-lines: 13-16\n ---\n import numpy as np\n import torch\n@@ -205,6 +205,15 @@ tensor([[[0.4254, 0.4305],\n \n ## Delete the deployed project\n \n+Don't forget to delete a Flow if you are not using it anymore.\n+\n ```bash\n jina cloud remove 1655d050ad\n-```\n\\ No newline at end of file\n+```\n+\n+\n+```text\n+Successfully removed Flow 1655d050ad.\n+```\n+\n+You just finished your first Jina toy project, congrats! You can now start your own project.\n\\ No newline at end of file\n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -62,14 +62,22 @@ You can use any Python library in {class}`~jina.Executor`. For example, let's ad\n \n In `executor.py`, let's add another endpoint `/get-tensor` as follows:\n \n-```python\n+```{code-block} python\n+---\n+emphasize-lines: 12-15\n+---\n import numpy as np\n import torch\n \n-from jina import Executor, DocumentArray, requests\n+from jina import Executor, requests, DocumentArray\n \n \n class MyExecutor(Executor):\n+    @requests\n+    def foo(self, docs: DocumentArray, **kwargs):\n+        docs[0].text = 'hello, world!'\n+        docs[1].text = 'goodbye, world!'\n+\n     @requests(on='/crunch-numbers')\n     def bar(self, docs: DocumentArray, **kwargs):\n         for doc in docs:\n@@ -86,7 +94,7 @@ Modify `client.py` to call `/crunch-numbers` endpoint:\n from jina import Client, DocumentArray\n \n if __name__ == '__main__':\n-    c = Client(host='grpc://0.0.0.0:54321')\n+    c = Client(host='grpcs://1655d050ad.wolf.jina.ai')\n     da = c.post('/crunch-numbers', DocumentArray.empty(2))\n     print(da.tensors)\n ```\n@@ -119,4 +127,84 @@ tensor([[[0.9594, 0.9373],\n          [0.7562, 0.2183],\n          [0.9239, 0.3294],\n          [0.2457, 0.9189]]], dtype=torch.float64)\n+```\n+\n+## Deploy to JCloud\n+\n+JCloud offers free CPU and GPU instances to host Jina project. Let's deploy our first project to JCloud.\n+\n+```bash\n+jina auth login\n+```\n+\n+Log in with your Github, Google or Email account.\n+\n+```bash\n+jina cloud deploy ./\n+```\n+\n+```{figure} deploy-jcloud-ongoing.png\n+```\n+\n+Deployment is fully automatic and takes a few minutes.\n+\n+After it is done, you should see the following message in the terminal.\n+\n+\n+```text\n+\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udf89 Flow is available! \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n+\u2502                                                   \u2502\n+\u2502   ID            1655d050ad                        \u2502\n+\u2502   Endpoint(s)   grpcs://1655d050ad.wolf.jina.ai   \u2502\n+\u2502                                                   \u2502\n+\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n+```\n+\n+\n+Now let's change the Client's code to use the deployed endpoint shown above:\n+\n+```{code-block} python\n+---\n+emphasize-lines: 4\n+---\n+from jina import Client, DocumentArray\n+\n+if __name__ == '__main__':\n+    c = Client(host='grpcs://1655d050ad.wolf.jina.ai')\n+    da = c.post('/crunch-numbers', DocumentArray.empty(2))\n+    print(da.tensors)\n+```\n+\n+```{tip}\n+The very first request can be a bit slow because the server is starting up.\n+```\n+\n+```text\n+tensor([[[0.4254, 0.4305],\n+         [0.6200, 0.5783],\n+         [0.7989, 0.8742],\n+         [0.1324, 0.7228],\n+         [0.1274, 0.6538],\n+         [0.1533, 0.7543],\n+         [0.3025, 0.7702],\n+         [0.6938, 0.9289],\n+         [0.5222, 0.7280],\n+         [0.7298, 0.4923]],\n+\n+        [[0.9747, 0.5026],\n+         [0.6438, 0.4007],\n+         [0.0899, 0.8635],\n+         [0.3142, 0.4142],\n+         [0.4447, 0.2540],\n+         [0.1109, 0.6260],\n+         [0.3850, 0.9894],\n+         [0.0845, 0.7538],\n+         [0.1444, 0.5136],\n+         [0.3368, 0.6162]]], dtype=torch.float64)\n+```\n+\n+## Delete the deployed project\n+\n+```bash\n+jina cloud remove 1655d050ad\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/get-started/deploy-jcloud-ongoing.png | file path B: docs/get-started/deploy-jcloud-ongoing.png\n\nBinary files /dev/null and b/docs/get-started/deploy-jcloud-ongoing.png differ\n\n\n###\n\n", "completion": "chore(docs): add jcloud to first app"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -198,9 +198,9 @@ jc status 15937a10bd\n ```\n \n ### Monitoring\n-To enable monitoring with the Flow, you can set `monitoring: true` in the Flow yaml and you'd be given access to a [Grafana](https://grafana.com/) dashboard.\n+Basic monitoring is provided to the Flows deployed on JCloud.\n \n-To access the dashboard, get the status of the Flow first (see above section), at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n+To access the [Grafana](https://grafana.com/) powered dashboard, get the status of the Flow first (see above section), at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n \n ```{figure} monitoring.png\n :width: 70%\n\n\n###\n\n", "completion": "docs(jcloud): adjust jcloud monitoring docs(#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/yaml-spec.md | file path B: docs/fundamentals/jcloud/yaml-spec.md\n\n@@ -60,7 +60,7 @@ executors:\n \n JCloud supports GPU workloads with two different usages: `shared` or `dedicated`. \n \n-If GPU is enabled, JCloud will provide NVIDIA A10G Tensor Core GPUs for workloads in both usage types.\n+If GPU is enabled, JCloud will provide NVIDIA A10G Tensor Core GPUs with 24G memory for workloads in both usage types.\n \n ```{note}\n When using GPU resources, it may take few extra mins until all Executors ready to serve traffic.\n@@ -81,12 +81,8 @@ executors:\n         gpu: shared\n ```\n \n-```{note}\n-When using shared GPU resources, it will share the GPU memory across pods(24G memory total). If your application is memory consuming, we suggest using a dedicated GPU.\n-```\n-\n ```{caution}\n-There are no special provisions in place to isolate replicas that run on the same underlying GPU. Each workload has access to the GPU memory and runs in the same fault-domain as of all the others. Therefore, if one workload crashes, they all do. \n+The tradeoffs with `shared` GPU are increased latency, jitter, and potential out-of-memory (OOM) conditions when many different applications are time-slicing on the GPU. If your application is memory consuming, we suggest using a dedicated GPU.\n ```\n \n #### Dedicated GPU\n@@ -237,30 +233,14 @@ to handle the initial requests since it may need to scale the deployments behind\n \n ## Config Gateway\n \n-To expose users' Flows to the public Internet with TLS, JCloud provides support for 2 Gateways [ALB](https://aws.amazon.com/elasticloadbalancing/application-load-balancer/) & [Kong API Gateway](https://konghq.com/products/api-gateway-platform). \n+To expose users' Flows to the public Internet with TLS, JCloud provides support Ingress Gateways.\n+\n+In JCloud. We use [Let's Encrypt](https://letsencrypt.org/) for TLS.\n \n ```{note}\n The JCloud gateway is different from Jina's Gateway. In JCloud, a gateway works as a proxy to distribute internet traffic between Flows, each of which has a Jina Gateway (which is responsible to manage external gRPC/HTTP/Websocket traffic to your Executors)\n ```\n \n-### Use ALB as API Gateway\n-\n-Currently, ALB is the default gateway for backward compatibility. We use AWS provided public certificates for TLS with the ALB.\n-\n-### Use Kong as API Gateway\n-\n-Kong is the recommended gateway in JCloud. We use [Let's Encrypt](https://letsencrypt.org/) for TLS with Kong. To enable Kong Gateway instead of ALB, specify the gateway ingress kind as `kong` in your JCloud YAML:\n-\n-```yaml\n-jtype: Flow\n-jcloud:\n-  gateway:\n-    ingress: kong\n-executors:\n-  - name: executor1\n-    uses: jinahub+docker://Executor1\n-```\n-\n ### Set timeout\n \n By default, JCloud gateway will close connections that have been idle for over `600` seconds. If you want longer connection timeout threshold, you can consider changing the `timeout` parameter in `gateway`.\n@@ -269,7 +249,6 @@ By default, JCloud gateway will close connections that have been idle for over `\n jtype: Flow\n jcloud:\n   gateway:\n-    ingress: kong\n     timeout: 600\n executors:\n   - name: executor1\n@@ -333,7 +312,7 @@ executors:\n :width: 70%\n ```\n \n-## Other deployment pptions\n+## Other deployment options\n \n ### Specify Jina version\n \n\n\n###\n\n", "completion": "docs: remove kong/alb from jcloud document (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -222,6 +222,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14800,3 +14801,20 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```4673e7ab```](https://github.com/jina-ai/jina/commit/4673e7abaaee91c7c9143288866bf139e5cce0a0)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```a4c48d1b```](https://github.com/jina-ai/jina/commit/a4c48d1b4a6b680c61d8a681ac7e2a3a26fa3cee)] __-__ __version__: the next version will be 3.7.13 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-14></a>\n+## Release Note (`3.7.14`)\n+\n+> Release time: 2022-08-22 13:52:20\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```4f380c7e```](https://github.com/jina-ai/jina/commit/4f380c7e6a9dea2dd67eda08da050eb83323da26)] __-__ fix pprint (*Han Xiao*)\n+ - [[```0bd289fe```](https://github.com/jina-ai/jina/commit/0bd289fe4f13025b337e4b2586cde9444afad1c0)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```96489914```](https://github.com/jina-ai/jina/commit/96489914a49449cc99e8c97473953318a908ce3a)] __-__ __version__: the next version will be 3.7.14 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.14'\n+__version__ = '3.7.15'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.15"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1675,7 +1675,6 @@ def send_telemetry_event(event: str, obj: Any) -> None:\n                 ).encode('utf-8')\n             )\n \n-            pprint({**metas, 'event': f'{obj.__class__.__name__}.{event}'})\n             req = urllib.request.Request(\n                 url, data=data, headers={'User-Agent': 'Mozilla/5.0'}\n             )\n\n\n###\n\n", "completion": "chore: fix pprint"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -221,6 +221,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14765,3 +14766,36 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```6fbd2be9```](https://github.com/jina-ai/jina/commit/6fbd2be9214339997d880c200a5a6a7b58418123)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```7d82fdc3```](https://github.com/jina-ai/jina/commit/7d82fdc3dc52b23305a23b155272108f57d26243)] __-__ __version__: the next version will be 3.7.12 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-13></a>\n+## Release Note (`3.7.13`)\n+\n+> Release time: 2022-08-21 21:03:25\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```b7bf0ee1```](https://github.com/jina-ai/jina/commit/b7bf0ee119131ac794b6abae10a9e4344adb5834)] __-__ set workspace in executor init method (#5072) (*Johannes Messner*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```f6dcde38```](https://github.com/jina-ai/jina/commit/f6dcde38f9ed4a85b25b4a31ec796abaad520add)] __-__ telemetry (#5078) (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```8ad0ead5```](https://github.com/jina-ai/jina/commit/8ad0ead55482f222bacc0687005f079df47cf2f4)] __-__ __docs__: refactor create project docs (*Han Xiao*)\n+ - [[```c7e19841```](https://github.com/jina-ai/jina/commit/c7e198414e71a28ce0a9b43e411885a5eeff100e)] __-__ update readme (*Han Xiao*)\n+ - [[```7b034d34```](https://github.com/jina-ai/jina/commit/7b034d34775787f535605cefdca8f2f08b84c4cd)] __-__ __docs__: refactor telemetry docs (*Han Xiao*)\n+ - [[```76f48f8f```](https://github.com/jina-ai/jina/commit/76f48f8f818a38c1b03be2866c3063181eced912)] __-__ __docs__: refactor jcloud docs (*Han Xiao*)\n+ - [[```e506da44```](https://github.com/jina-ai/jina/commit/e506da443944c23f8af417ec88dd9b525087b6cd)] __-__ __docs__: refactor hub docs (*Han Xiao*)\n+ - [[```b91f2084```](https://github.com/jina-ai/jina/commit/b91f20844bc29346f2d5c0b2c849fee6cc29404e)] __-__ __docs__: refactor executors docs (*Han Xiao*)\n+ - [[```f8a63ccf```](https://github.com/jina-ai/jina/commit/f8a63ccf813fbd9d31ce4c3f1625cb675d1d529d)] __-__ __docs__: refactor flow basic docs (*Han Xiao*)\n+ - [[```885914ad```](https://github.com/jina-ai/jina/commit/885914ad3e24817ad23fd65bc9f634c45a89339a)] __-__ __docs__: restructure docs (*Han Xiao*)\n+ - [[```36fdebe2```](https://github.com/jina-ai/jina/commit/36fdebe2778ad53da62bad40d273e6028d1bd527)] __-__ __docs__: fix docs in jcloud (*Han Xiao*)\n+ - [[```4673e7ab```](https://github.com/jina-ai/jina/commit/4673e7abaaee91c7c9143288866bf139e5cce0a0)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```a4c48d1b```](https://github.com/jina-ai/jina/commit/a4c48d1b4a6b680c61d8a681ac7e2a3a26fa3cee)] __-__ __version__: the next version will be 3.7.13 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.13'\n+__version__ = '3.7.14'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.14"}
{"prompt": " file path A: docs/telemetry.md | file path B: docs/telemetry.md\n\n@@ -1,8 +1,12 @@\n # Telemetry\n \n+```{warning}\n+To opt out of usage statistics, add the `--optout-telemetry` argument to the different Flows and Executors or set the `JINA_OPTOUT_TELEMETRY=1` as an environment variable.\n+```\n+\n Telemetry is the process of collecting data about the usage of a system. This data can be used to improve the system by understanding how it is being used and what areas need improvement.\n \n-Jina uses telemetry to collect data about how the software is being used. This data is then used to improve the software. For example, if Jina sees that a lot of users are having trouble with a certain feature, they can improve that feature to make it easier to use.\n+Jina AI uses telemetry to collect data about how Jina is being used. This data is then used to improve the software. For example, if we see that a lot of users are having trouble with a certain feature, we can improve that feature to make it easier to use.\n \n Telemetry is important for Jina because it allows the team to understand how the software is being used and what areas need improvement. Without telemetry, Jina would not be able to improve as quickly or as effectively.\n \n@@ -13,4 +17,3 @@ The data collected include:\n - A hashed unique session identifier;\n - Boolean events: start of a Flow, Gateway and Runtime.\n \n-To opt out of usage statistics, add the `--optout-telemetry` argument to the different Flows and Executors or set the `JINA_OPTOUT_TELEMETRY=1` as an environment variable.\n\\ No newline at end of file\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -39,7 +39,6 @@ exclude_patterns = [\n     'tests',\n     'page_templates',\n     '.github',\n-    'api'\n ]\n pygments_style = 'rainbow_dash'\n html_theme = 'furo'\n\n---\n file path A: docs/_static/main.css | file path B: docs/_static/main.css\n\n@@ -134,7 +134,7 @@ body[data-theme=\"auto\"] .only-dark-line {\n     display: none !important;\n }\n \n-.color-gradient-card {\n+.color-gradient-card-1 {\n     background: linear-gradient(270deg, #22c1c3, #fdbb2d);\n     background-size: 200% 200%;\n \n@@ -143,6 +143,15 @@ body[data-theme=\"auto\"] .only-dark-line {\n     animation: AnimationName 30s ease infinite;\n }\n \n+.color-gradient-card-2 {\n+    background: linear-gradient(270deg, #7060d9, #ff83b6);\n+    background-size: 200% 200%;\n+\n+    -webkit-animation: AnimationName 30s ease infinite;\n+    -moz-animation: AnimationName 30s ease infinite;\n+    animation: AnimationName 30s ease infinite;\n+}\n+\n @-webkit-keyframes AnimationName {\n     0%{background-position:0% 50%}\n     50%{background-position:100% 50%}\n\n---\n file path A: docs/fundamentals/executor/containerize-executor.md | file path B: docs/fundamentals/executor/containerize-executor.md\n\n@@ -158,7 +158,7 @@ docker build -t my_containerized_executor .\n \n Once the build is successful, this is what you should see under `docker images`:\n \n-```console\n+```shell\n REPOSITORY                       TAG                IMAGE ID       CREATED          SIZE\n my_containerized_executor        latest             5cead0161cb5   13 seconds ago   2.21GB\n ```\n@@ -180,7 +180,7 @@ for doc in returned_docs:\n     print(f'Document embedding of shape {doc.embedding.shape}')\n ```\n \n-```console\n+```shell\n Document returned with text: \"This Document is embedded by ContainerizedEncoder\"\n Document embedding of shape torch.Size([10])\n ```\n\n---\n file path A: docs/fundamentals/executor/executor-methods.md | file path B: docs/fundamentals/executor/executor-methods.md\n\n@@ -49,7 +49,7 @@ with f:\n     f.post(on='/search', inputs=[])\n ```\n \n-```console\n+```shell\n            Flow@18048[I]:\ud83c\udf89 Flow is ready to use!                                                   \n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:52255\n@@ -210,7 +210,7 @@ print(f'Resulting documents {returned_docs[0].text}')\n ```\n \n \n-```console\n+```shell\n            Flow@1244[I]:\ud83c\udf89 Flow is ready to use!\n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:54550\n@@ -271,7 +271,7 @@ with f:\n     )\n ```\n \n-```console\n+```shell\n            Flow@20588[I]:\ud83c\udf89 Flow is ready to use!\n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:62598\n@@ -307,7 +307,7 @@ with f:\n     )\n ```\n \n-```console\n+```shell\n            Flow@20394[I]:\ud83c\udf89 Flow is ready to use!\n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:52592\n@@ -400,7 +400,7 @@ with f:\n     f.post('', on_error=print_why)\n ```\n \n-```console\n+```shell\n [...]\n executor0/rep-0@28271[E]:NotImplementedError('no time for it')\n  add \"--quiet-error\" to suppress the exception details\n@@ -459,7 +459,7 @@ with f:\n ```\n \n \n-```console\n+```shell\n            Flow@23300[I]:\ud83c\udf89 Flow is ready to use!                                                   \n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:61855\n\n---\n file path A: docs/fundamentals/executor/executor-serve.md | file path B: docs/fundamentals/executor/executor-serve.md\n\n@@ -36,7 +36,7 @@ from jina import Client, DocumentArray, Document\n print(Client(port=12345).post(inputs=DocumentArray.empty(1), on='/foo').texts)\n ```\n \n-```console\n+```shell\n ['executed MyExec']\n ```\n \n\n---\n file path A: docs/fundamentals/flow/topologies.md | file path B: docs/fundamentals/flow/topologies.md\n\n@@ -220,7 +220,7 @@ print(\n )  # only the Document fullfilling the condition is processed and therefore returned.\n ```\n \n-```console\n+```shell\n [{'key': 5.0}]\n ```\n \n@@ -258,7 +258,7 @@ print(\n )  # only the Document fullfilling the condition is processed and therefore returned.\n ```\n \n-```console\n+```shell\n [{'key': 5.0}]\n ```\n ````\n@@ -302,7 +302,7 @@ with f:\n print(ret[:, 'tags'])  # Each Document satisfies one parallel branch/filter\n ```\n \n-```console\n+```shell\n [{'key': 5.0}, {'key': 4.0}]\n ```\n \n@@ -334,7 +334,7 @@ with f:\n print(ret[:, 'tags'])  # No Document satisfies both sequential filters\n ```\n \n-```console\n+```shell\n []\n ```\n ````\n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -1,48 +1,66 @@\n-# Create Project\n+# Create First Project\n \n-Let\u2019s write a small application with our new Jina development environment. To start, we'll use Jina CLI to make a new project for us. In your terminal of choice run:\n+Let's build a toy application with Jina. To start, we use Jina CLI to make a new project for us:\n \n ```bash\n jina new hello-jina\n ```\n \n-This will generate a new directory called `hello-jina` with the following files:\n+This will create a new project folder called `hello-jina` with the following file structure:\n \n ```text\n-hello-jina\n-|- app.py\n-|- executor1/\n-        |- config.yml\n-        |- executor.py\n+hello-jina/\n+    |- client.py\n+    |- flow.yml\n+    |- executor1/\n+            |- config.yml\n+            |- executor.py\n ```\n \n-- `app.py` is the entrypoint of your Jina project. You can run it via `python app.py`. \n+- `flow.yml` is the configuration file for the Jina Flow.\n - `executor1/` is where we'll write our {class}`~jina.Executor` code.\n - `config.yml` is the config file for the {class}`~jina.Executor`. It\u2019s where you keep metadata for your Executor, as well as dependencies.\n+- `client.py` is the entrypoint of your Jina project. You can run it via `python app.py`.\n \n There may be some other files like `README.md`, `manifest.yml`  `requirements.txt` to provide extra metadata about that {class}`~jina.Executor`. More information {ref}`can be found here<create-executor>`.\n \n-```bash\n-cd hello-jina\n-python app.py\n+\n+Now run it and observe the output of the server and client.\n+\n+\n+````{tab} Run server\n+```shell\n+jina flow --uses flow.yml\n ```\n \n-You should see this in your terminal:\n+```shell\n \n+\u2500\u2500\u2500\u2500 \ud83c\udf89 Flow is ready to serve! \u2500\u2500\u2500\u2500\n+\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83d\udd17 Endpoint \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n+\u2502  \u26d3     Protocol                    GRPC  \u2502\n+\u2502  \ud83c\udfe0       Local           0.0.0.0:54321  \u2502\n+\u2502  \ud83d\udd12     Private    192.168.200.56:54321  \u2502\n+\u2502  \ud83c\udf0d      Public    81.223.121.124:54321  \u2502\n+\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n+```\n+````\n+\n+````{tab} Run client\n ```bash\n-           Flow@99300[I]:\ud83c\udf89 Flow is ready to use!\n-\t\ud83d\udd17 Protocol: \t\tGRPC\n-\t\ud83c\udfe0 Local access:\t0.0.0.0:52971\n-\t\ud83d\udd12 Private network:\t192.168.0.102:52971\n-\t\ud83c\udf10 Public address:\t84.172.88.250:52971\n+python client.py\n+```\n+\n+```shell\n ['hello, world!', 'goodbye, world!']\n ```\n+````\n+\n \n-## Adding dependencies\n+## Add logics\n \n-You can use any third-party Python library in {class}`~jina.Executor`. Let's create `executor1/requirements.txt` and add `pytorch` to it.\n+You can use any Python library in {class}`~jina.Executor`. For example, let's add `pytorch` to `executor1/requirements.txt` and crunch some numbers. \n \n-Then in `executor.py`, let's add another endpoint `/get-tensor` as follows:\n+In `executor.py`, let's add another endpoint `/get-tensor` as follows:\n \n ```python\n import numpy as np\n@@ -52,42 +70,34 @@ from jina import Executor, DocumentArray, requests\n \n \n class MyExecutor(Executor):\n-    @requests(on='/get-tensor')\n+    @requests(on='/crunch-numbers')\n     def bar(self, docs: DocumentArray, **kwargs):\n         for doc in docs:\n             doc.tensor = torch.tensor(np.random.random([10, 2]))\n ```\n \n-## A dummy Jina application\n+Kill the last server by `ctrl-C` and restart the server by `jina flow --uses flow.yml`.\n \n+## Call `/crunch-number` endpoint\n \n-Now let's write a dummy application with our new dependency. In our `app.py`, add the following code:\n+Modify `client.py` to call `/crunch-numbers` endpoint:\n \n ```python\n-from jina import Flow, Document\n-\n-f = Flow().add(uses='executor1/config.yml')\n+from jina import Client, DocumentArray\n \n if __name__ == '__main__':\n-    with f:\n-        da = f.post('/get-tensor', [Document(), Document()])\n-        print(da.tensors)\n+    c = Client(host='grpc://0.0.0.0:54321')\n+    da = c.post('/crunch-numbers', DocumentArray.empty(2))\n+    print(da.tensors)\n ```\n \n-Once we save that, we can run our application by typing:\n+Once we save that, we can run our new client:\n \n ```bash\n-python app.py\n+python client.py\n ```\n \n-Assuming everything went well, you should see your application print this to the screen:\n-\n-```bash\n-       Flow@301[I]:\ud83c\udf89 Flow is ready to use!\n-\t\ud83d\udd17 Protocol: \t\tGRPC\n-\t\ud83c\udfe0 Local access:\t0.0.0.0:59667\n-\t\ud83d\udd12 Private network:\t192.168.0.102:59667\n-\t\ud83c\udf10 Public address:\t84.172.88.250:59667\n+```text\n tensor([[[0.9594, 0.9373],\n          [0.4729, 0.2012],\n          [0.7907, 0.3546],\n@@ -108,5 +118,5 @@ tensor([[[0.9594, 0.9373],\n          [0.3626, 0.0963],\n          [0.7562, 0.2183],\n          [0.9239, 0.3294],\n-         [0.2457, 0.9189]]], dtype=torch.float64\n+         [0.2457, 0.9189]]], dtype=torch.float64)\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/get-started/what-is-cross-modal-multi-modal.md | file path B: docs/get-started/what-is-cross-modal-multi-modal.md\n\n@@ -56,7 +56,7 @@ for d in db:\n         print(d.uri, m.uri, m.scores['cosine'].value)\n ```\n \n-```console\n+```shell\n left/02262.jpg right/03459.jpg 0.21102\n left/02262.jpg right/02964.jpg 0.13871843\n left/02262.jpg right/02103.jpg 0.18265384\n\n---\n file path A: docs/get-started/what-is-jina.md | file path B: docs/get-started/what-is-jina.md\n\n@@ -125,7 +125,7 @@ with f:\n     print(r.texts)\n ```\n \n-```console\n+```shell\n \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83c\udf89 Flow is ready to serve! \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83d\udd17 Endpoint \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n \u2502  \u26d3     Protocol                    GRPC  \u2502\n@@ -157,7 +157,7 @@ for d in docs:\n ```\n \n \n-```console\n+```shell\n ['hello, world!hello, world!', 'hello, world!hello, world!']\n ```\n ````\n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -118,7 +118,7 @@ with f:\n     f.index(inputs=docs, on_done=print_embedding)\n ```\n \n-```console\n+```shell\n \"Embed me please!\" has been embedded to shape (512,)\n ```\n \n@@ -177,7 +177,7 @@ with f1:\n     )\n ```\n \n-```console\n+```shell\n Received: \"Greetings from Flow1\"\n Received: \"Greetings from Flow2\"\n ```\n\n---\n file path A: docs/how-to/flow-switch.md | file path B: docs/how-to/flow-switch.md\n\n@@ -111,7 +111,7 @@ class ImageIndexer(Executor):\n ```\n ````\n \n-```console\n+```shell\n [{'embedded_by': 'textIndexer'}, {'embedded_by': 'textIndexer'}]\n [[0.37511057 0.14902827 0.31666838]\n  [0.18466062 0.17823904 0.20046065]]\n@@ -173,7 +173,7 @@ print(filtered_text_data.texts)  # print text\n print('---')\n print(filtered_image_data.tensors)\n ```\n-```console\n+```shell\n ['hey there!', 'hey there!']\n ---\n [[[0.50535537 0.50538128]\n@@ -269,7 +269,7 @@ for embedded_by, text, image in list(zip(embedded_by, texts, tensors)):\n     print(f'Embedded by: {embedded_by}; Text: {text}, Image: {image}')\n ```\n \n-```console\n+```shell\n Embedded by: textIndexer; Text: hey there!, Image: None\n Embedded by: textIndexer; Text: hey there!, Image: None\n Embedded by: imageIndexer; Text: , Image: [[0.60863086 0.39863197], [0.78668579 0.66100752]]\n\n---\n file path A: docs/how-to/gpu-executor.md | file path B: docs/how-to/gpu-executor.md\n\n@@ -67,7 +67,7 @@ print(f'Document embedding: {docs.embeddings}')\n print(docs.texts)\n ```\n \n-```console\n+```shell\n            Flow@80[I]:\ud83c\udf89 Flow is ready to use!\n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:49618\n@@ -94,7 +94,7 @@ print(f'Document embedding: {docs.embeddings}')\n print(docs.texts)\n ```\n \n-```console\n+```shell\n            Flow@80[I]:\ud83c\udf89 Flow is ready to use!\n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:56276\n@@ -336,7 +336,7 @@ And compare the results\n \n ````{tab} CPU \n \n-```console\n+```shell\n       executor0@26554[L]:ready and listening\n         gateway@26554[L]:ready and listening\n            Flow@26554[I]:\ud83c\udf89 Flow is ready to use!\n@@ -351,7 +351,7 @@ Working... \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n \n ````{tab} GPU \n \n-```console\n+```shell\n       executor0@21032[L]:ready and listening\n         gateway@21032[L]:ready and listening\n            Flow@21032[I]:\ud83c\udf89 Flow is ready to use!\n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -25,8 +25,81 @@ docker pull jinaai/jina:latest\n ```\n ````\n \n-Now that you\u2019re set up, let\u2019s dive into more of how Jina works and how to build great apps.\n+Now that you\u2019re set up, let\u2019s create a project:\n \n+```shell\n+jina new hello-jina\n+cd hello-jina\n+jina flow --uses flow.yml\n+python client.py\n+```\n+\n+And observe the result from your terminal.\n+\n+```shell\n+['hello, world!', 'goodbye, world!']\n+```\n+\n+\n+## Next steps\n+\n+:::::{grid} 2\n+:gutter: 3\n+\n+\n+::::{grid-item-card} {octicon}`cross-reference;1.5em` Learn DocArray API\n+:link: https://docarray.jina.ai\n+\n+DocArray is the foundational data structure of Jina. Before starting Jina, first learn DocArray to quickly build a POC. \n+::::\n+\n+::::{grid-item-card} {octicon}`gear;1.5em` Understand Executor\n+:link: fundamentals/executor/index\n+:link-type: doc\n+\n+{term}`Executor` is a self-contained logic unit that performs a group of tasks on a `DocumentArray`.\n+\n+::::\n+\n+::::{grid-item-card} {octicon}`workflow;1.5em` Understand Flow\n+:link: fundamentals/flow/index\n+:link-type: doc\n+\n+\n+{term}`Flow` orchestrates Executors into a processing pipeline to build a multi-modal/cross-modal application\n+::::\n+\n+::::{grid-item-card} {octicon}`package-dependents;1.5em` Explore Jina Hub\n+:link: fundamentals/executor/hub/index\n+:link-type: doc\n+:class-card: color-gradient-card-1\n+\n+\n+Jina Hub is an Executor marketplace that allows you to share, explore and test Executors.\n+\n+::::\n+\n+\n+::::{grid-item-card} {octicon}`cpu;1.5em` Deploy a Flow to JCloud\n+:link: fundamentals/jcloud/index\n+:link-type: doc\n+:class-card: color-gradient-card-2\n+\n+JCloud is a free CPU/GPU hosting platform for Jina projects.\n+::::\n+\n+\n+\n+\n+::::{grid-item-card} {octicon}`squirrel;1.5em` Read more in-depth tutorials\n+:link: how-to/index\n+:link-type: doc\n+\n+Check out more in-depth tutorials on the advanced usages of Jina.\n+::::\n+\n+\n+:::::\n \n ```{include} ../README.md\n :start-after: <!-- start support-pitch -->\n\n---\n file path A: jina/resources/project-template/app.py | file path B: None\n\n@@ -1,16 +0,0 @@\n-from jina import DocumentArray, Flow\n-\n-\n-def run():\n-    f = Flow().add(uses='executor1/config.yml')\n-    # or load from Flow YAML\n-    # f = Flow.load_config('flow.yml')\n-    with f:\n-        da = f.post('/', DocumentArray.empty(2))\n-        print(da.texts)\n-\n-\n-if __name__ == '__main__':\n-    run()\n-    # or run in terminal:\n-    # $ jina flow --uses flow.yml\n\n---\n file path A: None | file path B: jina/resources/project-template/client.py\n\n@@ -0,0 +1,6 @@\n+from jina import Client, DocumentArray\n+\n+if __name__ == '__main__':\n+    c = Client(host='grpc://0.0.0.0:54321')\n+    da = c.post('/', DocumentArray.empty(2))\n+    print(da.texts)\n\n---\n file path A: jina/resources/project-template/flow.yml | file path B: jina/resources/project-template/flow.yml\n\n@@ -1,3 +1,7 @@\n jtype: Flow\n+version: '1'\n+with:\n+  port: 54321\n executors:\n-- uses: executor1/config.yml\n\\ No newline at end of file\n+- uses: executor1/config.yml\n+  name: toyExecutor\n\\ No newline at end of file\n\n\n###\n\n", "completion": "chore(docs): refactor create project docs"}
{"prompt": " file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -39,6 +39,7 @@ exclude_patterns = [\n     'tests',\n     'page_templates',\n     '.github',\n+    'api'\n ]\n pygments_style = 'rainbow_dash'\n html_theme = 'furo'\n\n---\n file path A: jina/resources/project-template/flow.yml | file path B: jina/resources/project-template/flow.yml\n\n@@ -3,5 +3,5 @@ version: '1'\n with:\n   port: 54321\n executors:\n-- uses: executor1/config.yml\n-  name: toyExecutor\n\\ No newline at end of file\n+  - uses: executor1/config.yml\n+    name: toyExecutor\n\\ No newline at end of file\n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -33,29 +33,6 @@ Now that you\u2019re set up, let\u2019s dive into more of how Jina works and how to bu\n :end-before: <!-- end support-pitch -->\n ```\n \n-```{important}\n-\n-Telemetry is the process of collecting data about the usage of a system. This data can be used to improve the system by understanding how it is being used and what areas need improvement.\n-\n-Jina uses telemetry to collect data about how the software is being used. This data is then used to improve the software. For example, if Jina sees that a lot of users are having trouble with a certain feature, they can improve that feature to make it easier to use.\n-\n-Telemetry is important for Jina because it allows the team to understand how the software is being used and what areas need improvement. Without telemetry, Jina would not be able to improve as quickly or as effectively.\n-\n-The data collected include:\n-\n-- Jina and its dependencies versions;\n-- A hashed unique user identifier;\n-- A hashed unique session identifie;r\n-- Boolean events: start of a Flow, Gateway and Runtime.\n-\n-```\n-\n-```{tip}\n-If you'd like to opt out of usage statistics, make sure to add the `--optout-telemetry` argument to the different Flows and Executors or set the `JINA_OPTOUT_TELEMETRY=1` environment variable.\n-\n-```\n-\n-\n ```{toctree}\n :caption: Get Started\n :hidden:\n@@ -93,6 +70,7 @@ cli/index\n yaml-spec\n proto/docs\n envs/index\n+telemetry\n ```\n \n ```{toctree}\n\n---\n file path A: None | file path B: docs/telemetry.md\n\n@@ -0,0 +1,16 @@\n+# Telemetry\n+\n+Telemetry is the process of collecting data about the usage of a system. This data can be used to improve the system by understanding how it is being used and what areas need improvement.\n+\n+Jina uses telemetry to collect data about how the software is being used. This data is then used to improve the software. For example, if Jina sees that a lot of users are having trouble with a certain feature, they can improve that feature to make it easier to use.\n+\n+Telemetry is important for Jina because it allows the team to understand how the software is being used and what areas need improvement. Without telemetry, Jina would not be able to improve as quickly or as effectively.\n+\n+The data collected include:\n+\n+- Jina and its dependencies versions;\n+- A hashed unique user identifier;\n+- A hashed unique session identifier;\n+- Boolean events: start of a Flow, Gateway and Runtime.\n+\n+To opt out of usage statistics, add the `--optout-telemetry` argument to the different Flows and Executors or set the `JINA_OPTOUT_TELEMETRY=1` as an environment variable.\n\\ No newline at end of file\n\n\n###\n\n", "completion": "chore(docs): refactor telemetry docs"}
{"prompt": " file path A: docs/fundamentals/jcloud/yaml-spec.md | file path B: docs/fundamentals/jcloud/yaml-spec.md\n\n@@ -5,7 +5,10 @@ Built on top of {ref}`Flow YAML specification<flow-yaml-spec>`, JCloud YAML exte\n \n Here's a Flow with 2 Executors with specific resource needs. `indexer` demands for 10G `ebs` disk, whereas `encoder` demands for 2 cores, 8G RAM & 2 dedicated GPUs. \n \n-```yaml\n+```{code-block} yaml\n+---\n+emphasize-lines: 5-9,12-16\n+---\n jtype: Flow\n executors:\n   - name: indexer\n@@ -24,7 +27,7 @@ executors:\n         gpu: 2\n ```\n \n-## Control resources of Executors\n+## Allocate resources for Executors\n \n Since each Executor has its own business logic, it might require different Cloud resources. One might need a higher RAM, whereas another might need a bigger disk. \n \n@@ -330,7 +333,7 @@ executors:\n :width: 70%\n ```\n \n-## Other Deployment Options\n+## Other deployment pptions\n \n ### Specify Jina version\n \n\n---\n file path A: docs/yaml-spec.md | file path B: docs/yaml-spec.md\n\n@@ -1,6 +1,10 @@\n # {octicon}`file-code` YAML specification\n \n-YAML is widely used in Jina to define an Executor, Flow, Gateway, Hub manifest and JCloud. This page helps you navigate different YAML specifications.\n+YAML is widely used in Jina to define an Executor, Flow. This page helps you quickly navigate different YAML specifications.\n+\n+## Executor-level YAML\n+\n+Executor level YAML is placed inside the Executor directory, as a part of Executor file structure.\n \n :::::{grid} 2\n :gutter: 3\n@@ -13,6 +17,25 @@ YAML is widely used in Jina to define an Executor, Flow, Gateway, Hub manifest a\n Define the argument of `__init__`, Python module dependencies and other settings of an Executor. \n ::::\n \n+::::{grid-item-card} Hub Manifest YAML\n+:link: fundamentals/executor/hub/yaml-spec\n+:link-type: doc\n+\n+Define meta information about how the Executor appears in Jina Hub.\n+\n+::::\n+\n+\n+:::::\n+\n+## Flow-level YAML\n+\n+Flow level YAML is placed inside the Flow directory, as a part of Flow file structure. It defines the Executors that will be used in the Flow, the Gateway and the JCloud hosting specifications.\n+\n+\n+:::::{grid} 2\n+:gutter: 3\n+\n ::::{grid-item-card} Flow YAML\n :link: fundamentals/flow/yaml-spec\n :link-type: doc\n@@ -25,26 +48,19 @@ Define the Executors, the topology and the Gateway settings of a Flow.\n :link-type: doc\n \n Define the protocol, TLS, authentication and other settings of a Gateway.\n-\n++++\n+Gateway specification is nested under the Flow YAML via `with:` keywords.\n ::::\n \n-::::{grid-item-card} Hub Manifest YAML\n-:link: fundamentals/executor/hub/yaml-spec\n-:link-type: doc\n-\n-Define how the Executor appears in the Hub.\n-\n-::::\n-\n-\n ::::{grid-item-card} JCloud YAML\n :link: fundamentals/jcloud/yaml-spec\n :link-type: doc\n \n Define the resources and autoscaling settings on Jina Cloud\n \n-::::\n-\n++++\n+JCloud specification is nested under the Flow YAML via `jcloud:` keywords.\n \n+::::\n \n-:::::\n+:::::\n\\ No newline at end of file\n\n---\n file path A: docs/yaml-spec.md | file path B: docs/yaml-spec.md\n\n@@ -38,7 +38,7 @@ Define how the Executor appears in the Hub.\n \n \n ::::{grid-item-card} JCloud YAML\n-:link: fundamentals/jcloud/resources\n+:link: fundamentals/jcloud/yaml-spec\n :link-type: doc\n \n Define the resources and autoscaling settings on Jina Cloud\n\n\n###\n\n", "completion": "chore(docs): refactor jcloud docs"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -1,6 +1,6 @@\n <p align=\"center\">\n <br><br><br>\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: Build cross-modal and multi-modal applications on the cloud\" width=\"150px\"></a>\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: Build cross-modal and multi-modal applications on the cloud \u00b7 Neural Search \u00b7 Creative AI \u00b7 Cloud Native\" width=\"150px\"></a>\n <br><br><br>\n </p>\n \n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -179,8 +179,8 @@ ogp_custom_meta_tags = [\n     '<meta name=\"twitter:card\" content=\"summary_large_image\">',\n     '<meta name=\"twitter:site\" content=\"@JinaAI_\">',\n     '<meta name=\"twitter:creator\" content=\"@JinaAI_\">',\n-    '<meta name=\"description\" content=\"Build cross-modal and multi-modal applications on the cloud\">',\n-    '<meta property=\"og:description\" content=\"Build cross-modal and multi-modal applications on the cloud\">',\n+    '<meta name=\"description\" content=\"Build cross-modal and multi-modal applications on the cloud \u00b7 Neural Search \u00b7 Creative AI \u00b7 Cloud Native\">',\n+    '<meta property=\"og:description\" content=\"Build cross-modal and multi-modal applications on the cloud \u00b7 Neural Search \u00b7 Creative AI \u00b7 Cloud Native\">',\n     '''\n     <!-- Global site tag (gtag.js) - Google Analytics -->\n <script async src=\"https://www.googletagmanager.com/gtag/js?id=G-48ZDWC8GT6\"></script>\n\n---\n file path A: scripts/create-conda-recipe.py | file path B: scripts/create-conda-recipe.py\n\n@@ -166,7 +166,7 @@ recipe_object = {\n         'license': 'Apache-2.0',\n         'license_family': 'Apache',\n         'license_file': 'LICENSE',\n-        'summary': 'Build cross-modal and multi-modal applications on the cloud',\n+        'summary': 'Build cross-modal and multi-modal applications on the cloud \u00b7 Neural Search \u00b7 Creative AI \u00b7 Cloud Native',\n         'doc_url': 'https://docs.jina.ai',\n     },\n     'extra': {\n\n---\n file path A: setup.py | file path B: setup.py\n\n@@ -145,7 +145,7 @@ setup(\n     packages=find_packages(),\n     version=__version__,\n     include_package_data=True,\n-    description='Build cross-modal and multi-modal applications on the cloud',\n+    description='Build cross-modal and multi-modal applications on the cloud \u00b7 Neural Search \u00b7 Creative AI \u00b7 Cloud Native',\n     author='Jina AI',\n     author_email='hello@jina.ai',\n     license='Apache 2.0',\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -39,7 +39,6 @@ exclude_patterns = [\n     'tests',\n     'page_templates',\n     '.github',\n-    'api'\n ]\n pygments_style = 'rainbow_dash'\n html_theme = 'furo'\n\n---\n file path A: docs/fundamentals/executor/hub/create-hub-executor.md | file path B: docs/fundamentals/executor/hub/create-hub-executor.md\n\n@@ -27,29 +27,37 @@ MyExecutor/\n \u2514\u2500\u2500 executor.py\n ```\n \n-- `manifest.yml` should contain the Executor's annotations for getting better exposure on Jina Hub.\n+- `manifest.yml` should contain the Executor's annotations for getting better exposure on Jina Hub. {ref}`Its specification can be found here<manifest-yaml>`.\n - `config.yml` is the Executor's configuration file, where you can define **__init__** arguments using **with** keyword.\n - `requirements.txt` describes the Executor's Python dependencies.\n - `executor.py` should contain your Executor's main logic.\n - `README.md` should describe how to use your Executor.\n \n \n-## Fields of `manifest.yml`\n \n-`manifest.yml` is optional.\n+## Tips\n \n-`manifest.yml` annotates your image so that it can be better managed by the Hub portal. To get better exposure on Jina Hub, you may want to \n-carefully set `manifest.yml` to the correct values:\n \n-| Key                | Description                                                                                | Default |\n-| ---                | ---                                                                                        | ---     |\n-| `manifest_version` | The version of the manifest protocol                                                       | `1`     |\n-| `name`             | Human-readable title of the Executor                                                       | None    |\n-| `description`      | Human-readable description of the Executor                                                 | None    |\n-| `url`              | URL to find more information about the Executor, normally the GitHub repo URL              | None    |\n-| `keywords`         | A list of strings to help users filter and locate your package                             | None    |\n+When developing Hub {class}`~jina.Executor`s, make sure to follow these tips:\n \n-```{admonition} See Also\n-:class: seealso\n-{ref}`Hub Executor best practices <hub-executor-best-practices>`\n-```\n+* Use `jina hub new` CLI to create an Executor\n+\n+  To get started, always use the command and follow the instructions. This will ensure you follow the right file \n+structure.\n+\n+* No need to write Dockerfile manually \n+\n+  Most of the time, you do not need to create `Dockerfile` manually, {abbr}`Hubble (Hubble is the Jina Hub building system)` will generate a well-optimized Dockerfile according to your Executor \n+    package.\n+\n+\n+* No need to bump Jina version\n+\n+  Hub executors are version-agnostic. When you pull an Executor from Hub, Hubble will always select the right Jina \n+version for you. No worries about Jina version upgrade!\n+\n+\n+* Fill in `manifest.yml` correctly. \n+\n+  Information you include in `manifest.yml` will be displayed on our website.\n+Want to make your Executor eye-catching on our website? Fill all fields in `manifest.yml` with heart & love! {ref}`Its specification can be found here<manifest-yaml>`.\n\n---\n file path A: docs/fundamentals/executor/hub/executor-best-practices.md | file path B: None\n\n@@ -1,37 +0,0 @@\n-(hub-executor-best-practices)=\n-# Best practices\n-\n-## Developing Hub Executors\n-\n-When developing Hub {class}`~jina.Executor`s, make sure to follow these tips:\n-\n-* Use `jina hub new` CLI to create an Executor\n-\n-  To get started, always use the command and follow the instructions. This will ensure you follow the right file \n-structure.\n-\n-* No need to write Dockerfile manually \n-\n-  {abbr}`Hubble (Hubble is the Jina Hub building system)` will generate a well-optimized Dockerfile according to your Executor \n-    package\n-\n-\n-* No need to bump Jina version\n-\n-  Hub executors are version-agnostic. When you pull an Executor from Hub, Hubble will always select the right Jina \n-version for you. No worries about Jina version upgrade!\n-\n-\n-* Fill in `manifest.yml` correctly. \n-\n-  Information you include in `manifest.yml` will be displayed on our website.\n-Want to make your Executor eye-catching on our website? Fill all fields in `manifest.yml` with heart & love!\n-\n-\n-## Using Hub Executors\n-\n-When using Hub Executors, make sure to follow these tips:\n-\n-* Ensure sufficient Docker resources are allocated when using `jinahub+docker`\n-\n-  When `jinahub+docker` executors are not loading properly or are having issues during initialization, please ensure sufficient Docker resources are allocated.\n\n---\n file path A: docs/fundamentals/executor/hub/index.md | file path B: docs/fundamentals/executor/hub/index.md\n\n@@ -55,5 +55,5 @@ push-executor\n use-hub-executor\n ../../../how-to/sandbox\n ../../../how-to/debug-executor\n-executor-best-practices\n+yaml-spec\n ```\n\n---\n file path A: docs/fundamentals/executor/hub/use-hub-executor.md | file path B: docs/fundamentals/executor/hub/use-hub-executor.md\n\n@@ -73,6 +73,10 @@ with f:\n ```\n ````\n \n+\n+When `jinahub+docker://` executors are not loading properly or are having issues during initialization, please ensure sufficient Docker resources are allocated.\n+\n+\n ### Mount local volumes\n \n You can mount volumes into your dockerized Executor by passing a list of volumes to the `volumes` argument:\n\n---\n file path A: None | file path B: docs/fundamentals/executor/hub/yaml-spec.md\n\n@@ -0,0 +1,15 @@\n+(manifest-yaml)=\n+# {octicon}`file-code` YAML specification\n+\n+`manifest.yml` is an optional file that shipped with your Executor bundle. It annotates your Executor with meta information so that it can be better managed by the Hub system. \n+\n+To get better appealing on Jina Hub, you may want to \n+carefully set `manifest.yml` to the correct values:\n+\n+| Key                | Description                                                                                | Default |\n+| ---                | ---                                                                                        | ---     |\n+| `manifest_version` | The version of the manifest protocol                                                       | `1`     |\n+| `name`             | Human-readable title of the Executor                                                       | None    |\n+| `description`      | Human-readable description of the Executor                                                 | None    |\n+| `url`              | URL to find more information about the Executor, normally the GitHub repo URL              | None    |\n+| `keywords`         | A list of strings to help users filter and locate your package                             | None    |\n\n---\n file path A: docs/how-to/flow-switch.md | file path B: docs/how-to/flow-switch.md\n\n@@ -1,5 +1,5 @@\n (flow-switch)=\n-# Conditional route traffic inside a Flow\n+# Conditional route request inside a Flow\n \n In this tutorial you will gain a deeper insight into the {class}`~jina.Flow` 's {ref}`filter condition feature<flow-filter>`.\n \n\n---\n file path A: docs/how-to/gpu-executor.md | file path B: docs/how-to/gpu-executor.md\n\n@@ -1,5 +1,5 @@\n (gpu-executor)=\n-# Run Executors on GPU\n+# Build a GPU Executor\n \n This document will show you how to use an {class}`~jina.Executor` on a GPU, both locally and in a\n Docker container. You will also learn how to use GPU with pre-built Hub executors.\n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -90,7 +90,7 @@ how-to/index\n \n api-rst\n cli/index\n-yaml\n+yaml-spec\n proto/docs\n envs/index\n ```\n\n---\n file path A: docs/yaml.md | file path B: docs/yaml-spec.md\n\n@@ -29,7 +29,7 @@ Define the protocol, TLS, authentication and other settings of a Gateway.\n ::::\n \n ::::{grid-item-card} Hub Manifest YAML\n-:link: fundamentals/executor/hub/create-hub-executor\n+:link: fundamentals/executor/hub/yaml-spec\n :link-type: doc\n \n Define how the Executor appears in the Hub.\n\n\n###\n\n", "completion": "chore(docs): refactor hub docs"}
{"prompt": " file path A: docs/index.md | file path B: docs/index.md\n\n@@ -90,6 +90,7 @@ how-to/index\n \n api-rst\n cli/index\n+yaml\n proto/docs\n envs/index\n ```\n\n---\n file path A: None | file path B: docs/yaml.md\n\n@@ -0,0 +1,50 @@\n+# {octicon}`file-code` YAML specification\n+\n+YAML is widely used in Jina to define an Executor, Flow, Gateway, Hub manifest and JCloud. This page helps you navigate different YAML specifications.\n+\n+:::::{grid} 2\n+:gutter: 3\n+\n+\n+::::{grid-item-card} Executor YAML\n+:link: fundamentals/executor/yaml-spec\n+:link-type: doc\n+\n+Define the argument of `__init__`, Python module dependencies and other settings of an Executor. \n+::::\n+\n+::::{grid-item-card} Flow YAML\n+:link: fundamentals/flow/yaml-spec\n+:link-type: doc\n+\n+Define the Executors, the topology and the Gateway settings of a Flow.\n+::::\n+\n+::::{grid-item-card} Gateway YAML\n+:link: fundamentals/gateway/yaml-spec\n+:link-type: doc\n+\n+Define the protocol, TLS, authentication and other settings of a Gateway.\n+\n+::::\n+\n+::::{grid-item-card} Hub Manifest YAML\n+:link: fundamentals/executor/hub/create-hub-executor\n+:link-type: doc\n+\n+Define how the Executor appears in the Hub.\n+\n+::::\n+\n+\n+::::{grid-item-card} JCloud YAML\n+:link: fundamentals/jcloud/resources\n+:link-type: doc\n+\n+Define the resources and autoscaling settings on Jina Cloud\n+\n+::::\n+\n+\n+\n+:::::\n\n---\n file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -4,19 +4,15 @@\n \n Every {class}`~jina.Flow` provides an API Gateway to receive requests over the network. Supported protocols are gRPC, HTTP and WebSocket with TLS.\n \n-There are two ways of defining a Gateway, either directly from the Python API or using yaml files. For each section we will show you both possibles way of configuring your Gateway.\n+There are two ways of defining a Gateway, either directly from the Python or using YAML. The full YAML specification of Gateway can be {ref}`found here<yaml-spec>`.\n \n-```{admonition} Jina Client\n-:class: caution\n-\n-To showcase the workings of Flow, the examples below use a Client connecting to it, all from withing the same Python script.\n+```{toctree}\n+:hidden:\n \n-In most cases, this is not how a real user would access a Flow. Rather, they would use one of {ref}`several ways of connecting over a network<access-flow-api>`.\n-This does not affect how you have to configure your Flow API, so the examples here should translate seamlessly.\n-\n-For more proper use of the Client, and more information about the Client itself, see the {ref}`Client documentation <client>`.\n+yaml-spec\n ```\n \n+\n (flow-protocol)=\n ## Supported protocols\n You can use three different protocols to serve the `Flow`: gRPC, HTTP and Websocket.\n\n---\n file path A: None | file path B: docs/fundamentals/gateway/yaml-spec.md\n\n@@ -0,0 +1,25 @@\n+(gateway-yaml-spec)=\n+# {octicon}`file-code` YAML specification\n+\n+This page outlines the specification for Gateway.\n+\n+Gateway config is nested under `with` key of a Flow YAML. For example,\n+\n+```{code-block} yaml\n+---\n+emphasize-lines: 3-4\n+---\n+jtype: Flow\n+version: '1'\n+with:\n+  protocol: http\n+```\n+\n+Defines a Gateway that uses HTTP protocol.\n+\n+## Fields\n+\n+The following fields are defined for Gateway and can be set under `with` key of a Flow YAML.\n+\n+```{include} ../flow/gateway-args.md\n+```\n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -1,19 +1,15 @@\n (external-executor)=\n-# Use external Executors\n+# Include external Executors in a Flow\n \n-Normally, we have seen how {class}`~jina.Flow` ties up {class}`~jina.Executor`s together, and how an Executor lives in the context of a Flow.\n+We have seen how {class}`~jina.Flow` ties up {class}`~jina.Executor`s together, and how an Executor lives in the context of a Flow. Sometimes you may want to launch an Executor on its own, and then share it to different Flows. We call this kind of Executor *external*, as its lifecycle is not tied to the Flow.\n \n-However, this is not always the case, and sometimes you may want to launch an Executor on its own, and perhaps have the same\n-Executor be used by different Flows.\n \n-\n-````{admonition} Where can external Executors run?\n-:class: hint\n External Executors can run anywhere from the same environment as the Flow, to a Docker container, or even a remote\n environment, such as {ref}`JCloud <jcloud>`.\n \n-To deploy external Exectuors on JCloud, please follow {ref}`this documentation <external-executors>`.\n-````\n+```{tip}\n+To deploy external Executors on JCloud, please follow {ref}`this documentation <external-executors>`.\n+```\n \n As the first step in this tutorial, you will learn how to add already running external Executors to your Flow.\n After that, you will see how to create and use an external Executor yourself.\n@@ -151,7 +147,7 @@ We do this using a YAML file.\n In a new file called `my-exec.yml` we type:\n \n ```yaml\n-!MyExecutor\n+jtype: MyExecutor\n metas:\n   py_modules:\n     - exec.py\n\n---\n file path A: docs/how-to/flow-switch.md | file path B: docs/how-to/flow-switch.md\n\n@@ -1,10 +1,5 @@\n (flow-switch)=\n-# Add filter logic to Flow\n-\n-````{admonition} Requirements\n-:class: hint\n-To follow along with this How-To, you need Jina 3.2.2 or higher.\n-````\n+# Conditional route traffic inside a Flow\n \n In this tutorial you will gain a deeper insight into the {class}`~jina.Flow` 's {ref}`filter condition feature<flow-filter>`.\n \n\n---\n file path A: docs/how-to/scale-out.md | file path B: docs/how-to/scale-out.md\n\n@@ -1,7 +1,5 @@\n (scale-out)=\n-# Scale out your Executor\n-\n-## Overview\n+# Scale out with replicas and shards\n \n A Jina {class}`~jina.Flow` orchestrates multiple {class}`~jina.Executor`s.\n By default, a Jina Executor runs with a single `replica` and `shard`.\n@@ -12,7 +10,7 @@ To solve this, Jina Flow allows you to config the number of `replicas` and `shar\n `replica` is used to increase Executor throughput and availability.\n `shard` is used for data partitioning.\n \n-In this document, we'll dive into these two concepts and see how you can make use of `replicas` and `shards` to scale out your Executor.\n+In this chapter, we'll dive into these two concepts and see how you can make use of `replicas` and `shards` to scale out your Executor.\n \n ## Before you start\n <!-- Delete this section if your readers can go to the steps without requiring any prerequisite knowledge. -->\n@@ -23,12 +21,6 @@ Before you begin, make sure you meet these prerequisites:\n * Please install the following dependencies if you haven't:\n \n \n-```shell\n-pip install jina\n-pip install sklearn==1.0.2\n-pip install pqlite==0.2.3\n-```\n-\n ## Speed up a slow Executor: Replicas\n \n ### Context\n\n\n###\n\n", "completion": "chore(docs): refactor executors docs"}
{"prompt": " file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -39,6 +39,7 @@ exclude_patterns = [\n     'tests',\n     'page_templates',\n     '.github',\n+    'api'\n ]\n pygments_style = 'rainbow_dash'\n html_theme = 'furo'\n\n---\n file path A: docs/fundamentals/client/client.md | file path B: docs/fundamentals/client/client.md\n\n@@ -219,7 +219,7 @@ This feature is intended for the case where there are multiple Executors that ta\n This is often the case for Executors from the Hub, since they tend to share a common interface for parameters.\n \n \n-(callback-functions)=\n+\n ## Async send\n \n There also exists an async version of the Python Client which works with {meth}`~jina.clients.mixin.PostMixin.post` and {meth}`~jina.clients.mixin.MutateMixin.mutate`.\n@@ -316,7 +316,7 @@ with f:  # Using it as a Context Manager will start the Flow\n This will send the request to all Executors whose names start with 'bar', such as 'barExecutor'.\n In the simplest case, you can specify a precise Executor name, and the request will be sent only to that single Executor.\n \n-\n+(callback-functions)=\n ## Callbacks\n \n After performing {meth}`~jina.clients.mixin.PostMixin.post`, you may want to further process the obtained results.\n\n---\n file path A: docs/fundamentals/executor/hub/push-executor.md | file path B: docs/fundamentals/executor/hub/push-executor.md\n\n@@ -132,7 +132,7 @@ For example:\n     ```\n ````\n \n-For multiple enviroment variables, we can pass it in this way:\n+For multiple environment variables, we can pass it in this way:\n \n ```bash\n jina hub push --build-env FIRST=foo --build-env SECOND=bar\n\n---\n file path A: docs/fundamentals/executor/index.md | file path B: docs/fundamentals/executor/index.md\n\n@@ -49,7 +49,7 @@ executor-methods\n monitoring-executor\n executor-run\n executor-serve\n-yaml-spec\n executor-files\n containerize-executor\n+yaml-spec\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/fundamentals/executor/yaml-spec.md | file path B: docs/fundamentals/executor/yaml-spec.md\n\n@@ -1,5 +1,5 @@\n (executor-yaml-spec)=\n-# YAML specification\n+# {octicon}`file-code` YAML specification\n \n This page outlines the specification for valid Executor YAML files.\n \n\n---\n file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -4,65 +4,70 @@\n \n {class}`~jina.Flow` defines how your Executors are connected together and how your data *flows* through them.\n \n-Every {class}`~jina.Flow` can be defined either purely in Python, or be loaded from a YAML file.\n-\n-````{admonition} Best practice\n-:class: hint\n-\n-For production use we recommend YAML files to configure your Flows. This is because YAML files are:\n-\n-- independent of Python source code\n-- easy to edit, maintain and extend\n-- human-readable\n-\n-````\n \n ## Create\n \n-The most trivial {class}`~jina.Flow` is the empty Flow and, like any other Flow, it can be instantiated purely in Python, or from a\n-YAML file:\n+The most trivial {class}`~jina.Flow` is the empty Flow. It can be defined purely in Python or from a YAML file:\n \n ````{tab} Python\n \n ```python\n from jina import Flow\n \n-f = Flow()  # Create the empty Flow\n-with f:  # Using it as a Context Manager will start the Flow\n-    f.post(on='/search')  # This sends a request to the /search endpoint of the Flow\n+f = Flow()\n ```\n ````\n \n `````{tab} YAML\n-`flow.yml`:\n-\n ```yaml\n jtype: Flow\n ```\n+`````\n+\n+```{tip}\n+An empty Flow contains only {ref}`the Gateway<flow>`.\n+```\n+\n+For production, we recommend YAML files to define the Flows. This is because YAML files are independent of Python logic code and easy to maintain.\n+\n+\n+\n+\n+### Conversion between Python and YAML\n+\n+Python Flow definition can be easily converted to/from YAML definition.\n+\n+To load a Flow from a YAML file, use the {meth}`~jina.Flow.load_config`:\n \n ```python\n from jina import Flow\n \n-f = Flow.load_config('flow.yml')  # Load the Flow definition from Yaml file\n-\n-with f:  # Using it as a Context Manager will start the Flow\n-    f.post(on='/search')  # This sends a request to the /search endpoint of the Flow\n+f = Flow.load_config('flow.yml')\n ```\n \n-````{admonition} Hint: Dump Flow configuration\n-:class: hint\n+To export an existing Flow definition to a YAML file use {meth}`~jina.Flow.save_config`:\n \n-In addition to loading a Flow from a YAML file, you can also save an existing Flow configuration to YAML. To do so, execute `f.save_config('path/to/flow.yml')`.\n-````\n-`````\n+```python\n+from jina import Flow\n \n+f = Flow().add().add()  # Create a Flow with two Executors\n+\n+f.save_config('flow.yml')\n+```\n \n ## Start and stop\n \n When a {class}`~jina.Flow` starts, all its {ref}`added Executors <flow-add-executors>` will start as well, making it possible to {ref}`reach the service through its API <access-flow-api>`.\n \n-Jina Flows are context managers and can be started and stopped using Pythons `with` notation:\n+There are three ways to start a Flow. Depending on the use case, you can start a Flow either in Python, or from a YAML file, or from the terminal.\n \n+- Generally in Python: use Flow as a context manager in Python.\n+- As an entrypoint from terminal: use Jina CLI and a Flow YAML.\n+- As an entrypoint from Python code: use Flow as a context manager inside `if __name__ == '__main__'`\n+- No context manager: manually call {meth}`~jina.Flow.start`  and {meth}`~jina.Flow.close`.\n+\n+\n+````{tab} General in Python\n ```python\n from jina import Flow\n \n@@ -71,69 +76,49 @@ f = Flow()\n with f:\n     pass\n ```\n+````\n \n-The statement `with f:` starts the Flow, and exiting the indented `with` block stops the Flow, including all Executors defined in it.\n-\n-\n-### Start inside `__main__`\n-\n-If applicable, always start the Flow inside `if __name__ == '__main__'`. For example:\n-\n-````{tab} \u2705 Do\n-```{code-block} python\n----\n-emphasize-lines: 13, 14\n----\n-\n-from jina import Flow, Executor, requests\n+````{tab} Jina CLI entrypoint\n+```bash\n+jina flow --uses flow.yml\n+```\n+````\n \n-class CustomExecutor(Executor):\n-    @requests\n-    async def foo(self, **kwargs):\n-        ...\n+````{tab} Python entrypoint\n+```python\n+from jina import Flow\n \n-f = Flow().add(uses=CustomExecutor)\n+f = Flow()\n \n if __name__ == '__main__':\n     with f:\n-        ...\n+        pass\n ```\n ````\n \n-````{tab} \ud83d\ude14 Don't\n-```{code-block} python\n----\n-emphasize-lines: 2\n----\n+````{tab} Python no context manager\n+```python\n+from jina import Flow\n \n-from jina import Flow, Executor, requests\n+f = Flow()\n \n-class CustomExecutor(Executor):\n-    @requests\n-    def foo(self, **kwargs):\n-        ...\n+f.start()\n \n-f = Flow().add(uses=CustomExecutor)\n-with f:\n-    ...\n+f.close()\n+```\n+````\n \n-\"\"\"\n-# error\n-This probably means that you are not using fork to start your\n-child processes and you have forgotten to use the proper idiom\n-in the main module:\n+The statement `with f:` starts the Flow, and exiting the indented `with` block stops the Flow, including all Executors defined in it.\n \n-    if _name_ == '_main_':\n-        freeze_support()\n-        ...\n \n-The \"freeze_support()\" line can be omitted if the program\n-is not going to be frozen to produce an executable.\n+A successful start of a Flow looks like this:\n \n-\"\"\"\n+```{figure} success-flow.png\n+:scale: 70%\n ```\n \n-````\n+Your addresses and entrypoints can be found in the output. When enabling more features such as monitoring, HTTP gateway, TLS encryption, this display will also expand to contain more information.\n+\n \n ### Set multiprocessing `spawn` \n \n@@ -152,19 +137,27 @@ There's no need to set this for Windows, as it only supports spawn method for mu\n ## Serve forever\n \n In most scenarios, a Flow should remain reachable for prolonged periods of time.\n-This can be achieved by *blocking* the execution:\n+This can be achieved by `jina flow --uses flow.yml` from terminal.\n+\n+\n+Or if you are serving a Flow from Python:\n \n ```python\n from jina import Flow\n \n f = Flow()\n+\n with f:\n     f.block()\n ```\n \n The `.block()` method blocks the execution of the current thread or process, which enables external clients to access the Flow.\n \n-In this case, the Flow can be stopped by interrupting the thread or process. Alternatively, a `multiprocessing` or `threading` `Event` object can be passed to `.block()`, which stops the Flow once set.\n+In this case, the Flow can be stopped by interrupting the thread or process. \n+\n+### Server until an event\n+\n+Alternatively, a `multiprocessing` or `threading` `Event` object can be passed to `.block()`, which stops the Flow once set.\n \n ```python\n from jina import Flow\n@@ -221,6 +214,8 @@ One can also do it in the terminal via:\n jina export flowchart flow.yml flow.svg \n ```\n \n+One can also visualize a remote Flow by passing the URL to `jina export flowchart`.\n+\n ## Export\n \n A {class}`~jina.Flow` YAML can be exported as a Docker Compose YAML or a Kubernetes YAML bundle. \n\n---\n file path A: docs/fundamentals/flow/success-flow.png | file path B: docs/fundamentals/flow/success-flow.png\n\nBinary files /dev/null and b/docs/fundamentals/flow/success-flow.png differ\n\n---\n file path A: docs/fundamentals/flow/yaml-spec.md | file path B: docs/fundamentals/flow/yaml-spec.md\n\n@@ -1,5 +1,5 @@\n (flow-yaml-spec)=\n-# YAML specification\n+# {octicon}`file-code` YAML specification\n \n This page outlines the specification for valid {class}`~jina.Executor` YAML files.\n \n\n---\n file path A: docs/how-to/index.md | file path B: docs/how-to/index.md\n\n@@ -48,12 +48,12 @@ can put that into practice you can find {ref}`here <kubernetes>`.\n ```{toctree}\n :hidden:\n \n-google-colab\n-../fundamentals/clean-code\n+realtime-streaming\n+flow-switch\n scale-out\n+../fundamentals/clean-codegoogle-colab\n gpu-executor\n external-executor\n-flow-switch\n docker-compose\n kubernetes\n monitoring\n\n---\n file path A: None | file path B: docs/how-to/realtime-streaming.md\n\n@@ -0,0 +1,129 @@\n+# Build real-time streaming service\n+\n+In this example, we will build a real-time video streaming service, like Zoom. It allows multiple users to video chat via webcam. The whole solution is in 20 lines of code, showcasing how to powerful and easy to use Jina is.\n+\n+![](https://user-images.githubusercontent.com/2041322/185625220-40c1f887-3be4-49df-9318-c49e0fb7365e.gif)\n+\n+The source code [can be found here](https://github.com/jina-ai/jina-video-chat).\n+\n+## Basic idea\n+\n+Idea is straightforward: \n+\n+- It is a client-server architecture;\n+- Client uses webcam and collects frames and sends them to the server;\n+- Server aggregates the all frames from different users and sends back to the client;\n+- Client displays the received frames.\n+\n+## Client\n+\n+The more technical and interesting part is actually on the client side. The key is to set `request_size=1` and use callback to handle response (instead of return).\n+\n+```{tip}\n+You will need `opencv-python`, please install it via `pip install opencv-python`.\n+```\n+\n+\n+```python\n+import sys\n+import cv2\n+\n+if len(sys.argv) == 3:\n+    server_address = sys.argv[1]\n+    user = sys.argv[2]\n+else:\n+    print('Usage: ./client.py <server_address> <user>')\n+    sys.exit(1)\n+\n+\n+def render_recv(resp):\n+    for d in resp.docs:\n+        cv2.imshow('output', d.tensor)\n+\n+\n+from jina import Client, Document\n+\n+c = Client(host=server_address)\n+c.post(\n+    '/',\n+    Document.generator_from_webcam(\n+        tags={'user': user}, show_window=False, height_width=(200, 300)\n+    ),\n+    on_done=render_recv,\n+    request_size=1,\n+)\n+```\n+\n+Here we use [DocArray API `generator_from_webcam`](https://docarray.jina.ai/datatypes/video/#create-document-from-webcam) to create a Document generator from webcam, where each frame is a `Document` with a `tensor` field.\n+\n+The input hence has infinite length, until you hit `ESC` key.\n+\n+To achieve real-time streaming, you need to set `request_size` to 1. This means that the client will not do any batching and directly send each Document as a request. You also need to use {ref}`callback-functions` to handle the response. This is different from using the return in many other examples. Callback ensures the user can see the response as soon as it is received.\n+\n+\n+## Server\n+\n+Server is super simple. Concat all frames from different users and send back to the client.\n+\n+```python\n+import numpy as np\n+from jina import Executor, requests\n+\n+\n+class VideoChatExecutor(Executor):\n+    last_user_frames = {}\n+\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        for d in docs:\n+            self.last_user_frames[d.tags['user']] = d.tensor\n+            if len(self.last_user_frames) > 1:\n+                d.tensor = np.concatenate(list(self.last_user_frames.values()), axis=0)\n+```\n+\n+Save it as `executor.py` and create `executor.yml` with the following content:\n+\n+```yaml\n+jtype: VideoChatExecutor\n+py_modules:\n+  - executor.py\n+```\n+\n+Put both under `executor/` folder and now the Flow YAML looks like the following:\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - uses: executor/config.yml\n+    name: frameAggregator\n+```\n+\n+The whole file structure is illustrated below.\n+\n+```\n+flow.yml\n+executor/\n+    config.yml\n+    executor.py\n+```\n+\n+## Run\n+\n+First run the server:\n+\n+```bash\n+jina flow --uses flow.yml\n+```\n+\n+Note down the server address:\n+\n+![](https://github.com/jina-ai/jina-video-chat/raw/main/.github/server.png)\n+\n+Now run the client from different laptops:\n+\n+```bash\n+python client.py grpcs://your-server-address-from-last-image johannes\n+python client.py grpcs://your-server-address-from-last-image han\n+python client.py grpcs://your-server-address-from-last-image kalim\n+```\n+\n\n\n###\n\n", "completion": "chore(docs): refactor flow basic docs"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -78,6 +78,15 @@ To deploy,\n jc deploy flow.yml\n ```\n \n+````{tip}\n+Testing locally before deploying is recommended. You can use \n+\n+```bash\n+jina flow --uses flow.yml\n+```\n+````\n+\n+\n #### A project folder\n \n Just like a regular Python project, you can have sub-folders of Executor implementations; and a `flow.yml` on the top-level to connect all Executors together.\n\n---\n file path A: docs/fundamentals/jcloud/faq.md | file path B: docs/fundamentals/jcloud/faq.md\n\n@@ -16,19 +16,3 @@\n - **How long do you persist my service?**\n \n   Flows are terminated if they are not serving requests for the last 24hrs. But this is configurable by passing {ref}`retention-days <retention-days>` argument.\n-\n-- **My Flow deployment failed. How I do to fix it?**\n-\n-  As a first step, please enable verbose logs while deploying the Flow. You can add `--loglevel DEBUG` _before_ each CLI subcommand, e.g.\n-\n-  ```bash\n-  jc --loglevel DEBUG deploy flow.yml\n-  ```\n-\n-  Alternatively, you can also configure it by using environment variable `JCLOUD_LOGLEVEL`, e.g.\n-\n-  ```bash\n-  JCLOUD_LOGLEVEL=DEBUG jc deploy flow.yml\n-  ```\n-\n-  If you don't see any obvious errors, please raise an issue in [JCloud](https://github.com/jina-ai/jcloud/issues/new/choose)\n\n---\n file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -233,3 +233,19 @@ autoscale\n advanced\n faq\n ```\n+\n+## Troubleshooting\n+\n+If your deployment failed, please enable verbose logging and redeploy it. You can add `--loglevel DEBUG` _before_ each CLI subcommand, e.g.\n+\n+```bash\n+jc --loglevel DEBUG deploy flow.yml\n+```\n+\n+Alternatively, you can configure it by using environment variable `JCLOUD_LOGLEVEL`, e.g.\n+\n+```bash\n+JCLOUD_LOGLEVEL=DEBUG jc deploy flow.yml\n+```\n+\n+If you don't see any obvious errors, please raise an issue in [JCloud](https://github.com/jina-ai/jcloud/issues/new/choose)\n\n---\n file path A: docs/fundamentals/jcloud/faq.md | file path B: docs/fundamentals/jcloud/faq.md\n\n@@ -25,10 +25,10 @@\n   jc --loglevel DEBUG deploy flow.yml\n   ```\n \n-  Alternatively, you can also configure it by using Environment Variable `JCLOUD_LOGLEVEL`, e.g.\n+  Alternatively, you can also configure it by using environment variable `JCLOUD_LOGLEVEL`, e.g.\n \n   ```bash\n-  export JCLOUD_LOGLEVEL=DEBUG && jc deploy flow.yml\n+  JCLOUD_LOGLEVEL=DEBUG jc deploy flow.yml\n   ```\n \n   If you don't see any obvious errors, please raise an issue in [JCloud](https://github.com/jina-ai/jcloud/issues/new/choose)\n\n---\n file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -19,25 +19,26 @@ At this point, Jina Cloud hosts all your Jina projects and offers computational/\n ```\n \n ## Basic\n-### Install\n-If you have {ref}`installed jina <swagger-ui>`, there is no need to install `jcloud` CLI. However, you still can \n-install the CLI individually:\n+\n+Jina Cloud provides a CLI and you can use it simply via `jina cloud` from the terminal, or `jcloud` or simply `jc` for minimalists. \n+\n+\n+````{hint}\n+You can also only install Jina Cloud CLI without install `jina` package.\n+\n ```bash\n pip install jcloud\n jc -h\n ```\n \n-```{hint}\n+If you installed it individually, all of its commands come under the `jc` or `jcloud` executable.\n+\n+\n In case `jc` is already occupied by another tool, please use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n-```\n+````\n+\n+For the rest of this section, we will be using `jc` or `jcloud`. But again they are interchangable to `jina cloud`.\n \n-```{important}\n-You can use the `jcloud` CLI in 2 ways:\n-* If you installed it with `jina`, all of its commands come under the `jina cloud` command. Try `jina cloud --help` for \n-more info.\n-* If you installed it individually, all of its commands come under the `jc` or `jcloud` executable.\n-For the rest of this section, we will be using `jc` command rather than `jina cloud`.\n-```\n \n ### Login\n \n@@ -81,10 +82,10 @@ jc deploy flow.yml\n \n Just like a regular Python project, you can have sub-folders of Executor implementations; and a `flow.yml` on the top-level to connect all Executors together.\n \n-You can create an example local project using `jc new`. The default structure looks like:\n+You can create an example local project using `jc new hello`. The default structure looks like:\n \n ```\n-.\n+hello/\n \u251c\u2500\u2500 .env\n \u251c\u2500\u2500 executor1\n \u2502   \u251c\u2500\u2500 config.yml\n@@ -95,6 +96,7 @@ You can create an example local project using `jc new`. The default structure lo\n \n where,\n \n+- `hello/` is your top-level project folder.\n - `executor1` directory has all Executor related code/config. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/executor-files/). Multiple such Executor directories can be created.\n - `flow.yml` Your Flow YAML.\n - `.env` All environment variables used during deployment.\n@@ -102,7 +104,7 @@ where,\n To deploy,\n \n ```bash\n-jc deploy ./hello\n+jc deploy hello\n ```\n \n \n\n\n###\n\n", "completion": "chore(docs): fix docs in jcloud"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -119,6 +119,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         metas: Optional[Dict] = None,\n         requests: Optional[Dict] = None,\n         runtime_args: Optional[Dict] = None,\n+        workspace: Optional[str] = None,\n         **kwargs,\n     ):\n         \"\"\"`metas` and `requests` are always auto-filled with values from YAML config.\n@@ -127,11 +128,13 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         :param requests: a dict of endpoint-function mapping\n         :param runtime_args: a dict of arguments injected from :class:`Runtime` during runtime\n         :param kwargs: additional extra keyword arguments to avoid failing when extra params ara passed that are not expected\n+        :param workspace: the workspace of the executor. Only used if a workspace is not already provided in `metas` or `runtime_args`\n         \"\"\"\n         self._add_metas(metas)\n         self._add_requests(requests)\n         self._add_runtime_args(runtime_args)\n         self._init_monitoring()\n+        self._init_workspace = workspace\n         self.logger = JinaLogger(self.__class__.__name__)\n         if __dry_run_endpoint__ not in self.requests:\n             self.requests[__dry_run_endpoint__] = self._dry_run_func\n@@ -321,6 +324,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         workspace = (\n             getattr(self.runtime_args, 'workspace', None)\n             or getattr(self.metas, 'workspace')\n+            or self._init_workspace\n             or os.environ.get('JINA_DEFAULT_WORKSPACE_BASE')\n         )\n         if workspace:\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -9,8 +9,8 @@ from unittest import mock\n \n import pytest\n import yaml\n-\n from docarray import Document, DocumentArray\n+\n from jina import Client, Executor, Flow, requests\n from jina.clients.request import request_generator\n from jina.parsers import set_pod_parser\n@@ -370,6 +370,12 @@ def test_set_workspace(tmpdir):\n     with Flow().add(uses=WorkspaceExec, uses_metas={'workspace': str(tmpdir)}) as f:\n         resp = f.post(on='/foo', inputs=Document())\n     assert resp[0].text == complete_workspace\n+    complete_workspace_no_replicas = os.path.abspath(\n+        os.path.join(tmpdir, 'WorkspaceExec')\n+    )\n+    assert (\n+        WorkspaceExec(workspace=str(tmpdir)).workspace == complete_workspace_no_replicas\n+    )\n \n \n def test_default_workspace(tmpdir):\n\n\n###\n\n", "completion": "fix: set workspace in executor init method (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -220,6 +220,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14742,3 +14743,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```80393316```](https://github.com/jina-ai/jina/commit/803933169e57adf8bc17f4c0d723aaf5331f1658)] __-__ __version__: the next version will be 3.7.11 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-12></a>\n+## Release Note (`3.7.12`)\n+\n+> Release time: 2022-08-18 22:23:25\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ AlaeddineAbdessalem,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```6f87524c```](https://github.com/jina-ai/jina/commit/6f87524c5a9c2c3cf572d1bc1246709d6ef9b65d)] __-__ include jcloud cli (#5074) (*AlaeddineAbdessalem*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```10c63db2```](https://github.com/jina-ai/jina/commit/10c63db2067bd7f9512e16aadc3f6a41e25ede9f)] __-__ update pr template with reminder to add a description (#5062) (*Johannes Messner*)\n+ - [[```6fbd2be9```](https://github.com/jina-ai/jina/commit/6fbd2be9214339997d880c200a5a6a7b58418123)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```7d82fdc3```](https://github.com/jina-ai/jina/commit/7d82fdc3dc52b23305a23b155272108f57d26243)] __-__ __version__: the next version will be 3.7.12 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.12'\n+__version__ = '3.7.13'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.13"}
{"prompt": " file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -20,7 +20,8 @@ At this point, Jina Cloud hosts all your Jina projects and offers computational/\n \n ## Basic\n ### Install\n-\n+If you have {ref}`installed jina <swagger-ui>`, there is no need to install `jcloud` CLI. However, you still can \n+install the CLI individually:\n ```bash\n pip install jcloud\n jc -h\n@@ -30,6 +31,14 @@ jc -h\n In case `jc` is already occupied by another tool, please use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n ```\n \n+```{important}\n+You can use the `jcloud` CLI in 2 ways:\n+* If you installed it with `jina`, all of its commands come under the `jina cloud` command. Try `jina cloud --help` for \n+more info.\n+* If you installed it individually, all of its commands come under the `jc` or `jcloud` executable.\n+For the rest of this section, we will be using `jc` command rather than `jina cloud`.\n+```\n+\n ### Login\n \n ```bash\n\n---\n file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,8 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-jina-hubble-sdk==0.12.4:    core\n+jina-hubble-sdk>=0.13.0:    core\n+jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -229,23 +229,34 @@ def get_main_parser():\n         )\n     )\n \n+    from hubble.parsers import get_main_parser as get_hubble_parser\n+\n+    get_hubble_parser(\n+        sp.add_parser(\n+            'auth',\n+            description='Login to Jina AI with your GitHub/Google/Email account',\n+            formatter_class=_chf,\n+            help='Login to Jina AI',\n+        )\n+    )\n+\n     set_hub_parser(\n         sp.add_parser(\n             'hub',\n-            help='Push/pull an Executor to/from Jina Hub',\n+            help='Manage Executor on Jina Hub',\n             description='Push/Pull an Executor to/from Jina Hub',\n             formatter_class=_chf,\n         )\n     )\n \n-    from hubble.parsers import get_main_parser as get_hubble_parser\n+    from jcloud.parsers import get_main_parser as get_jcloud_parser\n \n-    get_hubble_parser(\n+    get_jcloud_parser(\n         sp.add_parser(\n-            'auth',\n-            description='Login to Jina AI with your GitHub/Google/Email account',\n+            'cloud',\n+            description='Manage Flows on Jina Cloud',\n             formatter_class=_chf,\n-            help='Login to Jina AI',\n+            help='Manage Flows on Jina Cloud',\n         )\n     )\n \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,8 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-jina-hubble-sdk==0.12.4:    core\n+jina-hubble-sdk>=0.13.0:    core\n+jcloud>=0.0.35:             core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n---\n file path A: jina_cli/__init__.py | file path B: jina_cli/__init__.py\n\n@@ -10,7 +10,7 @@ def _get_run_args(print_args: bool = True):\n \n     console = get_rich_console()\n \n-    silent_print = {'help', 'hub', 'export', 'auth'}\n+    silent_print = {'help', 'hub', 'export', 'auth', 'cloud'}\n \n     parser = get_main_parser()\n     if len(sys.argv) > 1:\n\n---\n file path A: jina_cli/api.py | file path B: jina_cli/api.py\n\n@@ -220,3 +220,13 @@ def auth(args: 'Namespace'):\n     from hubble import api\n \n     getattr(api, args.auth_cli.replace('-', '_'))(args)\n+\n+\n+def cloud(args: 'Namespace'):\n+    \"\"\"\n+    Use jcloud (Jina Cloud) commands\n+    :param args: arguments coming from the CLI.\n+    \"\"\"\n+    from jcloud import api\n+\n+    getattr(api, args.jc_cli.replace('-', '_'))(args)\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -10,8 +10,9 @@ ac_table = {\n         'export',\n         'new',\n         'gateway',\n-        'hub',\n         'auth',\n+        'hub',\n+        'cloud',\n         'help',\n         'pod',\n         'deployment',\n@@ -150,6 +151,13 @@ ac_table = {\n             '--retries',\n             '--floating',\n         ],\n+        'auth login': ['--help', '--force'],\n+        'auth logout': ['--help'],\n+        'auth token create': ['--help', '--expire'],\n+        'auth token delete': ['--help'],\n+        'auth token list': ['--help'],\n+        'auth token': ['--help', 'create', 'delete', 'list'],\n+        'auth': ['--help', 'login', 'logout', 'token'],\n         'hub new': [\n             '--help',\n             '--name',\n@@ -183,13 +191,27 @@ ac_table = {\n             '--force',\n         ],\n         'hub': ['--help', 'new', 'push', 'pull'],\n-        'auth login': ['--help', '--force'],\n-        'auth logout': ['--help'],\n-        'auth token create': ['--help', '--expire'],\n-        'auth token delete': ['--help'],\n-        'auth token list': ['--help'],\n-        'auth token': ['--help', 'create', 'delete', 'list'],\n-        'auth': ['--help', 'login', 'logout', 'token'],\n+        'cloud login': ['--help'],\n+        'cloud deploy': ['--help', '--name', '--workspace', '--env-file'],\n+        'cloud list': ['--help', '--status'],\n+        'cloud logs': ['--help', '--executor'],\n+        'cloud status': ['--help'],\n+        'cloud remove': ['--help'],\n+        'cloud new': ['--help'],\n+        'cloud survey': ['--help'],\n+        'cloud': [\n+            '--help',\n+            '--version',\n+            '--loglevel',\n+            'login',\n+            'deploy',\n+            'list',\n+            'logs',\n+            'status',\n+            'remove',\n+            'new',\n+            'survey',\n+        ],\n         'help': ['--help'],\n         'pod': [\n             '--help',\n\n\n###\n\n", "completion": "feat: include jcloud cli (#<issue-num>)"}
{"prompt": " file path A: .github/pull_request_template.md | file path B: .github/pull_request_template.md\n\n@@ -1,4 +1,13 @@\n-Goals:\n+<!---Decomposing the complex issue into subtasks can help you build it step-by-step. Thanks for your pull request! :rocket: --->\n+<!---We know that dev life is hectic, but **please provide a (brief) description** of what your PR does, and how it does it. **Otherwise, your PR cannot be reviewed!** --->\n+<!---This policy was agreed upon in a past company retro, and makes everyone's life a little easier. Thanks for your collaboration!--->\n+\n+**Goals:**\n+<!---https://docs.github.com/en/issues/tracking-your-work-with-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword--->\n+\n+- resolves #ISSUE-NUMBER\n+- ...\n+- ...\n \n - ...\n - ...\n\n\n###\n\n", "completion": "chore: update pr template with reminder to add a description (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -219,6 +219,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14720,3 +14721,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```bffe263c```](https://github.com/jina-ai/jina/commit/bffe263c40fa56a0e2b124296e3578cbd0173471)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```94c83cdb```](https://github.com/jina-ai/jina/commit/94c83cdb15110b05ba6c6bf1458927fd1e21b925)] __-__ __version__: the next version will be 3.7.10 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-11></a>\n+## Release Note (`3.7.11`)\n+\n+> Release time: 2022-08-17 21:09:48\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```15fd60d5```](https://github.com/jina-ai/jina/commit/15fd60d5eeffb42cfe4e679d0a4c81b2c06df1e4)] __-__ __cli__: jina auth cli error (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```80393316```](https://github.com/jina-ai/jina/commit/803933169e57adf8bc17f4c0d723aaf5331f1658)] __-__ __version__: the next version will be 3.7.11 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.11'\n+__version__ = '3.7.12'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-jina-hubble-sdk>=0.12.2:    core\n+jina-hubble-sdk==0.12.4:    core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.12"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-jina-hubble-sdk>=0.12.2:    core\n+jina-hubble-sdk==0.12.4:    core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n---\n file path A: jina_cli/api.py | file path B: jina_cli/api.py\n\n@@ -219,4 +219,4 @@ def auth(args: 'Namespace'):\n     \"\"\"\n     from hubble import api\n \n-    getattr(api, args.cli2.replace('-', '_'))(args)\n+    getattr(api, args.auth_cli.replace('-', '_'))(args)\n\n\n###\n\n", "completion": "fix(cli): jina auth cli error"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -218,6 +218,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14695,3 +14696,27 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```442a86cd```](https://github.com/jina-ai/jina/commit/442a86cdc6c942cb9f42a828b920d6cca70cf320)] __-__ __version__: the next version will be 3.7.9 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-10></a>\n+## Release Note (`3.7.10`)\n+\n+> Release time: 2022-08-17 12:22:49\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  tarrantro,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```b9bddd22```](https://github.com/jina-ai/jina/commit/b9bddd223b96c6f55de32b13dde1e3be3abab5dd)] __-__ __cli__: jina auth cli error (#5070) (*Han Xiao*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```840c221f```](https://github.com/jina-ai/jina/commit/840c221feaeaa0ea19c10d410dd39a7991c71372)] __-__ add gateway timeout and update shared gpu (#5069) (*tarrantro*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```bffe263c```](https://github.com/jina-ai/jina/commit/bffe263c40fa56a0e2b124296e3578cbd0173471)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```94c83cdb```](https://github.com/jina-ai/jina/commit/94c83cdb15110b05ba6c6bf1458927fd1e21b925)] __-__ __version__: the next version will be 3.7.10 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.10'\n+__version__ = '3.7.11'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.11"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-jina-hubble-sdk>=0.12.1:    core\n+jina-hubble-sdk>=0.12.2:    core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -238,6 +238,17 @@ def get_main_parser():\n         )\n     )\n \n+    from hubble.parsers import get_main_parser as get_hubble_parser\n+\n+    get_hubble_parser(\n+        sp.add_parser(\n+            'auth',\n+            description='Login to Jina AI with your GitHub/Google/Email account',\n+            formatter_class=_chf,\n+            help='Login to Jina AI',\n+        )\n+    )\n+\n     set_help_parser(\n         sp.add_parser(\n             'help',\n@@ -279,15 +290,4 @@ def get_main_parser():\n         )\n     )\n \n-    from hubble.parsers import get_main_parser as get_hubble_parser\n-\n-    get_hubble_parser(\n-        sp.add_parser(\n-            'auth',\n-            description='Login to Jina AI with your GitHub/Google/Email account',\n-            formatter_class=_chf,\n-            help='Login to Jina AI',\n-        )\n-    )\n-\n     return parser\n\n---\n file path A: jina/parsers/base.py | file path B: jina/parsers/base.py\n\n@@ -14,10 +14,10 @@ def set_base_parser():\n \n     # create the top-level parser\n     urls = {\n-        'Code': ('\ud83d\udcbb', 'https://github.com/jina-ai/jina'),\n+        'Code': ('\ud83d\udcbb', 'https://oss.jina.ai'),\n         'Docs': ('\ud83d\udcd6', 'https://docs.jina.ai'),\n         'Help': ('\ud83d\udcac', 'https://slack.jina.ai'),\n-        'Hiring!': ('\ud83d\ude4c', 'https://career.jina.ai'),\n+        'Hiring!': ('\ud83d\ude4c', 'https://jobs.jina.ai'),\n     }\n     url_str = '\\n'.join(\n         f'- {v[0]:<10} {k:10.10}\\t{colored(v[1], \"cyan\", attrs=[\"underline\"])}'\n@@ -26,7 +26,7 @@ def set_base_parser():\n \n     parser = argparse.ArgumentParser(\n         epilog=f'''\n-Jina (v{colored(__version__, \"green\")}) is the cloud-native neural search framework powered by deep learning.\n+Jina v{colored(__version__, \"green\")}: build cross-modal and multimodal applications on the cloud.\n \n {url_str}\n \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,7 +33,7 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-jina-hubble-sdk>=0.12.1:    core\n+jina-hubble-sdk>=0.12.2:    core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n---\n file path A: jina_cli/__init__.py | file path B: jina_cli/__init__.py\n\n@@ -10,7 +10,7 @@ def _get_run_args(print_args: bool = True):\n \n     console = get_rich_console()\n \n-    silent_print = {'help', 'hub', 'export'}\n+    silent_print = {'help', 'hub', 'export', 'auth'}\n \n     parser = get_main_parser()\n     if len(sys.argv) > 1:\n\n---\n file path A: jina_cli/api.py | file path B: jina_cli/api.py\n\n@@ -210,3 +210,13 @@ def help(args: 'Namespace'):\n     from jina_cli.lookup import lookup_and_print\n \n     lookup_and_print(args.query.lower())\n+\n+\n+def auth(args: 'Namespace'):\n+    \"\"\"\n+    Authenticate a user\n+    :param args: arguments coming from the CLI.\n+    \"\"\"\n+    from hubble import api\n+\n+    getattr(api, args.cli2.replace('-', '_'))(args)\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -11,11 +11,11 @@ ac_table = {\n         'new',\n         'gateway',\n         'hub',\n+        'auth',\n         'help',\n         'pod',\n         'deployment',\n         'client',\n-        'auth',\n     ],\n     'completions': {\n         'executor': [\n@@ -183,6 +183,13 @@ ac_table = {\n             '--force',\n         ],\n         'hub': ['--help', 'new', 'push', 'pull'],\n+        'auth login': ['--help', '--force'],\n+        'auth logout': ['--help'],\n+        'auth token create': ['--help', '--expire'],\n+        'auth token delete': ['--help'],\n+        'auth token list': ['--help'],\n+        'auth token': ['--help', 'create', 'delete', 'list'],\n+        'auth': ['--help', 'login', 'logout', 'token'],\n         'help': ['--help'],\n         'pod': [\n             '--help',\n@@ -306,12 +313,5 @@ ac_table = {\n             '--return-responses',\n             '--protocol',\n         ],\n-        'auth login': ['--help', '--force'],\n-        'auth logout': ['--help'],\n-        'auth token create': ['--help', '--expire'],\n-        'auth token delete': ['--help'],\n-        'auth token list': ['--help'],\n-        'auth token': ['--help', 'create', 'delete', 'list'],\n-        'auth': ['--help', 'login', 'logout', 'token'],\n     },\n }\n\n---\n file path A: tests/unit/test_cli.py | file path B: tests/unit/test_cli.py\n\n@@ -28,7 +28,7 @@ def test_help_lookup(cli, capsys):\n         assert cli in nkw2kw\n         lookup_and_print(cli)\n         captured = capsys.readouterr()\n-        assert captured.out\n+        assert 'Traceback (most recent call last)' not in captured.out\n \n \n def test_main_cli():\n\n\n###\n\n", "completion": "fix(cli): jina auth cli error (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -103,6 +103,21 @@ executors:\n     uses: jinahub+docker://Executor1\n ```\n \n+### Timeout\n+\n+By default, JCloud gateway will close connections that have been idle for over `600` seconds. If you want longer connection timeout threshold, you can consider changing the `timeout` parameter in `gateway`.\n+\n+```yaml\n+jtype: Flow\n+jcloud:\n+  gateway:\n+    ingress: kong\n+    timeout: 600\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+```\n+\n (retention-days)=\n ## Retention days\n \n\n---\n file path A: docs/fundamentals/jcloud/resources.md | file path B: docs/fundamentals/jcloud/resources.md\n\n@@ -95,7 +95,7 @@ When using GPU resources, it may take few extra mins until all Executors ready t\n \n ##### Shared\n \n-An executor using a `shared` GPU shares this GPU with up to 10 other Executors.\n+An executor using a `shared` GPU shares this GPU with up to 4 other Executors.\n This enables a time-slicing, which allows workloads that land on oversubscribed GPUs to interleave with one another.\n \n ```yaml\n@@ -108,6 +108,10 @@ executors:\n         gpu: shared\n ```\n \n+```{note}\n+When using shared GPU resources, it will share the GPU memory across pods(24G memory total). If your application is memory consuming, we suggest using a dedicated GPU.\n+```\n+\n ```{caution}\n There are no special provisions in place to isolate replicas that run on the same underlying GPU. Each workload has access to the GPU memory and runs in the same fault-domain as of all the others. Therefore, if one workload crashes, they all do. \n ```\n\n\n###\n\n", "completion": "docs: add gateway timeout and update shared gpu (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -217,6 +217,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14669,3 +14670,26 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```dfd1e07d```](https://github.com/jina-ai/jina/commit/dfd1e07dcce56f2b7d7de6310d120337a9e9b58c)] __-__ __docs__: fix typos (*Han Xiao*)\n  - [[```d579cb63```](https://github.com/jina-ai/jina/commit/d579cb63f7ee5d49952c8e77491ff30b5f74a6d8)] __-__ __version__: the next version will be 3.7.8 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-9></a>\n+## Release Note (`3.7.9`)\n+\n+> Release time: 2022-08-16 16:25:11\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  AlaeddineAbdessalem,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```26d24d03```](https://github.com/jina-ai/jina/commit/26d24d0374eaad95d16f949cf05b3be95916395a)] __-__ #5055 (#5066) (*Han Xiao*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```c1c500aa```](https://github.com/jina-ai/jina/commit/c1c500aadd9a33f64b19cd881740cc9c5ee6e6a5)] __-__ remove unused hub environment variables (#5067) (*AlaeddineAbdessalem*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```442a86cd```](https://github.com/jina-ai/jina/commit/442a86cdc6c942cb9f42a828b920d6cca70cf320)] __-__ __version__: the next version will be 3.7.9 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.9'\n+__version__ = '3.7.10'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.10"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1098,8 +1098,8 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         \"\"\"\n         # implementation_stub_inject_end_add\n \n-        needs = kwargs.get('needs', None)\n-        copy_flow = kwargs.get('copy_flow', True)\n+        needs = kwargs.pop('needs', None)\n+        copy_flow = kwargs.pop('copy_flow', True)\n         deployment_role = kwargs.get('deployment_role', DeploymentRoleType.DEPLOYMENT)\n \n         op_flow = copy.deepcopy(self) if copy_flow else self\n\n---\n file path A: jina/resources/logging.default.yml | file path B: jina/resources/logging.default.yml\n\n@@ -16,8 +16,8 @@ configs:\n     port: # when not given then record it locally,  /dev/log on linux /var/run/syslog on mac\n     formatter: PlainFormatter\n   RichHandler:\n-    format: '[dim]{name}@%(process)2d[/dim] %(message)s'\n-    markup: true\n+    format: '{name}@%(process)2d %(message)s'\n+    markup: false\n     rich_tracebacks: true\n     show_path: false\n     log_time_format: '[%x %X]'\n\\ No newline at end of file\n\n---\n file path A: jina/resources/logging.docker.yml | file path B: jina/resources/logging.docker.yml\n\n@@ -17,7 +17,7 @@ configs:\n     formatter: PlainFormatter\n   RichHandler:\n     format: '\ud83d\udc33 %(message)s'\n-    markup: true\n+    markup: false\n     show_path: false\n     show_level: false\n     show_time: false\n\\ No newline at end of file\n\n\n###\n\n", "completion": "fix: #5055 (#<issue-num>)"}
{"prompt": " file path A: docs/envs/index.md | file path B: docs/envs/index.md\n\n@@ -61,8 +61,6 @@ The following environment variables are used internally in Jina:\n | `JINA_GRPC_RECV_BYTES`          | Set by the grpc service to keep track of the received bytes                                                    |\n | `JINA_GRPC_SEND_BYTES`          | Set by the grpc service to keep track of the sent bytes                                                        |\n | `JINA_HUBBLE_REGISTRY`          | Set it to point to a different Jina Hub registry                                                               |\n-| `JINA_HUB_CACHE_DIR`            | The directory where hub will cache its executors inside JINA_HUB_ROOT                                          |\n-| `JINA_HUB_ROOT`                 | The base directory for HubIO to store and read files                                                           |\n | `JINA_LOG_CONFIG`               | The configuration used for the logger                                                                          |\n | `JINA_LOG_LEVEL`                | The logging level used: INFO, DEBUG, WARNING                                                                   |\n | `JINA_LOG_NO_COLOR`             | If set, disables color from rich console                                                                       |\n\n---\n file path A: docs/fundamentals/executor/hub/index.md | file path B: docs/fundamentals/executor/hub/index.md\n\n@@ -46,24 +46,6 @@ The Hub architecture looks like the following:\n :align: center\n ```\n \n-## Environment Variables\n-\n-A list of environment variables which takes effects during Jina Hub operations. e.g. `jina hub push`\n-\n-### `JINA_HUB_ROOT`\n-\n-**Define the place where the Executor package cache lives.** Default value is `~/.jina/hub-packages`\n-\n-````{admonition} Hint\n-:class: hint\n-You don't have permissions to create a directory in the home folder sometime. This is the right time to change the value.\n-````\n-\n-### `JINA_HUB_CACHE_DIR`\n-\n-**Define the place where the cache is stored during the downloading.** The cache will be deleted after downloading. Default value is `${JINA_HUB_ROOT}/.cache`.\n-\n-\n ```{toctree}\n :hidden:\n \n\n---\n file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -347,9 +347,7 @@ The error-free output below signifies a correctly running Gateway:\n     \"JINA_GRPC_RECV_BYTES\": \"(unset)\",\n     \"JINA_GRPC_SEND_BYTES\": \"(unset)\",\n     \"JINA_HUBBLE_REGISTRY\": \"(unset)\",\n-    \"JINA_HUB_CACHE_DIR\": \"(unset)\",\n     \"JINA_HUB_NO_IMAGE_REBUILD\": \"(unset)\",\n-    \"JINA_HUB_ROOT\": \"(unset)\",\n     \"JINA_LOCKS_ROOT\": \"(unset)\",\n     \"JINA_LOG_CONFIG\": \"(unset)\",\n     \"JINA_LOG_LEVEL\": \"(unset)\",\n@@ -374,7 +372,7 @@ curl http://localhost:12345/status\n ```\n \n ```json\n-{\"jina\":{\"jina\":\"######\",\"docarray\":\"######\",\"jina-proto\":\"######\",\"jina-vcs-tag\":\"(unset)\",\"protobuf\":\"######\",\"proto-backend\":\"######\",\"grpcio\":\"######\",\"pyyaml\":\"######\",\"python\":\"######\",\"platform\":\"######\",\"platform-release\":\"######\",\"platform-version\":\"######\",\"architecture\":\"######\",\"processor\":\"######\",\"uid\":\"######\",\"session-id\":\"######\",\"uptime\":\"######\",\"ci-vendor\":\"(unset)\"},\"envs\":{\"JINA_AUTH_TOKEN\":\"(unset)\",\"JINA_DEFAULT_HOST\":\"(unset)\",\"JINA_DEFAULT_TIMEOUT_CTRL\":\"(unset)\",\"JINA_DEFAULT_WORKSPACE_BASE\":\"######\",\"JINA_DEPLOYMENT_NAME\":\"(unset)\",\"JINA_DISABLE_UVLOOP\":\"(unset)\",\"JINA_EARLY_STOP\":\"(unset)\",\"JINA_FULL_CLI\":\"(unset)\",\"JINA_GATEWAY_IMAGE\":\"(unset)\",\"JINA_GRPC_RECV_BYTES\":\"(unset)\",\"JINA_GRPC_SEND_BYTES\":\"(unset)\",\"JINA_HUBBLE_REGISTRY\":\"(unset)\",\"JINA_HUB_CACHE_DIR\":\"(unset)\",\"JINA_HUB_NO_IMAGE_REBUILD\":\"(unset)\",\"JINA_HUB_ROOT\":\"(unset)\",\"JINA_LOG_CONFIG\":\"(unset)\",\"JINA_LOG_LEVEL\":\"(unset)\",\"JINA_LOG_NO_COLOR\":\"(unset)\",\"JINA_MP_START_METHOD\":\"(unset)\",\"JINA_RANDOM_PORT_MAX\":\"(unset)\",\"JINA_RANDOM_PORT_MIN\":\"(unset)\",\"JINA_DISABLE_HEALTHCHECK_LOGS\":\"(unset)\",\"JINA_LOCKS_ROOT\":\"(unset)\"}}\n+{\"jina\":{\"jina\":\"######\",\"docarray\":\"######\",\"jina-proto\":\"######\",\"jina-vcs-tag\":\"(unset)\",\"protobuf\":\"######\",\"proto-backend\":\"######\",\"grpcio\":\"######\",\"pyyaml\":\"######\",\"python\":\"######\",\"platform\":\"######\",\"platform-release\":\"######\",\"platform-version\":\"######\",\"architecture\":\"######\",\"processor\":\"######\",\"uid\":\"######\",\"session-id\":\"######\",\"uptime\":\"######\",\"ci-vendor\":\"(unset)\"},\"envs\":{\"JINA_AUTH_TOKEN\":\"(unset)\",\"JINA_DEFAULT_HOST\":\"(unset)\",\"JINA_DEFAULT_TIMEOUT_CTRL\":\"(unset)\",\"JINA_DEFAULT_WORKSPACE_BASE\":\"######\",\"JINA_DEPLOYMENT_NAME\":\"(unset)\",\"JINA_DISABLE_UVLOOP\":\"(unset)\",\"JINA_EARLY_STOP\":\"(unset)\",\"JINA_FULL_CLI\":\"(unset)\",\"JINA_GATEWAY_IMAGE\":\"(unset)\",\"JINA_GRPC_RECV_BYTES\":\"(unset)\",\"JINA_GRPC_SEND_BYTES\":\"(unset)\",\"JINA_HUBBLE_REGISTRY\":\"(unset)\",\"JINA_HUB_NO_IMAGE_REBUILD\":\"(unset)\",\"JINA_LOG_CONFIG\":\"(unset)\",\"JINA_LOG_LEVEL\":\"(unset)\",\"JINA_LOG_NO_COLOR\":\"(unset)\",\"JINA_MP_START_METHOD\":\"(unset)\",\"JINA_RANDOM_PORT_MAX\":\"(unset)\",\"JINA_RANDOM_PORT_MIN\":\"(unset)\",\"JINA_DISABLE_HEALTHCHECK_LOGS\":\"(unset)\",\"JINA_LOCKS_ROOT\":\"(unset)\"}}\n ```\n \n (server-compress)=\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -97,9 +97,7 @@ __jina_env__ = (\n     'JINA_GRPC_RECV_BYTES',\n     'JINA_GRPC_SEND_BYTES',\n     'JINA_HUBBLE_REGISTRY',\n-    'JINA_HUB_CACHE_DIR',\n     'JINA_HUB_NO_IMAGE_REBUILD',\n-    'JINA_HUB_ROOT',\n     'JINA_LOG_CONFIG',\n     'JINA_LOG_LEVEL',\n     'JINA_LOG_NO_COLOR',\n\n---\n file path A: tests/conftest.py | file path B: tests/conftest.py\n\n@@ -54,15 +54,6 @@ def port_generator():\n     return random_port\n \n \n-@pytest.fixture(scope='function')\n-def test_envs(tmpdir):\n-    os.environ['JINA_HUB_ROOT'] = str(tmpdir)\n-    os.environ['JINA_HUB_CACHE_DIR'] = str(tmpdir)\n-    yield None\n-    del os.environ['JINA_HUB_ROOT']\n-    del os.environ['JINA_HUB_CACHE_DIR']\n-\n-\n @pytest.fixture(autouse=True)\n def test_log_level(monkeypatch):\n     monkeypatch.setenv('JINA_LOG_LEVEL', 'DEBUG')\n\n---\n file path A: tests/integration/hub_usage/test_hub_usage.py | file path B: tests/integration/hub_usage/test_hub_usage.py\n\n@@ -49,11 +49,9 @@ def test_use_from_local_dir_flow_level():\n \n \n @pytest.fixture\n-def local_hub_executor(tmpdir, test_envs):\n+def local_hub_executor(tmpdir):\n     from jina.hubble import HubExecutor, helper, hubapi\n \n-    hubapi._hub_root = Path(os.environ.get('JINA_HUB_ROOT'))\n-\n     pkg_path = Path(__file__).parent / 'dummyhub'\n     stream_data = helper.archive_package(pkg_path)\n     with open(tmpdir / 'dummy_test.zip', 'wb') as temp_zip_file:\n@@ -65,7 +63,7 @@ def local_hub_executor(tmpdir, test_envs):\n \n \n def test_use_from_local_hub_deployment_level(\n-    test_envs, mocker, monkeypatch, local_hub_executor\n+    mocker, monkeypatch, local_hub_executor\n ):\n     from jina.hubble.hubio import HubExecutor, HubIO\n \n@@ -100,7 +98,7 @@ def test_use_from_local_hub_deployment_level(\n \n \n def test_use_from_local_hub_flow_level(\n-    test_envs, mocker, monkeypatch, local_hub_executor\n+    mocker, monkeypatch, local_hub_executor\n ):\n     from jina.hubble.hubio import HubExecutor, HubIO\n \n\n---\n file path A: tests/unit/hubble/test_hubapi.py | file path B: tests/unit/hubble/test_hubapi.py\n\n@@ -20,7 +20,7 @@ def test_executor():\n \n \n @pytest.mark.parametrize('install_deps', [True, False])\n-def test_install_local(test_envs, executor_zip_file, test_executor, install_deps):\n+def test_install_local(executor_zip_file, test_executor, install_deps):\n     assert not hubapi.exist_local(test_executor.uuid, test_executor.tag)\n     hubapi.install_local(executor_zip_file, test_executor, install_deps=install_deps)\n     assert hubapi.exist_local(test_executor.uuid, test_executor.tag)\n@@ -35,7 +35,7 @@ def test_install_local(test_envs, executor_zip_file, test_executor, install_deps\n     assert not hubapi.exist_local(test_executor.uuid, test_executor.tag)\n \n \n-def test_load_dump_secret(test_envs):\n+def test_load_dump_secret():\n     import tempfile\n \n     uuid8 = 'hello'\n@@ -47,7 +47,7 @@ def test_load_dump_secret(test_envs):\n     assert new_secret == secret\n \n \n-def test_load_dump_secret_existing_encryption_key(test_envs):\n+def test_load_dump_secret_existing_encryption_key():\n     import tempfile\n \n     uuid8 = 'hello'\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -572,7 +572,7 @@ class DownloadMockResponse:\n \n @pytest.mark.parametrize('executor_name', ['alias_dummy', None])\n @pytest.mark.parametrize('build_env', [['DOWNLOAD', 'DOMAIN'], None])\n-def test_pull(test_envs, mocker, monkeypatch, executor_name, build_env):\n+def test_pull(mocker, monkeypatch, executor_name, build_env):\n     mock = mocker.Mock()\n \n     def _mock_fetch(\n@@ -644,7 +644,7 @@ class MockDockerClient:\n             yield {}\n \n \n-def test_offline_pull(test_envs, mocker, monkeypatch, tmpfile):\n+def test_offline_pull(mocker, monkeypatch, tmpfile):\n     mock = mocker.Mock()\n \n     fail_meta_fetch = True\n\n\n###\n\n", "completion": "refactor: remove unused hub environment variables (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -216,6 +216,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14642,3 +14643,29 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```e7377947```](https://github.com/jina-ai/jina/commit/e7377947482c8d32b1aed0aee24a8efa14b33826)] __-__ __docs__: fix typos (*Han Xiao*)\n  - [[```6d218fbf```](https://github.com/jina-ai/jina/commit/6d218fbfa060226487174208ded10844b0ed28d2)] __-__ __version__: the next version will be 3.7.7 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-8></a>\n+## Release Note (`3.7.8`)\n+\n+> Release time: 2022-08-16 15:18:50\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  Zac Li,  \ud83d\ude47\n+\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```bf864748```](https://github.com/jina-ai/jina/commit/bf86474887ec0540c2d314a9f5b5aff514bbf04c)] __-__ __hub__: use hubble sdk (#5064) (*Han Xiao*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```317e9ce1```](https://github.com/jina-ai/jina/commit/317e9ce167025da15f11e34fc3694f5aa7cf1a0e)] __-__ __jcloud__: doc for gateway customization (#5065) (*Zac Li*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```a6be9481```](https://github.com/jina-ai/jina/commit/a6be9481ffee3e2a23015ec17b3da0d725667120)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```f3bcdaa8```](https://github.com/jina-ai/jina/commit/f3bcdaa8e6cebccd995a6fc627d38f36f64cb380)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```dfd1e07d```](https://github.com/jina-ai/jina/commit/dfd1e07dcce56f2b7d7de6310d120337a9e9b58c)] __-__ __docs__: fix typos (*Han Xiao*)\n+ - [[```d579cb63```](https://github.com/jina-ai/jina/commit/d579cb63f7ee5d49952c8e77491ff30b5f74a6d8)] __-__ __version__: the next version will be 3.7.8 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.8'\n+__version__ = '3.7.9'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.9"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,6 +33,7 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n+jina-hubble-sdk>=0.12.1:    core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n---\n file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -2,7 +2,6 @@\n \n import hashlib\n import io\n-import json\n import os\n import shelve\n import subprocess\n@@ -15,7 +14,7 @@ from contextlib import nullcontext\n from functools import lru_cache, wraps\n from pathlib import Path\n from typing import Dict, Optional, Tuple\n-from urllib.parse import urljoin, urlparse\n+from urllib.parse import urlparse\n \n from jina import __cache_path__, __resources_path__\n from jina.enums import BetterEnum\n@@ -30,33 +29,13 @@ from jina.importer import ImportExtensions\n from jina.logging.predefined import default_logger\n \n \n-@lru_cache()\n-def _get_hub_root() -> Path:\n-    hub_root = Path(os.environ.get('JINA_HUB_ROOT', __cache_path__))\n-\n-    if not hub_root.exists():\n-        hub_root.mkdir(parents=True, exist_ok=True)\n-\n-    return hub_root\n-\n-\n-@lru_cache()\n-def _get_hub_config() -> Optional[Dict]:\n-    hub_root = _get_hub_root()\n-\n-    config_file = hub_root.joinpath('config.json')\n-    if config_file.exists():\n-        with open(config_file) as f:\n-            return json.load(f)\n-\n-\n @lru_cache()\n def get_hub_packages_dir() -> Path:\n     \"\"\"Get the path of folder where the hub packages are stored\n \n     :return: the path of folder where the hub packages are stored\n     \"\"\"\n-    root = _get_hub_root()\n+    root = Path(__cache_path__)\n     hub_packages = root.joinpath('hub-package')\n \n     if not hub_packages.exists():\n@@ -71,7 +50,7 @@ def get_cache_db() -> Path:\n \n     :return: the path of cache db of hub Executors\n     \"\"\"\n-    root = _get_hub_root()\n+    root = Path(__cache_path__)\n     cache_db = root.joinpath('disk_cache.db')\n \n     return cache_db\n@@ -83,13 +62,7 @@ def get_download_cache_dir() -> Path:\n \n     :return: the path of cache folder where the downloading cache is stored\n     \"\"\"\n-    root = _get_hub_root()\n-    cache_dir = Path(\n-        os.environ.get(\n-            'JINA_HUB_CACHE_DIR',\n-            root.joinpath('.cache'),\n-        )\n-    )\n+    cache_dir = Path(__cache_path__)\n \n     if not cache_dir.exists():\n         cache_dir.mkdir(parents=True, exist_ok=True)\n@@ -97,64 +70,21 @@ def get_download_cache_dir() -> Path:\n     return cache_dir\n \n \n-@lru_cache()\n-def _get_hubble_base_url() -> str:\n-    \"\"\"Get base Hubble Url from os.environ or constants\n-\n-    :return: base Hubble Url\n-    \"\"\"\n-    return os.environ.get('JINA_HUBBLE_REGISTRY', 'https://api.hubble.jina.ai')\n-\n-\n-@lru_cache()\n-def _get_auth_token() -> Optional[str]:\n-    \"\"\"Get user auth token.\n-    .. note:: We first check `JINA_AUTH_TOKEN` environment variable.\n-        if token is not None, use env token. Otherwise, we get token from config.\n-\n-    :return: user auth token\n-    \"\"\"\n-    token_from_env = os.environ.get('JINA_AUTH_TOKEN')\n-    if token_from_env:\n-        return token_from_env\n-\n-    config = _get_hub_config()\n-    if config:\n-        return config.get('auth_token')\n-\n-\n def get_request_header() -> Dict:\n     \"\"\"Return the header of request with an authorization token.\n \n     :return: request header\n     \"\"\"\n     headers = _get_request_header_main()\n+    import hubble\n \n-    auth_token = _get_auth_token()\n+    auth_token = hubble.get_token()\n     if auth_token:\n         headers['Authorization'] = f'token {auth_token}'\n \n     return headers\n \n \n-def get_hubble_url_v1() -> str:\n-    \"\"\"Get v1 Hubble Url\n-\n-    :return: v1 Hubble url\n-    \"\"\"\n-    u = _get_hubble_base_url()\n-    return urljoin(u, '/v1')\n-\n-\n-def get_hubble_url_v2() -> str:\n-    \"\"\"Get v2 Hubble Url\n-\n-    :return: v2 Hubble url\n-    \"\"\"\n-    u = _get_hubble_base_url()\n-    return urljoin(u, '/v2')\n-\n-\n def parse_hub_uri(uri_path: str) -> Tuple[str, str, str, str]:\n     \"\"\"Parse the uri of the Jina Hub executor.\n \n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -8,6 +8,9 @@ import os\n import random\n from pathlib import Path\n from typing import Dict, Optional, Union\n+from urllib.parse import urljoin\n+\n+import hubble\n \n from jina import __resources_path__, __version__\n from jina.helper import ArgNamespace, get_rich_console, retry\n@@ -20,7 +23,6 @@ from jina.hubble.helper import (\n     get_cache_db,\n     get_download_cache_dir,\n     get_hubble_error_message,\n-    get_hubble_url_v2,\n     get_request_header,\n     get_requirements_env_variables,\n     parse_hub_uri,\n@@ -442,9 +444,9 @@ metas:\n \n                 st.update(f'Connecting to Jina Hub ...')\n                 if form_data.get('id'):\n-                    hubble_url = get_hubble_url_v2() + '/rpc/executor.update'\n+                    hubble_url = urljoin(hubble.utils.get_base_url(), 'executor.update')\n                 else:\n-                    hubble_url = get_hubble_url_v2() + '/rpc/executor.create'\n+                    hubble_url = urljoin(hubble.utils.get_base_url(), 'executor.create')\n \n                 # upload the archived executor to Jina Hub\n                 st.update(f'Uploading...')\n@@ -619,7 +621,6 @@ metas:\n     def _prettyprint_build_env_usage(self, console, build_env, usage_kind=None):\n         from rich import box\n         from rich.panel import Panel\n-        from rich.syntax import Syntax\n         from rich.table import Table\n \n         param_str = Table(\n@@ -679,7 +680,7 @@ metas:\n \n             return resp\n \n-        pull_url = get_hubble_url_v2() + f'/rpc/executor.getPackage'\n+        pull_url = urljoin(hubble.utils.get_base_url(), 'executor.getPackage')\n \n         payload = {'id': name, 'include': ['code'], 'rebuildImage': rebuild_image}\n         if image_required:\n@@ -744,7 +745,7 @@ metas:\n         port = None\n \n         json_response = requests.post(\n-            url=get_hubble_url_v2() + '/rpc/sandbox.get',\n+            url=urljoin(hubble.utils.get_base_url(), 'sandbox.get'),\n             json=payload,\n             headers=get_request_header(),\n         ).json()\n@@ -761,7 +762,7 @@ metas:\n         ):\n             try:\n                 json_response = requests.post(\n-                    url=get_hubble_url_v2() + '/rpc/sandbox.create',\n+                    url=urljoin(hubble.utils.get_base_url(), 'sandbox.create'),\n                     json=payload,\n                     headers=get_request_header(),\n                 ).json()\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -279,4 +279,15 @@ def get_main_parser():\n         )\n     )\n \n+    from hubble.parsers import get_main_parser as get_hubble_parser\n+\n+    get_hubble_parser(\n+        sp.add_parser(\n+            'auth',\n+            description='Login to Jina AI with your GitHub/Google/Email account',\n+            formatter_class=_chf,\n+            help='Login to Jina AI',\n+        )\n+    )\n+\n     return parser\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,6 +33,7 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n+jina-hubble-sdk>=0.12.1:    core\n uvloop:                     perf,standard,devel\n prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -15,6 +15,7 @@ ac_table = {\n         'pod',\n         'deployment',\n         'client',\n+        'auth',\n     ],\n     'completions': {\n         'executor': [\n@@ -305,5 +306,12 @@ ac_table = {\n             '--return-responses',\n             '--protocol',\n         ],\n+        'auth login': ['--help', '--force'],\n+        'auth logout': ['--help'],\n+        'auth token create': ['--help', '--expire'],\n+        'auth token delete': ['--help'],\n+        'auth token list': ['--help'],\n+        'auth token': ['--help', 'create', 'delete', 'list'],\n+        'auth': ['--help', 'login', 'logout', 'token'],\n     },\n }\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -13,14 +13,7 @@ import pytest\n import requests\n import yaml\n \n-from jina.hubble import hubio\n-from jina.hubble.helper import (\n-    _get_auth_token,\n-    _get_hub_config,\n-    _get_hub_root,\n-    disk_cache_offline,\n-    get_requirements_env_variables,\n-)\n+from jina.hubble.helper import disk_cache_offline, get_requirements_env_variables\n from jina.hubble.hubapi import get_secret_path\n from jina.hubble.hubio import HubExecutor, HubIO\n from jina.parsers.hubble import (\n@@ -32,25 +25,15 @@ from jina.parsers.hubble import (\n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n \n-def clear_function_caches():\n-    _get_auth_token.cache_clear()\n-    _get_hub_root.cache_clear()\n-    _get_hub_config.cache_clear()\n-\n-\n @pytest.fixture(scope='function')\n def auth_token(tmpdir):\n-    clear_function_caches()\n-    os.environ['JINA_HUB_ROOT'] = str(tmpdir)\n+    from hubble.utils.config import Config\n \n+    c = Config()\n     token = 'test-auth-token'\n-    with open(tmpdir / 'config.json', 'w') as f:\n-        json.dump({'auth_token': token}, f)\n-\n+    c.set('auth_token', token)\n     yield token\n-\n-    clear_function_caches()\n-    del os.environ['JINA_HUB_ROOT']\n+    c.delete('auth_token')\n \n \n class PostMockResponse:\n\n---\n file path A: tests/unit/test_helper.py | file path B: tests/unit/test_helper.py\n\n@@ -23,7 +23,6 @@ from jina.helper import (\n     retry,\n     run_async,\n )\n-from jina.hubble.helper import _get_hubble_base_url\n from jina.jaml.helper import complete_path\n from jina.logging.predefined import default_logger\n from jina.proto import jina_pb2\n@@ -302,11 +301,6 @@ def test_ci_vendor():\n     assert get_ci_vendor() == 'GITHUB_ACTIONS'\n \n \n-def test_get_hubble_base_url():\n-    for j in range(2):\n-        assert _get_hubble_base_url().startswith('http')\n-\n-\n def test_retry():\n     class TryMe:\n         def __init__(self, fail_count: int) -> None:\n\n\n###\n\n", "completion": "refactor(hub): use hubble sdk (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -91,13 +91,13 @@ Currently ALB is the default gateway for backward compatibility. We use AWS prov\n \n ### Kong\n \n-Kong is the recommended gateway in JCloud. We use [Let's Encrypt](https://letsencrypt.org/) for TLS with Kong. To enable Kong Gateway instead of ALB, specify the gateway kind as `kong` in your JCloud YAML:\n+Kong is the recommended gateway in JCloud. We use [Let's Encrypt](https://letsencrypt.org/) for TLS with Kong. To enable Kong Gateway instead of ALB, specify the gateway ingress kind as `kong` in your JCloud YAML:\n \n ```yaml\n jtype: Flow\n jcloud:\n   gateway:\n-    kind: kong\n+    ingress: kong\n executors:\n   - name: executor1\n     uses: jinahub+docker://Executor1\n\n---\n file path A: docs/fundamentals/jcloud/resources.md | file path B: docs/fundamentals/jcloud/resources.md\n\n@@ -149,3 +149,20 @@ executors:\n         memory: 8G\n         gpu: 2\n ```\n+\n+### Resources in Gateway\n+\n+If in special conditions you'd like to customize the Gateway's CPU or memory, that's possible too. Similarly, `memory` / `cpu` arg needs to be specificed under `resources` from `gateway`.\n+\n+```yaml\n+jtype: Flow\n+jcloud:\n+  gateway:\n+    resources:\n+      requests:\n+        memory: 800M\n+        cpu: 0.4\n+executors:\n+  - name: encoder\n+    uses: jinahub+docker://Encoder\n+```\n\n\n###\n\n", "completion": "docs(jcloud): doc for gateway customization (#<issue-num>)"}
{"prompt": " file path A: docs/index.md | file path B: docs/index.md\n\n@@ -60,8 +60,8 @@ If you'd like to opt out of usage statistics, make sure to add the `--optout-tel\n :caption: Get Started\n :hidden:\n \n-get-started/what-is\n-get-started/why-jina\n+get-started/what-is-cross-modal-multi-modal\n+get-started/what-is-jina\n fundamentals/architecture-overview\n get-started/install/index\n get-started/create-app\n\n---\n file path A: docs/get-started/what-is-jina.md | file path B: docs/get-started/what-is-jina.md\n\n@@ -1,14 +1,14 @@\n (what-is-jina)=\n # What is Jina?\n \n-Jina is the framework for helping you build cross-modal and multi-modal applications on the cloud. With Jina, developers can easily build high performant cloud native applications or services in production. But at this point, you are not buying those campaign words. That's okay and that's what this chapter is about: to tell you what Jina is and to convince you about it.\n+Jina is the framework for helping you to build cross-modal and multi-modal systems on the cloud. With Jina, developers can easily build high performant cloud native applications, services and systems in production. But at this point, you are not buying those campaign words. That's okay and that's what this chapter is about: to tell you what Jina is and to convince you about it.\n \n-In the {ref}`last chapter<intro-cm>`, you already learned cross-modal and multi-modal from the machine learning perspective. This chapter will talk more from the system and engineering side. Let's start with an example and understand why Jina is needed.\n+In the {ref}`last chapter<intro-cm>`, you already learned the idea of cross-modal and multi-modal from the machine learning perspective. This chapter will talk more from the system and engineering side. Let's start with an example and understand why Jina is needed.\n \n (motivate-example)=\n ## Motivation example\n \n-Why do we need Jina? Let's first see an example: an example that describes a life without Jina.\n+Why do you need Jina? Let's first see an example that describes a life without Jina.\n \n Imagine you are a **machine learning engineer** whose task is to build a shop-the-look service for an e-commerce company, i.e. allowing users to upload a photo and search visually similar items from the stock. Sounds cool and deep learning related, exactly what your expertise is, so let's get started.\n \n@@ -20,25 +20,25 @@ The indexing part is to create a visual representation of all the stock items. I\n \n The search part is to take a user-uploaded photo and find the visually similar items from stock. You first need to extract features from the user-uploaded photo using a convolutional neural network. Then, you can use the similarity metric to find the visually similar items from the stock. The similarity metric could be cosine similarity.\n \n-At this point, you need a deep learning framework such as PyTorch, some key-value database such as MongoDB, and possibly some vector search engine such as FAISS or Elasticsearch. As a machine learning engineer, you are probably most familiar with PyTorch. But you are smart and full of energy so nothing you can't learn. You easily glue them together.\n+At this point, you need a deep learning framework such as PyTorch, some key-value database such as MongoDB, and possibly some vector search engine such as FAISS or Elasticsearch. As a machine learning engineer, you are mostly familiar with PyTorch and prototyping. You are smart and full of energy so nothing you can't learn. You easily glue them together as the first _proof of concept_ (POC).\n \n ### As a service\n \n-Are we done? Not quite yet. Instead of some Python functions, your goal is to make it as a web service so that its IO goes through network. To do that, you need to _refactor_ the above logic in some web framework with some API so that it can be called by other services.\n+Are we done? We just start. Instead of some Python functions, your goal is to make it as a web service so that its IO goes through network. To do that, you need to _refactor_ the above logic in some web framework with some API so that it can be called by other services.\n \n There are many ways to do this, one example would be to use the Django web framework. You would create an endpoint that accepts user-uploaded photos, then use the above logic to find the visually similar items from stock. Finally, you would return the results to the user in the form of a JSON object.\n \n-At this point, you learned few new things such as REST API, web service, web framework, which seems to go beyond your scope of a \"machine learning engineer\". You started to wonder whether it is worth it to learn them. But you are a machine learning **engineer** after all, so you decided to learn. But deep down you feel that your engineering may not be sufficient to make it into production. After some time, you managed to glue everything together.\n+At this point, you learned a few new things such as REST API, web service, web framework, which seems to go beyond your scope of a \"machine learning engineer\". You started to wonder whether it is worth it to learn them. But a machine learning **engineer** is an engineer after all, and learning new things is always good. But deep down you feel that your engineering may not be sufficient to make it into production. After some time, you managed to glue everything together.\n \n ### Deployment\n \n-Product team is impressed by the progress and asks you to deploy it on AWS to serve some real traffic. You encountered many problems while migrating from local to the cloud, mostly because of dependencies issues, CUDA driver and GPU issues. You finally solved all of them by wrapping everything in a 30GB Docker image. It is a _big_ monolith container, but it is easy to deploy and manage for you. \n+The product team is impressed by the progress and asks you to deploy it on AWS to serve some real traffic. This is exciting because it means your POC will face the public and have real users. You encountered many problems while migrating from local to the cloud, mostly because of dependencies issues, CUDA driver and GPU issues. You finally solved all of them by wrapping everything in a 30GB Docker image. It is a _big_ monolith container, but it is easy to deploy and manage for you. \n \n ### Scalability and performance\n \n-Are we done now? Still not quite yet. The product team wants to ensure certain scalability of the service in practice, meaning that the feature extraction should be parallelized and concurrent user requests should be handled without lagging. Certain QPS (query per second) is required from the product team.\n+Are we done now? Not yet. The product team wants to ensure certain scalability of the service in practice, meaning that the feature extraction should be parallelized and concurrent user requests should be handled without lagging. Certain QPS (query per second) is required from the product team.\n \n-You tried with straightforward `multiprocessing` or `threading`, but nothing works out of the box with your deep learning stacks. You decided to learn more high-performance computing frameworks such as Dask or Ray and try to adopt them. After some trial and error, you finally glued everything together and made them work. At this point you feel exhausted as it diverges too far from your expertise. \n+You tried the straightforward `multiprocessing` and `threading`, but nothing works out of the box with your deep learning stacks. You decided to learn more high-performance computing frameworks such as Dask or Ray and try to adopt them. After some trial and error, you finally glued everything together and made them work. At this point you feel exhausted as it diverges too far from your expertise. \n \n ### Availability and downtime\n \n@@ -50,7 +50,7 @@ So you designed some naive failsafe mechanism that you just learned from a blog\n \n _\"How can I see the incoming traffic?\"_\n \n-You changed all `print` to `logger.info` and impatiently spin up a dashboard.\n+You changed all `print` to `logger.info` and impatiently spun up a dashboard.\n \n ### Security\n \n@@ -58,9 +58,9 @@ _\"Can we add some authentication header to it?\"_\n \n _\"Is this service prone to attack?\"_\n \n-At this point, you are burnt out. It goes too far from your expertise. You decided to hand over the project to a senior backend engineer, who is a new hire but has a lot of experience in infrastructure engineering and cloud services. He knows what he is doing and is willing to help you.\n+At this point, you are burnt out. It goes too far away from your expertise. You decided to hand over the project to a senior backend engineer, who is a new hire but has a lot of experience in infrastructure engineering and cloud services. He knows what he is doing and is willing to help you.\n \n-So you sit down with him, scrolling over your glued code and justifying all your tricks, design decisions and explaining the caveats. He kept nodding and you see it as some kind of recognition. Soon after he took a slow and thoughtful sip of his coffee, he said: \n+So you sit down with him, scrolling over your glued code and justifying all your tricks, design decisions and explaining all the caveats. He kept nodding and you see it as some kind of recognition. Soon after he took a slow and thoughtful sip of his coffee, he said: \n \n _\"Why don't we start to rewrite it?\"_\n \n@@ -70,7 +70,7 @@ The above example is quite real, and it reveals some gaps when developing a cros\n \n **First is the lack of design pattern for such system.** It is unclear how should one represent, compute, store, and transit the data with different modalities in a consistent way; and how can one switch between different tools and avoid glue code. \n \n-**Second is the large gap of between a proof-of-concept and a production system.** For a production system, cloud native techniques are often required to ensure the professionalism and scalability of the system. In particular, microservices, orchestration, containerization and observability are four pillars of such system. However, the learning curve is too steep for many machine learning engineers.\n+**Second is the large gap of between a proof-of-concept and a production system.** For a production system, cloud native techniques are often required to ensure the professionalism and scalability of the system. In particular, microservices, orchestration, containerization and observability are four pillars of such system. However, the learning curve is too steep for many machine learning engineers, preventing them to build production ready system.\n \n **Third is the long go-to-market time**. If a company chooses a wrong tech stack, it will take longer to bring the product to market. This is because the company will have to spend more time and resources on developing the product, refactoring it, going back and forth. In addition, a wrong stack can cause problems with the product itself, raising the risk of the product being unsuccessful.\n \n@@ -78,14 +78,16 @@ Jina is a solution to address above problems by providing a consistent design pa\n \n ### Why cloud native?\n \n+At first cloud native seems pretty irrelevant: why a cross-modal/multi-modal system is any related to cloud native? \n+\n Cloud native is a term that refers to a system that is designed to run on the cloud. It consists of a group of concepts:\n-- **Microservices**: Microservices are the core of a cloud-native system. They are the building blocks of a cloud-native system.\n+- **Microservices**: Microservices are the building blocks of a cloud native system.\n - **Orchestration**: Orchestration is the process of managing the microservices.\n - **Containerization**: Containerization is the process of packaging the microservices into containers.\n - **Observability**: Observability is the process of monitoring the system.\n-- **DevOps and CI/CD**: DevOps and CI/CD are the process of automating the system.\n+- **DevOps and CI/CD**: DevOps and CI/CD are the process of automating the integration of the system.\n \n-Sounds cool, But do we really need them?\n+Sounds cool but irrelevant, so do we really need them?\n \n Yes!\n \n@@ -96,9 +98,9 @@ Yes!\n | Cross-modal/multi-modal system is often a backend/infrastructure service that requires extra stablilty.                                                              | **DevOps and CI/CD** guarantees the integration and **Observability** provides the health information of the system. |\n \n \n-With that, let me reiterate what Jina is: Jina is a framework that provides a unified, cloud native solution for building cross-modal/multi-modal systems from day one. It provides the best developer experience from day one POC to production. It smooths your journey by resolving every subsection mentioned in {ref}`motivate-example`. No more tech debt, no more refactoring and back and forth between different systems.\n+With that, let me reiterate what Jina is: Jina is a framework that provides a unified, cloud native solution for building cross-modal/multi-modal systems from day one. It provides the best developer experience from day one POC to production. It smooths your journey by resolving every challenge mentioned in all subsections of {ref}`motivate-example`. No more tech debt, no more refactoring and back and forth between different systems.\n \n-Now it starts to make sense, right? Let's get our first taste on how Jina project looks like and how does it work.\n+Now it starts to make sense, right? Let's get our first taste on how a Jina project looks like and how does it work.\n \n ## Taste of Jina\n \n@@ -164,7 +166,7 @@ It is a pretty straightforward program. It abstracts away the complexity of a re\n \n In fact, one can achieve the same in 14 lines of code (`black`ed) with pure Python.\n \n-So does using Jina mean some special design pattern that needs one extra line of code to achieve the same result with pure Python? What's the deal?\n+So does using Jina mean learning some weird design pattern that needs one extra line of code to achieve the same result with pure Python? What's the deal?\n \n Here is the deal. The features below come out of the box with the above 15 lines of code:\n \n@@ -184,10 +186,10 @@ If you think that's a lot of over-promises, it is not. In fact, they barely scra\n \n With so many powerful features, the learning curve of Jina must be very steep, you might think. But it is not. In fact, you only need to know three concepts to master Jina. They are Document, Executor and Flow, which are introduced in {ref}`architecture-overview`.\n \n-A full-fledged cross-model/multi-model system is a combination of the following seven layers:\n+A full-fledged cross-modal/multi-modal system is a combination of the following seven layers:\n \n ```{figure} 7-layers.png\n-:scale: 50%\n+:scale: 40%\n ```\n \n This illustration is not exaggerating, it is a real-world example of a cross-modal/multi-modal system in production.\n@@ -195,7 +197,7 @@ This illustration is not exaggerating, it is a real-world example of a cross-mod\n Fortunately, as a Jina developer, you don't need to understand all of them. You only need to know what are relevant to your product logic and let Jina handles the rest. In particular, \n \n - **The data type**: represents the common data structure across the system; this corresponds to \"**Document**\" in Jina.\n-- **The logics**: represents the product logic of each component; this corresponds to \"**Executor**\" in Jina.\n+- **The logic**: represents the product logic of each component; this corresponds to \"**Executor**\" in Jina.\n - **The orchestration**: represents the workflow of all components; this corresponds to \"**Flow**\" in Jina.\n \n are all you need.\n@@ -204,7 +206,7 @@ are all you need.\n :scale: 50%\n ```\n \n-Patterns are nice, cloud native features are awesome. But what's the point if you need to spend months to learn them? Jina's design principles are simple and clear: flatten the learning curve for Python developers and make all awesome production-level features easily accessible.\n+Patterns are nice, cloud native features are cool. But what's the point if you need to spend months to learn them? Jina's design principles are simple and clear: flatten the learning curve of cloud native techniques and make all awesome production-level features easily accessible.\n \n \n ## Summary\n\n---\n file path A: docs/get-started/what-is.md | file path B: docs/get-started/what-is-cross-modal-multi-modal.md\n\n\n---\n file path A: docs/get-started/why-jina.md | file path B: docs/get-started/what-is-jina.md\n\n@@ -60,9 +60,9 @@ _\"Is this service prone to attack?\"_\n \n At this point, you are burnt out. It goes too far from your expertise. You decided to hand over the project to a senior backend engineer, who is a new hire but has a lot of experience in infrastructure engineering and cloud services. He knows what he is doing and is willing to help you.\n \n-So you sit down with him, scrolling over your glued code and justifying all your tricks, design decisions and caveats. He kept nodding. Soon after he took a slow and thoughtful sip of his coffee, he said: \n+So you sit down with him, scrolling over your glued code and justifying all your tricks, design decisions and explaining the caveats. He kept nodding and you see it as some kind of recognition. Soon after he took a slow and thoughtful sip of his coffee, he said: \n \n-\"Why don't we start to rewrite it?\"\n+_\"Why don't we start to rewrite it?\"_\n \n ## Problems and Jina's solution\n \n@@ -74,7 +74,7 @@ The above example is quite real, and it reveals some gaps when developing a cros\n \n **Third is the long go-to-market time**. If a company chooses a wrong tech stack, it will take longer to bring the product to market. This is because the company will have to spend more time and resources on developing the product, refactoring it, going back and forth. In addition, a wrong stack can cause problems with the product itself, raising the risk of the product being unsuccessful.\n \n-Jina is a solution to address above problems by providing a consistent design pattern for cross-modal/multi-modal systems with latest cloud native technologies.\n+Jina is a solution to address above problems by providing a consistent design pattern for cross-modal/multi-modal systems with the latest cloud native technologies.\n \n ### Why cloud native?\n \n@@ -164,7 +164,7 @@ It is a pretty straightforward program. It abstracts away the complexity of a re\n \n In fact, one can achieve the same in 14 lines of code (`black`ed) with pure Python.\n \n-So does using Jina means some special design pattern that needs one extra line of code to achieve the same result with pure Python? What's the deal?\n+So does using Jina mean some special design pattern that needs one extra line of code to achieve the same result with pure Python? What's the deal?\n \n Here is the deal. The features below come out of the box with the above 15 lines of code:\n \n\n\n###\n\n", "completion": "chore(docs): fix typos"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -215,6 +215,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14619,3 +14620,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```0c78b993```](https://github.com/jina-ai/jina/commit/0c78b993475292987e7ae26f58ba2779377d38f1)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```102bc6de```](https://github.com/jina-ai/jina/commit/102bc6defef4c163c145563a343841e667f9f953)] __-__ __version__: the next version will be 3.7.6 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-7></a>\n+## Release Note (`3.7.7`)\n+\n+> Release time: 2022-08-15 18:14:16\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Johannes Messner,  Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```22563074```](https://github.com/jina-ai/jina/commit/22563074bb02779d31258ea57da42d515be0bdbf)] __-__ cache hub pull with build env (#5061) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```e7377947```](https://github.com/jina-ai/jina/commit/e7377947482c8d32b1aed0aee24a8efa14b33826)] __-__ __docs__: fix typos (*Han Xiao*)\n+ - [[```6d218fbf```](https://github.com/jina-ai/jina/commit/6d218fbfa060226487174208ded10844b0ed28d2)] __-__ __version__: the next version will be 3.7.7 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.7'\n+__version__ = '3.7.8'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.8"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -356,14 +356,14 @@ metas:\n                 env_list = env.split('=')\n                 if len(env_list) != 2:\n                     raise Exception(\n-                        f'The --build-env parameter: `{env}` is wrong format. you can use: `--build-env {env}=YOUR_VALUE`.'\n+                        f'The `--build-env` parameter: `{env}` is wrong format. you can use: `--build-env {env}=YOUR_VALUE`.'\n                     )\n                 if check_requirements_env_variable(env_list[0]) is False:\n                     raise Exception(\n-                        f'The --build-env parameter key:`{env_list[0]}` can only consist of uppercase letter and number and underline.'\n+                        f'The `--build-env` parameter key:`{env_list[0]}` can only consist of uppercase letter and number and underline.'\n                     )\n                 build_env_dict[env_list[0]] = env_list[1]\n-            build_env = build_env_dict if len(list(build_env_dict.keys())) > 0 else None\n+            build_env = build_env_dict if build_env_dict else None\n \n         requirements_file = work_path / 'requirements.txt'\n \n@@ -433,7 +433,7 @@ metas:\n \n                 if build_env:\n                     form_data['buildEnv'] = json.dumps(build_env)\n-                \n+\n                 uuid8, secret = load_secret(work_path)\n                 if self.args.force_update or uuid8:\n                     form_data['id'] = self.args.force_update or uuid8\n@@ -712,7 +712,7 @@ metas:\n             image_name=image_name,\n             archive_url=resp['package']['download'],\n             md5sum=resp['package']['md5'],\n-            build_env=buildEnv.keys() if buildEnv else [],\n+            build_env=list(buildEnv.keys()) if buildEnv else [],\n         )\n \n     @staticmethod\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -21,15 +21,13 @@ from jina.hubble.helper import (\n     disk_cache_offline,\n     get_requirements_env_variables,\n )\n+from jina.hubble.hubapi import get_secret_path\n from jina.hubble.hubio import HubExecutor, HubIO\n from jina.parsers.hubble import (\n     set_hub_new_parser,\n     set_hub_pull_parser,\n     set_hub_push_parser,\n )\n-from jina.hubble.hubapi import (\n-    get_secret_path\n-)\n \n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n@@ -93,23 +91,34 @@ class PostMockResponse:\n \n \n class FetchMetaMockResponse:\n-    def __init__(self, response_code: int = 200, no_image=False, fail_count=0):\n+    def __init__(\n+        self,\n+        response_code: int = 200,\n+        no_image=False,\n+        fail_count=0,\n+        add_build_env=False,\n+    ):\n         self.response_code = response_code\n         self.no_image = no_image\n         self._tried_count = 0\n         self._fail_count = fail_count\n+        self._build_env = add_build_env\n \n     def json(self):\n         if self._tried_count <= self._fail_count:\n             return {'message': 'Internal server error'}\n \n+        commit_val = {'_id': 'commit_id', 'tags': ['v0']}\n+        if self._build_env:\n+            commit_val['commitParams'] = {'buildEnv': {'key1': 'val1', 'key2': 'val2'}}\n+\n         return {\n             'data': {\n                 'keywords': [],\n                 'id': 'dummy_mwu_encoder',\n                 'name': 'alias_dummy',\n                 'visibility': 'public',\n-                'commit': {'_id': 'commit_id', 'tags': ['v0']},\n+                'commit': commit_val,\n                 'package': {\n                     'containers': []\n                     if self.no_image\n@@ -169,7 +178,6 @@ def test_push(mocker, monkeypatch, path, mode, tmpdir, force, tag, no_cache, bui\n \n     result = HubIO(args).push()\n \n-    \n     exec_config_path = get_secret_path(os.stat(exec_path).st_ino)\n     shutil.rmtree(exec_config_path)\n \n@@ -219,13 +227,13 @@ def test_push(mocker, monkeypatch, path, mode, tmpdir, force, tag, no_cache, bui\n @pytest.mark.parametrize(\n     'env_variable_consist_error',\n     [\n-        'The --build-env parameter key:`{build_env_key}` can only consist of uppercase letter and number and underline.'\n+        'The `--build-env` parameter key:`{build_env_key}` can only consist of uppercase letter and number and underline.'\n     ],\n )\n @pytest.mark.parametrize(\n     'env_variable_format_error',\n     [\n-        'The --build-env parameter: `{build_env}` is wrong format. you can use: `--build-env {build_env}=YOUR_VALUE`.'\n+        'The `--build-env` parameter: `{build_env}` is wrong format. you can use: `--build-env {build_env}=YOUR_VALUE`.'\n     ],\n )\n @pytest.mark.parametrize('path', ['dummy_executor_fail'])\n@@ -313,7 +321,7 @@ def test_push_requirements_file_require_set_env_variables(\n \n     with pytest.raises(Exception) as info:\n         result = HubIO(args).push()\n-        \n+\n     assert requirements_file_need_build_env_error.format(\n         env_variables_str=','.join(requirements_file_env_variables)\n     ) in str(info.value)\n@@ -400,7 +408,6 @@ def test_push_wrong_dockerfile(\n \n     with pytest.raises(Exception) as info:\n         HubIO(args).push()\n-        \n \n     assert expected_error.format(dockerfile=dockerfile, work_path=args.path) in str(\n         info.value\n@@ -466,6 +473,41 @@ def test_fetch(mocker, monkeypatch, rebuild_image):\n     assert executor.tag == 'v0.1'\n \n \n+@pytest.mark.parametrize('rebuild_image', [True, False])\n+def test_fetch_with_buildenv(mocker, monkeypatch, rebuild_image):\n+    mock = mocker.Mock()\n+\n+    def _mock_post(url, json, headers=None):\n+        mock(url=url, json=json)\n+        return FetchMetaMockResponse(response_code=200, add_build_env=True)\n+\n+    monkeypatch.setattr(requests, 'post', _mock_post)\n+    args = set_hub_pull_parser().parse_args(['jinahub://dummy_mwu_encoder'])\n+\n+    executor, _ = HubIO(args).fetch_meta(\n+        'dummy_mwu_encoder', None, rebuild_image=rebuild_image, force=True\n+    )\n+\n+    assert executor.uuid == 'dummy_mwu_encoder'\n+    assert executor.name == 'alias_dummy'\n+    assert executor.tag == 'v0'\n+    assert executor.image_name == 'jinahub/pod.dummy_mwu_encoder'\n+    assert executor.md5sum == 'ecbe3fdd9cbe25dbb85abaaf6c54ec4f'\n+    assert executor.build_env == ['key1', 'key2']\n+\n+    _, mock_kwargs = mock.call_args_list[0]\n+    assert mock_kwargs['json']['rebuildImage'] is rebuild_image\n+\n+    executor, _ = HubIO(args).fetch_meta('dummy_mwu_encoder', '', force=True)\n+    assert executor.tag == 'v0'\n+\n+    _, mock_kwargs = mock.call_args_list[1]\n+    assert mock_kwargs['json']['rebuildImage'] is True  # default value must be True\n+\n+    executor, _ = HubIO(args).fetch_meta('dummy_mwu_encoder', 'v0.1', force=True)\n+    assert executor.tag == 'v0.1'\n+\n+\n def test_fetch_with_no_image(mocker, monkeypatch):\n     mock = mocker.Mock()\n \n\n\n###\n\n", "completion": "fix: cache hub pull with build env (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -214,6 +214,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14590,3 +14591,31 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```9fee2dff```](https://github.com/jina-ai/jina/commit/9fee2dff341fc5ef3a93f7fdda208ddc9457dd85)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```fe7b8894```](https://github.com/jina-ai/jina/commit/fe7b8894bc91a4d0d5ec9c255884d89c754189cb)] __-__ __version__: the next version will be 3.7.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-6></a>\n+## Release Note (`3.7.6`)\n+\n+> Release time: 2022-08-15 14:04:25\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  tarrantro,  Zac Li,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```49a842d9```](https://github.com/jina-ai/jina/commit/49a842d90a447d0f166ee5218bedabb90d6e0db0)] __-__ unify temp path to dot cache jina (#5058) (*Han Xiao*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```731d492c```](https://github.com/jina-ai/jina/commit/731d492cd02158cac8b5a228bdaaf37855358a11)] __-__ add CPU and GPU type (#5060) (*tarrantro*)\n+ - [[```d8f6f418```](https://github.com/jina-ai/jina/commit/d8f6f418877afcc1758d03d6df60d4aca6e1b912)] __-__ rewrite the telemetry session (#5059) (*Han Xiao*)\n+ - [[```01111539```](https://github.com/jina-ai/jina/commit/011115394c6e9c2ef7eb7223e61364c92758ddad)] __-__ __jcloud__: autoscale docs (#5056) (*Zac Li*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```299a908b```](https://github.com/jina-ai/jina/commit/299a908bb39ed0c0d6b3f00a5079237c2e2ca7cd)] __-__ __docs__: add what is jina (*Han Xiao*)\n+ - [[```23914a81```](https://github.com/jina-ai/jina/commit/23914a81120f73f0b807b70767fbe68a636f0903)] __-__ add what is cross multi modal (*Han Xiao*)\n+ - [[```0c78b993```](https://github.com/jina-ai/jina/commit/0c78b993475292987e7ae26f58ba2779377d38f1)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```102bc6de```](https://github.com/jina-ai/jina/commit/102bc6defef4c163c145563a343841e667f9f953)] __-__ __version__: the next version will be 3.7.6 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.6'\n+__version__ = '3.7.7'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.7"}
{"prompt": " file path A: None | file path B: docs/get-started/what-is.md\n\n@@ -0,0 +1,100 @@\n+# What is Cross-modal and Multi-modal?\n+\n+The term \"Modal\" is the shorthand for \"Data Modality\". Data modality can be thought of as the \"type\" of data. For example, a tweet is a modal of type \"text\"; a photo is a modal of type \"image\"; a video is a modal of type \"video\"; etc.\n+\n+Classical machine learning applications are usually focusing on a single modality at a time. For example, a spam filter is focused on text modality. A photo classifier is focused on image modality. A music recommender is focused on audio modality.\n+\n+However, in the real world, data is often multimodal, meaning that it consists of multiple modalities. For example, a tweet often contains not only text, but also images, videos, and links. A video often contains not only video frames, but also audio and text (e.g., subtitles).\n+\n+**Multi-modal** machine learning is a relatively new field that is concerned with the development of algorithms that can learn from multiple modalities of data.\n+\n+**Cross-modal** machine learning is a subfield of multi-modal machine learning that is concerned with the development of algorithms that can learn from multiple modalities of data that are not necessarily aligned. For example, learning from images and text where the images and text are not necessarily about the same thing.\n+\n+Thanks to recent advances in deep neural networks, a cross-modal or multi-modal system can go way beyond single modality. It enables advanced intelligence on all kinds of unstructured data, such as images, audio, video, PDF, 3D mesh, you name it.\n+\n+## Applications\n+\n+There are many potential applications of cross-modal machine learning. For example, a cross-modal machine learning algorithm could be used to automatically generate descriptions of images (e.g., for blind people). A search system could use a cross-modal machine learning algorithm to search for images by text queries (e.g., \"find me a picture of a dog\"). A text-to-image generation system could use a cross-modal machine learning algorithm to generate images from text descriptions (e.g., \"generate an image of a dog\").\n+\n+In particular, there are two families of applications: neural search and creative AI.\n+\n+### Neural Search\n+\n+One of the most promising applications of cross-modal machine learning is neural search. The core idea of neural search is to leverage state-of-the-art deep neural networks to build every component of a search system. In short, **neural search is deep neural network-powered information retrieval**. In academia, it\u2019s often called neural IR.\n+\n+\n+Below is an example of image embedding space generated by [DocArray](https://github.com/jina-ai/docarray)(the data structure behind Jina) and used for content-based image retrieval. Notice how similar images are mapped together in the embedding space.\n+\n+```{figure} https://github.com/jina-ai/docarray/raw/main/.github/README-img/tsne.gif?raw=true\n+```\n+\n+Searching is as simple as:\n+\n+```python\n+db = ...  # a DocumentArray of indexed images\n+queries = ...  # a DocumentArray of query images\n+\n+db.find(queries, limit=9)\n+for d in db:\n+    for m in d.matches:\n+        print(d.uri, m.uri, m.scores['cosine'].value)\n+```\n+\n+```console\n+left/02262.jpg right/03459.jpg 0.21102\n+left/02262.jpg right/02964.jpg 0.13871843\n+left/02262.jpg right/02103.jpg 0.18265384\n+left/02262.jpg right/04520.jpg 0.16477376\n+...\n+```\n+\n+Neural search is particularly well suited to cross-modal search tasks, because it can learn to map the features of one modality (e.g., text) to the features of another modality (e.g., images). This enables neural search engines to search for documents and images by text queries, and to search for text documents by image queries.\n+\n+\n+#### Think outside the (search) box\n+\n+Many neural search-powered applications do not have a search box:\n+\n+- A question-answering chatbot can be powered by neural search: by first indexing all hard-coded QA pairs and then semantically mapping user dialog to those pairs.\n+\n+- A smart speaker can be powered by neural search: by applying STT (speech-to-text) and semantically mapping text to internal commands.\n+\n+- A recommendation system can be powered by neural search: by embedding user-item information into vectors and finding top-K nearest neighbours of a user/item.\n+\n+Neural search creates a new way to comprehend the world. It is creating new doors that lead to new businesses.\n+\n+### Creative AI\n+\n+Another potential application of cross-modal machine learning is creative AI. Creative AI systems use artificial intelligence to generate new content, such as images, videos, or text. For example, Open AI GPT3  is a machine learning platform that can generate text. The system is trained on a large corpus of text, such as books, articles, and websites. Once trained, the system can generate new text that is similar to the training data. This can be used to generate new articles, stories, or even poems.\n+\n+Open AI DALLE is another example of a creative AI system. This system generates images from textual descriptions. For example, given the text \"a black cat with green eyes\", the system will generate an image of a black cat with green eyes. Below is an example of generating images from a text prompt using [DALL\u00b7E Flow](https://github.com/jina-ai/dalle-flow)(a text-to-image system built on top of Jina).\n+\n+\n+```python\n+server_url = 'grpc://dalle-flow.jina.ai:51005'\n+prompt = 'an oil painting of a humanoid robot playing chess in the style of Matisse'\n+\n+from docarray import Document\n+\n+doc = Document(text=prompt).post(server_url, parameters={'num_images': 8})\n+da = doc.matches\n+\n+da.plot_image_sprites(fig_size=(10, 10), show_index=True)\n+```\n+\n+```{figure} https://github.com/jina-ai/dalle-flow/raw/main/.github/client-dalle.png?raw=true\n+```\n+\n+Creative AI holds great potential for the future.  It has the potential to revolutionize how we interact with machines, helping us create more personalized experiences:\n+\n+- It can be used to create realistic 3D images and videos of people and objects, which can be used in movies, video games, and other visual media.\n+\n+- It can be used to generate realistic and natural-sounding dialogue, which can be used in movies, video games, and other forms of entertainment.\n+\n+- It can be used to create new and innovative designs for products, which can be used in manufacturing and other industries.\n+\n+- It can be used to create new and innovative marketing campaigns, which can be used in advertising and other industries.\n+\n+## What's next?\n+\n+In the next chapter, we will explain why Jina is the perfect framework for building neural search, creative AI and any cross-modal or multi-modal applications.\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/get-started/why-jina.md\n\n@@ -0,0 +1,4 @@\n+# Why Jina and Cloud-Native?\n+\n+\n+\n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -60,9 +60,10 @@ If you'd like to opt out of usage statistics, make sure to add the `--optout-tel\n :caption: Get Started\n :hidden:\n \n+get-started/what-is\n+fundamentals/architecture-overview\n get-started/install/index\n get-started/create-app\n-fundamentals/architecture-overview\n ```\n \n ```{toctree}\n\n\n###\n\n", "completion": "docs: add what is cross multi modal"}
{"prompt": " file path A: docs/fundamentals/jcloud/resources.md | file path B: docs/fundamentals/jcloud/resources.md\n\n@@ -26,6 +26,8 @@ executors:\n \n By default, `0.1 (1/10 of a core)` CPU is allocated to each Executor. You can use `cpu` arg under `resources` to customise it.\n \n+JCloud offers the general Intel Xeon processor (Skylake 8175M or Cascade Lake 8259CL) by default. \n+\n ```{note}\n Maximum of 16 cores is allowed per Executor.\n ```\n@@ -83,7 +85,9 @@ executors:\n \n #### GPU\n \n-JCloud supports GPU workloads with two different usages - `shared` & `dedicated`.\n+JCloud supports GPU workloads with two different usages: `shared` or `dedicated`. \n+\n+If GPU is enabled, JCloud will provide NVIDIA A10G Tensor Core GPUs for workloads in both usage types.\n \n ```{note}\n When using GPU resources, it may take few extra mins until all Executors ready to serve traffic.\n\n\n###\n\n", "completion": "docs: add CPU and GPU type (#<issue-num>)"}
{"prompt": " file path A: docs/index.md | file path B: docs/index.md\n\n@@ -33,22 +33,27 @@ Now that you\u2019re set up, let\u2019s dive into more of how Jina works and how to bu\n :end-before: <!-- end support-pitch -->\n ```\n \n-## Telemetry\n+```{important}\n \n-In order to help Jina build better solutions for the community, Jina collects some usage statistics when using it. It is impossible for Jina or any other party to identify users with the data collected,\n-you can see easily in the code which data is being collected by checking the code in {meth}`~jina.serve.helper._telemetry_run_in_thread`.\n+Telemetry is the process of collecting data about the usage of a system. This data can be used to improve the system by understanding how it is being used and what areas need improvement.\n \n-The data collected is:\n+Jina uses telemetry to collect data about how the software is being used. This data is then used to improve the software. For example, if Jina sees that a lot of users are having trouble with a certain feature, they can improve that feature to make it easier to use.\n \n-- Jina version\n-- DocArray version\n-- Other packages versions\n-- A random unique user identifier\n-- A random unique session identifier\n-- Event emitting the statistics. Flow start or Runtime start\n+Telemetry is important for Jina because it allows the team to understand how the software is being used and what areas need improvement. Without telemetry, Jina would not be able to improve as quickly or as effectively.\n \n-If you'd like to opt out of usage statistics, make sure to add the `optout-telemetry` argument to the different Flows and Executors or set the `JINA_OPTOUT_TELEMETRY` environment variable.\n+The data collected include:\n \n+- Jina and its dependencies versions;\n+- A hashed unique user identifier;\n+- A hashed unique session identifie;r\n+- Boolean events: start of a Flow, Gateway and Runtime.\n+\n+```\n+\n+```{tip}\n+If you'd like to opt out of usage statistics, make sure to add the `--optout-telemetry` argument to the different Flows and Executors or set the `JINA_OPTOUT_TELEMETRY=1` environment variable.\n+\n+```\n \n \n ```{toctree}\n\n\n###\n\n", "completion": "docs: rewrite the telemetry session (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -42,6 +42,7 @@ executors:\n       capacity: on-demand\n ```\n \n+(external-executors)=\n ## External executors\n \n You can also expose only the Executors by setting `expose_gateway` to `False`. Read more about {ref}`External Executors <external-executors>`\n\n---\n file path A: None | file path B: docs/fundamentals/jcloud/autoscale.md\n\n@@ -0,0 +1,56 @@\n+# Autoscaling\n+\n+In JCloud, demand-based autoscaling functionality is naturally offered thanks to the underlying Kubernetes architecture. This means that you can maintain [serverless](https://en.wikipedia.org/wiki/Serverless_computing) deployments in a cost-effective way with no headache of setting the [right number of replicas](https://docs.jina.ai/how-to/scale-out/#scale-out-your-executor) anymore!\n+\n+## Serverless\n+\n+Autoscaling can be enabled by using `jinahub+serverless` protocol for Exectuor's `uses` in the Flow YAML, such as:\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: executor1\n+    uses: jinahub+serverless://Executor1\n+```\n+\n+JCloud Autoscaling leverages [Knative](https://knative.dev/docs/) behind the scenes, and `jinahub+serverless` uses a set of Knative configuratons as defaults:\n+\n+```{note}\n+For more information about the Knative Autoscaling configurations, please visit [Knative Autoscaling](https://knative.dev/docs/serving/autoscaling/).\n+```\n+\n+| Name   | Value       | Description                                     |\n+|--------|-------------|-------------------------------------------------|\n+| min    | 0           | Minimum number of replicas (0 means serverless) |\n+| max    | 2           | Maximum number of replicas                      |\n+| metric | concurrency | Metric for scaling                              |\n+| target | 100         | Target number after which replicas autoscale    |\n+\n+## Configurations\n+\n+If `jinahub+serverless` doesn't meet your requirements, you can further customize Autoscaling configurations by using the `autoscale` argument on a per Executor basis in the Flow YAML, such as:\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+    jcloud:\n+      autoscale:\n+        min: 1\n+        max: 2\n+        metric: rps\n+        target: 50\n+```\n+\n+Below are the defaults and requirements for the configurations:\n+\n+| Name   | Default     | Allowed                  |\n+|--------|-------------|--------------------------|\n+| min    | 1           | int                      |\n+| max    | 2           | int, up to 5             |\n+| metric | concurrency | `concurrency`  /   `rps` |\n+| target | 100         | int                      |\n+\n+After JCloud deployment using the Autoscaling configurations, the Flow serving part is just the same; the only difference you would probably notice is it may take extra seconds\n+to handle the initial requests since it may need to scale the deployments behind the scenes. Let JCloud handle the scaling from now on and you should only worry about the code!\n\n---\n file path A: docs/fundamentals/jcloud/basic.md | file path B: None\n\n@@ -1,199 +0,0 @@\n-# Basic\n-\n-```{tip}\n-JCloud client is an opensource project. [Check here for its repository](https://github.com/jina-ai/jcloud). \n-```\n-\n-## Install\n-\n-```bash\n-pip install jcloud\n-jc -h\n-```\n-\n-In case `jc` is already occupied by another tool, please use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n-\n-\n-## Login\n-\n-```bash\n-jc login\n-```\n-\n-You can use a Google/GitHub account to register and login. For all the next steps, logging in is mandatory.\n-\n-If you have no access to the web browser in your integration environment, you can set the Environment Variable `JINA_AUTH_TOKEN` using auth token before working with JCloud. Auth token can be generated by user login or Personal Access Token (PAT) creation, please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` includes `jina-auth` already).\n-\n-## Deploy\n-\n-In Jina's idiom, a project is a [Flow](https://docs.jina.ai/fundamentals/flow/), which represents an end-to-end task such as indexing, searching or recommending. In this README, we will use \"project\" and \"Flow\" interchangeably.\n-\n-A Flow can have two types of file structure: a single YAML file or a project folder.\n-\n-### A single YAML file\n-\n-A self-contained YAML file, consisting of all configs at the [Flow](https://docs.jina.ai/fundamentals/flow/)-level and [Executor](https://docs.jina.ai/fundamentals/executor/)-level.\n-\n-> All Executors' `uses` must follow the format `jinahub+docker://MyExecutor` (from [Jina Hub](https://hub.jina.ai)) to avoid any local file dependencies.\n-\n-e.g.-\n-\n-```yaml\n-# flow.yml\n-jtype: Flow\n-executors:\n-  - name: sentencizer\n-    uses: jinahub+docker://Sentencizer\n-```\n-\n-To deploy,\n-\n-```bash\n-jc deploy flow.yml\n-```\n-\n-### A project folder\n-\n-Just like a regular Python project, you can have sub-folders of Executor implementations; and a `flow.yml` on the top-level to connect all Executors together.\n-\n-You can create an example local project using `jc new`. The default structure looks like:\n-\n-```\n-.\n-\u251c\u2500\u2500 .env\n-\u251c\u2500\u2500 executor1\n-\u2502   \u251c\u2500\u2500 config.yml\n-\u2502   \u251c\u2500\u2500 executor.py\n-\u2502   \u2514\u2500\u2500 requirements.txt\n-\u2514\u2500\u2500 flow.yml\n-```\n-\n-where,\n-\n-- `executor1` directory has all Executor related code/config. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/executor-files/). Multiple such Executor directories can be created.\n-- `flow.yml` Your Flow YAML.\n-- `.env` All environment variables used during deployment.\n-\n-To deploy,\n-\n-```bash\n-jc deploy ./hello\n-```\n-\n-\n-The Flow is successfully deployed when you see:\n-\n-```{figure} deploy.png\n-:width: 70%\n-```\n-\n-You will get a Flow ID, say `173503c192`. This ID is required to manage, view logs and remove the Flow.\n-\n-As this Flow is deployed with default gRPC gateway (feel free to change it to `http` or `websocket`), you can use `jina.Client` to access it:\n-\n-```python\n-from jina import Client, Document\n-\n-c = Client(host='https://173503c192.wolf.jina.ai')\n-print(c.post('/', Document(text='hello')))\n-```\n-\n-\n-\n-## View logs\n-\n-To watch the logs in realtime:\n-\n-```bash\n-jc logs 173503c192\n-```\n-\n-You can also stream logs for a particular Executor by passing its name:\n-\n-```bash\n-jc logs 173503c192 --executor sentencizer\n-```\n-\n-## Remove Flows\n-\n-You can either remove a single Flow, multiple selected Flows or even all Flows by passing different kind of identifiers.\n-\n-To remove a single Flow:\n-\n-```bash\n-jc remove 173503c192\n-```\n-\n-To remove multiple selected Flows:\n-\n-```bash\n-jc remove 173503c192 887f6313e5 ddb8a2c4ef\n-```\n-\n-To remove all Flows:\n-\n-```bash\n-jc remove all\n-```\n-\n-By default, removing multiple selected / all Flows would be in interactive mode where confirmation will be sent prior to\n-the deletion, to make it non-interactive to better suit your use case, set below environment variable before running the command:\n-\n-```bash\n-export JCLOUD_NO_INTERACTIVE=1\n-```\n-\n-## Get status\n-\n-To get the status of a Flow:\n-```bash\n-jc status 15937a10bd\n-```\n-\n-```{figure} status.png\n-:width: 70%\n-```\n-\n-## Monitoring\n-To enable monitoring with the Flow, you can set `monitoring: true` in the Flow yaml and you'd be given access to a [Grafana](https://grafana.com/) dashboard.\n-\n-To access the dashboard, get the status of the Flow first (see above section), at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n-\n-```{figure} monitoring.png\n-:width: 70%\n-```\n-\n-## List Flows\n-\n-To list all the Flows you have:\n-```bash\n-jc list\n-```\n-\n-You can see the ALIVE Flows deployed by you.\n-\n-```{figure} list.png\n-:width: 70%\n-```\n-\n-\n-You can also filter your Flows by passing a status:\n-\n-```bash\n-jc list --status FAILED\n-```\n-\n-\n-```{figure} list_failed.png\n-:width: 70%\n-```\n-\n-Or see all the flows:\n-\n-```bash\n-jc list --status ALL\n-```\n-\n-```{figure} list_all.png\n-:width: 70%\n-```\n\n---\n file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -1,3 +1,4 @@\n+(jcloud)=\n # JCloud\n \n ```{figure} https://docs.jina.ai/_images/jcloud-banner.png\n@@ -17,13 +18,207 @@ After building a Jina project, the next step is to deploy and host it on Cloud.\n At this point, Jina Cloud hosts all your Jina projects and offers computational/storage resources **for free**!\n ```\n \n+## Basic\n+### Install\n+\n+```bash\n+pip install jcloud\n+jc -h\n+```\n+\n+```{hint}\n+In case `jc` is already occupied by another tool, please use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n+```\n+\n+### Login\n+\n+```bash\n+jc login\n+```\n+\n+You can use a Google/GitHub account to register and login. For all the next steps, logging in is mandatory.\n+\n+If you have no access to the web browser in your integration environment, you can set the Environment Variable `JINA_AUTH_TOKEN` using auth token before working with JCloud. Auth token can be generated by user login or Personal Access Token (PAT) creation, please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` includes `jina-auth` already).\n+\n+### Deploy\n+\n+In Jina's idiom, a project is a [Flow](https://docs.jina.ai/fundamentals/flow/), which represents an end-to-end task such as indexing, searching or recommending. In this README, we will use \"project\" and \"Flow\" interchangeably.\n+\n+A Flow can have two types of file structure: a single YAML file or a project folder.\n+\n+#### A single YAML file\n+\n+A self-contained YAML file, consisting of all configs at the [Flow](https://docs.jina.ai/fundamentals/flow/)-level and [Executor](https://docs.jina.ai/fundamentals/executor/)-level.\n+\n+> All Executors' `uses` must follow the format `jinahub+docker://MyExecutor` (from [Jina Hub](https://hub.jina.ai)) to avoid any local file dependencies.\n+\n+e.g.-\n+\n+```yaml\n+# flow.yml\n+jtype: Flow\n+executors:\n+  - name: sentencizer\n+    uses: jinahub+docker://Sentencizer\n+```\n+\n+To deploy,\n+\n+```bash\n+jc deploy flow.yml\n+```\n+\n+#### A project folder\n+\n+Just like a regular Python project, you can have sub-folders of Executor implementations; and a `flow.yml` on the top-level to connect all Executors together.\n+\n+You can create an example local project using `jc new`. The default structure looks like:\n+\n+```\n+.\n+\u251c\u2500\u2500 .env\n+\u251c\u2500\u2500 executor1\n+\u2502   \u251c\u2500\u2500 config.yml\n+\u2502   \u251c\u2500\u2500 executor.py\n+\u2502   \u2514\u2500\u2500 requirements.txt\n+\u2514\u2500\u2500 flow.yml\n+```\n+\n+where,\n+\n+- `executor1` directory has all Executor related code/config. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/executor-files/). Multiple such Executor directories can be created.\n+- `flow.yml` Your Flow YAML.\n+- `.env` All environment variables used during deployment.\n+\n+To deploy,\n+\n+```bash\n+jc deploy ./hello\n+```\n+\n+\n+The Flow is successfully deployed when you see:\n+\n+```{figure} deploy.png\n+:width: 70%\n+```\n+\n+You will get a Flow ID, say `173503c192`. This ID is required to manage, view logs and remove the Flow.\n+\n+As this Flow is deployed with default gRPC gateway (feel free to change it to `http` or `websocket`), you can use `jina.Client` to access it:\n+\n+```python\n+from jina import Client, Document\n+\n+c = Client(host='https://173503c192.wolf.jina.ai')\n+print(c.post('/', Document(text='hello')))\n+```\n+\n+\n+\n+### View logs\n+\n+To watch the logs in realtime:\n+\n+```bash\n+jc logs 173503c192\n+```\n+\n+You can also stream logs for a particular Executor by passing its name:\n+\n+```bash\n+jc logs 173503c192 --executor sentencizer\n+```\n+\n+### Remove Flows\n+\n+You can either remove a single Flow, multiple selected Flows or even all Flows by passing different kind of identifiers.\n+\n+To remove a single Flow:\n+\n+```bash\n+jc remove 173503c192\n+```\n+\n+To remove multiple selected Flows:\n+\n+```bash\n+jc remove 173503c192 887f6313e5 ddb8a2c4ef\n+```\n+\n+To remove all Flows:\n+\n+```bash\n+jc remove all\n+```\n+\n+By default, removing multiple selected / all Flows would be in interactive mode where confirmation will be sent prior to\n+the deletion, to make it non-interactive to better suit your use case, set below environment variable before running the command:\n+\n+```bash\n+export JCLOUD_NO_INTERACTIVE=1\n+```\n+\n+### Get status\n+\n+To get the status of a Flow:\n+```bash\n+jc status 15937a10bd\n+```\n+\n+```{figure} status.png\n+:width: 70%\n+```\n+\n+### Monitoring\n+To enable monitoring with the Flow, you can set `monitoring: true` in the Flow yaml and you'd be given access to a [Grafana](https://grafana.com/) dashboard.\n+\n+To access the dashboard, get the status of the Flow first (see above section), at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n+\n+```{figure} monitoring.png\n+:width: 70%\n+```\n+\n+### List Flows\n+\n+To list all the Flows you have:\n+```bash\n+jc list\n+```\n+\n+You can see the ALIVE Flows deployed by you.\n+\n+```{figure} list.png\n+:width: 70%\n+```\n+\n+\n+You can also filter your Flows by passing a status:\n+\n+```bash\n+jc list --status FAILED\n+```\n+\n+\n+```{figure} list_failed.png\n+:width: 70%\n+```\n+\n+Or see all the flows:\n+\n+```bash\n+jc list --status ALL\n+```\n+\n+```{figure} list_all.png\n+:width: 70%\n+```\n+\n ```{toctree}\n :hidden:\n \n-basic\n resources\n+autoscale\n advanced\n faq\n ```\n-\n-\n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -10,7 +10,9 @@ Executor be used by different Flows.\n ````{admonition} Where can external Executors run?\n :class: hint\n External Executors can run anywhere from the same environment as the Flow, to a Docker container, or even a remote\n-machine.\n+environment, such as {ref}`JCloud <jcloud>`.\n+\n+To deploy external Exectuors on JCloud, please follow {ref}`this documentation <external-executors>`.\n ````\n \n As the first step in this tutorial, you will learn how to add already running external Executors to your Flow.\n\n---\n file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -14,6 +14,10 @@ always see them as just a starting point to get you off the ground.\n In this how-to you will go through how to deploy a simple Flow using Kubernetes, how to customize the Kubernetes configuration\n to your needs, and how to scale Executors using replicas and shards.\n \n+```{note}\n+Do you know {ref}`JCloud <jcloud>` simplifies Flow deployment and hosting? It saves all the trouble for you so you can focus on what really matters!\n+```\n+\n ## Preliminaries\n \n To follow along with this how-to, you will need access to a Kubernetes cluster.\n\n\n###\n\n", "completion": "docs(jcloud): autoscale docs (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -213,6 +213,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14560,3 +14561,31 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```ecb95829```](https://github.com/jina-ai/jina/commit/ecb95829f67d594616d5650086cbfaea1c598e97)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```286bdce8```](https://github.com/jina-ai/jina/commit/286bdce8b2c3afcb3b65a76c49dd6343bb28e171)] __-__ __version__: the next version will be 3.7.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-5></a>\n+## Release Note (`3.7.5`)\n+\n+> Release time: 2022-08-10 10:19:23\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Jina Dev Bot,  zhangkai,  samsja,  Deepankar Mahapatro,  tarrantro,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```6cc4497a```](https://github.com/jina-ai/jina/commit/6cc4497a02a69613c0ed22558d8bced855871a88)] __-__ hubble support env variables (#5023) (*zhangkai*)\n+ - [[```12404535```](https://github.com/jina-ai/jina/commit/124045351137d80d118f9692de4295d50561f1e1)] __-__ add dryrun to cli (#5050) (*samsja*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```1d60655d```](https://github.com/jina-ai/jina/commit/1d60655df9ba770e232d575f1e589f7a8054393f)] __-__ __jcloud__: fix formatting (#5048) (*Deepankar Mahapatro*)\n+ - [[```6df83cf1```](https://github.com/jina-ai/jina/commit/6df83cf1b1c8621fdbd749352dd9c589c086ad50)] __-__ improve grpc third party client documentation (#5047) (*samsja*)\n+ - [[```8c6321ac```](https://github.com/jina-ai/jina/commit/8c6321ac1732b0dae2c44f9cc76c18e095b67f00)] __-__ refactor resources, add gpu, kong  (#5027) (*tarrantro*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```d6d4c30a```](https://github.com/jina-ai/jina/commit/d6d4c30ab4ba0c8b14593d31218beca11315e616)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```9fee2dff```](https://github.com/jina-ai/jina/commit/9fee2dff341fc5ef3a93f7fdda208ddc9457dd85)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```fe7b8894```](https://github.com/jina-ai/jina/commit/fe7b8894bc91a4d0d5ec9c255884d89c754189cb)] __-__ __version__: the next version will be 3.7.5 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.5'\n+__version__ = '3.7.6'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.6"}
{"prompt": " file path A: docs/fundamentals/flow/health-check.md | file path B: docs/fundamentals/flow/health-check.md\n\n@@ -48,6 +48,21 @@ True\n ```\n ````\n \n+````{tab} via CLI\n+```python\n+from jina import Flow\n+\n+with Flow(port=12345).add() as f:\n+    f.block()\n+```\n+```bash\n+jina dryrun grpc://localhost:12345\n+```\n+```text\n+dry run successful\n+```\n+````\n+\n ### Flow status using third-party clients\n \n You can check the status of a Flow using any gRPC/HTTP/Websocket client, not just Jina's Client implementation.\n\n---\n file path A: jina/checker.py | file path B: jina/checker.py\n\n@@ -55,3 +55,32 @@ class NetworkChecker:\n \n         # returns 1 (anomaly) when it comes to here\n         exit(1)\n+\n+\n+def dry_run_checker(args: 'argparse.Namespace'):\n+    \"\"\"\n+    call dry run on the given endpoint\n+    :param args: args provided by the CLI.\n+    \"\"\"\n+    # No retry mechanism for dry run since it is built in the Flow\n+\n+    from jina import Client\n+\n+    client = Client(host=args.host)\n+\n+    try:\n+\n+        if client.dry_run(timeout=args.timeout):\n+            default_logger.info('dry run successful')\n+            exit(0)\n+        else:\n+            default_logger.warning('dry run failed')\n+            exit(1)\n+\n+    except KeyboardInterrupt:\n+        pass\n+\n+    exit(1)\n+\n+\n+# returns 1 (anomaly) when it comes to here\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -1,4 +1,5 @@\n from jina.parsers.client import mixin_comm_protocol_parser\n+from jina.parsers.dryrun import set_dryrun_parser\n from jina.parsers.helper import _SHOW_ALL_ARGS\n from jina.parsers.orchestrate.runtimes.head import mixin_head_parser\n \n@@ -192,6 +193,15 @@ def get_main_parser():\n         )\n     )\n \n+    set_dryrun_parser(\n+        sp.add_parser(\n+            'dryrun',\n+            help='Dryrun a Flow',\n+            description='send a dryrun request to a Flow to check if it is working',\n+            formatter_class=_chf,\n+        )\n+    )\n+\n     set_export_parser(\n         sp.add_parser(\n             'export',\n\n---\n file path A: None | file path B: jina/parsers/dryrun.py\n\n@@ -0,0 +1,30 @@\n+\"\"\"Argparser module for pinging\"\"\"\n+from jina.parsers.base import set_base_parser\n+\n+\n+def set_dryrun_parser(parser=None):\n+    \"\"\"Set the parser for `dryrun`\n+\n+    :param parser: an existing parser to build upon\n+    :return: the parser\n+    \"\"\"\n+    if not parser:\n+        parser = set_base_parser()\n+\n+    parser.add_argument(\n+        'host',\n+        type=str,\n+        help='The full host address of the Gateway, e.g. grpc://localhost:12345',\n+    )\n+\n+    parser.add_argument(\n+        '--timeout',\n+        type=int,\n+        default=3000,\n+        help='''\n+Timeout in millisecond of one check\n+-1 for waiting forever\n+''',\n+    )\n+\n+    return parser\n\n---\n file path A: jina_cli/api.py | file path B: jina_cli/api.py\n\n@@ -127,6 +127,17 @@ def ping(args: 'Namespace'):\n     NetworkChecker(args)\n \n \n+def dryrun(args: 'Namespace'):\n+    \"\"\"\n+    Check the health of a Flow\n+\n+    :param args: arguments coming from the CLI.\n+    \"\"\"\n+    from jina.checker import dry_run_checker\n+\n+    dry_run_checker(args)\n+\n+\n def client(args: 'Namespace'):\n     \"\"\"\n     Start a client connects to the gateway\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -6,6 +6,7 @@ ac_table = {\n         'executor',\n         'flow',\n         'ping',\n+        'dryrun',\n         'export',\n         'new',\n         'gateway',\n@@ -83,6 +84,7 @@ ac_table = {\n             '--inspect',\n         ],\n         'ping': ['--help', '--timeout', '--retries'],\n+        'dryrun': ['--help', '--timeout'],\n         'export flowchart': ['--help', '--vertical-layout'],\n         'export kubernetes': ['--help', '--k8s-namespace'],\n         'export docker-compose': ['--help', '--network_name'],\n\n\n###\n\n", "completion": "feat: add dryrun to cli (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/resources.md | file path B: docs/fundamentals/jcloud/resources.md\n\n@@ -4,7 +4,7 @@ Since each Executor has its own business logic, it might need different Cloud re\n \n In JCloud, we allow users to pass highly customizable, fine-grained resource requests for each Executor using `resources` argument in your Flow YAML.\n \n-### Memory\n+#### Memory\n \n By default, `100M` of RAM is allocated to each Executor. You can use `memory` arg under `resources` to customise it.\n \n@@ -22,7 +22,7 @@ executors:\n         memory: 8G\n ```\n \n-### CPU\n+#### CPU\n \n By default, `0.1 (1/10 of a core)` CPU is allocated to each Executor. You can use `cpu` arg under `resources` to customise it.\n \n@@ -40,7 +40,7 @@ executors:\n         cpu: 0.5\n ```\n \n-### Storage\n+#### Storage\n \n JCloud supports 2 kinds of Storage types [efs](https://aws.amazon.com/efs/) (default) and [ebs](https://aws.amazon.com/ebs/). The former one is a network file storage, whereas the latter is a block device.\n \n@@ -81,7 +81,7 @@ executors:\n           type: efs\n ```\n \n-### GPU\n+#### GPU\n \n JCloud supports GPU workloads with two different usages - `shared` & `dedicated`.\n \n@@ -89,7 +89,7 @@ JCloud supports GPU workloads with two different usages - `shared` & `dedicated`\n When using GPU resources, it may take few extra mins until all Executors ready to serve traffic.\n ```\n \n-#### Shared\n+##### Shared\n \n An executor using a `shared` GPU shares this GPU with up to 10 other Executors.\n This enables a time-slicing, which allows workloads that land on oversubscribed GPUs to interleave with one another.\n@@ -108,7 +108,7 @@ executors:\n There are no special provisions in place to isolate replicas that run on the same underlying GPU. Each workload has access to the GPU memory and runs in the same fault-domain as of all the others. Therefore, if one workload crashes, they all do. \n ```\n \n-#### Dedicated\n+##### Dedicated\n \n Using a dedicated GPU is the default way to provision GPU for the Executor. This will automatically create nodes or assign the Executor to land on a GPU node. In this case, executor owns the whole GPU. You can assign between 1 and 4 GPUs.\n \n@@ -123,7 +123,7 @@ executors:\n ```\n \n \n-## Example\n+### Example\n \n Here's a Flow with 2 Executors with specific resource needs. `indexer` demands for 10G `ebs` disk, whereas `encoder` demands for 2 cores, 8G RAM & 2 dedicated GPUs. \n \n\n\n###\n\n", "completion": "docs(jcloud): fix formatting (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/client/client.md\n\n@@ -2,10 +2,16 @@\n # Client\n {class}`~jina.Client` enables you to send Documents to a running {class}`~jina.Flow` in a number of different ways, as shown below.\n \n-Clients support three different networking protocols: HTTP, gRPC, WebSocket and GraphQL\n+Clients support four different networking protocols: **HTTP**, **gRPC**, **WebSocket** and **GraphQL**\n \n For each of them, you first connect your Client to the API Gateway, before you can send requests to it.\n \n+```{hint}\n+If you want to connect to your Flow from a programming language other than Python, please follow the third party \n+client {ref}`documentation <third-party-client>`.\n+```\n+\n+\n ## Connect\n \n If there is not already a Flow running in the background or on the network, you can start one:\n@@ -533,5 +539,5 @@ For details on the allowed mutation arguments and response fields, see {ref}`her\n ```{toctree}\n :hidden:\n \n-access-flow-api\n+third-party-client\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/fundamentals/flow/access-flow-api.md | file path B: docs/fundamentals/client/third-party-client.md\n\n@@ -1,7 +1,7 @@\n-(access-flow-api)=\n+(third-party-client)=\n # Third-party clients\n \n-This page is about accessing the Flow with other clients, e.g. `curl`.\n+This page is about accessing the Flow with other clients, e.g. `curl`, or programming languages other than python.\n \n ## HTTP\n \n@@ -230,6 +230,17 @@ We provide a suite of templates for the Jina Flow, in this [collection](https://\n \n This contribution was made by [Jonathan Rowley](https://jina-ai.slack.com/archives/C0169V26ATY/p1649689443888779?thread_ts=1649428823.420879&cid=C0169V26ATY), in our [community Slack](slack.jina.ai). \n \n+## gRPC\n+\n+To use the gRPC protocol with a language other than Python you will need to :\n+\n+* Download the two proto definition files: `jina.proto` and `docarray.proto` from [github](https://github.com/jina-ai/jina/tree/master/jina/proto) (be sure to use the latest release branch)\n+* Compile them with [protoc](https://grpc.io/docs/protoc-installation/) and precise to which programming language you want to compile them.\n+* Add the generated files to your project and import them in your code. \n+\n+You should finally be able to communicate with your Flow using the gRPC protocol. You can find more information on the gRPC\n+`message` and `service` that you can use to communicate in the  [Protobuf documentation](../../proto/docs.md).\n+\n (flow-graphql)=\n ## GraphQL\n \n@@ -289,10 +300,6 @@ The available fields in the GraphQL API are defined by the [Document Strawberry\n Essentially, you can ask for any property of a Document, including `embedding`, `text`, `tensor`, `id`, `matches`, `tags`,\n and more.\n \n-## gRPC\n-\n-If you want to create a gRPC client in another language, you will need to compile the [Protobuf definition](../../proto/docs.md). In Python, you can use our {ref}`own client <client>`.\n-\n ## Websocket\n \n Websocket uses persistent connections between the client & Flow, hence allowing streaming use cases. \n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -67,7 +67,7 @@ fundamentals/architecture-overview\n fundamentals/executor/index\n fundamentals/flow/index\n fundamentals/gateway/index\n-fundamentals/flow/client\n+fundamentals/client/client\n fundamentals/executor/hub/index\n fundamentals/jcloud/index\n how-to/index\n\n---\n file path A: docs/proto/docs.md | file path B: docs/proto/docs.md\n\n@@ -10,6 +10,7 @@\n     - [DataRequestListProto](#jina-DataRequestListProto)\n     - [DataRequestProto](#jina-DataRequestProto)\n     - [DataRequestProto.DataContentProto](#jina-DataRequestProto-DataContentProto)\n+    - [DataRequestProtoWoData](#jina-DataRequestProtoWoData)\n     - [EndpointsProto](#jina-EndpointsProto)\n     - [HeaderProto](#jina-HeaderProto)\n     - [JinaInfoProto](#jina-JinaInfoProto)\n@@ -116,6 +117,23 @@ Represents a DataRequest\n \n \n \n+<a name=\"jina-DataRequestProtoWoData\"></a>\n+\n+### DataRequestProtoWoData\n+\n+\n+\n+| Field | Type | Label | Description |\n+| ----- | ---- | ----- | ----------- |\n+| header | [HeaderProto](#jina-HeaderProto) |  | header contains meta info defined by the user |\n+| parameters | [google.protobuf.Struct](#google-protobuf-Struct) |  | extra kwargs that will be used in executor |\n+| routes | [RouteProto](#jina-RouteProto) | repeated | status info on every routes |\n+\n+\n+\n+\n+\n+\n <a name=\"jina-EndpointsProto\"></a>\n \n ### EndpointsProto\n\n\n###\n\n", "completion": "docs: improve grpc third party client documentation (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -16,75 +16,17 @@ jc deploy flow.yml --env-file flow.env\n   jc deploy ./hello --env-file ./hello/custom.env\n   ```\n \n-## Request for fine-grained `resources`\n+## jina version\n \n-### memory\n-\n-By default, `jcloud` allocates `100M` of RAM to each Executor. There might be cases where your Executor requires more memory. For example, DALLE-mini (generating image from text prompt) would need more than 100M to load the model. You can request higher memory for your Executor using `resources` arg while deploying the Flow (max 16G allowed per Executor).\n-\n-```yaml\n-jtype: Flow\n-executors:\n-  - name: dalle_mini\n-    uses: jinahub+docker://DalleMini\n-    jcloud:\n-      resources:\n-        memory: 8G\n-```\n-\n-### CPU\n-\n-By default, `jcloud` allocates `0.1 (1/10 of a core)` CPU to each Executor. There might be cases where your Executor requires more CPU; you can do so by using `resources` arg while deploying the Flow (max 16 CPU allowed per Executor). The input value should be a number, indicating the number of full CPU cores.\n-\n-```yaml\n-jtype: Flow\n-executors:\n-  - name: custom1\n-    uses: jinahub+docker://CustomExecutor1\n-    jcloud:\n-      resources:\n-        cpu: 0.5\n-```\n-\n-### storage\n-\n-We currently support 2 kinds of storage types [efs](https://aws.amazon.com/efs/) (default) and [ebs](https://aws.amazon.com/ebs/). The former one is a network file storage, whereas the latter is a block device.\n-\n-````{note}\n-\n-By default, we attach an `efs` to all the Executors in a Flow. The benefits of doing so are\n-\n-- It can grow in size dynamically, so you don't need to shrink/grow volumes as & when necessary.\n-- All Executors in the Flow can share a disk.\n-- The same disk can also be shared with another Flow by passing a workspace-id while deploying a Flow.\n-\n-```bash\n-jc deploy flow.yml --workspace-id <prev-flow-id>\n-```\n-\n-If your Executor needs high IO, you can use `ebs` instead. Please note that,\n-\n-- The disk cannot be shared with other Executors / Flows.\n-- You must pass a size of storage (default: `1G`, max `10G`).\n-\n-````\n+To manage `jina` version while deploying a Flow to `jcloud`, you can pass `version` arg in the Flow yaml.\n \n ```yaml\n jtype: Flow\n+jcloud:\n+  version: 3.4.11\n executors:\n-  - name: indexer1\n-    uses: jinahub+docker://SimpleIndexer\n-    jcloud:\n-      resources:\n-        storage:\n-          type: ebs\n-          size: 10G\n-  - name: indexer2\n-    uses: jinahub+docker://SimpleIndexer\n-    jcloud:\n-      resources:\n-        storage:\n-          type: efs\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n ```\n \n ## Capacity (`spot` vs `on-demand`)\n@@ -94,8 +36,8 @@ For cost optimization, `jcloud` tries to deploy all Executors on `spot` capacity\n ```yaml\n jtype: Flow\n executors:\n-  - name: custom\n-    uses: jinahub+docker://CustomExecutor\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n     jcloud:\n       capacity: on-demand\n ```\n@@ -134,29 +76,42 @@ executors:\n :width: 70%\n ```\n \n-## `jina` version\n+## Internet Exposure & TLS\n \n-To manage `jina` version while deploying a Flow to `jcloud`, you can pass `version` arg in the Flow yaml.\n+To expose users' Flows to the internet with TLS, JCloud provides support for 2 Gateways [ALB](https://aws.amazon.com/elasticloadbalancing/application-load-balancer/) & [Kong API Gateway](https://konghq.com/products/api-gateway-platform). \n+\n+```{note}\n+The JCloud gateway is different from Jina's Gateway. In JCloud, a gateway works as a proxy to distribute internet traffic between Flows, each of which has a Jina Gateway (which is responsible to manage external gRPC/HTTP/Websocket traffic to your Executors)\n+```\n+\n+### ALB\n+\n+Currently ALB is the default gateway for backward compatibility. We use AWS provided public certificates for TLS with the ALB.\n+\n+### Kong\n+\n+Kong is the recommended gateway in JCloud. We use [Let's Encrypt](https://letsencrypt.org/) for TLS with Kong. To enable Kong Gateway instead of ALB, specify the gateway kind as `kong` in your JCloud YAML:\n \n ```yaml\n jtype: Flow\n jcloud:\n-  version: 3.4.11\n+  gateway:\n+    kind: kong\n executors:\n-  - name: custom\n-    uses: jinahub+docker://CustomExecutor\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n ```\n \n (retention-days)=\n ## Retention days\n \n-In JCloud, we have a default life-cycle of 24hrs for Flows, after which they're removed, if idle. You can manage the same yourself by passing the right parameter for `retention-days` under `jcloud`. `0` is to use the default life-cycle, `X` (0<X<365), which is meant to keep the Flow alive until X days, and `-1` is for never expired,\n+In JCloud, we have a default life-cycle of 24hrs for Flows, after which they're removed if idle. You can manage the same yourself by passing the right parameter for `retention-days` under `jcloud`. `0` is to use the default life-cycle, `X` (0<X<365), which is meant to keep the Flow alive until X days, and `-1` is for never expired,\n \n ```yaml\n jtype: Flow\n jcloud:\n   retention_days: -1\n executors:\n-  - name: custom\n-    uses: jinahub+docker://CustomExecutor\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n ```\n\n---\n file path A: docs/fundamentals/jcloud/basic.md | file path B: docs/fundamentals/jcloud/basic.md\n\n@@ -20,7 +20,7 @@ In case `jc` is already occupied by another tool, please use `jcloud` instead. I\n jc login\n ```\n \n-You can use a Google/GitHub account to register and login. Without logging in, you can't do anything.\n+You can use a Google/GitHub account to register and login. For all the next steps, logging in is mandatory.\n \n If you have no access to the web browser in your integration environment, you can set the Environment Variable `JINA_AUTH_TOKEN` using auth token before working with JCloud. Auth token can be generated by user login or Personal Access Token (PAT) creation, please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` includes `jina-auth` already).\n \n\n---\n file path A: docs/fundamentals/jcloud/faq.md | file path B: docs/fundamentals/jcloud/faq.md\n\n@@ -6,13 +6,12 @@\n \n - **How powerful is JCloud?**\n \n-  JCloud scales according to your need. You can demand all the resources (RAM / disk / instance-capacity) your Flows & Executors need. If there's anything particular you'd be looking for, you can contact us [on Slack](https://slack.jina.ai) or let us know via `jc survey`.\n+  JCloud scales according to your need. You can demand all the resources (GPU / RAM / CPU / Storage / instance-capacity) your Flows & Executors need. If there's anything particular you'd be looking for, you can contact us [on Slack](https://slack.jina.ai) or let us know via `jc survey`.\n \n - **What restrictions are there on JCloud?**\n \n-  - JCloud doesn't support GPUs yet.\n-  - Executors are currently allowed a maximum of 16G RAM & 10GB disk (using EBS).\n   - Deployments are only supported in `us-east` region.\n+  - Each Executor is allowed a maximum of 4 GPUs, 16G RAM, 16 CPU cores & 10GB of block storage.\n \n - **How long do you persist my service?**\n \n\n---\n file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -11,18 +11,17 @@\n ```\n \n \n-After you built a Jina project, the next step is to deploy and host it somewhere. JCloud simplifies deploying and hosting your Jina projects on Jina Cloud. It provides a simple CLI with five commands to manage the lifecycle of your Jina projects.\n-\n-Strictly speaking JCloud has two parts: the cloud part (i.e. Jina Cloud) and the client part. Specifically, using JCloud means deploying a Jina project with the client to the cloud. This chapter will guide you to use client.\n+After building a Jina project, the next step is to deploy and host it on Cloud. JCloud simplifies deploying and hosting your Jina projects on Jina Cloud. It provides a simple CLI with five commands to manage the lifecycle of your Jina projects.\n \n ```{tip}\n-At this Jina Cloud hosts your Jina project and offers computational and storage resources **for free**!\n+At this point, Jina Cloud hosts all your Jina projects and offers computational/storage resources **for free**!\n ```\n \n ```{toctree}\n :hidden:\n \n basic\n+resources\n advanced\n faq\n ```\n\n---\n file path A: None | file path B: docs/fundamentals/jcloud/resources.md\n\n@@ -0,0 +1,147 @@\n+## Resources\n+\n+Since each Executor has its own business logic, it might need different Cloud resources. One might need a higher RAM, whereas another might need a bigger disk. \n+\n+In JCloud, we allow users to pass highly customizable, fine-grained resource requests for each Executor using `resources` argument in your Flow YAML.\n+\n+### Memory\n+\n+By default, `100M` of RAM is allocated to each Executor. You can use `memory` arg under `resources` to customise it.\n+\n+```{note}\n+Maximum of 16G RAM is allowed per Executor.\n+```\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+    jcloud:\n+      resources:\n+        memory: 8G\n+```\n+\n+### CPU\n+\n+By default, `0.1 (1/10 of a core)` CPU is allocated to each Executor. You can use `cpu` arg under `resources` to customise it.\n+\n+```{note}\n+Maximum of 16 cores is allowed per Executor.\n+```\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+    jcloud:\n+      resources:\n+        cpu: 0.5\n+```\n+\n+### Storage\n+\n+JCloud supports 2 kinds of Storage types [efs](https://aws.amazon.com/efs/) (default) and [ebs](https://aws.amazon.com/ebs/). The former one is a network file storage, whereas the latter is a block device.\n+\n+````{note}\n+\n+By default, we attach an `efs` to all the Executors in a Flow. The benefits of doing so are\n+\n+- It can grow in size dynamically, so you don't need to shrink/grow volumes as & when necessary.\n+- All Executors in the Flow can share a disk.\n+- The same disk can also be shared with another Flow by passing a workspace-id while deploying a Flow.\n+\n+```bash\n+jc deploy flow.yml --workspace-id <prev-flow-id>\n+```\n+\n+If your Executor needs high IO, you can use `ebs` instead. Please note that,\n+\n+- The disk cannot be shared with other Executors / Flows.\n+- You must pass a size of storage (default: `1G`, max `10G`).\n+\n+````\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+    jcloud:\n+      resources:\n+        storage:\n+          type: ebs\n+          size: 10G\n+  - name: executor2\n+    uses: jinahub+docker://Executor2\n+    jcloud:\n+      resources:\n+        storage:\n+          type: efs\n+```\n+\n+### GPU\n+\n+JCloud supports GPU workloads with two different usages - `shared` & `dedicated`.\n+\n+```{note}\n+When using GPU resources, it may take few extra mins until all Executors ready to serve traffic.\n+```\n+\n+#### Shared\n+\n+An executor using a `shared` GPU shares this GPU with up to 10 other Executors.\n+This enables a time-slicing, which allows workloads that land on oversubscribed GPUs to interleave with one another.\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+    jcloud:\n+      resources:\n+        gpu: shared\n+```\n+\n+```{caution}\n+There are no special provisions in place to isolate replicas that run on the same underlying GPU. Each workload has access to the GPU memory and runs in the same fault-domain as of all the others. Therefore, if one workload crashes, they all do. \n+```\n+\n+#### Dedicated\n+\n+Using a dedicated GPU is the default way to provision GPU for the Executor. This will automatically create nodes or assign the Executor to land on a GPU node. In this case, executor owns the whole GPU. You can assign between 1 and 4 GPUs.\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: executor1\n+    uses: jinahub+docker://Executor1\n+    jcloud:\n+      resources:\n+        gpu: 2\n+```\n+\n+\n+## Example\n+\n+Here's a Flow with 2 Executors with specific resource needs. `indexer` demands for 10G `ebs` disk, whereas `encoder` demands for 2 cores, 8G RAM & 2 dedicated GPUs. \n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: indexer\n+    uses: jinahub+docker://Indexer\n+    jcloud:\n+      resources:\n+        storage: \n+          type: ebs\n+          size: 10G\n+  - name: encoder\n+    uses: jinahub+docker://Encoder\n+    jcloud:\n+      resources:\n+        cpu: 2\n+        memory: 8G\n+        gpu: 2\n+```\n\n\n###\n\n", "completion": "docs: refactor resources, add gpu, kong  (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -212,6 +212,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14537,3 +14538,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```81999e97```](https://github.com/jina-ai/jina/commit/81999e970c0c7f5e6fc1b1584fa1dbe0faa628ab)] __-__ __version__: the next version will be 3.7.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-4></a>\n+## Release Note (`3.7.4`)\n+\n+> Release time: 2022-08-03 12:31:57\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```4c3d760f```](https://github.com/jina-ai/jina/commit/4c3d760f511da2c8716bd01c2f4566040b8d500e)] __-__ do not send target_executor to Executors (#5041) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```a51b42cc```](https://github.com/jina-ai/jina/commit/a51b42cc74a57427282ef5d0f6933b7791a1b3a4)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```ecb95829```](https://github.com/jina-ai/jina/commit/ecb95829f67d594616d5650086cbfaea1c598e97)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```286bdce8```](https://github.com/jina-ai/jina/commit/286bdce8b2c3afcb3b65a76c49dd6343bb28e171)] __-__ __version__: the next version will be 3.7.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.4'\n+__version__ = '3.7.5'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.5"}
{"prompt": " file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -140,6 +140,10 @@ class RequestHandler:\n                     has_specific_params = True\n                     break\n \n+            target_executor = request.header.target_executor\n+            # reset it in case we send to an external gateway\n+            request.header.target_executor = ''\n+\n             for origin_node in request_graph.origin_nodes:\n                 leaf_tasks = origin_node.get_leaf_tasks(\n                     connection_pool=connection_pool,\n@@ -147,7 +151,7 @@ class RequestHandler:\n                     previous_task=None,\n                     endpoint=endpoint,\n                     executor_endpoint_mapping=self._executor_endpoint_mapping,\n-                    target_executor_pattern=request.header.target_executor,\n+                    target_executor_pattern=target_executor or None,\n                     request_input_parameters=request_input_parameters,\n                     request_input_has_specific_params=has_specific_params,\n                     copy_request_at_send=num_outgoing_nodes > 1 and has_specific_params\n\n---\n file path A: tests/integration/external_deployment/test_external_deployment.py | file path B: tests/integration/external_deployment/test_external_deployment.py\n\n@@ -58,7 +58,7 @@ class MyExternalExecutor(Executor):\n \n @pytest.mark.parametrize('num_shards', [1, 2], indirect=True)\n def test_flow_with_external_deployment(\n-    external_deployment, external_deployment_args, input_docs, num_shards\n+        external_deployment, external_deployment_args, input_docs, num_shards\n ):\n     with external_deployment:\n         external_args = vars(external_deployment_args)\n@@ -80,7 +80,7 @@ def test_flow_with_external_deployment(\n \n @pytest.mark.parametrize('num_shards', [2], indirect=True)\n def test_two_flow_with_shared_external_deployment(\n-    external_deployment, external_deployment_args, input_docs, num_shards\n+        external_deployment, external_deployment_args, input_docs, num_shards\n ):\n     external_deployment.head_args.disable_reduce = True\n     with external_deployment:\n@@ -96,8 +96,8 @@ def test_two_flow_with_shared_external_deployment(\n \n         flow2 = (\n             Flow()\n-            .add(name='foo')\n-            .add(\n+                .add(name='foo')\n+                .add(\n                 **external_args,\n                 name='external_fake',\n                 external=True,\n@@ -161,12 +161,12 @@ def external_deployment_shards_2(external_deployment_shards_2_args):\n \n @pytest.mark.parametrize('num_shards', [1, 2], indirect=True)\n def test_flow_with_external_deployment_shards(\n-    external_deployment_shards_1,\n-    external_deployment_shards_2,\n-    external_deployment_shards_1_args,\n-    external_deployment_shards_2_args,\n-    input_docs,\n-    num_shards,\n+        external_deployment_shards_1,\n+        external_deployment_shards_2,\n+        external_deployment_shards_1_args,\n+        external_deployment_shards_2_args,\n+        input_docs,\n+        num_shards,\n ):\n     with external_deployment_shards_1, external_deployment_shards_2:\n         external_args_1 = vars(external_deployment_shards_1_args)\n@@ -179,20 +179,20 @@ def test_flow_with_external_deployment_shards(\n         del external_args_2['deployment_role']\n         flow = (\n             Flow()\n-            .add(name='executor1')\n-            .add(\n+                .add(name='executor1')\n+                .add(\n                 **external_args_1,\n                 name='external_fake_1',\n                 external=True,\n                 needs=['executor1'],\n             )\n-            .add(\n+                .add(\n                 **external_args_2,\n                 name='external_fake_2',\n                 external=True,\n                 needs=['executor1'],\n             )\n-            .needs(needs=['external_fake_1', 'external_fake_2'], port=random_port())\n+                .needs(needs=['external_fake_1', 'external_fake_2'], port=random_port())\n         )\n \n         with flow:\n@@ -226,10 +226,10 @@ def external_deployment_pre_shards(external_deployment_pre_shards_args):\n \n @pytest.mark.parametrize('num_shards', [1, 2], indirect=True)\n def test_flow_with_external_deployment_pre_shards(\n-    external_deployment_pre_shards,\n-    external_deployment_pre_shards_args,\n-    input_docs,\n-    num_shards,\n+        external_deployment_pre_shards,\n+        external_deployment_pre_shards_args,\n+        input_docs,\n+        num_shards,\n ):\n     with external_deployment_pre_shards:\n         external_args = vars(external_deployment_pre_shards_args)\n@@ -238,20 +238,20 @@ def test_flow_with_external_deployment_pre_shards(\n         del external_args['deployment_role']\n         flow = (\n             Flow()\n-            .add(\n+                .add(\n                 **external_args,\n                 name='external_fake',\n                 external=True,\n             )\n-            .add(\n+                .add(\n                 name='executor1',\n                 needs=['external_fake'],\n             )\n-            .add(\n+                .add(\n                 name='executor2',\n                 needs=['external_fake'],\n             )\n-            .needs(['executor1', 'executor2'])\n+                .needs(['executor1', 'executor2'])\n         )\n         with flow:\n             resp = flow.index(inputs=input_docs)\n@@ -286,10 +286,10 @@ def external_deployment_join(external_deployment_join_args):\n \n @pytest.mark.parametrize('num_shards', [1, 2], indirect=True)\n def test_flow_with_external_deployment_join(\n-    external_deployment_join,\n-    external_deployment_join_args,\n-    input_docs,\n-    num_shards,\n+        external_deployment_join,\n+        external_deployment_join_args,\n+        input_docs,\n+        num_shards,\n ):\n     with external_deployment_join:\n         external_args = vars(external_deployment_join_args)\n@@ -298,19 +298,19 @@ def test_flow_with_external_deployment_join(\n         del external_args['deployment_role']\n         flow = (\n             Flow()\n-            .add(\n+                .add(\n                 **external_args,\n                 external=True,\n             )\n-            .add(\n+                .add(\n                 name='executor1',\n                 needs=['executor0'],\n             )\n-            .add(\n+                .add(\n                 name='executor2',\n                 needs=['executor0'],\n             )\n-            .needs(\n+                .needs(\n                 **external_args,\n                 external=True,\n                 needs=['executor1', 'executor2'],\n@@ -321,3 +321,23 @@ def test_flow_with_external_deployment_join(\n \n         # Reducing applied everywhere, expect 50 docs, same as the input\n         validate_response(resp, len(input_docs))\n+\n+\n+def test_external_flow_with_target_executor():\n+    class ExtExecutor(Executor):\n+\n+        @requests\n+        def foo(self, docs, **kwargs):\n+            for doc in docs:\n+                doc.text = 'external'\n+\n+    external_flow = Flow().add(uses=ExtExecutor)\n+\n+    with external_flow:\n+        d = Document(text='sunset with green landscape by the river')\n+        f = Flow().add(port=external_flow.port, external=True, name='external_executor')\n+        with f:\n+            response = f.post(on='/', inputs=d, target_executor='external_executor')\n+\n+\n+    assert response[0].text == 'external'\n\n\n###\n\n", "completion": "fix: do not send target_executor to Executors (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -211,6 +211,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14515,3 +14516,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```5116b922```](https://github.com/jina-ai/jina/commit/5116b92271f174002be6de545bd4a64d3d023586)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```32dd47af```](https://github.com/jina-ai/jina/commit/32dd47af6d0255dc93e1d2aac234171dfc3b86b0)] __-__ __version__: the next version will be 3.7.2 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-3></a>\n+## Release Note (`3.7.3`)\n+\n+> Release time: 2022-07-28 14:29:23\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```032bd5e6```](https://github.com/jina-ai/jina/commit/032bd5e662dd16d4cfb394857074779970ae444a)] __-__ fix specific params problem with branches (#5038) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```81999e97```](https://github.com/jina-ai/jina/commit/81999e970c0c7f5e6fc1b1584fa1dbe0faa628ab)] __-__ __version__: the next version will be 3.7.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.3'\n+__version__ = '3.7.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.4"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -210,6 +210,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14494,3 +14495,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```87cede55```](https://github.com/jina-ai/jina/commit/87cede55c78d05c18cb1c28de901865a67257500)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d7f6860f```](https://github.com/jina-ai/jina/commit/d7f6860f3666a8670e817f7b18914876fea52f5b)] __-__ __version__: the next version will be 3.7.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-2></a>\n+## Release Note (`3.7.2`)\n+\n+> Release time: 2022-07-28 09:19:06\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Zac Li,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```fb88015e```](https://github.com/jina-ai/jina/commit/fb88015e2b0ce4d68099903f25de966563ebfa97)] __-__ add more logging in grpc dry run (#5036) (*Zac Li*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```5116b922```](https://github.com/jina-ai/jina/commit/5116b92271f174002be6de545bd4a64d3d023586)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```32dd47af```](https://github.com/jina-ai/jina/commit/32dd47af6d0255dc93e1d2aac234171dfc3b86b0)] __-__ __version__: the next version will be 3.7.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.2'\n+__version__ = '3.7.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.3"}
{"prompt": " file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -46,6 +46,10 @@ class GRPCBaseClient(BaseClient):\n                 )\n                 if response.code == jina_pb2.StatusProto.SUCCESS:\n                     return True\n+                else:\n+                    self.logger.error(\n+                        f'Returned code is not expected! Exception: {response.exception}'\n+                    )\n         except Exception as e:\n             self.logger.error(f'Error while getting response from grpc server {e!r}')\n \n\n---\n file path A: jina/clients/base/http.py | file path B: jina/clients/base/http.py\n\n@@ -65,7 +65,7 @@ class HTTPBaseClient(BaseClient):\n                 if r_str['code'] == jina_pb2.StatusProto.SUCCESS:\n                     return True\n                 else:\n-                    self.logger.debug(\n+                    self.logger.error(\n                         f'Returned code is not expected! Description: {r_str[\"description\"]}'\n                     )\n             except Exception as e:\n\n\n###\n\n", "completion": "fix: add more logging in grpc dry run (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -209,6 +209,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14452,3 +14453,43 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```1f34093a```](https://github.com/jina-ai/jina/commit/1f34093ae5d8ddeeb659cdd6bc95ad83a7704779)] __-__ bump jina version (#5022) (*Joan Fontanals*)\n  - [[```4af73ba1```](https://github.com/jina-ai/jina/commit/4af73ba1a56594b2076ba058f976977862bae029)] __-__ __version__: the next version will be 3.6.17 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-1></a>\n+## Release Note (`3.7.1`)\n+\n+> Release time: 2022-07-27 11:10:20\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Zac Li,  Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```277756d8```](https://github.com/jina-ai/jina/commit/277756d877ade63aef4d87e96746001684ccb02a)] __-__ add telemetry (#5024) (*Joan Fontanals*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```b33b21fc```](https://github.com/jina-ai/jina/commit/b33b21fc28d84d3652e17690666a5bf8737397bf)] __-__ fix the name of the event from runtimes (#5034) (*Joan Fontanals*)\n+ - [[```28a8ae4c```](https://github.com/jina-ai/jina/commit/28a8ae4c851f5af6c1d8d158dd619cc87104245a)] __-__ fix get openapi schemas (#5035) (*Joan Fontanals*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```f37aba6a```](https://github.com/jina-ai/jina/commit/f37aba6a569f80d34e6cad70b462b1767d71866e)] __-__ hide tgraph, cpool and streaming under new usable api (#5031) (*Joan Fontanals*)\n+ - [[```d4f79ea9```](https://github.com/jina-ai/jina/commit/d4f79ea9a15d80cc51c59209655cc277763073d3)] __-__ small refactor on streamer (#5030) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```38ece9fa```](https://github.com/jina-ai/jina/commit/38ece9fa55ea77431db10226cf1f2dc206d79dea)] __-__ update jcloud auth docs (#5029) (*Zac Li*)\n+ - [[```38e8f2f2```](https://github.com/jina-ai/jina/commit/38e8f2f2b61ea4f080cb924138caea88fcedebb3)] __-__ add jcloud cpu docs (#5026) (*Zac Li*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```7ff2a4c3```](https://github.com/jina-ai/jina/commit/7ff2a4c3d4fb23ff3cee074e8c96abf0015905b8)] __-__ divide unit orchestrate flow slow tests (#5025) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```feb9ad75```](https://github.com/jina-ai/jina/commit/feb9ad75f1416151bc21144983e628d943717522)] __-__ fix readme (*Han Xiao*)\n+ - [[```87cede55```](https://github.com/jina-ai/jina/commit/87cede55c78d05c18cb1c28de901865a67257500)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d7f6860f```](https://github.com/jina-ai/jina/commit/d7f6860f3666a8670e817f7b18914876fea52f5b)] __-__ __version__: the next version will be 3.7.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.1'\n+__version__ = '3.7.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.2"}
{"prompt": " file path A: jina/serve/runtimes/asyncio.py | file path B: jina/serve/runtimes/asyncio.py\n\n@@ -66,7 +66,7 @@ class AsyncNewLoopRuntime(BaseRuntime, MonitoringMixin, ABC):\n         self._setup_monitoring()\n         if not self.args.optout_telemetry and 'JINA_DISABLE_TELMETRY' not in os.environ:\n             from jina.serve.helper import _telemetry_run_in_thread\n-            _telemetry_run_in_thread(event=f'{type(self)}.start')\n+            _telemetry_run_in_thread(event=f'{self.__class__.__name__}.start')\n         self._loop.run_until_complete(self.async_setup())\n \n     def run_forever(self):\n\n\n###\n\n", "completion": "fix: fix the name of the event from runtimes (#<issue-num>)"}
{"prompt": " file path A: scripts/get-openapi-schemas.py | file path B: scripts/get-openapi-schemas.py\n\n@@ -2,8 +2,6 @@ import json\n \n from jina.logging.logger import JinaLogger\n from jina.parsers import set_gateway_parser\n-from jina.serve.networking import GrpcConnectionPool\n-from jina.serve.runtimes.gateway.graph.topology_graph import TopologyGraph\n from jina.serve.runtimes.gateway.http.app import get_fastapi_app\n \n JINA_LOGO_URL = 'https://api.jina.ai/logo/logo-product/jina-core/horizontal-layout/colored/Product%20logo_Core_vertical_colorful%402x-margin.png'\n@@ -14,8 +12,6 @@ args = set_gateway_parser().parse_args([])\n logger = JinaLogger('')\n gateway_app = get_fastapi_app(\n     args,\n-    topology_graph=TopologyGraph({}),\n-    connection_pool=GrpcConnectionPool(logger=logger),\n     logger=logger,\n )\n gateway_schema = gateway_app.openapi()\n\n\n###\n\n", "completion": "fix: fix get openapi schemas (#<issue-num>)"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -755,12 +755,6 @@ class GrpcConnectionPool:\n                 shard_id = 0\n             return await self._connections.remove_replica(deployment, address, shard_id)\n \n-    def start(self):\n-        \"\"\"\n-        Starts the connection pool\n-        \"\"\"\n-        pass\n-\n     async def close(self):\n         \"\"\"\n         Closes the connection pool\n\n---\n file path A: jina/serve/runtimes/gateway/grpc/__init__.py | file path B: jina/serve/runtimes/gateway/grpc/__init__.py\n\n@@ -131,7 +131,6 @@ class GRPCGatewayRuntime(GatewayRuntime):\n \n     async def async_run_forever(self):\n         \"\"\"The async running of server.\"\"\"\n-        self._connection_pool.start()\n         await self.server.wait_for_termination()\n \n     async def dry_run(self, empty, context) -> jina_pb2.StatusProto:\n\n---\n file path A: jina/serve/runtimes/gateway/http/__init__.py | file path B: jina/serve/runtimes/gateway/http/__init__.py\n\n@@ -89,8 +89,7 @@ class HTTPGatewayRuntime(GatewayRuntime):\n         await self._server.setup()\n \n     async def async_run_forever(self):\n-        \"\"\"Running method of ther server.\"\"\"\n-        self._connection_pool.start()\n+        \"\"\"Running method of the server.\"\"\"\n         await self._server.serve()\n \n     async def _wait_for_cancel(self):\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/__init__.py | file path B: jina/serve/runtimes/gateway/websocket/__init__.py\n\n@@ -90,7 +90,6 @@ class WebSocketGatewayRuntime(GatewayRuntime):\n \n     async def async_run_forever(self):\n         \"\"\"Running method of ther server.\"\"\"\n-        self._connection_pool.start()\n         await self._server.serve()\n \n     async def _wait_for_cancel(self):\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/app.py | file path B: jina/serve/runtimes/gateway/websocket/app.py\n\n@@ -130,7 +130,6 @@ def get_fastapi_app(\n         ),\n         result_handler=request_handler.handle_result(),\n     )\n-\n     streamer.Call = streamer.stream\n \n     @app.get(\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -179,7 +179,6 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n \n     async def async_run_forever(self):\n         \"\"\"Block until the GRPC server is terminated\"\"\"\n-        self.connection_pool.start()\n         await self._grpc_server.wait_for_termination()\n \n     async def async_cancel(self):\n\n\n###\n\n", "completion": "refactor: small refactor on streamer (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/basic.md | file path B: docs/fundamentals/jcloud/basic.md\n\n@@ -22,6 +22,8 @@ jc login\n \n You can use a Google/GitHub account to register and login. Without logging in, you can't do anything.\n \n+If you have no access to the web browser in your integration environment, you can set the Environment Variable `JINA_AUTH_TOKEN` using auth token before working with JCloud. Auth token can be generated by user login or Personal Access Token (PAT) creation, please visit [jina-auth](https://github.com/jina-ai/auth) for more information (`jc` includes `jina-auth` already).\n+\n ## Deploy\n \n In Jina's idiom, a project is a [Flow](https://docs.jina.ai/fundamentals/flow/), which represents an end-to-end task such as indexing, searching or recommending. In this README, we will use \"project\" and \"Flow\" interchangeably.\n\n\n###\n\n", "completion": "docs: update jcloud auth docs (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -32,6 +32,20 @@ executors:\n         memory: 8G\n ```\n \n+### CPU\n+\n+By default, `jcloud` allocates `0.1 (1/10 of a core)` CPU to each Executor. There might be cases where your Executor requires more CPU; you can do so by using `resources` arg while deploying the Flow (max 16 CPU allowed per Executor). The input value should be a number, indicating the number of full CPU cores.\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: custom1\n+    uses: jinahub+docker://CustomExecutor1\n+    jcloud:\n+      resources:\n+        cpu: 0.5\n+```\n+\n ### storage\n \n We currently support 2 kinds of storage types [efs](https://aws.amazon.com/efs/) (default) and [ebs](https://aws.amazon.com/ebs/). The former one is a network file storage, whereas the latter is a block device.\n\n\n###\n\n", "completion": "docs: add jcloud cpu docs (#<issue-num>)"}
{"prompt": " file path A: scripts/get-all-test-paths.sh | file path B: scripts/get-all-test-paths.sh\n\n@@ -1,17 +1,19 @@\n #!/usr/bin/env bash\n set -ex\n if [[ $1 == \"windows\" ]]; then\n-    declare -a array2=( $(ls -d tests/{unit}/*/ | grep -v '__pycache__'| grep -v 'unit/serve' | grep -v 'unit/orchestrate'))\n-    declare -a array3=( $(ls -d tests/{unit}/orchestrate/*/ | grep -v '__pycache__'))\n-    declare -a array4=( $(ls -d tests/{unit}/serve/*/ | grep -v '__pycache__'))\n-    dest1=( \"${array2[@]}\" \"${array3[@]}\" \"${array4[@]}\" )\n+    declare -a unit_base=( $(ls -d tests/{unit}/*/ | grep -v '__pycache__'| grep -v 'unit/serve' | grep -v 'unit/orchestrate'))\n+    declare -a unit_orchestrate_flow=( $(ls -d tests/unit/orchestrate/flow/*/ | grep -v '__pycache__'))\n+    declare -a unit_orchestrate=( $(ls -d tests/unit/orchestrate/*/ | grep -v '__pycache__' | grep -v 'orchestrate/flow'))\n+    declare -a unit_serve=( $(ls -d tests/{unit}/serve/*/ | grep -v '__pycache__'))\n+    dest1=( \"${unit_base[@]}\" \"${unit_orchestrate_flow[@]}\" \"${unit_orchestrate[@]}\" \"${unit_serve[@]}\" )\n     printf '%s\\n' \"${dest1[@]}\" | jq -R . | jq -cs .\n else\n-    declare -a array1=( \"tests/unit/*.py\" \"tests/integration/*.py\")\n-    declare -a array2=( $(ls -d tests/{unit,integration}/*/ | grep -v '__pycache__' | grep -v 'unit/serve' | grep -v 'unit/orchestrate'))\n-    declare -a array3=( $(ls -d tests/unit/orchestrate/*/ | grep -v '__pycache__'))\n-    declare -a array4=( $(ls -d tests/unit/serve/*/ | grep -v '__pycache__'))\n-    dest=( \"${array1[@]}\" \"${array2[@]}\" \"${array3[@]}\" \"${array4[@]}\" )\n+    declare -a unit_integration_base=( \"tests/unit/*.py\" \"tests/integration/*.py\")\n+    declare -a unit_integration_base_2=( $(ls -d tests/{unit,integration}/*/ | grep -v '__pycache__' | grep -v 'unit/serve' | grep -v 'unit/orchestrate'))\n+    declare -a orchestrate_flow=( $(ls -d tests/unit/orchestrate/flow/*/ | grep -v '__pycache__'))\n+    declare -a orchestrate_base=( $(ls -d tests/unit/orchestrate/*/ | grep -v '__pycache__' | grep -v 'orchestrate/flow'))\n+    declare -a unit_serve=( $(ls -d tests/unit/serve/*/ | grep -v '__pycache__'))\n+    dest=( \"${unit_integration_base[@]}\" \"${unit_integration_base_2[@]}\" \"${orchestrate_flow[@]}\" \"${orchestrate_base[@]}\" \"${unit_serve[@]}\" )\n \n     printf '%s\\n' \"${dest[@]}\" | jq -R . | jq -cs .\n fi\n\\ No newline at end of file\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_floating_pod.py | file path B: None\n\n@@ -1,24 +0,0 @@\n-import pytest\n-\n-from jina import Document, Executor, Flow, requests\n-\n-\n-class MyExecutor(Executor):\n-    @requests\n-    async def add_text(self, docs, **kwargs):\n-        docs[0].text = 'hello'\n-\n-\n-@pytest.mark.parametrize('floating, expect_str', [(True, 'world'), (False, 'hello')])\n-def test_floating_pod(floating, expect_str):\n-    f = (\n-        Flow()\n-        .add(replicas=3, name='a1')\n-        .add(name='a2', floating=floating, uses=MyExecutor)\n-        .add(name='a3')\n-        .add(floating=floating, uses=MyExecutor)\n-    )\n-\n-    with f:\n-        da = f.post('/', Document(text='world'))\n-        assert da[0].text == expect_str\n\n\n###\n\n", "completion": "ci: divide unit orchestrate flow slow tests (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -208,6 +208,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14433,3 +14434,19 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```c01a9fee```](https://github.com/jina-ai/jina/commit/c01a9fee2965584dea48b91383fd414c69acabc9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```394bf110```](https://github.com/jina-ai/jina/commit/394bf11051ce787dd010bed32790940968bb7419)] __-__ __version__: the next version will be 3.6.16 (*Jina Dev Bot*)\n \n+<a name=release-note-3-7-0></a>\n+## Release Note (`3.7.0`)\n+\n+> Release time: 2022-07-21 08:50:56\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```1f34093a```](https://github.com/jina-ai/jina/commit/1f34093ae5d8ddeeb659cdd6bc95ad83a7704779)] __-__ bump jina version (#5022) (*Joan Fontanals*)\n+ - [[```4af73ba1```](https://github.com/jina-ai/jina/commit/4af73ba1a56594b2076ba058f976977862bae029)] __-__ __version__: the next version will be 3.6.17 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.7.0'\n+__version__ = '3.7.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.7.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.17'\n+__version__ = '3.7.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: bump jina version (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -207,6 +207,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14406,3 +14407,29 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```6a8ceaad```](https://github.com/jina-ai/jina/commit/6a8ceaadad702ed0f239f04e7f95c7e60d5a73e9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```356d2b76```](https://github.com/jina-ai/jina/commit/356d2b76c844422ff542f5189de1e568beff87eb)] __-__ __version__: the next version will be 3.6.15 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-16></a>\n+## Release Note (`3.6.16`)\n+\n+> Release time: 2022-07-21 08:22:03\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Roshan Jossy,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```1b3edacf```](https://github.com/jina-ai/jina/commit/1b3edacf531e4e8d29eac4ea73785f8d201255d6)] __-__ wait for floating Executor tasks (#5004) (*Joan Fontanals*)\n+ - [[```6ba1d165```](https://github.com/jina-ai/jina/commit/6ba1d165a2aad8e863006be69c813b5cac3d8a21)] __-__ do not await gather endpoints, simply schedule task (#5015) (*Joan Fontanals*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```6f5b3f2a```](https://github.com/jina-ai/jina/commit/6f5b3f2a9b13c2eae78b746531132cbfcdc8c2da)] __-__ fix endpoint discovery tries (#5014) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```c9b68d3d```](https://github.com/jina-ai/jina/commit/c9b68d3d15d46ee7d62d9f7e1f22c539fb309f8b)] __-__ update action to update dockerhub description (#5021) (*Roshan Jossy*)\n+ - [[```c01a9fee```](https://github.com/jina-ai/jina/commit/c01a9fee2965584dea48b91383fd414c69acabc9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```394bf110```](https://github.com/jina-ai/jina/commit/394bf11051ce787dd010bed32790940968bb7419)] __-__ __version__: the next version will be 3.6.16 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.16'\n+__version__ = '3.6.17'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.17"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -25,11 +25,11 @@ jobs:\n           fetch-depth: 100\n       - run: |\n           truncate --size=24KB README.md > README-trunc.md\n-      - uses: peter-evans/dockerhub-description@v2.3.0\n-        env:\n-          DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_DEVBOT_USER }}\n-          DOCKERHUB_PASSWORD: ${{ secrets.DOCKERHUB_DEVBOT_PWD }}\n-          DOCKERHUB_REPOSITORY: jinaai/jina\n+      - uses: peter-evans/dockerhub-description@v3\n+        with:\n+          username: ${{ secrets.DOCKERHUB_DEVBOT_USER  }}\n+          password: ${{ secrets.DOCKERHUB_DEVBOT_PWD }}\n+          repository: jinaai/jina\n           readme-filepath: ./README-trunc.md\n       - uses: actions/checkout@v2\n         with:\n\n\n###\n\n", "completion": "chore: update action to update dockerhub description (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -206,6 +206,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14384,3 +14385,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```c056fad0```](https://github.com/jina-ai/jina/commit/c056fad074ae6f46a61b193fd89af6b7f0751be8)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```e710e2ea```](https://github.com/jina-ai/jina/commit/e710e2eaa85337b047c45694bb640c5033d951be)] __-__ __version__: the next version will be 3.6.14 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-15></a>\n+## Release Note (`3.6.15`)\n+\n+> Release time: 2022-07-18 08:02:57\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```6e0652c6```](https://github.com/jina-ai/jina/commit/6e0652c68daf29c3957326762d3c384e5f53e766)] __-__ disable deploy sandbox when plotting (#5017) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```6a8ceaad```](https://github.com/jina-ai/jina/commit/6a8ceaadad702ed0f239f04e7f95c7e60d5a73e9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```356d2b76```](https://github.com/jina-ai/jina/commit/356d2b76c844422ff542f5189de1e568beff87eb)] __-__ __version__: the next version will be 3.6.15 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.15'\n+__version__ = '3.6.16'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.16"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1283,7 +1283,9 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         )\n \n     @allowed_levels([FlowBuildLevel.EMPTY])\n-    def build(self, copy_flow: bool = False) -> 'Flow':\n+    def build(\n+        self, copy_flow: bool = False, disable_build_sandbox: bool = False\n+    ) -> 'Flow':\n         \"\"\"\n         Build the current Flow and make it ready to use\n \n@@ -1293,6 +1295,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n             context manager, or using :meth:`start`, :meth:`build` will be invoked.\n \n         :param copy_flow: when set to true, then always copy the current Flow and do the modification on top of it then return, otherwise, do in-line modification\n+        :param disable_build_sandbox: when set to true, the sandbox building part will be skipped, will be used by `plot`\n         :return: the current Flow (by default)\n \n         .. note::\n@@ -1317,8 +1320,9 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         if op_flow.args.inspect == FlowInspectType.COLLECT:\n             op_flow.gather_inspect(copy_flow=False)\n \n-        for deployment in self._deployment_nodes.values():\n-            deployment.update_sandbox_args()\n+        if not disable_build_sandbox:\n+            for deployment in self._deployment_nodes.values():\n+                deployment.update_sandbox_args()\n \n         if GATEWAY_NAME not in op_flow._deployment_nodes:\n             op_flow._add_gateway(\n@@ -1729,7 +1733,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         )\n \n         if build and op_flow._build_level.value == FlowBuildLevel.EMPTY:\n-            op_flow.build(False)\n+            op_flow.build(copy_flow=False, disable_build_sandbox=True)\n \n         mermaid_str = op_flow._mermaid_str\n         if vertical_layout:\n\n\n###\n\n", "completion": "feat: disable deploy sandbox when plotting (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -205,6 +205,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14360,3 +14361,25 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```5987b1e2```](https://github.com/jina-ai/jina/commit/5987b1e2acf9a07a7d2ac5759deb4cc809c0695e)] __-__ __version__: the next version will be 3.6.13 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-14></a>\n+## Release Note (`3.6.14`)\n+\n+> Release time: 2022-07-17 15:52:56\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ felix-wang,  Han Xiao,  Jina Dev Bot,  Joan Fontanals,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```b2304e6b```](https://github.com/jina-ai/jina/commit/b2304e6ba700e4b7b73f1ca840f46868b34d8bfc)] __-__ use python module path in pymodules (#5013) (*felix-wang*)\n+ - [[```d23ad848```](https://github.com/jina-ai/jina/commit/d23ad84874567cf08c5aeb08aeeeb10ac4476eee)] __-__ fix the async request iterator prefetching behavior (#5012) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```21edc961```](https://github.com/jina-ai/jina/commit/21edc9614a0300b46d7260f90632277885fb0c0d)] __-__ update docs (*Han Xiao*)\n+ - [[```c056fad0```](https://github.com/jina-ai/jina/commit/c056fad074ae6f46a61b193fd89af6b7f0751be8)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```e710e2ea```](https://github.com/jina-ai/jina/commit/e710e2eaa85337b047c45694bb640c5033d951be)] __-__ __version__: the next version will be 3.6.14 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.14'\n+__version__ = '3.6.15'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.15"}
{"prompt": " file path A: jina/jaml/helper.py | file path B: jina/jaml/helper.py\n\n@@ -216,6 +216,8 @@ def complete_path(\n         return os.path.abspath(_p)\n     elif raise_nonexist:\n         raise FileNotFoundError(f'can not find {path}')\n+    else:\n+        return path\n \n \n def _search_file_in_paths(path, extra_search_paths: Optional[List[str]] = None):\n\n---\n file path A: None | file path B: tests/unit/serve/executors/dummy_executor.py\n\n@@ -0,0 +1,13 @@\n+from jina import Executor, requests\n+\n+\n+class MyExecutor(Executor):\n+    def __init__(self, bar, **kwargs):\n+        super().__init__(**kwargs)\n+        self.bar = bar\n+\n+    @requests\n+    def process(self, docs, **kwargs):\n+        for d in docs:\n+            d.text = 'hello world'\n+        return docs\n\n---\n file path A: tests/unit/serve/executors/metas_executors.py | file path B: tests/unit/serve/executors/metas_executors.py\n\n@@ -1,4 +1,4 @@\n-from jina import Executor, requests, DocumentArray\n+from jina import DocumentArray, Executor, requests\n \n \n class TestExecutor(Executor):\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -75,6 +75,31 @@ def test_executor_import_with_external_dependencies(capsys):\n     assert 'hello' in out\n \n \n+def test_executor_with_pymodule_path():\n+    with pytest.raises(FileNotFoundError):\n+        ex = Executor.load_config(\n+            '''\n+        jtype: BaseExecutor\n+        metas:\n+            py_modules:\n+                - jina.no_valide.executor\n+        '''\n+        )\n+\n+    ex = Executor.load_config(\n+        '''\n+    jtype: MyExecutor\n+    with:\n+        bar: 123\n+    metas:\n+        py_modules:\n+            - unit.serve.executors.dummy_executor\n+    '''\n+    )\n+    assert ex.bar == 123\n+    assert ex.process(DocumentArray([Document()]))[0].text == 'hello world'\n+\n+\n @property\n def workspace(self) -> str:\n     \"\"\"\n\n---\n file path A: tests/unit/serve/executors/test_set_metas.py | file path B: tests/unit/serve/executors/test_set_metas.py\n\n@@ -73,3 +73,6 @@ def test_name_python_jaml_identical():\n     # Make sure that the executor meta name is equal to only the class name\n     assert jaml_metas_name == 'TestExecutor'\n     assert py_metas_name == 'TestExecutor'\n+\n+    # Make sure that the executor can be loaded from a native python module path as well\n+    load_py_modules({'py_modules': ['metas_executors']})\n\n\n###\n\n", "completion": "fix: use python module path in pymodules (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -468,12 +468,12 @@ with Flow() as f:\n \n ````\n \n-\n+(client-compress)=\n ## Enable compression\n \n-If the communication to the Gateway is via gRPC, you can pass `compression` parameter to  {meth}`~jina.clients.mixin.PostMixin.post` to benefit from (gRPC compression)[https://grpc.github.io/grpc/python/grpc.html#compression] methods. \n+If the communication to the Gateway is via gRPC, you can pass `compression` parameter to  {meth}`~jina.clients.mixin.PostMixin.post` to benefit from [gRPC compression](https://grpc.github.io/grpc/python/grpc.html#compression) methods. \n \n-The supported choices are: None, `NoCompression`, `Gzip` and `Deflate`.\n+The supported choices are: None, `gzip` and `deflate`.\n \n ```python\n from jina import Client\n@@ -482,6 +482,11 @@ client = Client()\n client.post(..., compression='Gzip')\n ```\n \n+Note that this setting is only effective the communication between the client and the Flow's gateway.\n+\n+One can also specify the compression of the internal communication {ref}`as described here<serve-compress>`.\n+\n+\n ## Enable TLS\n \n To connect to a {class}`~jina.Flow` that has been {ref}`configured to use TLS <flow-tls>` in combination with gRPC, http, or websocket,\n\n---\n file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -19,7 +19,7 @@ For more proper use of the Client, and more information about the Client itself,\n \n (flow-protocol)=\n ## Supported protocols\n-You can use three different protocols to serve the `Flow`: `grpc`,`http` and `websocket`\n+You can use three different protocols to serve the `Flow`: gRPC, HTTP and Websocket.\n \n ````{tab} gRPC\n \n@@ -377,20 +377,23 @@ curl http://localhost:12345/status\n {\"jina\":{\"jina\":\"######\",\"docarray\":\"######\",\"jina-proto\":\"######\",\"jina-vcs-tag\":\"(unset)\",\"protobuf\":\"######\",\"proto-backend\":\"######\",\"grpcio\":\"######\",\"pyyaml\":\"######\",\"python\":\"######\",\"platform\":\"######\",\"platform-release\":\"######\",\"platform-version\":\"######\",\"architecture\":\"######\",\"processor\":\"######\",\"uid\":\"######\",\"session-id\":\"######\",\"uptime\":\"######\",\"ci-vendor\":\"(unset)\"},\"envs\":{\"JINA_AUTH_TOKEN\":\"(unset)\",\"JINA_DEFAULT_HOST\":\"(unset)\",\"JINA_DEFAULT_TIMEOUT_CTRL\":\"(unset)\",\"JINA_DEFAULT_WORKSPACE_BASE\":\"######\",\"JINA_DEPLOYMENT_NAME\":\"(unset)\",\"JINA_DISABLE_UVLOOP\":\"(unset)\",\"JINA_EARLY_STOP\":\"(unset)\",\"JINA_FULL_CLI\":\"(unset)\",\"JINA_GATEWAY_IMAGE\":\"(unset)\",\"JINA_GRPC_RECV_BYTES\":\"(unset)\",\"JINA_GRPC_SEND_BYTES\":\"(unset)\",\"JINA_HUBBLE_REGISTRY\":\"(unset)\",\"JINA_HUB_CACHE_DIR\":\"(unset)\",\"JINA_HUB_NO_IMAGE_REBUILD\":\"(unset)\",\"JINA_HUB_ROOT\":\"(unset)\",\"JINA_LOG_CONFIG\":\"(unset)\",\"JINA_LOG_LEVEL\":\"(unset)\",\"JINA_LOG_NO_COLOR\":\"(unset)\",\"JINA_MP_START_METHOD\":\"(unset)\",\"JINA_RANDOM_PORT_MAX\":\"(unset)\",\"JINA_RANDOM_PORT_MIN\":\"(unset)\",\"JINA_DISABLE_HEALTHCHECK_LOGS\":\"(unset)\",\"JINA_LOCKS_ROOT\":\"(unset)\"}}\n ```\n \n-\n+(server-compress)=\n ## Add gRPC compression\n \n-Communication between {class}`~jina.Executor`s inside a {class}`~jina.Flow` is done via `grpc`. To optimize the performance and the bandwidth of these connections,\n-Jina allows the users to specify their (`compression`)[https://grpc.github.io/grpc/python/grpc.html#compression] by passing this `compression` argument to the Flow.\n+The communication between {class}`~jina.Executor`s inside a {class}`~jina.Flow` is done via gRPC. To optimize the performance and the bandwidth of these connections,\n+Jina allows the users to specify their [compression](https://grpc.github.io/grpc/python/grpc.html#compression) by specifying `compression` argument to the Flow.\n \n-The supported methods are: `NoCompression`, `Gzip` and `Deflate`.\n+The supported methods are: none, `gzip` and `deflate`.\n \n ```python\n from jina import Flow\n \n-f = Flow(compression='Gzip').add(...)\n+f = Flow(compression='gzip').add(...)\n ```\n \n+Note that this setting is only effective the internal communication of the Flow.\n+One can also specify the compression between client and gateway {ref}`as described here<client-compress>`.\n+\n (flow-tls)=\n \n ## Enable TLS\n\n\n###\n\n", "completion": "chore: update docs"}
{"prompt": " file path A: jina/serve/stream/helper.py | file path B: jina/serve/stream/helper.py\n\n@@ -60,9 +60,6 @@ class AsyncRequestsIterator:\n         return self\n \n     async def __anext__(self):\n-        if self._prefetch > 0:\n-            while self._request_counter.count >= self._prefetch:\n-                await asyncio.sleep(0)\n         if isinstance(self.iterator, Iterator):\n \n             \"\"\"\n@@ -85,4 +82,7 @@ class AsyncRequestsIterator:\n             # we assume that `AsyncIterator` doesn't block the event loop\n             request = await self.iterator.__anext__()\n \n+        if self._prefetch > 0:\n+            while self._request_counter.count >= self._prefetch:\n+                await asyncio.sleep(0)\n         return request\n\n\n###\n\n", "completion": "fix: fix the async request iterator prefetching behavior (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -204,6 +204,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14338,3 +14339,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```1e0a8a77```](https://github.com/jina-ai/jina/commit/1e0a8a7733f98e51388d808794d84f1091f45bda)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n  - [[```674229ed```](https://github.com/jina-ai/jina/commit/674229ed40be920b8b15c1a6f1758121670937a2)] __-__ __version__: the next version will be 3.6.12 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-13></a>\n+## Release Note (`3.6.13`)\n+\n+> Release time: 2022-07-14 15:10:51\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ felix-wang,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```9e38b05b```](https://github.com/jina-ai/jina/commit/9e38b05b7e18f62fe900fda8f9f38690f86fd3a4)] __-__ map multiple endpoints to same func (#5009) (*felix-wang*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```5987b1e2```](https://github.com/jina-ai/jina/commit/5987b1e2acf9a07a7d2ac5759deb4cc809c0695e)] __-__ __version__: the next version will be 3.6.13 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.13'\n+__version__ = '3.6.14'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.14"}
{"prompt": " file path A: docs/fundamentals/flow/add-executors.md | file path B: docs/fundamentals/flow/add-executors.md\n\n@@ -292,7 +292,9 @@ param3: 30\n ```\n \n ### Set `requests` via `uses_requests`\n-You can set/override the `requests` configuration of an executor and bind methods to endpoints that you provide. In the following codes, we replace the endpoint `/foo` binded to the `foo()` function with `/non_foo` and add a new endpoint `/bar` for binding `bar()`. Note the `all_req()` function is binded to **all** the endpoints except those explicitly bound to other functions, i.e. `/non_foo` and `/bar`.\n+You can set/override the `requests` configuration of an executor and bind methods to endpoints that you provide. \n+In the following codes, we replace the endpoint `/foo` binded to the `foo()` function with both `/non_foo` and `/alias_foo`. \n+And add a new endpoint `/bar` for binding `bar()`. Note the `all_req()` function is binded to **all** the endpoints except those explicitly bound to other functions, i.e. `/non_foo`, `/alias_foo` and `/bar`.\n \n ```python\n from jina import Executor, requests, Flow\n@@ -316,12 +318,14 @@ flow = Flow().add(\n     uses_requests={\n         '/bar': 'bar',\n         '/non_foo': 'foo',\n+        '/alias_foo': 'foo',\n     },\n )\n with flow as f:\n     f.post('/bar', parameters={'recipient': 'bar()'})\n     f.post('/non_foo', parameters={'recipient': 'foo()'})\n     f.post('/foo', parameters={'recipient': 'all_req()'})\n+    f.post('/alias_foo', parameters={'recipient': 'foo()'})\n ```\n \n ```text\n@@ -332,8 +336,10 @@ with flow as f:\n \t\ud83c\udfe0 Local access:\t0.0.0.0:36507\n \t\ud83d\udd12 Private network:\t192.168.1.101:36507\n \t\ud83c\udf10 Public address:\t197.28.82.165:36507\n-bar\n-foo\n+bar bar()\n+foo foo()\n+all req all_req()\n+foo foo()\n ```\n \n ## Unify NDArray types\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -179,14 +179,14 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n     def _add_requests(self, _requests: Optional[Dict]):\n         if not hasattr(self, 'requests'):\n             self.requests = {}\n-\n         if _requests:\n             func_names = {f.__name__: e for e, f in self.requests.items()}\n             for endpoint, func in _requests.items():\n                 # the following line must be `getattr(self.__class__, func)` NOT `getattr(self, func)`\n                 # this to ensure we always have `_func` as unbound method\n                 if func in func_names:\n-                    del self.requests[func_names[func]]\n+                    if func_names[func] in self.requests:\n+                        del self.requests[func_names[func]]\n \n                 _func = getattr(self.__class__, func)\n                 if callable(_func):\n\n---\n file path A: tests/integration/v2_api/test_override_requests.py | file path B: tests/integration/v2_api/test_override_requests.py\n\n@@ -11,7 +11,9 @@ def test_override_requests():\n             for doc in docs:\n                 doc.text = 'foo called'\n \n-    with Flow(port=port).add(uses=FooExecutor, uses_requests={'/non_foo': 'foo'}) as f:\n+    with Flow(port=port).add(\n+        uses=FooExecutor, uses_requests={'/non_foo': 'foo', '/another_foo': 'foo'}\n+    ) as f:\n         c = Client(port=f.port)\n         resp1 = c.post(\n             on='/foo', inputs=DocumentArray([Document(text='')]), return_responses=True\n@@ -21,9 +23,15 @@ def test_override_requests():\n             inputs=DocumentArray([Document(text='')]),\n             return_responses=True,\n         )\n+        resp3 = c.post(\n+            on='/another_foo',\n+            inputs=DocumentArray([Document(text='')]),\n+            return_responses=True,\n+        )\n \n     assert resp1[0].docs[0].text == ''\n     assert resp2[0].docs[0].text == 'foo called'\n+    assert resp3[0].docs[0].text == 'foo called'\n \n \n def test_override_requests_uses_after():\n\n\n###\n\n", "completion": "fix: map multiple endpoints to same func (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -203,6 +203,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14316,3 +14317,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```c5fded55```](https://github.com/jina-ai/jina/commit/c5fded55d5c0f869faea71378be9a0824eb245d9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```e1c5756d```](https://github.com/jina-ai/jina/commit/e1c5756db2bb4a9065fe9d4b9311b57028d8cdc4)] __-__ __version__: the next version will be 3.6.11 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-12></a>\n+## Release Note (`3.6.12`)\n+\n+> Release time: 2022-07-14 14:56:14\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```683f8fa7```](https://github.com/jina-ai/jina/commit/683f8fa748126f32c6de64763ff807c46c94685c)] __-__ terminate the pod, potential problem with containerpod (#5011) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```7ff09b1c```](https://github.com/jina-ai/jina/commit/7ff09b1c4635b502464d1c936ed786c00ea53145)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```1e0a8a77```](https://github.com/jina-ai/jina/commit/1e0a8a7733f98e51388d808794d84f1091f45bda)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```674229ed```](https://github.com/jina-ai/jina/commit/674229ed40be920b8b15c1a6f1758121670937a2)] __-__ __version__: the next version will be 3.6.12 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.12'\n+__version__ = '3.6.13'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.13"}
{"prompt": " file path A: jina/orchestrate/pods/__init__.py | file path B: jina/orchestrate/pods/__init__.py\n\n@@ -170,7 +170,7 @@ class BasePod(ABC):\n             self.logger.debug(\n                 f'{\"shutdown is is already set\" if self.is_shutdown.is_set() else \"Runtime was never started\"}. Runtime will end gracefully on its own'\n             )\n-            pass\n+            self._terminate()\n         self.is_shutdown.set()\n         self.logger.debug(__stop_msg__)\n         self.logger.close()\n\n\n###\n\n", "completion": "fix: terminate the pod, potential problem with containerpod (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -202,6 +202,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14285,3 +14286,32 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```17662518```](https://github.com/jina-ai/jina/commit/176625180e4c94c329b8354473a24b9b6b68d4af)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d6690f66```](https://github.com/jina-ai/jina/commit/d6690f6668027c4338d3f1e834fbbb033e278698)] __-__ __version__: the next version will be 3.6.10 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-11></a>\n+## Release Note (`3.6.11`)\n+\n+> Release time: 2022-07-13 09:45:10\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Zac Li,  Jina Dev Bot,  Joan Fontanals,  samsja,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```f0703afe```](https://github.com/jina-ai/jina/commit/f0703afe45e07c032e0a8068d3cdf16992b40cd7)] __-__ param per executor gateway (#4939) (*samsja*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```7e127049```](https://github.com/jina-ai/jina/commit/7e127049d2ea838e7c6c1159604b705d77f3513f)] __-__ more logging in dry run (#5008) (*Zac Li*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```73784fda```](https://github.com/jina-ai/jina/commit/73784fda86821b9ff8906fdc990027cb27d9d9c4)] __-__ have baseexecutor bind default endpoint (#5007) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```295649fe```](https://github.com/jina-ai/jina/commit/295649fe971f4c0ed4da01a218b8e9f6c79bda34)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```c5fded55```](https://github.com/jina-ai/jina/commit/c5fded55d5c0f869faea71378be9a0824eb245d9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```e1c5756d```](https://github.com/jina-ai/jina/commit/e1c5756db2bb4a9065fe9d4b9311b57028d8cdc4)] __-__ __version__: the next version will be 3.6.11 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.11'\n+__version__ = '3.6.12'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.12"}
{"prompt": " file path A: jina/clients/base/http.py | file path B: jina/clients/base/http.py\n\n@@ -64,6 +64,10 @@ class HTTPBaseClient(BaseClient):\n                 self._handle_response_status(r_status, r_str, url)\n                 if r_str['code'] == jina_pb2.StatusProto.SUCCESS:\n                     return True\n+                else:\n+                    self.logger.debug(\n+                        f'Returned code is not expected! Description: {r_str[\"description\"]}'\n+                    )\n             except Exception as e:\n                 self.logger.error(\n                     f'Error while fetching response from HTTP server {e!r}'\n\n\n###\n\n", "completion": "fix: more logging in dry run (#<issue-num>)"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -21,7 +21,6 @@ from jina.serve.executors.decorators import (\n )\n \n if TYPE_CHECKING:\n-    from docarray import DocumentArray\n     from prometheus_client import Summary\n \n __dry_run_endpoint__ = '_jina_dry_run_'\n@@ -141,6 +140,8 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                 f' Endpoint {__dry_run_endpoint__} is defined by the Executor. Be aware that this endpoint is usually reserved to enable health checks from the Client through the gateway.'\n                 f' So it is recommended not to expose this endpoint. '\n             )\n+        if type(self) == BaseExecutor:\n+            self.requests[__default_endpoint__] = self._dry_run_func\n \n     def _dry_run_func(self, *args, **kwargs):\n         pass\n\n---\n file path A: tests/unit/clients/test_helper.py | file path B: tests/unit/clients/test_helper.py\n\n@@ -5,7 +5,6 @@ from jina import Executor, Flow, requests\n from jina.clients.base.helper import HTTPClientlet, WebsocketClientlet\n from jina.clients.request.helper import _new_data_request\n from jina.excepts import BadServer\n-\n from jina.logging.logger import JinaLogger\n from jina.types.request.data import DataRequest\n \n@@ -42,9 +41,7 @@ async def test_http_clientlet():\n @pytest.mark.asyncio\n async def test_websocket_clientlet():\n     with pytest.raises(aiohttp.ClientError):\n-        async with WebsocketClientlet(\n-            url='ws://localhost:12345', logger=logger\n-        ) as iolet:\n+        async with WebsocketClientlet(url='ws://localhost:12345', logger=logger):\n             pass\n \n \n@@ -63,14 +60,3 @@ def test_client_behaviour(flow_with_exception_request, mocker):\n             )\n         on_always_mock.assert_called_once()\n         on_done_mock.assert_not_called()\n-\n-    on_error_mock = mocker.Mock()\n-    on_done_mock = mocker.Mock()\n-    on_always_mock = mocker.Mock()\n-    with flow_with_exception_request as f:\n-        f.post(\n-            '', on_done=on_done_mock, on_error=on_error_mock, on_always=on_always_mock\n-        )\n-    on_always_mock.assert_called_once()\n-    on_done_mock.assert_not_called()\n-    on_error_mock.assert_called_once()\n\n\n###\n\n", "completion": "test: have baseexecutor bind default endpoint (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -201,6 +201,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14245,3 +14246,41 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```2a2f57d6```](https://github.com/jina-ai/jina/commit/2a2f57d6e0bd8c8eb05ffcd9e5065bc592f94eb9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```407a266e```](https://github.com/jina-ai/jina/commit/407a266e9ee638015063b3dda41291dd6476ed16)] __-__ __version__: the next version will be 3.6.9 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-10></a>\n+## Release Note (`3.6.10`)\n+\n+> Release time: 2022-07-11 07:01:07\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ zhangkai,  Joan Fontanals,  Zac Li,  samsja,  Jina Dev Bot,  Deepankar Mahapatro,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```0b74830b```](https://github.com/jina-ai/jina/commit/0b74830b701ce3aca8405c5bcc2b51ce4a68e2d0)] __-__ set prefetch default to 1000 (#4985) (*Joan Fontanals*)\n+ - [[```c3849c6f```](https://github.com/jina-ai/jina/commit/c3849c6fee4a65a77a82b2cfda9670d727ff0f53)] __-__ allow to access parameters of data request wo loading data  (#4991) (*samsja*)\n+ - [[```34997cc0```](https://github.com/jina-ai/jina/commit/34997cc032eebe5a30452ddc018f5eb403c1c667)] __-__ allow to load parameters from jina data request proto wo loading the full docs (#4950) (*samsja*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```f70caed2```](https://github.com/jina-ai/jina/commit/f70caed27eb76d14c503b4e46bb23ec07e30b04a)] __-__ __hubble__: fix the way to generate executor name of the func hub pull (#5001) (*zhangkai*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```b2fa4fe5```](https://github.com/jina-ai/jina/commit/b2fa4fe54b85a51bb672b9030eb850678b81121c)] __-__ __jcloud__: add monitoring bit (#4997) (*Zac Li*)\n+ - [[```2dd40397```](https://github.com/jina-ai/jina/commit/2dd40397eae9b13adc2f68e5e79b33c8673a9d5e)] __-__ change pqlite reference to annlite in docs (#4994) (*Joan Fontanals*)\n+ - [[```d498a172```](https://github.com/jina-ai/jina/commit/d498a1726694c4b28a140e542e667301b9599861)] __-__ __jcloud__: expand faq section (#4993) (*Zac Li*)\n+ - [[```73589ff0```](https://github.com/jina-ai/jina/commit/73589ff0b968da0eab90f2126925d071dc09e267)] __-__ __jcloud__: refactor faq section (#4989) (*Deepankar Mahapatro*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```9b6824fa```](https://github.com/jina-ai/jina/commit/9b6824fa5bcd6cd8b47881c85c70f6255c3d7331)] __-__ add debug lines for test (#4982) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```0dcb2277```](https://github.com/jina-ai/jina/commit/0dcb227729a8449fb363ca8500627f3bf77de942)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```17662518```](https://github.com/jina-ai/jina/commit/176625180e4c94c329b8354473a24b9b6b68d4af)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d6690f66```](https://github.com/jina-ai/jina/commit/d6690f6668027c4338d3f1e834fbbb033e278698)] __-__ __version__: the next version will be 3.6.10 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.10'\n+__version__ = '3.6.11'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.11"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -787,7 +787,7 @@ metas:\n                     force=need_pull,\n                 )\n \n-                presented_id = getattr(executor, 'name', executor.uuid)\n+                presented_id = executor.name if executor.name else executor.uuid\n                 executor_name = (\n                     f'{presented_id}'\n                     if executor.visibility == 'public' or not secret\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -375,8 +375,8 @@ class DownloadMockResponse:\n     def status_code(self):\n         return self.response_code\n \n-\n-def test_pull(test_envs, mocker, monkeypatch):\n+@pytest.mark.parametrize('executor_name', ['alias_dummy', None])\n+def test_pull(test_envs, mocker, monkeypatch, executor_name):\n     mock = mocker.Mock()\n \n     def _mock_fetch(\n@@ -391,7 +391,7 @@ def test_pull(test_envs, mocker, monkeypatch):\n         return (\n             HubExecutor(\n                 uuid='dummy_mwu_encoder',\n-                name='alias_dummy',\n+                name=executor_name,\n                 tag='v0',\n                 image_name='jinahub/pod.dummy_mwu_encoder',\n                 md5sum=None,\n@@ -416,6 +416,14 @@ def test_pull(test_envs, mocker, monkeypatch):\n     monkeypatch.setattr(requests, 'get', _mock_download)\n     monkeypatch.setattr(requests, 'head', _mock_head)\n \n+    def _mock_get_prettyprint_usage(self,console, executor_name, usage_kind=None):\n+        mock(console=console)\n+        mock(usage_kind=usage_kind)\n+        print('_mock_get_prettyprint_usage executor_name:', executor_name)\n+        assert executor_name != 'None'\n+\n+    monkeypatch.setattr(HubIO, '_get_prettyprint_usage', _mock_get_prettyprint_usage)\n+\n     args = set_hub_pull_parser().parse_args(['jinahub://dummy_mwu_encoder'])\n     HubIO(args).pull()\n \n\n\n###\n\n", "completion": "fix(hubble): fix the way to generate executor name of the func hub pull (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/basic.md | file path B: docs/fundamentals/jcloud/basic.md\n\n@@ -143,16 +143,27 @@ export JCLOUD_NO_INTERACTIVE=1\n \n ## Get status\n \n+To get the status of a Flow:\n ```bash\n-jc status 173503c192\n+jc status 15937a10bd\n ```\n \n ```{figure} status.png\n :width: 70%\n ```\n \n+## Monitoring\n+To enable monitoring with the Flow, you can set `monitoring: true` in the Flow yaml and you'd be given access to a [Grafana](https://grafana.com/) dashboard.\n+\n+To access the dashboard, get the status of the Flow first (see above section), at the bottom of the pane you should see the `dashboards` link. Visit the URL and you will find some basic metrics such as 'Number of Request Gateway Received' and 'Time elapsed between receiving a request and sending back the response':\n+\n+```{figure} monitoring.png\n+:width: 70%\n+```\n+\n ## List Flows\n \n+To list all the Flows you have:\n ```bash\n jc list\n ```\n\n---\n file path A: docs/fundamentals/jcloud/monitoring.png | file path B: docs/fundamentals/jcloud/monitoring.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/monitoring.png differ\n\n---\n file path A: docs/fundamentals/jcloud/status.png | file path B: docs/fundamentals/jcloud/status.png\n\nBinary files a/docs/fundamentals/jcloud/status.png and b/docs/fundamentals/jcloud/status.png differ\n\n\n###\n\n", "completion": "docs(jcloud): add monitoring bit (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/docker-compose.md | file path B: docs/how-to/docker-compose.md\n\n@@ -41,7 +41,7 @@ always be `unhealthy`\n To follow this how-to, you should first ensure that [`Docker Compose`](https://docs.docker.com/compose/install/) is installed locally.\n \n This example shows how to build and deploy a Flow with Docker Compose, using [`CLIPImageEncoder`](https://hub.jina.ai/executor/0hnlmu3q)\n-as an image encoder and [`PQLiteIndexer`](https://hub.jina.ai/executor/pn1qofsj) as an indexer to perform fast nearest\n+as an image encoder and [`ANNLiteIndexer`](https://hub.jina.ai/executor/7yypg8qk) as an indexer to perform fast nearest\n neighbor retrieval on image embeddings.\n \n ### Deploy your Flow\n\n---\n file path A: docs/how-to/scale-out.md | file path B: docs/how-to/scale-out.md\n\n@@ -126,9 +126,9 @@ If you are deploying Jina with K8s, you can consider this `Executor` as a K8s `D\n \n Now with your text corpus encoded as TF-IDF embeddings,\n it's time to save the results.\n-We'll use Jina's [PQLiteIndexer](https://hub.jina.ai/executor/pn1qofsj) to persist our embeddings for fast Approximate Nearest Neighbor Search.\n+We'll use Jina's [ANNLiteIndexer](https://hub.jina.ai/executor/7yypg8qk) to persist our embeddings for fast Approximate Nearest Neighbor Search.\n \n-And you add this `PQLiteIndexer` to your Flow:\n+And you add this `ANNLiteIndexer` to your Flow:\n \n ```python\n from jina import Flow\n@@ -139,7 +139,7 @@ f = (\n     .add(name='slow_executor', uses=MyVectorizer)\n     .add(\n         name='pqlite_executor',\n-        uses='jinahub://PQLiteIndexer/v0.2.3-rc',\n+        uses='jinahub://ANNLiteIndexer/v0.2.3-rc',\n         uses_with={\n             'dim': 130107,  # the dimension is fitted on the corpus in news dataset\n             'metric': 'cosine',\n@@ -158,9 +158,9 @@ with f:\n     f.post(on='/index', inputs=news_generator, show_progress=True)\n ```\n \n-The `PQLiteIndexer` will save your indexed Documents to your specified `workspace` (directory).\n+The `ANNLiteIndexer` will save your indexed Documents to your specified `workspace` (directory).\n Since the default number of shards is one.\n-All the data will be saved to `YOUR-WORKSPACE-DIR/PQLiteIndexer/0/` where `0` is the shard id.\n+All the data will be saved to `YOUR-WORKSPACE-DIR/ANNLiteIndexer/0/` where `0` is the shard id.\n \n If you want to distribute your data to different places, Jina allows you to use `shards` to specify the number of shards.\n \n@@ -171,7 +171,7 @@ f = (\n     .add(name='slow_executor', uses=MyVectorizer)\n     .add(\n         name='pqlite_executor',\n-        uses='jinahub://PQLiteIndexer',\n+        uses='jinahub://ANNLiteIndexer',\n         uses_with={'dim': 130107, 'metric': 'cosine'},\n         workspace='CHANGE-TO-YOUR-PATH/workspace',\n         install_requirements=True,\n@@ -181,7 +181,7 @@ f = (\n ```\n \n Now open your workspace directory, you'll find we created 2 shards to store your indexed Documents:\n-`YOUR-WORKSPACE-DIR/PQLiteIndexer/0/` and `YOUR-WORKSPACE-DIR/PQLiteIndexer/1/`.\n+`YOUR-WORKSPACE-DIR/ANNLiteIndexer/0/` and `YOUR-WORKSPACE-DIR/ANNLiteIndexer/1/`.\n \n ### Different polling strategies\n \n@@ -210,7 +210,7 @@ f = (\n     .add(name='slow_executor', uses=MyVectorizer)\n     .add(\n         name='pqlite_executor',\n-        uses='jinahub://PQLiteIndexer/v0.2.3-rc',\n+        uses='jinahub://ANNLiteIndexer/v0.2.3-rc',\n         uses_with={'dim': 130107, 'metric': 'cosine'},\n         workspace='CHANGE-TO-YOUR-PATH/workspace',\n         install_requirements=True,\n@@ -229,4 +229,4 @@ Jina will collect `matches` from all `shards` and return the reduced results.\n Jina can help you scale out your applications easily and effectively.\n Depending on your needs, if you want to increase the `Executor` throughput, use the `replicas` argument.\n If you want to partition your data across multiple places,\n-use the `shards` with the `polling` strategy you want.\n\\ No newline at end of file\n+use the `shards` with the `polling` strategy you want.\n\n\n###\n\n", "completion": "docs: change pqlite reference to annlite in docs (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/faq.md | file path B: docs/fundamentals/jcloud/faq.md\n\n@@ -26,4 +26,10 @@\n   jc --loglevel DEBUG deploy flow.yml\n   ```\n \n+  Alternatively, you can also configure it by using Environment Variable `JCLOUD_LOGLEVEL`, e.g.\n+\n+  ```bash\n+  export JCLOUD_LOGLEVEL=DEBUG && jc deploy flow.yml\n+  ```\n+\n   If you don't see any obvious errors, please raise an issue in [JCloud](https://github.com/jina-ai/jcloud/issues/new/choose)\n\n\n###\n\n", "completion": "docs(jcloud): expand faq section (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -133,6 +133,7 @@ executors:\n     uses: jinahub+docker://CustomExecutor\n ```\n \n+(retention-days)=\n ## Retention days\n \n In JCloud, we have a default life-cycle of 24hrs for Flows, after which they're removed, if idle. You can manage the same yourself by passing the right parameter for `retention-days` under `jcloud`. `0` is to use the default life-cycle, `X` (0<X<365), which is meant to keep the Flow alive until X days, and `-1` is for never expired,\n\n---\n file path A: docs/fundamentals/jcloud/faq.md | file path B: docs/fundamentals/jcloud/faq.md\n\n@@ -1,25 +1,29 @@\n # FAQ\n \n-- **Why does it take a while on every operation of `jcloud`?**\n+- **Is everything free?**\n \n-  Because the event listener at Jina Cloud is serverless by design, which means it spawns an instance on-demand to process your requests from `jcloud`. Note that operations such as `deploy`, `remove` in `jcloud` are not high-frequency. Hence, having a serverless listener is much more cost-efficient than an always-on listener. The downside is slower operations, nevertheless this does not affect the deployed service. Your deployed service is **always on**.\n+  Yes! We just need your feedback - use `jc survey` to help us understand your needs.\n \n-- **How long do you persist my service?**\n+- **How powerful is JCloud?**\n \n-  Forever. Until you manually `remove` it, we will persist your service as long as possible.\n+  JCloud scales according to your need. You can demand all the resources (RAM / disk / instance-capacity) your Flows & Executors need. If there's anything particular you'd be looking for, you can contact us [on Slack](https://slack.jina.ai) or let us know via `jc survey`.\n \n-- **Is everything free?**\n+- **What restrictions are there on JCloud?**\n \n-  Yes! We just need your feedback - use `jc survey` to help us understand your needs.\n+  - JCloud doesn't support GPUs yet.\n+  - Executors are currently allowed a maximum of 16G RAM & 10GB disk (using EBS).\n+  - Deployments are only supported in `us-east` region.\n \n-- **How powerful is Jina Cloud?**\n+- **How long do you persist my service?**\n \n-  Jina Cloud scales according to your need. You can demand for the resources your Flow requires. If there's anything particular you'd be looking for, you can contact us [on Slack](https://slack.jina.ai) or let us know via `jc survey`.\n+  Flows are terminated if they are not serving requests for the last 24hrs. But this is configurable by passing {ref}`retention-days <retention-days>` argument.\n \n-- **How can I enable verbose logs with `jcloud`?**\n+- **My Flow deployment failed. How I do to fix it?**\n \n-  To make the output more verbose, you can add `--loglevel DEBUG` _before_ each CLI subcommand, e.g.\n+  As a first step, please enable verbose logs while deploying the Flow. You can add `--loglevel DEBUG` _before_ each CLI subcommand, e.g.\n \n   ```bash\n-  jc --loglevel DEBUG deploy toy.yml\n-  ```\n\\ No newline at end of file\n+  jc --loglevel DEBUG deploy flow.yml\n+  ```\n+\n+  If you don't see any obvious errors, please raise an issue in [JCloud](https://github.com/jina-ai/jcloud/issues/new/choose)\n\n\n###\n\n", "completion": "docs(jcloud): refactor faq section (#<issue-num>)"}
{"prompt": " file path A: tests/conftest.py | file path B: tests/conftest.py\n\n@@ -68,6 +68,11 @@ def test_log_level(monkeypatch):\n     monkeypatch.setenv('JINA_LOG_LEVEL', 'DEBUG')\n \n \n+@pytest.fixture(autouse=True)\n+def test_grpc_fork_support_false(monkeypatch):\n+    monkeypatch.setenv('GRPC_ENABLE_FORK_SUPPORT', 'false')\n+\n+\n @pytest.fixture(autouse=True)\n def test_timeout_ctrl_time(monkeypatch):\n     monkeypatch.setenv('JINA_DEFAULT_TIMEOUT_CTRL', '500')\n\n\n###\n\n", "completion": "test: add debug lines for test (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -200,6 +200,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14215,3 +14216,31 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```897b0eb9```](https://github.com/jina-ai/jina/commit/897b0eb951cde120aa6af05a036a9b6e88abb571)] __-__ __version__: the next version will be 3.6.8 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-9></a>\n+## Release Note (`3.6.9`)\n+\n+> Release time: 2022-06-29 15:03:04\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  tarrantro,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```27a3f942```](https://github.com/jina-ai/jina/commit/27a3f942c7f228f072c35832aa9e4fb1d30a6118)] __-__ allow to pass a list of port monitoring to replicas  (#4961) (*samsja*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```d21870ac```](https://github.com/jina-ai/jina/commit/d21870ac47fc1594b45a5f01ee48cddf5c18b2ff)] __-__ fix reconnect issues (#4941) (*Johannes Messner*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```0884fe9e```](https://github.com/jina-ai/jina/commit/0884fe9e7ff4e429442d8cbbad75b181ac371583)] __-__ add wolf ebs support docs (#4980) (*tarrantro*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```2a2f57d6```](https://github.com/jina-ai/jina/commit/2a2f57d6e0bd8c8eb05ffcd9e5065bc592f94eb9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```407a266e```](https://github.com/jina-ai/jina/commit/407a266e9ee638015063b3dda41291dd6476ed16)] __-__ __version__: the next version will be 3.6.9 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.9'\n+__version__ = '3.6.10'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.10"}
{"prompt": " file path A: docs/fundamentals/flow/monitoring-flow.md | file path B: docs/fundamentals/flow/monitoring-flow.md\n\n@@ -91,6 +91,56 @@ On the other hand, If you want to only enable the monitoring on a given Executor\n Flow().add(...).add(uses=MyExecutor, monitoring=True)\n ```\n \n+### Enable monitoring with replicas and shards\n+\n+```{tip} \n+This section is only relevant if you deploy your Flow natively. When deploying your Flow with Kubernetes or Docker Compose\n+all of the `port_monitoring` will be set to default : `9090`.  \n+```\n+\n+To enable monitoring with replicas and shards when deploying natively, you need to pass a list of `port_monitoring` separated by a comma to your Flow.\n+\n+Example:\n+\n+````{tab} via Python API\n+\n+```python\n+from jina import Flow\n+\n+with Flow(monitoring=True).add(\n+    uses='jinahub://SimpleIndexer', replicas=2, port_monitoring='9091,9092'\n+) as f:\n+    f.block()\n+```\n+````\n+\n+````{tab} via YAML\n+This example shows how to start a Flow with monitoring enabled via yaml:\n+\n+In a `flow.yaml` file\n+```yaml\n+jtype: Flow\n+with:\n+  monitoring: true\n+executors:\n+- uses: jinahub://SimpleIndexer\n+  replicas=2\n+  port_monitoring: '9091,9092'\n+```\n+\n+```bash\n+jina flow --uses flow.yaml\n+```\n+````\n+\n+```{tip} Monitoring with shards\n+When using shards, an extra head will be created and you will need to pass a list of N+1 ports to `port_monitoring`, N beeing the number of shards you desire\n+```\n+\n+If you precise fewer `port_monitoring` than you have replicas of your Executor (or even not passing any at all), the unknown ports\n+will be assigned randomly. It is a better practice to precise a port for every replica, otherwise you will have to change \n+your Prometheus configuration each time you restart your application.\n+\n ## Available metrics\n \n A {class}`~jina.Flow` supports different metrics out of the box, in addition to allowing the user to define their own custom metrics.\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1618,3 +1618,30 @@ def is_port_free(host, port):\n             return False\n         else:\n             return True\n+\n+\n+def _parse_ports(port: str) -> Union[int, List]:\n+    \"\"\"Parse port\n+\n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+\n+        _parse_port('8000')\n+        8000\n+\n+        _parse_port('8001:8002:8005')\n+        [80001, 8002, 8005]\n+\n+    :param port: the string to parse\n+    :return: the port or the iterable ports\n+    \"\"\"\n+    try:\n+        port = int(port)\n+    except ValueError as e:\n+        if ',' in port:\n+            port = [int(port_) for port_ in port.split(',')]\n+        else:\n+            raise e\n+    return port\n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -12,7 +12,7 @@ from typing import Dict, List, Optional, Set, Union\n \n from jina import __default_executor__, __default_host__, __docker_host__, helper\n from jina.enums import DeploymentRoleType, PodRoleType, PollingType\n-from jina.helper import CatchAllCleanupContextManager\n+from jina.helper import CatchAllCleanupContextManager, _parse_ports\n from jina.hubble.helper import replace_secret_of_hub_uri\n from jina.hubble.hubio import HubIO\n from jina.jaml.helper import complete_path\n@@ -101,6 +101,13 @@ class BaseDeployment(ExitStack):\n         \"\"\"\n         return self.head_args.port if self.head_args else None\n \n+    @property\n+    def head_port_monitoring(self):\n+        \"\"\"Get the port_monitoring of the HeadPod of this deployment\n+        .. # noqa: DAR201\n+        \"\"\"\n+        return self.head_args.port_monitoring if self.head_args else None\n+\n     def __enter__(self) -> 'BaseDeployment':\n         with CatchAllCleanupContextManager(self):\n             return self.start()\n@@ -248,6 +255,7 @@ class Deployment(BaseDeployment):\n         self.uses_after_pod = None\n         self.head_pod = None\n         self.shards = {}\n+        self._update_port_args()\n         self.update_pod_args()\n         self._sandbox_deployed = False\n \n@@ -255,6 +263,17 @@ class Deployment(BaseDeployment):\n         super().__exit__(exc_type, exc_val, exc_tb)\n         self.join()\n \n+    def _update_port_args(self):\n+        _all_port_monitoring = _parse_ports(self.args.port_monitoring)\n+        self.args.all_port_monitoring = (\n+            [_all_port_monitoring]\n+            if not type(_all_port_monitoring) == list\n+            else _all_port_monitoring\n+        )\n+        self.args.port_monitoring = int(\n+            self.args.all_port_monitoring[0]\n+        )  # this is for the head\n+\n     def update_pod_args(self):\n         \"\"\"Update args of all its pods based on Deployment args. Including head/tail\"\"\"\n         if isinstance(self.args, Dict):\n@@ -688,9 +707,30 @@ class Deployment(BaseDeployment):\n                 if args.deployment_role == DeploymentRoleType.GATEWAY or args.external:\n                     _args.port = args.port\n                 elif args.shards == 1 and args.replicas == 1:\n+                    _args.port = args.port\n+                    _args.port_monitoring = args.port_monitoring\n+\n+                elif args.shards == 1:\n+                    _args.port_monitoring = (\n+                        helper.random_port()\n+                        if replica_id >= len(args.all_port_monitoring)\n+                        else args.all_port_monitoring[replica_id]\n+                    )\n                     # if there are no shards/replicas, we dont need to distribute ports randomly\n                     # we should rather use the pre assigned one\n-                    args.port = args.port\n+                    _args.port = helper.random_port()\n+                elif args.shards > 1:\n+                    port_monitoring_index = (\n+                        replica_id + args.replicas * shard_id + 1\n+                    )  # the first index is for the head\n+                    _args.port_monitoring = (\n+                        helper.random_port()\n+                        if port_monitoring_index >= len(args.all_port_monitoring)\n+                        else args.all_port_monitoring[\n+                            port_monitoring_index\n+                        ]  # we skip the head port here\n+                    )\n+                    _args.port = helper.random_port()\n                 else:\n                     _args.port = helper.random_port()\n                     _args.port_monitoring = helper.random_port()\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -798,7 +798,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         output_array_type: Optional[str] = None,\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n-        port_monitoring: Optional[int] = None,\n+        port_monitoring: Optional[str] = None,\n         py_modules: Optional[List[str]] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -3,10 +3,11 @@ from jina.parsers.helper import _SHOW_ALL_ARGS\n from jina.parsers.orchestrate.runtimes.head import mixin_head_parser\n \n \n-def set_pod_parser(parser=None):\n+def set_pod_parser(parser=None, port_monitoring=True):\n     \"\"\"Set the parser for the Pod\n \n     :param parser: an optional existing parser to build upon\n+    :param port_monitoring: if to include the port parsing\n     :return: the parser\n     \"\"\"\n     if not parser:\n@@ -31,7 +32,7 @@ def set_pod_parser(parser=None):\n     mixin_container_runtime_parser(parser)\n     mixin_remote_runtime_parser(parser)\n     mixin_distributed_feature_parser(parser)\n-    mixin_pod_parser(parser)\n+    mixin_pod_parser(parser, port_monitoring=port_monitoring)\n     mixin_hub_pull_options_parser(parser)\n     mixin_head_parser(parser)\n \n@@ -49,7 +50,7 @@ def set_deployment_parser(parser=None):\n \n         parser = set_base_parser()\n \n-    set_pod_parser(parser)\n+    set_pod_parser(parser, port_monitoring=False)\n \n     from jina.parsers.orchestrate.deployment import mixin_base_deployment_parser\n \n\n---\n file path A: jina/parsers/orchestrate/deployment.py | file path B: jina/parsers/orchestrate/deployment.py\n\n@@ -1,6 +1,7 @@\n \"\"\"Argparser module for Deployment runtimes\"\"\"\n import argparse\n \n+from jina import helper\n from jina.enums import DeploymentRoleType\n from jina.parsers.helper import _SHOW_ALL_ARGS, KVAppendAction, add_arg_group\n \n@@ -59,3 +60,11 @@ def mixin_base_deployment_parser(parser):\n         default=False,\n         help='If set, connect to deployment using tls encryption',\n     )\n+\n+    gp.add_argument(\n+        '--port-monitoring',\n+        type=str,\n+        default=str(helper.random_port()),\n+        dest='port_monitoring',\n+        help=f'The port on which the prometheus server is exposed, default is a random port between [49152, 65535]',\n+    )\n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -6,9 +6,10 @@ from jina.enums import PodRoleType\n from jina.parsers.helper import _SHOW_ALL_ARGS, KVAppendAction, add_arg_group\n \n \n-def mixin_pod_parser(parser):\n+def mixin_pod_parser(parser, port_monitoring=True):\n     \"\"\"Mixing in arguments required by :class:`Pod` into the given parser.\n     :param parser: the parser instance to which we add arguments\n+    :param port_monitoring: if to include the port parsing\n     \"\"\"\n \n     gp = add_arg_group(parser, title='Pod')\n@@ -96,13 +97,14 @@ def mixin_pod_parser(parser):\n         help='If set, spawn an http server with a prometheus endpoint to expose metrics',\n     )\n \n-    gp.add_argument(\n-        '--port-monitoring',\n-        type=int,\n-        default=helper.random_port(),  # default prometheus server port\n-        dest='port_monitoring',\n-        help=f'The port on which the prometheus server is exposed, default is a random port between [49152, 65535]',\n-    )\n+    if port_monitoring:\n+        gp.add_argument(\n+            '--port-monitoring',\n+            type=int,\n+            default=helper.random_port(),\n+            dest='port_monitoring',\n+            help=f'The port on which the prometheus server is exposed, default is a random port between [49152, 65535]',\n+        )\n \n     gp.add_argument(\n         '--retries',\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -268,7 +268,6 @@ ac_table = {\n             '--replicas',\n             '--port',\n             '--monitoring',\n-            '--port-monitoring',\n             '--retries',\n             '--floating',\n             '--install-requirements',\n@@ -286,6 +285,7 @@ ac_table = {\n             '--external',\n             '--deployment-role',\n             '--tls',\n+            '--port-monitoring',\n         ],\n         'client': [\n             '--help',\n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -3,8 +3,8 @@ import time\n \n import pytest\n import requests as req\n-\n from docarray import Document, DocumentArray\n+\n from jina import Executor, Flow, requests\n from jina.parsers import set_gateway_parser, set_pod_parser\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n@@ -68,21 +68,94 @@ def test_enable_monitoring_gateway(protocol, port_generator, executor):\n \n \n def test_monitoring_head(port_generator, executor):\n+    n_shards = 2\n+    port_shards_list = [port_generator() for _ in range(n_shards)]\n+    port_head = port_generator()\n+    port_monitoring = ','.join([str(port) for port in [port_head] + port_shards_list])\n+    port1 = port_generator()\n+\n+    f = Flow(monitoring=True, port_monitoring=port1).add(\n+        uses=executor, port_monitoring=port_monitoring, shards=n_shards\n+    )\n+\n+    assert f._deployment_nodes['executor0'].head_port_monitoring == port_head\n+\n+    unique_port_exposed = set(\n+        [\n+            pod[0].port_monitoring\n+            for key, pod in f._deployment_nodes['executor0'].pod_args['pods'].items()\n+        ]\n+    )\n+\n+    assert unique_port_exposed == set(port_shards_list)\n+    with f:\n+        for port in [port_head, port1] + port_shards_list:\n+            resp = req.get(f'http://localhost:{port}/')\n+            assert resp.status_code == 200\n+\n+        f.search(inputs=DocumentArray())\n+        resp = req.get(f'http://localhost:{port_head}/')\n+        assert f'jina_receiving_request_seconds' in str(resp.content)\n+        assert f'jina_sending_request_seconds' in str(resp.content)\n+\n+\n+def test_monitoring_head_few_port(port_generator, executor):\n+    n_shards = 2\n     port1 = port_generator()\n     port2 = port_generator()\n \n-    with Flow(monitoring=True, port_monitoring=port_generator()).add(\n-        uses=executor, port_monitoring=port1\n-    ).add(uses=executor, port_monitoring=port2, shards=2) as f:\n-        port3 = f._deployment_nodes['executor0'].pod_args['pods'][0][0].port_monitoring\n-        port4 = f._deployment_nodes['executor1'].pod_args['pods'][0][0].port_monitoring\n+    f = Flow(monitoring=True, port_monitoring=port1).add(\n+        uses=executor, port_monitoring=port2, shards=n_shards\n+    )\n+\n+    assert f._deployment_nodes['executor0'].head_port_monitoring == port2\n \n-        for port in [port1, port2, port3, port4]:\n+    unique_port_exposed = set(\n+        [\n+            pod[0].port_monitoring\n+            for key, pod in f._deployment_nodes['executor0'].pod_args['pods'].items()\n+        ]\n+    )\n+    with f:\n+        for port in [port2, port1]:\n+            resp = req.get(f'http://localhost:{port}/')\n+            assert resp.status_code == 200\n+\n+\n+def test_monitoring_replicas_and_shards(port_generator, executor):\n+    n_shards = 2\n+    n_replicas = 3\n+    port_shards_list = [port_generator() for _ in range(n_shards * n_replicas)]\n+    port_head = port_generator()\n+    port_monitoring = ','.join([str(port) for port in [port_head] + port_shards_list])\n+    port1 = port_generator()\n+\n+    f = Flow(monitoring=True, port_monitoring=port1).add(\n+        uses=executor,\n+        port_monitoring=port_monitoring,\n+        shards=n_shards,\n+        replicas=n_replicas,\n+    )\n+\n+    assert f._deployment_nodes['executor0'].head_port_monitoring == port_head\n+\n+    unique_port_exposed = set(\n+        [\n+            pod.port_monitoring\n+            for _, deployment in f._deployment_nodes.items()\n+            for _, list_pod in deployment.pod_args['pods'].items()\n+            for pod in list_pod\n+        ]\n+    )\n+\n+    assert unique_port_exposed == set(port_shards_list)\n+    with f:\n+        for port in [port_head, port1] + port_shards_list:\n             resp = req.get(f'http://localhost:{port}/')\n             assert resp.status_code == 200\n \n         f.search(inputs=DocumentArray())\n-        resp = req.get(f'http://localhost:{port2}/')\n+        resp = req.get(f'http://localhost:{port_head}/')\n         assert f'jina_receiving_request_seconds' in str(resp.content)\n         assert f'jina_sending_request_seconds' in str(resp.content)\n \n@@ -232,6 +305,7 @@ def test_pending_request(port_generator, failure_in_executor, protocol):\n \n         p_send.start()\n         time.sleep(1)\n+\n         _assert_pending_value('1.0', runtime_name, port0)\n \n         p_send.join()\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow.py\n\n@@ -608,3 +608,10 @@ def _validate_flow(f):\n         else:\n             for n in pod.needs:\n                 assert 'end-gateway' in graph_dict[n]\n+\n+\n+def test_set_port_deployment(port_generator):\n+    port = port_generator()\n+    with Flow().add(uses=Executor, port=port) as f:\n+        assert f._deployment_nodes['executor0'].pod_args['pods'][0][0].port == port\n+        f.index(inputs=[])\n\n---\n file path A: tests/unit/test_helper.py | file path B: tests/unit/test_helper.py\n\n@@ -9,6 +9,7 @@ from jina import Executor, Flow, __default_endpoint__\n from jina.clients.helper import _safe_callback, pprint_routes\n from jina.excepts import BadClientCallback, NotSupportedError\n from jina.helper import (\n+    _parse_ports,\n     cached_property,\n     convert_tuple_to_list,\n     deprecated_alias,\n@@ -364,3 +365,11 @@ def test_run_async():\n \n     end_fd_count = p.num_fds()\n     assert first_fd_count == end_fd_count\n+\n+\n+@pytest.mark.parametrize(\n+    'port, output',\n+    [('8080', 8080), ('1,2,6', [1, 2, 6])],\n+)\n+def test_parse_port(port, output):\n+    assert _parse_ports(port) == output\n\n\n###\n\n", "completion": "feat: allow to pass a list of port monitoring to replicas  (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -8,7 +8,6 @@\n jc deploy flow.yml --env-file flow.env\n ```\n \n-\n ### A project folder\n \n - You can include your environment variables in the `.env` file in the local project and JCloud will take care of managing them.\n@@ -17,7 +16,9 @@ jc deploy flow.yml --env-file flow.env\n   jc deploy ./hello --env-file ./hello/custom.env\n   ```\n \n-## Fine-grained `resources` request\n+## Request for fine-grained `resources`\n+\n+### memory\n \n By default, `jcloud` allocates `100M` of RAM to each Executor. There might be cases where your Executor requires more memory. For example, DALLE-mini (generating image from text prompt) would need more than 100M to load the model. You can request higher memory for your Executor using `resources` arg while deploying the Flow (max 16G allowed per Executor).\n \n@@ -31,7 +32,48 @@ executors:\n         memory: 8G\n ```\n \n-## `spot` vs `on-demand` capacity\n+### storage\n+\n+We currently support 2 kinds of storage types [efs](https://aws.amazon.com/efs/) (default) and [ebs](https://aws.amazon.com/ebs/). The former one is a network file storage, whereas the latter is a block device.\n+\n+````{note}\n+\n+By default, we attach an `efs` to all the Executors in a Flow. The benefits of doing so are\n+\n+- It can grow in size dynamically, so you don't need to shrink/grow volumes as & when necessary.\n+- All Executors in the Flow can share a disk.\n+- The same disk can also be shared with another Flow by passing a workspace-id while deploying a Flow.\n+\n+```bash\n+jc deploy flow.yml --workspace-id <prev-flow-id>\n+```\n+\n+If your Executor needs high IO, you can use `ebs` instead. Please note that,\n+\n+- The disk cannot be shared with other Executors / Flows.\n+- You must pass a size of storage (default: `1G`, max `10G`).\n+\n+````\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: indexer1\n+    uses: jinahub+docker://SimpleIndexer\n+    jcloud:\n+      resources:\n+        storage:\n+          type: ebs\n+          size: 10G\n+  - name: indexer2\n+    uses: jinahub+docker://SimpleIndexer\n+    jcloud:\n+      resources:\n+        storage:\n+          type: efs\n+```\n+\n+## Capacity (`spot` vs `on-demand`)\n \n For cost optimization, `jcloud` tries to deploy all Executors on `spot` capacity. These are ideal for stateless Executors, which can withstand interruptions & restarts. It is recommended to use `on-demand` capacity for stateful Executors (e.g.- indexers) though.\n \n@@ -43,8 +85,8 @@ executors:\n     jcloud:\n       capacity: on-demand\n ```\n-(jcloud-external-executors)=\n-## Deploy external executors\n+\n+## External executors\n \n You can also expose only the Executors by setting `expose_gateway` to `False`. Read more about {ref}`External Executors <external-executors>`\n \n@@ -61,7 +103,6 @@ executors:\n :width: 70%\n ```\n \n-\n Similarly, you can also deploy & expose multiple External Executors.\n \n ```yaml\n@@ -78,7 +119,8 @@ executors:\n ```{figure} external-executors-multiple.png\n :width: 70%\n ```\n-## Deploy with specific `jina` version\n+\n+## `jina` version\n \n To manage `jina` version while deploying a Flow to `jcloud`, you can pass `version` arg in the Flow yaml.\n \n@@ -91,9 +133,9 @@ executors:\n     uses: jinahub+docker://CustomExecutor\n ```\n \n-## Flow retention days\n+## Retention days\n \n-In Jcloud, we have default life-cycle(24hrs) for each flow and we will remove flows periodically if they are beyond the life-cycle. To change the default behavior and manage it by yourself, you can setup `retention_days` args in `jcloud`. `-1` is never expired, `0` is to use the default life-cycle, or `X`(0<X<365), which means keep the flow utill X days. `0` is the default value if you don't pass `retention_days` argument.\n+In JCloud, we have a default life-cycle of 24hrs for Flows, after which they're removed, if idle. You can manage the same yourself by passing the right parameter for `retention-days` under `jcloud`. `0` is to use the default life-cycle, `X` (0<X<365), which is meant to keep the Flow alive until X days, and `-1` is for never expired,\n \n ```yaml\n jtype: Flow\n@@ -102,4 +144,4 @@ jcloud:\n executors:\n   - name: custom\n     uses: jinahub+docker://CustomExecutor\n-```\n\\ No newline at end of file\n+```\n\n\n###\n\n", "completion": "docs: add wolf ebs support docs (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -199,6 +199,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14192,3 +14193,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```8314c83b```](https://github.com/jina-ai/jina/commit/8314c83b8bf9dcc7f2b33a49acd6d2ff7765b6e5)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```f8de1a1f```](https://github.com/jina-ai/jina/commit/f8de1a1fae6b0890de35f16c8c6ccd562bd16b78)] __-__ __version__: the next version will be 3.6.7 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-8></a>\n+## Release Note (`3.6.8`)\n+\n+> Release time: 2022-06-28 13:16:22\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Delgermurun,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```4a201bfc```](https://github.com/jina-ai/jina/commit/4a201bfc6ba562353c25320e136955d9f90de236)] __-__ __import__: remove early check file exist (#4977) (*Han Xiao*)\n+ - [[```3a0e0720```](https://github.com/jina-ai/jina/commit/3a0e07208cc3b273e201f61df53e417bef22a092)] __-__ use secret if logged in user provided it explicitly (#4975) (*Delgermurun*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```897b0eb9```](https://github.com/jina-ai/jina/commit/897b0eb951cde120aa6af05a036a9b6e88abb571)] __-__ __version__: the next version will be 3.6.8 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.8'\n+__version__ = '3.6.9'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.9"}
{"prompt": " file path A: jina/jaml/helper.py | file path B: jina/jaml/helper.py\n\n@@ -195,12 +195,17 @@ def parse_config_source(\n         )\n \n \n-def complete_path(path: str, extra_search_paths: Optional[List[str]] = None) -> str:\n+def complete_path(\n+    path: str,\n+    extra_search_paths: Optional[List[str]] = None,\n+    raise_nonexist: bool = True,\n+) -> str:\n     \"\"\"\n     Complete the path of file via searching in abs and relative paths.\n \n     :param path: path of file.\n     :param extra_search_paths: extra paths to conduct search\n+    :param raise_nonexist: raise exception if the file does not exist\n     :return: Completed file path.\n     \"\"\"\n     _p = _search_file_in_paths(path, extra_search_paths)\n@@ -209,7 +214,7 @@ def complete_path(path: str, extra_search_paths: Optional[List[str]] = None) ->\n         _p = path\n     if _p:\n         return os.path.abspath(_p)\n-    else:\n+    elif raise_nonexist:\n         raise FileNotFoundError(f'can not find {path}')\n \n \n@@ -263,5 +268,5 @@ def load_py_modules(d: Dict, extra_search_paths: Optional[List[str]] = None) ->\n \n     _finditem(d)\n     if mod:\n-        mod = [complete_path(m, extra_search_paths) for m in mod]\n+        mod = [complete_path(m, extra_search_paths, raise_nonexist=False) for m in mod]\n         PathImporter.add_modules(*mod)\n\n\n###\n\n", "completion": "fix(import): remove early check file exist (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/hub/push-executor.md | file path B: docs/fundamentals/executor/hub/push-executor.md\n\n@@ -21,6 +21,11 @@ jina hub push [--public/--private] <path_to_executor_folder>\n \n It will return `NAME` & `SECRET`, which you will need to use (if the Executor is private) or update the Executor. **Please keep them carefully.**\n \n+````{admonition} Note\n+:class: note\n+If you are logged in to the Hub using our CLI tools (`jina auth login` or `jcloud login`), you can push and pull your executors without `SECRET`.\n+````\n+\n You can then visit [the Hub portal](https://hub.jina.ai), click on the \"Recent\" tab and see your published Executor.\n \n ````{admonition} Note\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -406,6 +406,7 @@ metas:\n                 )\n \n                 image = None\n+                warning = None\n                 session_id = req_header.get('jinameta-session-id')\n                 for stream_line in resp.iter_lines():\n                     stream_msg = json.loads(stream_line)\n@@ -439,6 +440,7 @@ metas:\n                         )\n                     elif t == 'complete':\n                         image = stream_msg['payload']\n+                        warning = stream_msg.get('warning')\n                         st.update(\n                             f'Cloud building ... [dim]{subject}: {t} ({stream_msg[\"message\"]})[/dim]'\n                         )\n@@ -454,7 +456,9 @@ metas:\n                             )\n \n                 if image:\n-                    new_uuid8, new_secret = self._prettyprint_result(console, image)\n+                    new_uuid8, new_secret = self._prettyprint_result(\n+                        console, image, warning=warning\n+                    )\n                     if new_uuid8 != uuid8 or new_secret != secret:\n                         dump_secret(work_path, new_uuid8, new_secret or '')\n                 else:\n@@ -469,7 +473,7 @@ metas:\n                 )\n                 raise e\n \n-    def _prettyprint_result(self, console, image):\n+    def _prettyprint_result(self, console, image, *, warning: Optional[str] = None):\n         # TODO: only support single executor now\n \n         from rich import box\n@@ -501,6 +505,12 @@ metas:\n \n         table.add_row(':eyes: Visibility', visibility)\n \n+        if warning:\n+            table.add_row(\n+                ':warning: Warning',\n+                f':exclamation:\ufe0f [bold yellow]{warning}',\n+            )\n+\n         p1 = Panel(\n             table,\n             title='Published',\n\n\n###\n\n", "completion": "fix: use secret if logged in user provided it explicitly (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -198,6 +198,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14150,3 +14151,44 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```0fbb7335```](https://github.com/jina-ai/jina/commit/0fbb73357a4670f590c7c9336153a5fb1ac482db)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```f968cbe5```](https://github.com/jina-ai/jina/commit/f968cbe592ae1f565ef96634e0d40b4b4de9b50f)] __-__ __version__: the next version will be 3.6.6 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-7></a>\n+## Release Note (`3.6.7`)\n+\n+> Release time: 2022-06-28 10:54:01\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  zhangkai,  Johannes Messner,  Jina Dev Bot,  Han Xiao,  Delgermurun,  Deepankar Mahapatro,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```e0b78d56```](https://github.com/jina-ai/jina/commit/e0b78d5692e42646ad3554c85a9ea7507ab8e954)] __-__ __flow__: adding floating deployment (#4967) (*Han Xiao*)\n+ - [[```355f89f6```](https://github.com/jina-ai/jina/commit/355f89f6e39b27e4c539d0fa88f54dc35afb148b)] __-__ improve ui after flow success (#4966) (*Han Xiao*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```1d5271a8```](https://github.com/jina-ai/jina/commit/1d5271a85b14d09fe8fec81407572043862fe663)] __-__ fix monitoring update of metrics on exception (#4974) (*Joan Fontanals*)\n+ - [[```c27a47be```](https://github.com/jina-ai/jina/commit/c27a47be54624ea59c877ce07c9562cbe07ca8af)] __-__ replace broken executor files docs link (#4964) (*Delgermurun*)\n+ - [[```ef961e96```](https://github.com/jina-ai/jina/commit/ef961e96c663954c523cc9376d2221b7c150652b)] __-__ add async dry run method (#4963) (*Deepankar Mahapatro*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```558e683a```](https://github.com/jina-ai/jina/commit/558e683a6bf7f3a1ed813aa41c440359546301eb)] __-__ change exec name in test (#4970) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```b595584b```](https://github.com/jina-ai/jina/commit/b595584b696d00b0a24d84abbd83814ded953069)] __-__ expose networking requests in api reference (#4960) (*Johannes Messner*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```2512caf5```](https://github.com/jina-ai/jina/commit/2512caf5c7ee2f917aee7eddeb5a919e7da120a2)] __-__ remove unnecessary folder (#4969) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```afa3892f```](https://github.com/jina-ai/jina/commit/afa3892fdd6c9df7ff9d2bd91d14911369e91f92)] __-__ remove lz4 reqs (#4978) (*Joan Fontanals*)\n+ - [[```e33513ec```](https://github.com/jina-ai/jina/commit/e33513ec3365065e61f93c9190e659d6e75833b3)] __-__ add hub integration (#4971) (*zhangkai*)\n+ - [[```8314c83b```](https://github.com/jina-ai/jina/commit/8314c83b8bf9dcc7f2b33a49acd6d2ff7765b6e5)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```f8de1a1f```](https://github.com/jina-ai/jina/commit/f8de1a1fae6b0890de35f16c8c6ccd562bd16b78)] __-__ __version__: the next version will be 3.6.7 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.7'\n+__version__ = '3.6.8'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.8"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -33,9 +33,8 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-lz4<3.1.2:                        perf, standard,devel\n-uvloop:                     perf, standard,devel\n-prometheus_client:          perf, standard,devel\n+uvloop:                     perf,standard,devel\n+prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n docarray[common]>=0.13.14:  standard,devel\n@@ -70,9 +69,9 @@ pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n torch:                      cicd\n psutil:                     test\n-strawberry-graphql>=0.96.0: cicd, devel\n-sgqlc:                      cicd, devel\n+strawberry-graphql>=0.96.0: cicd,devel\n+sgqlc:                      cicd,devel\n bs4:                        cicd\n jsonschema:                 cicd\n portforward>=0.2.4:         cicd\n-tensorflow>=2.0:            cicd\n\\ No newline at end of file\n+tensorflow>=2.0:            cicd\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -33,9 +33,8 @@ grpcio-health-checking>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n docarray>=0.13.14:          core\n-lz4<3.1.2:                        perf, standard,devel\n-uvloop:                     perf, standard,devel\n-prometheus_client:          perf, standard,devel\n+uvloop:                     perf,standard,devel\n+prometheus_client:          perf,standard,devel\n fastapi>=0.76.0:            standard,devel\n uvicorn[standard]:          standard,devel\n docarray[common]>=0.13.14:  standard,devel\n@@ -70,9 +69,9 @@ pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n torch:                      cicd\n psutil:                     test\n-strawberry-graphql>=0.96.0: cicd, devel\n-sgqlc:                      cicd, devel\n+strawberry-graphql>=0.96.0: cicd,devel\n+sgqlc:                      cicd,devel\n bs4:                        cicd\n jsonschema:                 cicd\n portforward>=0.2.4:         cicd\n-tensorflow>=2.0:            cicd\n\\ No newline at end of file\n+tensorflow>=2.0:            cicd\n\n\n###\n\n", "completion": "chore: remove lz4 reqs (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -60,6 +60,22 @@ class RequestHandler:\n             self._receiving_request_metrics = None\n             self._pending_requests_metrics = None\n \n+    def _update_start_request_metrics(self, request: 'Request'):\n+        if self._receiving_request_metrics:\n+            self._request_init_time[request.request_id] = time.time()\n+        if self._pending_requests_metrics:\n+            self._pending_requests_metrics.inc()\n+\n+    def _update_end_request_metrics(self, result: 'Request'):\n+        if self._receiving_request_metrics:\n+            init_time = self._request_init_time.pop(\n+                result.request_id\n+            )  # need to pop otherwise it stays in memory forever\n+            self._receiving_request_metrics.observe(time.time() - init_time)\n+\n+        if self._pending_requests_metrics:\n+            self._pending_requests_metrics.dec()\n+\n     def handle_request(\n         self, graph: 'TopologyGraph', connection_pool: 'GrpcConnectionPool'\n     ) -> Callable[['Request'], 'asyncio.Future']:\n@@ -94,10 +110,8 @@ class RequestHandler:\n                 self._executor_endpoint_mapping[node.name] = endp.endpoints\n \n         def _handle_request(request: 'Request') -> 'asyncio.Future':\n-            if self._receiving_request_metrics:\n-                self._request_init_time[request.request_id] = time.time()\n-            if self._pending_requests_metrics:\n-                self._pending_requests_metrics.inc()\n+            self._update_start_request_metrics(request)\n+\n             # important that the gateway needs to have an instance of the graph per request\n             request_graph = copy.deepcopy(graph)\n \n@@ -142,10 +156,14 @@ class RequestHandler:\n             async def _process_results_at_end_gateway(\n                 tasks: List[asyncio.Task], request_graph: TopologyGraph\n             ) -> asyncio.Future:\n-                if self._executor_endpoint_mapping is None:\n-                    await asyncio.gather(gather_endpoints(request_graph))\n+                try:\n+                    if self._executor_endpoint_mapping is None:\n+                        await asyncio.gather(gather_endpoints(request_graph))\n \n-                partial_responses = await asyncio.gather(*tasks)\n+                    partial_responses = await asyncio.gather(*tasks)\n+                except:\n+                    self._update_end_request_metrics(request)\n+                    raise\n                 partial_responses, metadatas = zip(*partial_responses)\n                 filtered_partial_responses = list(\n                     filter(lambda x: x is not None, partial_responses)\n@@ -185,19 +203,11 @@ class RequestHandler:\n             :param result: The result returned to the gateway. It extracts the request to be returned to the client\n             :return: Returns a request to be returned to the client\n             \"\"\"\n-\n             for route in result.routes:\n                 if route.executor == 'gateway':\n                     route.end_time.GetCurrentTime()\n \n-            if self._receiving_request_metrics:\n-                init_time = self._request_init_time.pop(\n-                    result.request_id\n-                )  # need to pop otherwise it stays in memory forever\n-                self._receiving_request_metrics.observe(time.time() - init_time)\n-\n-            if self._pending_requests_metrics:\n-                self._pending_requests_metrics.dec()\n+            self._update_end_request_metrics(result)\n \n             return result\n \n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -3,9 +3,15 @@ import time\n \n import pytest\n import requests as req\n-from docarray import DocumentArray\n \n+from docarray import Document, DocumentArray\n from jina import Executor, Flow, requests\n+from jina.parsers import set_gateway_parser, set_pod_parser\n+from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n+from jina.serve.runtimes.gateway.grpc import GRPCGatewayRuntime\n+from jina.serve.runtimes.gateway.http import HTTPGatewayRuntime\n+from jina.serve.runtimes.gateway.websocket import WebSocketGatewayRuntime\n+from jina.serve.runtimes.worker import WorkerRuntime\n \n \n @pytest.fixture()\n@@ -68,7 +74,6 @@ def test_monitoring_head(port_generator, executor):\n     with Flow(monitoring=True, port_monitoring=port_generator()).add(\n         uses=executor, port_monitoring=port1\n     ).add(uses=executor, port_monitoring=port2, shards=2) as f:\n-\n         port3 = f._deployment_nodes['executor0'].pod_args['pods'][0][0].port_monitoring\n         port4 = f._deployment_nodes['executor1'].pod_args['pods'][0][0].port_monitoring\n \n@@ -89,7 +94,6 @@ def test_document_processed_total(port_generator, executor):\n     with Flow(monitoring=True, port_monitoring=port0).add(\n         uses=executor, port_monitoring=port1\n     ) as f:\n-\n         resp = req.get(f'http://localhost:{port1}/')\n         assert resp.status_code == 200\n \n@@ -133,7 +137,7 @@ def test_disable_monitoring_on_pods(port_generator, executor):\n         monitoring=False,\n     ):\n         with pytest.raises(req.exceptions.ConnectionError):  # disable on port1\n-            resp = req.get(f'http://localhost:{port1}/')\n+            _ = req.get(f'http://localhost:{port1}/')\n \n         resp = req.get(f'http://localhost:{port0}/')  # enable on port0\n         assert resp.status_code == 200\n@@ -149,7 +153,7 @@ def test_disable_monitoring_on_gatway_only(port_generator, executor):\n         monitoring=True,\n     ):\n         with pytest.raises(req.exceptions.ConnectionError):  # disable on port1\n-            resp = req.get(f'http://localhost:{port0}/')\n+            _ = req.get(f'http://localhost:{port0}/')\n \n         resp = req.get(f'http://localhost:{port1}/')  # enable on port0\n         assert resp.status_code == 200\n@@ -162,7 +166,6 @@ def test_requests_size(port_generator, executor):\n     with Flow(monitoring=True, port_monitoring=port0).add(\n         uses=executor, port_monitoring=port1\n     ) as f:\n-\n         f.post('/foo', inputs=DocumentArray.empty(size=1))\n \n         resp = req.get(f'http://localhost:{port1}/')  # enable on port0\n@@ -192,61 +195,152 @@ def test_requests_size(port_generator, executor):\n         assert measured_request_bytes_sum > measured_request_bytes_sum_init\n \n \n-def test_pending_request(port_generator):\n+def _assert_pending_value(val: str, runtime_name, port):\n+    resp = req.get(f'http://localhost:{port}/')\n+    assert resp.status_code == 200\n+    assert (\n+        f'jina_number_of_pending_requests{{runtime_name=\"{runtime_name}\"}} {val}'\n+        in str(resp.content)\n+    )\n+\n+\n+@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+@pytest.mark.parametrize('failure_in_executor', [False, True])\n+def test_pending_request(port_generator, failure_in_executor, protocol):\n     port0 = port_generator()\n     port1 = port_generator()\n+    runtime_name = (\n+        'gateway/rep-0/GRPCGatewayRuntime' if protocol == 'grpc' else 'gateway/rep-0'\n+    )\n \n     class SlowExecutor(Executor):\n         @requests\n         def foo(self, docs, **kwargs):\n             time.sleep(5)\n+            if failure_in_executor:\n+                raise Exception\n \n-    with Flow(monitoring=True, port_monitoring=port0).add(\n+    with Flow(monitoring=True, port_monitoring=port0, protocol=protocol).add(\n         uses=SlowExecutor, port_monitoring=port1\n     ) as f:\n \n         def _send_request():\n-            f.search(inputs=DocumentArray.empty(size=1))\n-\n-        def _assert_pending_value(val: str):\n-            resp = req.get(f'http://localhost:{port0}/')\n-            assert resp.status_code == 200\n-            assert (\n-                f'jina_number_of_pending_requests{{runtime_name=\"gateway/rep-0/GRPCGatewayRuntime\"}} {val}'\n-                in str(resp.content)\n-            )\n-\n-        _assert_while = lambda: _assert_pending_value(\n-            '1.0'\n-        )  # while the request is being processed the counter is at one\n-        _assert_after = lambda: _assert_pending_value(\n-            '0.0'\n-        )  # but before and after it is at 0\n-        _assert_before = lambda: _assert_pending_value(\n-            '0.0'\n-        )  # but before and after it is at 0\n+            f.search(inputs=DocumentArray.empty(size=1), continue_on_error=True)\n \n         p_send = multiprocessing.Process(target=_send_request)\n-        p_before = multiprocessing.Process(target=_assert_before)\n-        p_while = multiprocessing.Process(target=_assert_while)\n+        _assert_pending_value('0.0', runtime_name, port0)\n \n-        p_before.start()\n-        time.sleep(1)\n         p_send.start()\n         time.sleep(1)\n-        p_while.start()\n-\n-        for p in [p_before, p_send, p_while]:\n-            p.join()\n-\n-        exitcodes = []\n-        for p in [p_before, p_send, p_while]:\n-            p.terminate()\n-            exitcodes.append(\n-                p.exitcode\n-            )  # collect the exit codes and assert after all of them have been terminated, to avoid timeouts\n-\n-        for code in exitcodes:\n-            assert not code\n-\n-        _assert_after()\n+        _assert_pending_value('1.0', runtime_name, port0)\n+\n+        p_send.join()\n+        assert p_send.exitcode == 0\n+        _assert_pending_value('0.0', runtime_name, port0)\n+\n+\n+def _create_worker_runtime(port, name='', executor=None):\n+    args = set_pod_parser().parse_args([])\n+    args.port = port\n+    args.name = name\n+    if executor:\n+        args.uses = executor\n+    with WorkerRuntime(args) as runtime:\n+        runtime.run_forever()\n+\n+\n+def _create_gateway_runtime(\n+    graph_description, pod_addresses, port, port_monitoring, protocol='grpc', retries=-1\n+):\n+    if protocol == 'http':\n+        gateway_runtime = HTTPGatewayRuntime\n+    elif protocol == 'websocket':\n+        gateway_runtime = WebSocketGatewayRuntime\n+    else:\n+        gateway_runtime = GRPCGatewayRuntime\n+    with gateway_runtime(\n+        set_gateway_parser().parse_args(\n+            [\n+                '--graph-description',\n+                graph_description,\n+                '--deployments-addresses',\n+                pod_addresses,\n+                '--port',\n+                str(port),\n+                '--retries',\n+                str(retries),\n+                '--monitoring',\n+                '--port-monitoring',\n+                str(port_monitoring),\n+            ]\n+        )\n+    ) as runtime:\n+        runtime.run_forever()\n+\n+\n+def _create_worker(port):\n+    # create a single worker runtime\n+    p = multiprocessing.Process(target=_create_worker_runtime, args=(port,))\n+    p.start()\n+    time.sleep(0.1)\n+    return p\n+\n+\n+def _create_gateway(port, port_monitoring, graph, pod_addr, protocol, retries=-1):\n+    # create a single worker runtime\n+    # create a single gateway runtime\n+    p = multiprocessing.Process(\n+        target=_create_gateway_runtime,\n+        args=(graph, pod_addr, port, port_monitoring, protocol, retries),\n+    )\n+    p.start()\n+    time.sleep(0.1)\n+    return p\n+\n+\n+def _send_request(gateway_port, protocol):\n+    \"\"\"send request to gateway and see what happens\"\"\"\n+    from jina.clients import Client\n+\n+    c = Client(host='localhost', port=gateway_port, protocol=protocol)\n+    return c.post(\n+        '/foo',\n+        inputs=[Document(text='hi') for _ in range(2)],\n+        request_size=1,\n+        return_responses=True,\n+        continue_on_error=True,\n+    )\n+\n+\n+@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+def test_pending_requests_with_connection_error(port_generator, protocol):\n+    runtime_name = 'gateway/GRPCGatewayRuntime' if protocol == 'grpc' else 'gateway'\n+    gateway_port = port_generator()\n+    worker_port = port_generator()\n+    port_monitoring = port_generator()\n+    graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\n+    pod_addresses = f'{{\"pod0\": [\"0.0.0.0:{worker_port}\"]}}'\n+\n+    gateway_process = _create_gateway(\n+        gateway_port, port_monitoring, graph_description, pod_addresses, protocol\n+    )\n+\n+    time.sleep(1.0)\n+\n+    AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'0.0.0.0:{gateway_port}',\n+        ready_or_shutdown_event=multiprocessing.Event(),\n+    )\n+\n+    try:\n+        p = multiprocessing.Process(target=_send_request, args=(gateway_port, protocol))\n+        p.start()\n+        p.join()\n+        time.sleep(2)\n+        _assert_pending_value('0.0', runtime_name, port_monitoring)\n+    except Exception:\n+        assert False\n+    finally:  # clean up runtimes\n+        gateway_process.terminate()\n+        gateway_process.join()\n\n\n###\n\n", "completion": "fix: fix monitoring update of metrics on exception (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/force-release.yml | file path B: .github/workflows/force-release.yml\n\n@@ -19,8 +19,16 @@ jobs:\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n \n+  hub-integration: \n+    uses: jina-ai/hub-integration/.github/workflows/main.yml@main\n+    with:\n+      actions: 'all'\n+    secrets:\n+      jina_dev_bot: ${{ secrets.JINA_DEV_BOT }}\n+      jina_auth_token: ${{ secrets.JINA_AUTH_TOKEN }}\n+\n   regular-release:\n-    needs: token-check\n+    needs: [token-check, hub-integration]\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2\n\n\n###\n\n", "completion": "build: add hub integration (#<issue-num>)"}
{"prompt": " file path A: docs/api-rst.rst | file path B: docs/api-rst.rst\n\n@@ -53,8 +53,23 @@ For further details, please refer to the full :ref:`user guide <executor-cookboo\n    websocket.AsyncWebSocketClient\n \n \n+:mod:`jina.types.request` - Networking messages\n+--------------------\n+\n+.. currentmodule:: jina.types.request\n+\n+.. autosummary::\n+   :nosignatures:\n+   :template: class.rst\n+\n+   Request\n+   data.DataRequest\n+   data.Response\n+   status.StatusMessage\n+\n+\n \n-:mod:`jina.serve.runtimes` - Internals\n+:mod:`jina.serve.runtimes` - Flow internals\n --------------------\n \n .. currentmodule:: jina.serve.runtimes\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -118,6 +118,7 @@ extensions = [\n     'sphinx_inline_tabs',\n ]\n \n+intersphinx_mapping = {'docarray': ('https://docarray.jina.ai/', None)}\n myst_enable_extensions = ['colon_fence']\n autosummary_generate = True\n \n\n---\n file path A: jina/types/request/__init__.py | file path B: jina/types/request/__init__.py\n\n@@ -8,12 +8,13 @@ from jina.types.mixin import ProtoTypeMixin\n \n class Request(ProtoTypeMixin):\n     \"\"\"\n-    :class:`Request` is one of the **primitive data type** in Jina.\n+    :class:`Request` is one of the primitive data types in Jina, and serves as a base for\n+    :class:`~data.DataRequest` and :class:`~data.Response`.\n \n     It offers a Pythonic interface to allow users access and manipulate\n     :class:`jina.jina_pb2.RequestProto` object without working with Protobuf itself.\n \n-    A container for serialized :class:`jina_pb2.RequestProto` that only triggers deserialization\n+    It serves as a container for serialized :class:`jina_pb2.RequestProto` that only triggers deserialization\n     and decompression when receives the first read access to its member.\n \n     It overrides :meth:`__getattr__` to provide the same get/set interface as an\n\n---\n file path A: jina/types/request/data.py | file path B: jina/types/request/data.py\n\n@@ -15,7 +15,13 @@ RequestSourceType = TypeVar(\n \n \n class DataRequest(Request):\n-    \"\"\"Represents a DataRequest used for exchanging DocumentArrays to and within a Flow\"\"\"\n+    \"\"\"\n+    Represents a DataRequest used for exchanging :class:`docarray.DocumentArray` with and within a Flow.\n+\n+    When calling :meth:`~jina.clients.mixin.PostMixin.post` on any Jina client,\n+    the provided input :class:`docarray.DocumentArray` will be\n+    converted to a :class:`DataRequest` before being sent to a Flow.\n+    \"\"\"\n \n     class _DataContent:\n         def __init__(self, content: 'jina_pb2.DataRequestProto.DataContentProto'):\n@@ -239,11 +245,10 @@ class DataRequest(Request):\n \n class Response(DataRequest):\n     \"\"\"\n-    Response is the :class:`Request` object returns from the flow. Right now it shares the same representation as\n-    :class:`Request`. At 0.8.12, :class:`Response` is a simple alias. But it does give a more consistent semantic on\n-    the client API: send a :class:`Request` and receive a :class:`Response`.\n+    Response is the :class:`~jina.types.request.Request` object returned by the flow.\n \n-    .. note::\n-        For now it only exposes `Docs` and `GroundTruth`. Users should very rarely access `Control` commands, so preferably\n-        not confuse the user by adding `CommandMixin`.\n+    At the moment it is an alias for :class:`~jina.types.request.Request`,\n+    and therefore shares an identical representation.\n+    Currently, its sole purpose is to give a more consistent semantic on\n+    the client API: send a :class:`~jina.types.request.data.DataRequest` and receive a :class:`~jina.types.request.data.Response`.\n     \"\"\"\n\n\n###\n\n", "completion": "docs: expose networking requests in api reference (#<issue-num>)"}
{"prompt": " file path A: tests/unit/my-mwu-encoder/0/my-mwu-encoder.bin | file path B: tests/unit/my-mwu-encoder/0/my-mwu-encoder.bin\n\nBinary files a/tests/unit/my-mwu-encoder/0/my-mwu-encoder.bin and /dev/null differ\n\n\n###\n\n", "completion": "test: remove unnecessary folder (#<issue-num>)"}
{"prompt": " file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py\n\n@@ -80,7 +80,7 @@ def test_bad_flow_customized(mocker, protocol):\n     validate_callback(on_error_mock, validate)\n \n \n-class MyExecutor(Executor):\n+class NotImplementedExecutor(Executor):\n     @requests\n     def foo(self, **kwargs):\n         raise NotImplementedError\n@@ -102,7 +102,7 @@ def test_except_with_shards(mocker, protocol):\n         Flow(protocol=protocol)\n         .add(name='r1')\n         .add(name='r2', uses=DummyCrafterExcept, shards=3)\n-        .add(name='r3', uses=MyExecutor)\n+        .add(name='r3', uses=NotImplementedExecutor)\n     )\n \n     with f:\n@@ -118,29 +118,29 @@ def test_except_with_shards(mocker, protocol):\n     validate_callback(on_error_mock, validate)\n \n \n-@pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n+@pytest.mark.parametrize('protocol', ['grpc', 'websocket', 'http'])\n def test_on_error_callback(mocker, protocol):\n-    def validate1():\n-        raise NotImplementedError\n-\n-    def validate2(x, *args):\n+    def validate(x, *args):\n         x = x.routes\n         assert len(x) == 3  # gateway, r1, r3, gateway\n         badones = [r for r in x if r.status.code == jina_pb2.StatusProto.ERROR]\n         assert badones[0].executor == 'r3'\n \n-    f = Flow(protocol=protocol).add(name='r1').add(name='r3', uses=MyExecutor)\n+    f = (\n+        Flow(protocol=protocol)\n+        .add(name='r1')\n+        .add(name='r3', uses=NotImplementedExecutor)\n+    )\n \n     on_error_mock = mocker.Mock()\n \n     with f:\n         f.index(\n             [Document(text='abbcs'), Document(text='efgh')],\n-            on_done=validate1,\n             on_error=on_error_mock,\n         )\n \n-    validate_callback(on_error_mock, validate2)\n+    validate_callback(on_error_mock, validate)\n \n \n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n@@ -159,7 +159,7 @@ def test_no_error_callback(mocker, protocol):\n     on_error_mock.assert_not_called()\n \n \n-@pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n+@pytest.mark.parametrize('protocol', ['websocket', 'http', 'grpc'])\n def test_flow_on_callback(protocol):\n     f = Flow(protocol=protocol).add()\n     hit = []\n\n\n###\n\n", "completion": "refactor: change exec name in test (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/executor-args.md | file path B: docs/fundamentals/flow/executor-args.md\n\n@@ -32,6 +32,7 @@\n | `monitoring` | If set, spawn an http server with a prometheus endpoint to expose metrics | `boolean` | `False` |\n | `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n | `retries` | Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas) | `number` | `-1` |\n+| `floating` | If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one. | `boolean` | `False` |\n | `install_requirements` | If set, install `requirements.txt` in the Hub Executor bundle to local | `boolean` | `False` |\n | `force_update` | If set, always pull the latest Hub Executor bundle even it exists on local | `boolean` | `False` |\n | `compression` | The compression mechanism used when sending requests from the Head to the WorkerRuntimes. For more details, check https://grpc.github.io/grpc/python/grpc.html#compression. | `string` | `None` |\n\n---\n file path A: docs/fundamentals/flow/flow-args.md | file path B: docs/fundamentals/flow/flow-args.md\n\n@@ -5,6 +5,6 @@\n | `log_config` | The YAML config of the logger used in this object. | `string` | `default` |\n | `quiet` | If set, then no log will be emitted from this object. | `boolean` | `False` |\n | `quiet_error` | If set, then exception stack information will not be added to the log | `boolean` | `False` |\n-| `uses` | The YAML file represents a flow | `string` | `None` |\n+| `uses` | The YAML path represents a flow. It can be either a local file path or a URL. | `string` | `None` |\n | `env` | The map of environment variables that are available inside runtime | `object` | `None` |\n | `inspect` | The strategy on those inspect deployments in the flow.<br><br>    If `REMOVE` is given then all inspect deployments are removed when building the flow. | `string` | `COLLECT` |\n\\ No newline at end of file\n\n---\n file path A: docs/fundamentals/flow/gateway-args.md | file path B: docs/fundamentals/flow/gateway-args.md\n\n@@ -44,4 +44,5 @@\n | `replicas` | The number of replicas in the deployment | `number` | `1` |\n | `monitoring` | If set, spawn an http server with a prometheus endpoint to expose metrics | `boolean` | `False` |\n | `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n-| `retries` | Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas) | `number` | `-1` |\n\\ No newline at end of file\n+| `retries` | Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas) | `number` | `-1` |\n+| `floating` | If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one. | `boolean` | `False` |\n\\ No newline at end of file\n\n---\n file path A: jina/jaml/helper.py | file path B: jina/jaml/helper.py\n\n@@ -1,7 +1,8 @@\n import collections\n import json\n import os\n-import warnings\n+import urllib.parse\n+import urllib.request\n from typing import Any, Dict, List, Optional, TextIO, Tuple, Union\n \n from yaml import MappingNode\n@@ -129,6 +130,7 @@ def parse_config_source(\n     allow_class_type: bool = True,\n     allow_dict: bool = True,\n     allow_json: bool = True,\n+    allow_url: bool = True,\n     extra_search_paths: Optional[List[str]] = None,\n     *args,\n     **kwargs,\n@@ -144,6 +146,7 @@ def parse_config_source(\n     :param allow_class_type: flag\n     :param allow_dict: flag\n     :param allow_json: flag\n+    :param allow_url: flag\n     :param extra_search_paths: extra paths to search for\n     :param args: unused\n     :param kwargs: unused\n@@ -165,6 +168,10 @@ def parse_config_source(\n     elif allow_yaml_file and is_yaml_filepath(path):\n         comp_path = complete_path(path, extra_search_paths)\n         return open(comp_path, encoding='utf8'), comp_path\n+    elif allow_url and urllib.parse.urlparse(path).scheme in {'http', 'https'}:\n+        req = urllib.request.Request(path, headers={'User-Agent': 'Mozilla/5.0'})\n+        with urllib.request.urlopen(req) as fp:\n+            return io.StringIO(fp.read().decode('utf-8')), None\n     elif allow_raw_yaml_content and path.lstrip().startswith(('!', 'jtype')):\n         # possible YAML content\n         path = path.replace('|', '\\n    with: ')\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -144,6 +144,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         env: Optional[dict] = None,\n         expose_endpoints: Optional[str] = None,\n         expose_graphql_endpoint: Optional[bool] = False,\n+        floating: Optional[bool] = False,\n         graph_conditions: Optional[str] = '{}',\n         graph_description: Optional[str] = '{}',\n         grpc_server_kwargs: Optional[dict] = None,\n@@ -193,6 +194,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         :param env: The map of environment variables that are available inside runtime\n         :param expose_endpoints: A JSON string that represents a map from executor endpoints (`@requests(on=...)`) to HTTP endpoints.\n         :param expose_graphql_endpoint: If set, /graphql endpoint is added to HTTP interface.\n+        :param floating: If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one.\n         :param graph_conditions: Dictionary stating which filtering conditions each Executor in the graph requires to receive Documents.\n         :param graph_description: Routing graph for the gateway\n         :param grpc_server_kwargs: Dictionary of kwargs arguments that will be passed to the grpc server when starting the server # todo update\n@@ -309,7 +311,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n               When not given, then the default naming strategy will apply.\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n-        :param uses: The YAML file represents a flow\n+        :param uses: The YAML path represents a flow. It can be either a local file path or a URL.\n         :param workspace: The working directory for any IO operations in this object. If not set, then derive from its parent `workspace`.\n \n         .. # noqa: DAR202\n@@ -366,6 +368,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         :param env: The map of environment variables that are available inside runtime\n         :param expose_endpoints: A JSON string that represents a map from executor endpoints (`@requests(on=...)`) to HTTP endpoints.\n         :param expose_graphql_endpoint: If set, /graphql endpoint is added to HTTP interface.\n+        :param floating: If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one.\n         :param graph_conditions: Dictionary stating which filtering conditions each Executor in the graph requires to receive Documents.\n         :param graph_description: Routing graph for the gateway\n         :param grpc_server_kwargs: Dictionary of kwargs arguments that will be passed to the grpc server when starting the server # todo update\n@@ -458,7 +461,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n               When not given, then the default naming strategy will apply.\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n-        :param uses: The YAML file represents a flow\n+        :param uses: The YAML path represents a flow. It can be either a local file path or a URL.\n         :param workspace: The working directory for any IO operations in this object. If not set, then derive from its parent `workspace`.\n \n         .. # noqa: DAR102\n@@ -782,6 +785,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         entrypoint: Optional[str] = None,\n         env: Optional[dict] = None,\n         external: Optional[bool] = False,\n+        floating: Optional[bool] = False,\n         force_update: Optional[bool] = False,\n         gpus: Optional[str] = None,\n         host: Optional[str] = '0.0.0.0',\n@@ -834,6 +838,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         :param entrypoint: The entrypoint command overrides the ENTRYPOINT in Docker image. when not set then the Docker image ENTRYPOINT takes effective.\n         :param env: The map of environment variables that are available inside runtime\n         :param external: The Deployment will be considered an external Deployment that has been started independently from the Flow.This Deployment will not be context managed by the Flow.\n+        :param floating: If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one.\n         :param force_update: If set, always pull the latest Hub Executor bundle even it exists on local\n         :param gpus: This argument allows dockerized Jina executor discover local gpu devices.\n \n@@ -979,6 +984,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         :param entrypoint: The entrypoint command overrides the ENTRYPOINT in Docker image. when not set then the Docker image ENTRYPOINT takes effective.\n         :param env: The map of environment variables that are available inside runtime\n         :param external: The Deployment will be considered an external Deployment that has been started independently from the Flow.This Deployment will not be context managed by the Flow.\n+        :param floating: If set, the current Pod/Deployment can not be further chained, and the next `.add()` will chain after the last Pod/Deployment not this current one.\n         :param force_update: If set, always pull the latest Hub Executor bundle even it exists on local\n         :param gpus: This argument allows dockerized Jina executor discover local gpu devices.\n \n@@ -1159,7 +1165,8 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n \n         op_flow._deployment_nodes[deployment_name] = Deployment(args, needs)\n \n-        op_flow._last_deployment = deployment_name\n+        if not args.floating:\n+            op_flow._last_deployment = deployment_name\n \n         return op_flow\n \n@@ -1362,7 +1369,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         hanging_deployments = _hanging_deployments(op_flow)\n         if hanging_deployments:\n             op_flow.logger.warning(\n-                f'{hanging_deployments} are hanging in this flow with no deployment receiving from them, '\n+                f'{hanging_deployments} are \"floating\" in this flow with no deployment receiving from them, '\n                 f'you may want to double check if it is intentional or some mistake'\n             )\n         op_flow._build_level = FlowBuildLevel.GRAPH\n\n---\n file path A: jina/orchestrate/flow/builder.py | file path B: jina/orchestrate/flow/builder.py\n\n@@ -1,12 +1,12 @@\n from functools import wraps\n-from typing import List, TYPE_CHECKING\n+from typing import TYPE_CHECKING, List\n \n from jina.excepts import FlowBuildLevelError\n \n # noinspection PyUnreachableCode\n if TYPE_CHECKING:\n-    from jina.orchestrate.flow.base import Flow\n     from jina.enums import FlowBuildLevel\n+    from jina.orchestrate.flow.base import Flow\n \n \n def allowed_levels(levels: List['FlowBuildLevel']):\n@@ -48,7 +48,7 @@ def _hanging_deployments(op_flow: 'Flow') -> List[str]:\n     :param op_flow: the Flow we're operating on\n     :return: names of hanging Deployments (nobody recv from them) in the Flow.\n     \"\"\"\n-    all_needs = {v for p in op_flow._deployment_nodes.values() for v in p.needs}\n-    all_names = {p for p in op_flow._deployment_nodes.keys()}\n+    all_needs = {k for p, v in op_flow for k in v.needs}\n+    all_names = {p for p, v in op_flow if not v.args.floating}\n     # all_names is always a superset of all_needs\n     return list(all_names.difference(all_needs))\n\n---\n file path A: jina/parsers/flow.py | file path B: jina/parsers/flow.py\n\n@@ -13,7 +13,12 @@ def mixin_flow_features_parser(parser):\n \n     gp = add_arg_group(parser, title='Flow Feature')\n \n-    gp.add_argument('--uses', type=str, help='The YAML file represents a flow')\n+    gp.add_argument(\n+        '--uses',\n+        type=str,\n+        help='The YAML path represents a flow. It can be either a local file path or a URL.',\n+    )\n+\n     gp.add_argument(\n         '--env',\n         action=KVAppendAction,\n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -111,3 +111,11 @@ def mixin_pod_parser(parser):\n         dest='retries',\n         help=f'Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas)',\n     )\n+\n+    gp.add_argument(\n+        '--floating',\n+        action='store_true',\n+        default=False,\n+        help='If set, the current Pod/Deployment can not be further chained, '\n+        'and the next `.add()` will chain after the last Pod/Deployment not this current one.',\n+    )\n\n---\n file path A: jina_cli/autocomplete.py | file path B: jina_cli/autocomplete.py\n\n@@ -57,6 +57,7 @@ ac_table = {\n             '--monitoring',\n             '--port-monitoring',\n             '--retries',\n+            '--floating',\n             '--install-requirements',\n             '--force-update',\n             '--force',\n@@ -141,6 +142,7 @@ ac_table = {\n             '--monitoring',\n             '--port-monitoring',\n             '--retries',\n+            '--floating',\n         ],\n         'hub new': [\n             '--help',\n@@ -216,6 +218,7 @@ ac_table = {\n             '--monitoring',\n             '--port-monitoring',\n             '--retries',\n+            '--floating',\n             '--install-requirements',\n             '--force-update',\n             '--force',\n@@ -267,6 +270,7 @@ ac_table = {\n             '--monitoring',\n             '--port-monitoring',\n             '--retries',\n+            '--floating',\n             '--install-requirements',\n             '--force-update',\n             '--force',\n\n---\n file path A: None | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_floating_pod.py\n\n@@ -0,0 +1,24 @@\n+import pytest\n+\n+from jina import Document, Executor, Flow, requests\n+\n+\n+class MyExecutor(Executor):\n+    @requests\n+    async def add_text(self, docs, **kwargs):\n+        docs[0].text = 'hello'\n+\n+\n+@pytest.mark.parametrize('floating, expect_str', [(True, 'world'), (False, 'hello')])\n+def test_floating_pod(floating, expect_str):\n+    f = (\n+        Flow()\n+        .add(replicas=3, name='a1')\n+        .add(name='a2', floating=floating, uses=MyExecutor)\n+        .add(name='a3')\n+        .add(floating=floating, uses=MyExecutor)\n+    )\n+\n+    with f:\n+        da = f.post('/', Document(text='world'))\n+        assert da[0].text == expect_str\n\n\n###\n\n", "completion": "feat(flow): adding floating deployment (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1494,7 +1494,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n \n         progress = Progress(\n             SpinnerColumn(),\n-            TextColumn('Waiting [b]{task.fields[pending_str]}[/]', justify='right'),\n+            TextColumn('Waiting [b]{task.fields[pending_str]}[/]...', justify='right'),\n             BarColumn(),\n             MofNCompleteColumn(),\n             TimeElapsedColumn(),\n@@ -1516,27 +1516,26 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                     daemon=True,\n                 )\n                 threads.append(t)\n-                t.start()\n-\n-            # kick off spinner thread\n-            t_m = threading.Thread(\n-                target=_polling_status, args=(progress, task), daemon=True\n-            )\n-            t_m.start()\n \n             # kick off ip getter thread, address, http, graphq\n             all_panels = []\n \n             t_ip = threading.Thread(\n-                target=self._get_address_table, args=(all_panels,), daemon=True\n+                target=self._get_summary_table, args=(all_panels, results), daemon=True\n             )\n-            t_ip.start()\n+            threads.append(t_ip)\n+\n+            # kick off spinner thread\n+            t_m = threading.Thread(\n+                target=_polling_status, args=(progress, task), daemon=True\n+            )\n+            threads.append(t_m)\n+\n+            for t in threads:\n+                t.start()\n \n             for t in threads:\n                 t.join()\n-            if t_ip is not None:\n-                t_ip.join()\n-            t_m.join()\n \n             error_deployments = [k for k, v in results.items() if v != 'done']\n             if error_deployments:\n@@ -1874,7 +1873,9 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         table.add_column('', justify='right')\n         return table\n \n-    def _get_address_table(self, all_panels: List[Panel]):\n+    def _get_summary_table(self, all_panels: List[Panel], results):\n+\n+        results['summary'] = 'pending'\n \n         address_table = self._init_table()\n \n@@ -2014,6 +2015,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                 )\n             )\n \n+        results['summary'] = 'done'\n         return all_panels\n \n     @allowed_levels([FlowBuildLevel.RUNNING])\n\n\n###\n\n", "completion": "feat: improve ui after flow success (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/executor-args.md | file path B: docs/fundamentals/flow/executor-args.md\n\n@@ -11,7 +11,7 @@\n | `uses_with` | Dictionary of keyword arguments that will override the `with` configuration in `uses` | `object` | `None` |\n | `uses_metas` | Dictionary of keyword arguments that will override the `metas` configuration in `uses` | `object` | `None` |\n | `uses_requests` | Dictionary of keyword arguments that will override the `requests` configuration in `uses` | `object` | `None` |\n-| `py_modules` | The customized python modules need to be imported before loading the executor<br><br>Note that the recommended way is to only import a single module - a simple python file, if your<br>executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,<br>which should be structured as a python package. For more details, please see the<br>`Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__ | `array` | `None` |\n+| `py_modules` | The customized python modules need to be imported before loading the executor<br><br>Note that the recommended way is to only import a single module - a simple python file, if your<br>executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,<br>which should be structured as a python package. For more details, please see the<br>`Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__ | `array` | `None` |\n | `port` | The port for input data to bind to, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n | `host_in` | The host address for binding to, by default it is 0.0.0.0 | `string` | `0.0.0.0` |\n | `native` | If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime. | `boolean` | `False` |\n\n---\n file path A: docs/fundamentals/flow/gateway-args.md | file path B: docs/fundamentals/flow/gateway-args.md\n\n@@ -11,7 +11,7 @@\n | `uses_with` | Dictionary of keyword arguments that will override the `with` configuration in `uses` | `object` | `None` |\n | `uses_metas` | Dictionary of keyword arguments that will override the `metas` configuration in `uses` | `object` | `None` |\n | `uses_requests` | Dictionary of keyword arguments that will override the `requests` configuration in `uses` | `object` | `None` |\n-| `py_modules` | The customized python modules need to be imported before loading the executor<br><br>Note that the recommended way is to only import a single module - a simple python file, if your<br>executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,<br>which should be structured as a python package. For more details, please see the<br>`Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__ | `array` | `None` |\n+| `py_modules` | The customized python modules need to be imported before loading the executor<br><br>Note that the recommended way is to only import a single module - a simple python file, if your<br>executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,<br>which should be structured as a python package. For more details, please see the<br>`Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__ | `array` | `None` |\n | `port` | The port for input data to bind to, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n | `host_in` | The host address for binding to, by default it is 0.0.0.0 | `string` | `0.0.0.0` |\n | `native` | If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime. | `boolean` | `False` |\n\n---\n file path A: docs/fundamentals/jcloud/basic.md | file path B: docs/fundamentals/jcloud/basic.md\n\n@@ -68,7 +68,7 @@ You can create an example local project using `jc new`. The default structure lo\n \n where,\n \n-- `executor1` directory has all Executor related code/config. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/repository-structure/). Multiple such Executor directories can be created.\n+- `executor1` directory has all Executor related code/config. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/executor-files/). Multiple such Executor directories can be created.\n - `flow.yml` Your Flow YAML.\n - `.env` All environment variables used during deployment.\n \n\n---\n file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -621,7 +621,7 @@ We can not discover any Executor in your uploaded bundle. This is often due to o\n   - The bundle did not contain any valid executor.\n   - The config.yml's `jtype` is mismatched with the actual Executor class name.\n     For more information about the expected bundle structure, please refer to the documentation.\n-    https://docs.jina.ai/fundamentals/executor/repository-structure/\n+    https://docs.jina.ai/fundamentals/executor/executor-files/#multiple-python-files-yaml \n '''\n         msg += '''\n For more detailed information, you can try the `executor-normalizer` locally to see the root cause.\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -239,7 +239,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n           Note that the recommended way is to only import a single module - a simple python file, if your\n           executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,\n           which should be structured as a python package. For more details, please see the\n-          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__\n+          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n         :param replicas: The number of replicas in the deployment\n@@ -412,7 +412,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n           Note that the recommended way is to only import a single module - a simple python file, if your\n           executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,\n           which should be structured as a python package. For more details, please see the\n-          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__\n+          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n         :param replicas: The number of replicas in the deployment\n@@ -878,7 +878,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n           Note that the recommended way is to only import a single module - a simple python file, if your\n           executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,\n           which should be structured as a python package. For more details, please see the\n-          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__\n+          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n         :param quiet_remote_logs: Do not display the streaming of remote logs on local console\n@@ -1023,7 +1023,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n           Note that the recommended way is to only import a single module - a simple python file, if your\n           executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,\n           which should be structured as a python package. For more details, please see the\n-          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__\n+          `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n         :param quiet_remote_logs: Do not display the streaming of remote logs on local console\n\n---\n file path A: jina/parsers/orchestrate/runtimes/worker.py | file path B: jina/parsers/orchestrate/runtimes/worker.py\n\n@@ -66,7 +66,7 @@ The customized python modules need to be imported before loading the executor\n Note that the recommended way is to only import a single module - a simple python file, if your\n executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,\n which should be structured as a python package. For more details, please see the\n-`Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__\n+`Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__\n ''',\n     )\n \n\n\n###\n\n", "completion": "fix: replace broken executor files docs link (#<issue-num>)"}
{"prompt": " file path A: jina/clients/grpc.py | file path B: jina/clients/grpc.py\n\n@@ -1,5 +1,10 @@\n from jina.clients.base.grpc import GRPCBaseClient\n-from jina.clients.mixin import AsyncPostMixin, HealthCheckMixin, PostMixin\n+from jina.clients.mixin import (\n+    AsyncHealthCheckMixin,\n+    AsyncPostMixin,\n+    HealthCheckMixin,\n+    PostMixin,\n+)\n \n \n class GRPCClient(GRPCBaseClient, PostMixin, HealthCheckMixin):\n@@ -23,7 +28,7 @@ class GRPCClient(GRPCBaseClient, PostMixin, HealthCheckMixin):\n     \"\"\"\n \n \n-class AsyncGRPCClient(GRPCBaseClient, AsyncPostMixin, HealthCheckMixin):\n+class AsyncGRPCClient(GRPCBaseClient, AsyncPostMixin, AsyncHealthCheckMixin):\n     \"\"\"\n     Asynchronous client connecting to a Gateway using gRPC protocol.\n \n\n---\n file path A: jina/clients/http.py | file path B: jina/clients/http.py\n\n@@ -1,5 +1,6 @@\n from jina.clients.base.http import HTTPBaseClient\n from jina.clients.mixin import (\n+    AsyncHealthCheckMixin,\n     AsyncMutateMixin,\n     AsyncPostMixin,\n     HealthCheckMixin,\n@@ -30,7 +31,7 @@ class HTTPClient(HTTPBaseClient, PostMixin, MutateMixin, HealthCheckMixin):\n \n \n class AsyncHTTPClient(\n-    HTTPBaseClient, AsyncPostMixin, AsyncMutateMixin, HealthCheckMixin\n+    HTTPBaseClient, AsyncPostMixin, AsyncMutateMixin, AsyncHealthCheckMixin\n ):\n     \"\"\"\n     Asynchronous client connecting to a Gateway using HTTP protocol.\n\n---\n file path A: jina/clients/mixin.py | file path B: jina/clients/mixin.py\n\n@@ -8,6 +8,7 @@ from jina.importer import ImportExtensions\n \n if TYPE_CHECKING:\n     from docarray import DocumentArray\n+\n     from jina.clients.base import CallbackFnType, InputType\n     from jina.types.request import Response\n \n@@ -100,6 +101,18 @@ class HealthCheckMixin:\n         return run_async(self.client._dry_run, **kwargs)\n \n \n+class AsyncHealthCheckMixin:\n+    \"\"\"The Health check Mixin for Client and Flow to expose `dry_run` API\"\"\"\n+\n+    async def dry_run(self, **kwargs) -> bool:\n+        \"\"\"Sends a dry run to the Flow to validate if the Flow is ready to receive requests\n+\n+        :param kwargs: potential kwargs received passed from the public interface\n+        :return: boolean indicating the health/readiness of the Flow\n+        \"\"\"\n+        return await self.client._dry_run(**kwargs)\n+\n+\n class PostMixin:\n     \"\"\"The Post Mixin class for Client and Flow\"\"\"\n \n\n---\n file path A: jina/clients/websocket.py | file path B: jina/clients/websocket.py\n\n@@ -1,5 +1,10 @@\n from jina.clients.base.websocket import WebSocketBaseClient\n-from jina.clients.mixin import AsyncPostMixin, HealthCheckMixin, PostMixin\n+from jina.clients.mixin import (\n+    AsyncHealthCheckMixin,\n+    AsyncPostMixin,\n+    HealthCheckMixin,\n+    PostMixin,\n+)\n \n \n class WebSocketClient(WebSocketBaseClient, PostMixin, HealthCheckMixin):\n@@ -23,7 +28,7 @@ class WebSocketClient(WebSocketBaseClient, PostMixin, HealthCheckMixin):\n     \"\"\"\n \n \n-class AsyncWebSocketClient(WebSocketBaseClient, AsyncPostMixin, HealthCheckMixin):\n+class AsyncWebSocketClient(WebSocketBaseClient, AsyncPostMixin, AsyncHealthCheckMixin):\n     \"\"\"\n     Asynchronous client connecting to a Gateway using WebSocket protocol.\n \n\n---\n file path A: tests/integration/runtimes/test_gateway_dry_run.py | file path B: tests/integration/runtimes/test_gateway_dry_run.py\n\n@@ -1,14 +1,8 @@\n-import asyncio\n-import json\n import multiprocessing\n-import threading\n-import time\n-from collections import defaultdict\n \n import pytest\n \n-from jina import Client, Document, Executor, requests\n-from jina.enums import PollingType\n+from jina import Client\n from jina.parsers import set_gateway_parser, set_pod_parser\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n from jina.serve.runtimes.gateway.grpc import GRPCGatewayRuntime\n@@ -49,10 +43,7 @@ def _create_gateway_runtime(graph_description, pod_addresses, port, protocol='gr\n         runtime.run_forever()\n \n \n-@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n-def test_dry_run_of_flow(port_generator, protocol):\n-    worker_port = port_generator()\n-    port = port_generator()\n+def _setup(worker_port, port, protocol):\n     graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\n     pod_addresses = f'{{\"pod0\": [\"0.0.0.0:{worker_port}\"]}}'\n \n@@ -79,11 +70,19 @@ def test_dry_run_of_flow(port_generator, protocol):\n         ctrl_address=f'0.0.0.0:{port}',\n         ready_or_shutdown_event=multiprocessing.Event(),\n     )\n+    return worker_process, gateway_process\n \n+\n+@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+def test_dry_run_of_flow(port_generator, protocol):\n+    worker_port = port_generator()\n+    port = port_generator()\n+    worker_process, gateway_process = _setup(worker_port, port, protocol)\n     # send requests to the gateway\n-    c = Client(host='localhost', port=port, asyncio=True, protocol=protocol)\n+    c = Client(host='localhost', port=port, protocol=protocol)\n     dry_run_alive = c.dry_run()\n \n+    # _teardown(worker_process, gateway_process, dry_run_alive)\n     worker_process.terminate()\n     worker_process.join()\n \n@@ -97,3 +96,29 @@ def test_dry_run_of_flow(port_generator, protocol):\n \n     assert gateway_process.exitcode == 0\n     assert worker_process.exitcode == 0\n+\n+\n+@pytest.mark.asyncio\n+@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+async def test_async_dry_run_of_flow(port_generator, protocol):\n+    worker_port = port_generator()\n+    port = port_generator()\n+    worker_process, gateway_process = _setup(worker_port, port, protocol)\n+    # send requests to the gateway\n+    c = Client(host='localhost', asyncio=True, port=port, protocol=protocol)\n+    dry_run_alive = await c.dry_run()\n+\n+    # _teardown(worker_process, gateway_process, dry_run_alive)\n+    worker_process.terminate()\n+    worker_process.join()\n+\n+    dry_run_worker_removed = await c.dry_run()\n+\n+    gateway_process.terminate()\n+    gateway_process.join()\n+\n+    assert dry_run_alive\n+    assert not dry_run_worker_removed\n+\n+    assert gateway_process.exitcode == 0\n+    assert worker_process.exitcode == 0\n\n\n###\n\n", "completion": "fix: add async dry run method (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -197,6 +197,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14118,3 +14119,33 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```ace551ff```](https://github.com/jina-ai/jina/commit/ace551ffd0ec688866d85986c5d72b9f0e1d1542)] __-__ update JClould banner (#4938) (*Kelly*)\n  - [[```9dac3f69```](https://github.com/jina-ai/jina/commit/9dac3f693b6b7d89b9b02095b68e7e07cb358087)] __-__ __version__: the next version will be 3.6.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-6></a>\n+## Release Note (`3.6.6`)\n+\n+> Release time: 2022-06-24 14:18:33\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  Johannes Messner,  Jina Dev Bot,  tarrantro,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```3469bd88```](https://github.com/jina-ai/jina/commit/3469bd883f9f8cdb2467447c456bdd9aa12eaa34)] __-__ native python module path in py_modules (#4954) (*Han Xiao*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```12910c1c```](https://github.com/jina-ai/jina/commit/12910c1ca4c6a242f682225b4f36de802617697c)] __-__ revert 4410 and fix silent error (#4949) (*Han Xiao*)\n+ - [[```6eaf38ba```](https://github.com/jina-ai/jina/commit/6eaf38ba151a585de94ac7781be7c19e6dae7145)] __-__ handle replicas in ui monitoring (#4956) (*samsja*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```675f1075```](https://github.com/jina-ai/jina/commit/675f10757da899ed4728bff9170461c1318caf89)] __-__ explanation how to set env vars (#4955) (*Johannes Messner*)\n+ - [[```4c41d4e8```](https://github.com/jina-ai/jina/commit/4c41d4e8888e39e438b460f7be1cb8e042b7af57)] __-__ undo wolf document updates (#4953) (*tarrantro*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```0fbb7335```](https://github.com/jina-ai/jina/commit/0fbb73357a4670f590c7c9336153a5fb1ac482db)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```f968cbe5```](https://github.com/jina-ai/jina/commit/f968cbe592ae1f565ef96634e0d40b4b4de9b50f)] __-__ __version__: the next version will be 3.6.6 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.6'\n+__version__ = '3.6.7'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.7"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1524,11 +1524,11 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n             )\n             t_m.start()\n \n-            # kick off ip getter thread\n-            addr_table = self._init_table()\n+            # kick off ip getter thread, address, http, graphq\n+            all_panels = []\n \n             t_ip = threading.Thread(\n-                target=self._get_address_table, args=(addr_table,), daemon=True\n+                target=self._get_address_table, args=(all_panels,), daemon=True\n             )\n             t_ip.start()\n \n@@ -1545,14 +1545,10 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                 )\n                 self.close()\n                 raise RuntimeFailToStart\n+            from rich.rule import Rule\n \n-        if addr_table:\n             print(\n-                Panel(\n-                    addr_table,\n-                    title=':tada: [b]Flow is ready to serve![/]',\n-                    expand=False,\n-                )\n+                Rule(':tada: Flow is ready to serve!'), *all_panels\n             )  # can't use logger here see : https://github.com/Textualize/rich/discussions/2024\n         self.logger.debug(\n             f'{self.num_deployments} Deployments (i.e. {self.num_pods} Pods) are running in this Flow'\n@@ -1870,24 +1866,27 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         return self._deployment_nodes.items().__iter__()\n \n     def _init_table(self):\n-        table = Table(title=None, box=None, highlight=True, show_header=False)\n-        table.add_column('', justify='right')\n-        table.add_column('', justify='right')\n+        table = Table(\n+            title=None, box=None, highlight=True, show_header=False, min_width=40\n+        )\n+        table.add_column('', justify='left')\n         table.add_column('', justify='right')\n         table.add_column('', justify='right')\n-\n         return table\n \n-    def _get_address_table(self, address_table):\n+    def _get_address_table(self, all_panels: List[Panel]):\n+\n+        address_table = self._init_table()\n+\n         _protocol = str(self.protocol)\n         if self.gateway_args.ssl_certfile and self.gateway_args.ssl_keyfile:\n             _protocol = f'{self.protocol}S'\n             address_table.add_row(\n-                ':link:', 'Protocol', f':closed_lock_with_key: {_protocol}'\n+                ':chains:', 'Protocol', f':closed_lock_with_key: {_protocol}'\n             )\n \n         else:\n-            address_table.add_row(':link:', 'Protocol', _protocol)\n+            address_table.add_row(':chains:', 'Protocol', _protocol)\n \n         _protocol = _protocol.lower()\n         address_table.add_row(\n@@ -1908,8 +1907,18 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                 f'[link={_protocol}://{self.address_public}:{self.port}]{self.address_public}:{self.port}[/]',\n             )\n \n+        all_panels.append(\n+            Panel(\n+                address_table,\n+                title=':link: [b]Endpoint[/]',\n+                expand=False,\n+            )\n+        )\n+\n         if self.protocol == GatewayProtocolType.HTTP:\n \n+            http_ext_table = self._init_table()\n+\n             _address = [\n                 f'[link={_protocol}://localhost:{self.port}/docs]Local[/]',\n                 f'[link={_protocol}://{self.address_private}:{self.port}/docs]Private[/]',\n@@ -1918,10 +1927,10 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                 _address.append(\n                     f'[link={_protocol}://{self.address_public}:{self.port}/docs]Public[/]'\n                 )\n-            address_table.add_row(\n+            http_ext_table.add_row(\n                 ':speech_balloon:',\n-                'Swagger UI [dim](/docs)[/]',\n-                '\u00b7'.join(_address),\n+                'Swagger UI',\n+                '.../docs',\n             )\n \n             _address = [\n@@ -1934,10 +1943,10 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                     f'[link={_protocol}://{self.address_public}:{self.port}/redoc]Public[/]'\n                 )\n \n-            address_table.add_row(\n+            http_ext_table.add_row(\n                 ':books:',\n-                'Redoc [dim](/redoc)[/]',\n-                '\u00b7'.join(_address),\n+                'Redoc',\n+                '.../redoc',\n             )\n \n             if self.gateway_args.expose_graphql_endpoint:\n@@ -1951,32 +1960,61 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                         f'[link={_protocol}://{self.address_public}:{self.port}/graphql]Public[/]'\n                     )\n \n-                address_table.add_row(\n+                http_ext_table.add_row(\n                     ':strawberry:',\n-                    'GraphQL UI [dim](/graphql)[/]',\n-                    '\u00b7'.join(_address),\n+                    'GraphQL UI',\n+                    '.../graphql',\n                 )\n \n+            all_panels.append(\n+                Panel(\n+                    http_ext_table,\n+                    title=':gem: [b]HTTP extension[/]',\n+                    expand=False,\n+                )\n+            )\n+\n         if self.monitoring:\n-            for name, deployment in self:\n-                _address = [\n-                    f'[link=http://localhost:{deployment.args.port_monitoring}]Local[/]',\n-                    f'[link=http://{self.address_private}:{deployment.args.port_monitoring}]Private[/]',\n-                ]\n+            monitor_ext_table = self._init_table()\n \n-                if self.address_public:\n-                    _address.append(\n-                        f'[link=http://{self.address_public}:{deployment.args.port_monitoring}]Public[/]'\n-                    )\n+            for name, deployment in self:\n \n                 if deployment.args.monitoring:\n-                    address_table.add_row(\n-                        ':bar_chart:',\n-                        f'Monitor [b]{name}:{deployment.args.port_monitoring}[/]',\n-                        '\u00b7'.join(_address),\n-                    )\n \n-        return address_table\n+                    for replica in deployment.pod_args['pods'][0]:\n+                        _address = [\n+                            f'[link=http://localhost:{replica.port_monitoring}]Local[/]',\n+                            f'[link=http://{self.address_private}:{replica.port_monitoring}]Private[/]',\n+                        ]\n+\n+                        if self.address_public:\n+                            _address.append(\n+                                f'[link=http://{self.address_public}:{deployment.args.port_monitoring}]Public[/]'\n+                            )\n+\n+                        _name = (\n+                            name\n+                            if len(deployment.pod_args['pods'][0]) == 1\n+                            else replica.name\n+                        )\n+\n+                        monitor_ext_table.add_row(\n+                            ':flashlight:',  # upstream issue: they dont have :torch: emoji, so we use :flashlight:\n+                            # to represent observability of Prometheus (even they have :torch: it will be a war\n+                            # between AI community and Cloud-native community fighting on this emoji)\n+                            _name,\n+                            f'...[b]:{replica.port_monitoring}[/]',\n+                        )\n+\n+            all_panels.append(\n+                Panel(\n+                    monitor_ext_table,\n+                    title=':gem: [b]Prometheus extension[/]',\n+                    expand=False,\n+                )\n+            )\n+\n+        return all_panels\n \n     @allowed_levels([FlowBuildLevel.RUNNING])\n     def block(\n\n\n###\n\n", "completion": "fix: handle replicas in ui monitoring (#<issue-num>)"}
{"prompt": " file path A: docs/envs/index.md | file path B: docs/envs/index.md\n\n@@ -1,28 +1,73 @@\n (jina-env-vars)=\n # Environment Variables\n \n-The following environment variables are used internally in Jina.\n-\n-| Environment variable          | Description |\n-|-------------------------------| ----------- |\n-| `JINA_AUTH_TOKEN`               | If provided, jina hub push would push this Executor to specific account |\n-| `JINA_DEFAULT_HOST`             | The default host where the server is exposed |\n-| `JINA_DEFAULT_TIMEOUT_CTRL`     | The default timeout time used by Flow to check the readiness of Executors |\n-| `JINA_DEFAULT_WORKSPACE_BASE`   | The default workspace folder set to the runtime if none provided through arguments |\n-| `JINA_DEPLOYMENT_NAME`          | The name of the deployment exposed, used by the Head Runtime in Kubernetes to connect to different deployments |\n-| `JINA_DISABLE_UVLOOP`           | If set, Jina will not use uvloop event loop for concurrent execution |\n-| `JINA_FULL_CLI`                 | If set, all the CLI options will be shown in help |\n-| `JINA_GATEWAY_IMAGE`            | Used when exporting a Flow to Kubernetes or docker-compose to override the default gateway image |\n-| `JINA_GRPC_RECV_BYTES`          | Set by the grpc service to keep track of the received bytes |\n-| `JINA_GRPC_SEND_BYTES`          | Set by the grpc service to keep track of the sent bytes  |\n-| `JINA_HUBBLE_REGISTRY`          | Set it to point to a different Jina Hub registry |\n-| `JINA_HUB_CACHE_DIR`            | The directory where hub will cache its executors inside JINA_HUB_ROOT |\n-| `JINA_HUB_ROOT`                 | The base directory for HubIO to store and read files |\n-| `JINA_LOG_CONFIG`               | The configuration used for the logger |\n-| `JINA_LOG_LEVEL`                | The logging level used: INFO, DEBUG, WARNING |\n-| `JINA_LOG_NO_COLOR`             | If set, disables color from rich console |\n-| `JINA_MP_START_METHOD`          | Sets the multiprocessing start method used by jina |\n-| `JINA_RANDOM_PORT_MAX`          | The max port number used when selecting random ports to apply for Executors or gateway |\n-| `JINA_RANDOM_PORT_MIN`          | The min port number used when selecting random ports to apply for Executors or gateway |\n-| `JINA_DISABLE_HEALTHCHECK_LOGS` | If set, disables the logs when processing health check requests |\n-| `JINA_LOCKS_ROOT`               | The root folder where file locks for concurrent Executor initialization |\n+Jina uses a number of environment variables to determine different behaviours.\n+\n+If you use containerized Executors (including {ref}`Kubernetes <kubernetes>` and {ref}`Docker Compose <docker-compose>`), you can pass separate environment variables to each Executor in the following way:\n+\n+\n+`````{tab} YAML\n+\n+```yaml\n+jtype: Flow\n+version: '1'\n+with: {}\n+executors:\n+- name: executor0\n+  port: 49583\n+  env:\n+    JINA_LOG_LEVEL: DEBUG\n+    MYSECRET: ${{ ENV.MYSECRET }}\n+- name: executor1\n+  port: 62156\n+  env:\n+    JINA_LOG_LEVEL: INFO\n+    CUDA_VISIBLE_DEVICES: 1\n+```\n+`````\n+````{tab} Python\n+\n+```python\n+from jina import Flow\n+import os\n+\n+secret = os.environ['MYSECRET']\n+f = (\n+    Flow()\n+    .add(env={'JINA_LOG_LEVEL': 'DEBUG', 'MYSECRET': secret})\n+    .add(env={'JINA_LOG_LEVEL': 'INFO', 'CUDA_VISIBLE_DEVICES': 1})\n+)\n+f.save_config(\"envflow.yml\")\n+```\n+````\n+\n+```{admonition} See Also\n+:class: seealso\n+For more information about the environment variable syntax used in Jina YAML configurations, see {ref}`here <migration-env-var>`.\n+```\n+\n+The following environment variables are used internally in Jina:\n+\n+| Environment variable          | Description                                                                                                    |\n+|-------------------------------|----------------------------------------------------------------------------------------------------------------|\n+| `JINA_AUTH_TOKEN`               | If provided, `jina hub push` pushes this Executor to specific account                                          |\n+| `JINA_DEFAULT_HOST`             | The default host where the server is exposed                                                                   |\n+| `JINA_DEFAULT_TIMEOUT_CTRL`     | The default timeout time used by Flow to check the readiness of Executors                                      |\n+| `JINA_DEFAULT_WORKSPACE_BASE`   | The default workspace folder used by an Executor if none provided through arguments                            |\n+| `JINA_DEPLOYMENT_NAME`          | The name of the deployment, used by the Head Runtime in Kubernetes to connect to different deployments |\n+| `JINA_DISABLE_UVLOOP`           | If set, Jina will not use uvloop event loop for concurrent execution                                           |\n+| `JINA_FULL_CLI`                 | If set, all the CLI options will be shown in help                                                              |\n+| `JINA_GATEWAY_IMAGE`            | Used when exporting a Flow to Kubernetes or docker-compose to override the default gateway image               |\n+| `JINA_GRPC_RECV_BYTES`          | Set by the grpc service to keep track of the received bytes                                                    |\n+| `JINA_GRPC_SEND_BYTES`          | Set by the grpc service to keep track of the sent bytes                                                        |\n+| `JINA_HUBBLE_REGISTRY`          | Set it to point to a different Jina Hub registry                                                               |\n+| `JINA_HUB_CACHE_DIR`            | The directory where hub will cache its executors inside JINA_HUB_ROOT                                          |\n+| `JINA_HUB_ROOT`                 | The base directory for HubIO to store and read files                                                           |\n+| `JINA_LOG_CONFIG`               | The configuration used for the logger                                                                          |\n+| `JINA_LOG_LEVEL`                | The logging level used: INFO, DEBUG, WARNING                                                                   |\n+| `JINA_LOG_NO_COLOR`             | If set, disables color from rich console                                                                       |\n+| `JINA_MP_START_METHOD`          | Sets the multiprocessing start method used by jina                                                             |\n+| `JINA_RANDOM_PORT_MAX`          | The max port number used when selecting random ports to apply for Executors or gateway                         |\n+| `JINA_RANDOM_PORT_MIN`          | The min port number used when selecting random ports to apply for Executors or gateway                         |\n+| `JINA_DISABLE_HEALTHCHECK_LOGS` | If set, disables the logs when processing health check requests                                                |\n+| `JINA_LOCKS_ROOT`               | The root folder where file locks for concurrent Executor initialization                                        |\n\n---\n file path A: docs/get-started/migrate.md | file path B: docs/get-started/migrate.md\n\n@@ -274,7 +274,7 @@ callback function is specified.\n `.post()` can still be configured to return a list of Responses, by passing `return_responses=True` to the Client or Flow\n constructors.\n \n-\n+(migration-env-var)=\n ## Consistent YAML parsing syntax\n \n In Jina 3, YAML syntax is aligned with [Github Actions notation](https://docs.github.com/en/actions/learn-github-actions/environment-variables),\n\n\n###\n\n", "completion": "docs: explanation how to set env vars (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -166,9 +166,10 @@ An Executor object contains {attr}`~.jina.serve.executors.BaseExecutor.metas` as\n \n The list of the `metas` are:\n \n-- `name`: Name given to the Executor\n-- `description`: Optional description of the Executor\n-- `py_modules`: List of Python modules needed to import the Executor\n+- `name`: Name given to the Executor;\n+- `description`: Description of the Executor (optional, reserved for future-use in auto-docs);\n+- `py_modules`: List of Python modules needed to import the Executor. It can be Python package path e.g. `foo.bar.package.module` or file path to the modules needed to import the Executor.\n+\n \n These can be provided to the Executor via the {ref}`Python or YAML API <executor-api>`.\n \n@@ -184,7 +185,7 @@ The list of the `runtime_args` is:\n - `shards`: Number of {ref}`shards <partition-data-by-using-shards>` of the same Executor deployed with the Flow.\n - `shard_id`: Identifier of the `shard` corresponding to the given Executor instance.\n - `workspace`: Path to be used by the Executor. Note that the actual workspace directory used by the Executor is obtained by appending `'/<executor_name>/<shard_id>/'` to this value.\n-- `py_modules`: Path to the modules needed to import the Executor. This is another way to pass `py-modules` to the Executor from the Flow\n+- `py_modules`: Python package path e.g. `foo.bar.package.module` or file path to the modules needed to import the Executor. This is another way to pass `py-modules` to the Executor from the Flow\n \n These can **not** be provided by the user through any API. They are generated by the Flow orchestration.\n \n\n---\n file path A: jina/importer.py | file path B: jina/importer.py\n\n@@ -1,3 +1,4 @@\n+import importlib\n import os\n import sys\n import warnings\n@@ -139,14 +140,20 @@ class PathImporter:\n \n         :param paths: Paths of the modules.\n         \"\"\"\n-        from jina.jaml.helper import complete_path\n \n-        paths = [complete_path(m) for m in paths]\n+        # assume paths are Python module names\n+        not_python_module_paths = []\n+        for path in paths:\n+            if not os.path.isfile(path):\n+                try:\n+                    importlib.import_module(path)\n+                except:\n+                    not_python_module_paths.append(path)\n+            else:\n+                not_python_module_paths.append(path)\n \n-        for p in paths:\n-            if not os.path.exists(p):\n-                raise FileNotFoundError(\n-                    f'cannot import module from {p}, file not exist'\n-                )\n+        # try again, but assume they are file paths instead of module names\n+        from jina.jaml.helper import complete_path\n \n-            _path_import(p)\n+        for m in not_python_module_paths:\n+            _path_import(complete_path(m))\n\n---\n file path A: jina/jaml/helper.py | file path B: jina/jaml/helper.py\n\n@@ -256,15 +256,5 @@ def load_py_modules(d: Dict, extra_search_paths: Optional[List[str]] = None) ->\n \n     _finditem(d)\n     if mod:\n-        if len(mod) > 1:\n-            warnings.warn(\n-                'It looks like you are trying to import multiple python modules using'\n-                ' `py_modules`. When using multiple python files to define an executor,'\n-                ' the recommended practice is to structure the files in a python'\n-                ' package, and only import the `__init__.py` file of that package.'\n-                ' For more details, please check out the cookbook: '\n-                'https://docs.jina.ai/fundamentals/executor/repository-structure/'\n-            )\n-\n         mod = [complete_path(m, extra_search_paths) for m in mod]\n         PathImporter.add_modules(*mod)\n\n\n###\n\n", "completion": "feat: native python module path in py_modules (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -102,14 +102,4 @@ jcloud:\n executors:\n   - name: custom\n     uses: jinahub+docker://CustomExecutor\n-```\n-\n-## Jcloud Annotations\n-\n-To manage `jcloud` resources in kubernetes, we will update the annotations to resources. Below are the arguments that will pass to kubernetes annotation and its format.\n-\n-```\n-'jina.ai/jina-version': jcloud.version # jina version of flows\n-'jina.ai/retention-days': jcloud.retention_days # flow retetion period\n-'jina.ai/user': flow.user # User of the flow\n-```\n+```\n\\ No newline at end of file\n\n\n###\n\n", "completion": "docs: undo wolf document updates (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -196,6 +196,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14090,3 +14091,29 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```873c5a30```](https://github.com/jina-ai/jina/commit/873c5a30fc3c7d67b858f8c54491492ba9fa2929)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```68af1d07```](https://github.com/jina-ai/jina/commit/68af1d075374028c4dadc9c76d58d5311a3cc921)] __-__ __version__: the next version will be 3.6.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-5></a>\n+## Release Note (`3.6.5`)\n+\n+> Release time: 2022-06-23 07:57:23\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  tarrantro,  Jina Dev Bot,  samsja,  Kelly,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```65d68735```](https://github.com/jina-ai/jina/commit/65d6873500f008dafba193340f8731bca39bc7dc)] __-__ expose kwargs to Clients (#4947) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```6715f0b3```](https://github.com/jina-ai/jina/commit/6715f0b357fc7dd89e260ef9d9239efa720268a8)] __-__ add wolf annotations document (#4944) (*tarrantro*)\n+ - [[```aeb44de5```](https://github.com/jina-ai/jina/commit/aeb44de5132e23cd67596369ea0026f5a8aaa9ad)] __-__ add external executor tls for jcloud (#4942) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```5c446cf8```](https://github.com/jina-ai/jina/commit/5c446cf8243103c8c3fca5c1b737f9c6b7e5ab9b)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```ace551ff```](https://github.com/jina-ai/jina/commit/ace551ffd0ec688866d85986c5d72b9f0e1d1542)] __-__ update JClould banner (#4938) (*Kelly*)\n+ - [[```9dac3f69```](https://github.com/jina-ai/jina/commit/9dac3f693b6b7d89b9b02095b68e7e07cb358087)] __-__ __version__: the next version will be 3.6.5 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.5'\n+__version__ = '3.6.6'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.6"}
{"prompt": " file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -40,7 +40,10 @@ class GRPCBaseClient(BaseClient):\n                 stub = jina_pb2_grpc.JinaGatewayDryRunRPCStub(channel)\n                 self.logger.debug(f'connected to {self.args.host}:{self.args.port}')\n                 call_result = stub.dry_run(\n-                    jina_pb2.google_dot_protobuf_dot_empty__pb2.Empty(), **kwargs\n+                    jina_pb2.google_dot_protobuf_dot_empty__pb2.Empty(),\n+                    metadata=kwargs.get('metadata', None),\n+                    credentials=kwargs.get('credentials', None),\n+                    timeout=kwargs.get('timeout', None),\n                 )\n                 metadata, response = (\n                     await call_result.trailing_metadata(),\n@@ -80,12 +83,14 @@ class GRPCBaseClient(BaseClient):\n                 self.logger.debug(f'connected to {self.args.host}:{self.args.port}')\n \n                 with ProgressBar(\n-                    total_length=self._inputs_length, disable=not (self.show_progress)\n+                    total_length=self._inputs_length, disable=not self.show_progress\n                 ) as p_bar:\n-\n                     async for resp in stub.Call(\n                         req_iter,\n                         compression=self.compression,\n+                        metadata=kwargs.get('metadata', None),\n+                        credentials=kwargs.get('credentials', None),\n+                        timeout=kwargs.get('timeout', None),\n                     ):\n                         callback_exec(\n                             response=resp,\n\n---\n file path A: jina/clients/base/helper.py | file path B: jina/clients/base/helper.py\n\n@@ -17,26 +17,38 @@ if TYPE_CHECKING:\n class AioHttpClientlet(ABC):\n     \"\"\"aiohttp session manager\"\"\"\n \n-    def __init__(self, url: str, logger: 'JinaLogger') -> None:\n+    def __init__(self, url: str, logger: 'JinaLogger', **kwargs) -> None:\n         \"\"\"HTTP Client to be used with the streamer\n \n         :param url: url to send http/websocket request to\n         :param logger: jina logger\n+        :param kwargs: kwargs  which will be forwarded to the `aiohttp.Session` instance. Used to pass headers to requests\n         \"\"\"\n         self.url = url\n         self.logger = logger\n         self.msg_recv = 0\n         self.msg_sent = 0\n         self.session = None\n+        self._session_kwargs = {}\n+        if kwargs.get('headers', None):\n+            self._session_kwargs['headers'] = kwargs.get('headers')\n+        if kwargs.get('auth', None):\n+            self._session_kwargs['auth'] = kwargs.get('auth')\n+        if kwargs.get('cookies', None):\n+            self._session_kwargs['cookies'] = kwargs.get('cookies')\n \n     @abstractmethod\n-    async def send_message(self):\n-        \"\"\"Send message to Gateway\"\"\"\n+    async def send_message(self, **kwargs):\n+        \"\"\"Send message to Gateway\n+        :param kwargs: kwargs which will be forwarded to the `aiohttp.Session.post` method. Used to pass headers to requests\n+        \"\"\"\n         ...\n \n     @abstractmethod\n-    async def send_dry_run(self):\n-        \"\"\"Query the dry_run endpoint from Gateway\"\"\"\n+    async def send_dry_run(self, **kwargs):\n+        \"\"\"Query the dry_run endpoint from Gateway\n+        :param kwargs: kwargs which will be forwarded to the `aiohttp.Session.post` method. Used to pass headers to requests\n+        \"\"\"\n         ...\n \n     @abstractmethod\n@@ -63,7 +75,7 @@ class AioHttpClientlet(ABC):\n         with ImportExtensions(required=True):\n             import aiohttp\n \n-        self.session = aiohttp.ClientSession()\n+        self.session = aiohttp.ClientSession(**self._session_kwargs)\n         await self.session.__aenter__()\n         return self\n \n@@ -206,6 +218,7 @@ class WebsocketClientlet(AioHttpClientlet):\n         self.websocket = await self.session.ws_connect(\n             url=self.url,\n             protocols=(WebsocketSubProtocols.BYTES.value,),\n+            **self._session_kwargs,\n         ).__aenter__()\n         self.response_iter = WsResponseIter(self.websocket)\n         return self\n\n---\n file path A: jina/clients/base/http.py | file path B: jina/clients/base/http.py\n\n@@ -44,7 +44,7 @@ class HTTPBaseClient(BaseClient):\n     async def _dry_run(self, **kwargs) -> bool:\n         \"\"\"Sends a dry run to the Flow to validate if the Flow is ready to receive requests\n \n-        :param kwargs: potential kwargs received passed from the public interface\n+        :param kwargs: kwargs coming from the public interface. Includes arguments to be passed to the `HTTPClientlet`\n         :return: boolean indicating the health/readiness of the Flow\n         \"\"\"\n         from jina.proto import jina_pb2\n@@ -54,10 +54,10 @@ class HTTPBaseClient(BaseClient):\n                 proto = 'https' if self.args.tls else 'http'\n                 url = f'{proto}://{self.args.host}:{self.args.port}/dry_run'\n                 iolet = await stack.enter_async_context(\n-                    HTTPClientlet(url=url, logger=self.logger)\n+                    HTTPClientlet(url=url, logger=self.logger, **kwargs)\n                 )\n \n-                response = await iolet.send_dry_run()\n+                response = await iolet.send_dry_run(**kwargs)\n                 r_status = response.status\n \n                 r_str = await response.json()\n@@ -83,7 +83,7 @@ class HTTPBaseClient(BaseClient):\n         :param on_done: the callback for on_done\n         :param on_error: the callback for on_error\n         :param on_always: the callback for on_always\n-        :param kwargs: kwargs for _get_task_name and _get_requests\n+        :param kwargs: kwargs coming from the public interface. Includes arguments to be passed to the `HTTPClientlet`\n         :yields: generator over results\n         \"\"\"\n         with ImportExtensions(required=True):\n@@ -102,7 +102,7 @@ class HTTPBaseClient(BaseClient):\n                 proto = 'https' if self.args.tls else 'http'\n                 url = f'{proto}://{self.args.host}:{self.args.port}/post'\n                 iolet = await stack.enter_async_context(\n-                    HTTPClientlet(url=url, logger=self.logger)\n+                    HTTPClientlet(url=url, logger=self.logger, **kwargs)\n                 )\n \n                 def _request_handler(request: 'Request') -> 'asyncio.Future':\n\n---\n file path A: jina/clients/base/websocket.py | file path B: jina/clients/base/websocket.py\n\n@@ -25,7 +25,7 @@ class WebSocketBaseClient(BaseClient):\n     async def _dry_run(self, **kwargs) -> bool:\n         \"\"\"Sends a dry run to the Flow to validate if the Flow is ready to receive requests\n \n-        :param kwargs: potential kwargs received passed from the public interface\n+        :param kwargs: kwargs coming from the public interface. Includes arguments to be passed to the `WebsocketClientlet`\n         :return: boolean indicating the readiness of the Flow\n         \"\"\"\n         async with AsyncExitStack() as stack:\n@@ -33,7 +33,7 @@ class WebSocketBaseClient(BaseClient):\n                 proto = 'wss' if self.args.tls else 'ws'\n                 url = f'{proto}://{self.args.host}:{self.args.port}/dry_run'\n                 iolet = await stack.enter_async_context(\n-                    WebsocketClientlet(url=url, logger=self.logger)\n+                    WebsocketClientlet(url=url, logger=self.logger, **kwargs)\n                 )\n \n                 async def _receive():\n@@ -84,7 +84,7 @@ class WebSocketBaseClient(BaseClient):\n         :param on_done: the callback for on_done\n         :param on_error: the callback for on_error\n         :param on_always: the callback for on_always\n-        :param kwargs: kwargs for _get_task_name and _get_requests\n+        :param kwargs: kwargs coming from the public interface. Includes arguments to be passed to the `WebsocketClientlet`\n         :yields: generator over results\n         \"\"\"\n         with ImportExtensions(required=True):\n@@ -103,7 +103,7 @@ class WebSocketBaseClient(BaseClient):\n                 proto = 'wss' if self.args.tls else 'ws'\n                 url = f'{proto}://{self.args.host}:{self.args.port}/'\n                 iolet = await stack.enter_async_context(\n-                    WebsocketClientlet(url=url, logger=self.logger)\n+                    WebsocketClientlet(url=url, logger=self.logger, **kwargs)\n                 )\n \n                 request_buffer: Dict[\n\n---\n file path A: jina/clients/mixin.py | file path B: jina/clients/mixin.py\n\n@@ -7,7 +7,7 @@ from jina.helper import get_or_reuse_loop, run_async\n from jina.importer import ImportExtensions\n \n if TYPE_CHECKING:\n-    from jina import DocumentArray\n+    from docarray import DocumentArray\n     from jina.clients.base import CallbackFnType, InputType\n     from jina.types.request import Response\n \n@@ -221,7 +221,7 @@ class AsyncPostMixin:\n         :param show_progress: if set, client will show a progress bar on receiving every request.\n         :param continue_on_error: if set, a Request that causes callback error will be logged only without blocking the further requests.\n         :param return_responses: if set to True, the result will come as Response and not as a `DocumentArray`\n-        :param kwargs: additional parameters\n+        :param kwargs: additional parameters, can be used to pass metadata or authentication information in the server call\n         :yield: Response object\n \n         .. warning::\n\n---\n file path A: tests/integration/clients_extra_kwargs/__init__.py | file path B: tests/integration/clients_extra_kwargs/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/clients_extra_kwargs/test_clients_post_extra_kwargs.py\n\n@@ -0,0 +1,86 @@\n+import os\n+\n+import grpc\n+import pytest\n+\n+from jina import Flow, __default_host__\n+from jina.clients import Client\n+from jina.excepts import PortAlreadyUsed\n+from jina.helper import is_port_free\n+from jina.serve.runtimes.gateway.grpc import GRPCGatewayRuntime as _GRPCGatewayRuntime\n+from tests import random_docs\n+\n+\n+@pytest.fixture(scope='function')\n+def flow_with_grpc(monkeypatch):\n+    class AuthInterceptor(grpc.aio.ServerInterceptor):\n+        def __init__(self, key):\n+            self._valid_metadata = ('rpc-auth-header', key)\n+\n+            def deny(_, context):\n+                context.abort(grpc.StatusCode.UNAUTHENTICATED, 'Invalid key')\n+\n+            self._deny = grpc.unary_unary_rpc_method_handler(deny)\n+\n+        async def intercept_service(self, continuation, handler_call_details):\n+            meta = handler_call_details.invocation_metadata\n+\n+            metas_dicts = {m.key: m.value for m in meta}\n+            assert 'rpc-auth-header' in metas_dicts\n+            assert (\n+                metas_dicts['rpc-auth-header'] == 'access_key'\n+            ), f'Invalid access key detected, got {metas_dicts[\"rpc-auth-header\"]}'\n+\n+            for m in meta:\n+                if m == self._valid_metadata:\n+                    return await continuation(handler_call_details)\n+\n+            return self._deny\n+\n+    class AlternativeGRPCGatewayRuntime(_GRPCGatewayRuntime):\n+        async def async_setup(self):\n+            \"\"\"\n+            The async method to setup.\n+            Create the gRPC server and expose the port for communication.\n+            \"\"\"\n+            if not self.args.proxy and os.name != 'nt':\n+                os.unsetenv('http_proxy')\n+                os.unsetenv('https_proxy')\n+\n+            if not (is_port_free(__default_host__, self.args.port)):\n+                raise PortAlreadyUsed(f'port:{self.args.port}')\n+\n+            self.server = grpc.aio.server(\n+                interceptors=(AuthInterceptor('access_key'),),\n+                options=[\n+                    ('grpc.max_send_message_length', -1),\n+                    ('grpc.max_receive_message_length', -1),\n+                ],\n+            )\n+\n+            self._set_topology_graph()\n+            self._set_connection_pool()\n+\n+            await self._async_setup_server()\n+\n+    monkeypatch.setattr(\n+        'jina.serve.runtimes.gateway.grpc.GRPCGatewayRuntime',\n+        AlternativeGRPCGatewayRuntime,\n+    )\n+    return Flow(protocol='grpc').add()\n+\n+\n+def test_client_grpc_kwargs(flow_with_grpc):\n+    with flow_with_grpc:\n+        client = Client(\n+            port=flow_with_grpc.port,\n+            host='localhost',\n+            protocol='grpc',\n+        )\n+\n+        meta_data = (('rpc-auth-header', 'invalid_access_key'),)\n+\n+        try:\n+            client.post('', random_docs(1), request_size=1, metadata=meta_data)\n+        except Exception as exc:\n+            assert 'Invalid access key detected, got invalid_access_key' in repr(exc)\n\n---\n file path A: tests/unit/clients/python/test_client.py | file path B: tests/unit/clients/python/test_client.py\n\n@@ -3,12 +3,10 @@ import time\n \n import pytest\n import requests\n-from docarray import Document, DocumentArray\n \n-from jina import Executor, Flow, __windows__, helper\n+from jina import Executor, Flow, helper\n from jina import requests as req\n from jina.clients import Client\n-from jina.excepts import BadClientInput\n from jina.orchestrate.pods.factory import PodFactory\n from jina.parsers import set_gateway_parser\n from tests import random_docs\n\n---\n file path A: tests/unit/clients/python/test_on_err.py | file path B: tests/unit/clients/python/test_on_err.py\n\n@@ -1,12 +1,11 @@\n from typing import Optional\n \n import aiohttp\n-import grpc\n import numpy as np\n import pytest\n-from docarray import DocumentArray\n from docarray.document.generators import from_ndarray\n \n+from docarray import DocumentArray\n from jina import Client, Flow\n from jina.excepts import BadClientCallback\n \n\n---\n file path A: tests/unit/clients/test_helper.py | file path B: tests/unit/clients/test_helper.py\n\n@@ -1,9 +1,10 @@\n import aiohttp\n import pytest\n-from jina import Flow, Executor, requests\n-from jina.logging.logger import JinaLogger\n-from jina.clients.request.helper import _new_data_request\n+\n+from jina import Executor, Flow, requests\n from jina.clients.base.helper import HTTPClientlet, WebsocketClientlet\n+from jina.clients.request.helper import _new_data_request\n+from jina.logging.logger import JinaLogger\n from jina.types.request.data import DataRequest\n \n logger = JinaLogger('clientlet')\n\n\n###\n\n", "completion": "feat: expose kwargs to Clients (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -90,3 +90,26 @@ executors:\n   - name: custom\n     uses: jinahub+docker://CustomExecutor\n ```\n+\n+## Flow retention days\n+\n+In Jcloud, we have default life-cycle(24hrs) for each flow and we will remove flows periodically if they are beyond the life-cycle. To change the default behavior and manage it by yourself, you can setup `retention_days` args in `jcloud`. `-1` is never expired, `0` is to use the default life-cycle, or `X`(0<X<365), which means keep the flow utill X days. `0` is the default value if you don't pass `retention_days` argument.\n+\n+```yaml\n+jtype: Flow\n+jcloud:\n+  retention_days: -1\n+executors:\n+  - name: custom\n+    uses: jinahub+docker://CustomExecutor\n+```\n+\n+## Jcloud Annotations\n+\n+To manage `jcloud` resources in kubernetes, we will update the annotations to resources. Below are the arguments that will pass to kubernetes annotation and its format.\n+\n+```\n+'jina.ai/jina-version': jcloud.version # jina version of flows\n+'jina.ai/retention-days': jcloud.retention_days # flow retetion period\n+'jina.ai/user': flow.user # User of the flow\n+```\n\n\n###\n\n", "completion": "docs: add wolf annotations document (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/add-executors.md | file path B: docs/fundamentals/flow/add-executors.md\n\n@@ -158,7 +158,7 @@ f = Flow(extra_search_paths=['../executor']).add(uses='config1.yml').add(uses='c\n ```\n \n ````\n-\n+(external-executors)=\n ### External Executors\n \n Usually a Flow will manage all of its Executors. External Executors are not managed by the current Flow object but by others. For example, one may want to share expensive Executors between Flows. Often these Executors are stateless, GPU based Encoders.\n@@ -173,6 +173,19 @@ Flow().add(host='123.45.67.89', port=12345, external=True)\n \n This is adding an external Executor to the Flow. The Flow will not start or stop this Executor and assumes that is externally managed and available at `123.45.67.89:12345`\n \n+You can also use external Executors with `tls` enabled.\n+\n+```python\n+from jina import Flow\n+\n+Flow().add(host='123.45.67.89', port=443, external=True, tls=True)\n+```\n+\n+```{hint} \n+Using `tls` to connect to the External Executor is especially needed if you want to use an external Executor deployed with JCloud. See the JCloud {ref}`documentation <jcloud-external-executors>`\n+for further details\n+```\n+\n \n ## Set configs\n You can set and override {class}`~jina.Executor` configs when adding them into a {class}`~jina.Flow`.\n\n---\n file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -43,10 +43,10 @@ executors:\n     jcloud:\n       capacity: on-demand\n ```\n-\n+(jcloud-external-executors)=\n ## Deploy external executors\n \n-You can also expose the Executors only by setting `expose_gateway` to `false`. Read more about [External Executors.](https://docs.jina.ai/how-to/external-executor/)\n+You can also expose only the Executors by setting `expose_gateway` to `False`. Read more about {ref}`External Executors <external-executors>`\n \n ```yaml\n jtype: Flow\n\n\n###\n\n", "completion": "docs: add external executor tls for jcloud (#<issue-num>)"}
{"prompt": " file path A: docs/_static/jcloud-banner.png | file path B: docs/_static/jcloud-banner.png\n\nBinary files a/docs/_static/jcloud-banner.png and b/docs/_static/jcloud-banner.png differ\n\n\n###\n\n", "completion": "chore: update JClould banner (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -195,6 +195,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14058,3 +14059,33 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```8e19bfdc```](https://github.com/jina-ai/jina/commit/8e19bfdc8f95c209320ab1a2a67216234c44efef)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```3e168dd9```](https://github.com/jina-ai/jina/commit/3e168dd9208365490031345aa0475fbdb4a9a9ce)] __-__ __version__: the next version will be 3.6.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-4></a>\n+## Release Note (`3.6.4`)\n+\n+> Release time: 2022-06-20 11:22:38\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Han Xiao,  Jina Dev Bot,  Johannes Messner,  Zac Li,  Sha Zhou,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```84eafa80```](https://github.com/jina-ai/jina/commit/84eafa80a2a6abb0346bff70cfe9008a93db8850)] __-__ fix port monitoring (#4931) (*samsja*)\n+ - [[```245891f5```](https://github.com/jina-ai/jina/commit/245891f564dcd9e977817d9c21767bc8d7d74c2d)] __-__ __doc__: update the description and default questions for qabot (#4928) (*Sha Zhou*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```70ce851f```](https://github.com/jina-ai/jina/commit/70ce851f244ea071ed95e048d789141a708d4c1f)] __-__ remove broken api sidebar (#4936) (*Johannes Messner*)\n+ - [[```74269235```](https://github.com/jina-ai/jina/commit/7426923589e7a19442daaae6e6b438b58f851fc4)] __-__ examples in docstrings (#4933) (*Johannes Messner*)\n+ - [[```3b6b6dda```](https://github.com/jina-ai/jina/commit/3b6b6ddab1370ca4bd398d2213a8318a402844ff)] __-__ create api reference (#4913) (*Johannes Messner*)\n+ - [[```1cd8645d```](https://github.com/jina-ai/jina/commit/1cd8645dcf9cfe1afd0d6b8ef285aed182c7e5b0)] __-__ add jcloud version doc (#4929) (*Zac Li*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```07921b52```](https://github.com/jina-ai/jina/commit/07921b5212cfd98b48c8f822cb64277d633483bd)] __-__ fix readme (*Han Xiao*)\n+ - [[```944f8e56```](https://github.com/jina-ai/jina/commit/944f8e56321eb5d152d3bb1337c298fd86bc7af6)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```873c5a30```](https://github.com/jina-ai/jina/commit/873c5a30fc3c7d67b858f8c54491492ba9fa2929)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```68af1d07```](https://github.com/jina-ai/jina/commit/68af1d075374028c4dadc9c76d58d5311a3cc921)] __-__ __version__: the next version will be 3.6.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.4'\n+__version__ = '3.6.5'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.5"}
{"prompt": " file path A: docs/fundamentals/flow/monitoring-flow.md | file path B: docs/fundamentals/flow/monitoring-flow.md\n\n@@ -57,10 +57,11 @@ metrics endpoints:\n * `http://localhost:9090` for the gateway\n * `http://localhost:9091` for the SimpleIndexer\n \n-````{admonition} Default Monitoring port\n-:class: hint\n-The default monitoring port is `9090`, if you want to enable the monitoring on both the Gateway and the Executors you need to specify\n-the `prometheus_port` for the Executors. \n+````{admonition} Change the default monitoring port\n+:class: caution\n+When Jina is used locally, all of the `port_monitoring` will be random by default (within the range [49152, 65535]). However we \n+strongly encourage you to precise these ports for the Gateway and for all of the Executors. Otherwise it will change at \n+restart and you will have to change your Prometheus configuration file.\n ````\n \n \n\n---\n file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -274,6 +274,9 @@ class K8sDeploymentConfig:\n                 )\n                 parsed_args['head_deployment'].gpus = None\n                 parsed_args['head_deployment'].port = GrpcConnectionPool.K8S_PORT\n+                parsed_args[\n+                    'head_deployment'\n+                ].port_monitoring = GrpcConnectionPool.K8S_PORT_MONITORING\n                 parsed_args['head_deployment'].uses = None\n                 parsed_args['head_deployment'].uses_metas = None\n                 parsed_args['head_deployment'].uses_with = None\n@@ -315,6 +318,8 @@ class K8sDeploymentConfig:\n             cargs.uses_after = None\n             if args.name != 'gateway':\n                 cargs.port = GrpcConnectionPool.K8S_PORT\n+                cargs.port_monitoring = GrpcConnectionPool.K8S_PORT_MONITORING\n+\n             cargs.uses_before_address = None\n             cargs.uses_after_address = None\n             if shards > 1:\n\n---\n file path A: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py | file path B: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py\n\n@@ -59,6 +59,10 @@ def get_deployment_yamls(\n     if not port:\n         port = GrpcConnectionPool.K8S_PORT\n \n+    if not port_monitoring:\n+        port_monitoring = GrpcConnectionPool.K8S_PORT_MONITORING\n+\n+\n     deployment_params = {\n         'name': name,\n         'namespace': namespace,\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -2206,6 +2206,12 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n \n                 v.args.port = GrpcConnectionPool.K8S_PORT\n                 v.first_pod_args.port = GrpcConnectionPool.K8S_PORT\n+\n+                v.args.port_monitoring = GrpcConnectionPool.K8S_PORT_MONITORING\n+                v.first_pod_args.port_monitoring = (\n+                    GrpcConnectionPool.K8S_PORT_MONITORING\n+                )\n+\n                 v.args.default_port = False\n \n             deployment_base = os.path.join(output_base_path, node)\n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -29,6 +29,7 @@ if TYPE_CHECKING:\n \n DEFAULT_MINIMUM_RETRIES = 3\n \n+\n class ReplicaList:\n     \"\"\"\n     Maintains a list of connections to replicas and uses round robin for selecting a replica\n@@ -148,6 +149,7 @@ class GrpcConnectionPool:\n     K8S_PORT_USES_AFTER = 8082\n     K8S_PORT_USES_BEFORE = 8081\n     K8S_PORT = 8080\n+    K8S_PORT_MONITORING = 9090\n \n     class ConnectionStubs:\n         \"\"\"\n\n---\n file path A: tests/k8s/test_k8s.py | file path B: tests/k8s/test_k8s.py\n\n@@ -6,9 +6,9 @@ import os\n import pytest\n import requests as req\n import yaml\n+from docarray import DocumentArray\n from pytest_kind import cluster\n \n-from docarray import DocumentArray\n from jina import Document, Executor, Flow, requests\n from jina.orchestrate.deployments import Deployment\n from jina.orchestrate.deployments.config.k8s import K8sDeploymentConfig\n@@ -245,15 +245,9 @@ async def test_flow_with_monitoring(logger, tmpdir, docker_images, port_generato\n     dump_path = os.path.join(str(tmpdir), 'test-flow-with-monitoring')\n     namespace = f'test-flow-monitoring'.lower()\n \n-    port1 = port_generator()\n-    port2 = port_generator()\n-    flow = Flow(\n-        name='test-flow-monitoring', monitoring=True, port_monitoring=port1\n-    ).add(\n+    flow = Flow(name='test-flow-monitoring', monitoring=True).add(\n         name='segmenter',\n         uses=f'docker://{docker_images[0]}',\n-        monitoring=True,\n-        port_monitoring=port2,\n     )\n \n     flow.to_kubernetes_yaml(dump_path, k8s_namespace=namespace)\n@@ -286,10 +280,21 @@ async def test_flow_with_monitoring(logger, tmpdir, docker_images, port_generato\n         .metadata.name\n     )\n \n-    pod_port_ref = [(gateway_pod_name, port1)]\n+    executor_pod_name = (\n+        core_client.list_namespaced_pod(\n+            namespace=namespace, label_selector='app=segmenter'\n+        )\n+        .items[0]\n+        .metadata.name\n+    )\n \n-    for (pod_name, port) in pod_port_ref:\n-        with portforward.forward(namespace, pod_name, port, port, config_path):\n+    port_monitoring = GrpcConnectionPool.K8S_PORT_MONITORING\n+    port = port_generator()\n+\n+    for pod_name in [gateway_pod_name, executor_pod_name]:\n+        with portforward.forward(\n+            namespace, pod_name, port, port_monitoring, config_path\n+        ):\n             resp = req.get(f'http://localhost:{port}/')\n             assert resp.status_code == 200\n \n\n---\n file path A: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py | file path B: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py\n\n@@ -70,6 +70,7 @@ def test_parse_args(\n                 'uses_metas',\n                 'uses_before_address',\n                 'uses_after_address',\n+                'port_monitoring',\n             ),\n         )\n         assert (\n@@ -129,6 +130,7 @@ def test_parse_args(\n             if len(deployment_config.deployment_args['deployments']) > 1\n             else 'executor'\n         )\n+        assert depl_arg.port_monitoring == GrpcConnectionPool.K8S_PORT_MONITORING\n         cargs = copy.deepcopy(args)\n         cargs.shard_id = i\n         assert namespace_equal(\n@@ -142,6 +144,7 @@ def test_parse_args(\n                 'uses_before',  # the uses_before and after is head business\n                 'uses_after',\n                 'name',\n+                'port_monitoring',\n             ),\n         )\n \n@@ -206,6 +209,7 @@ def test_parse_args_custom_executor(shards: int):\n                 'port',\n                 'k8s_namespace',\n                 'name',\n+                'port_monitoring',\n             ),\n         )\n \n\n\n###\n\n", "completion": "fix: fix port monitoring (#<issue-num>)"}
{"prompt": " file path A: docs/api-rst.rst | file path B: docs/api-rst.rst\n\n@@ -14,7 +14,6 @@ For further details, please refer to the full :ref:`user guide <executor-cookboo\n \n .. autosummary::\n    :nosignatures:\n-   :toctree: stubs/flow\n    :template: class.rst\n \n    base.Flow\n@@ -28,7 +27,6 @@ For further details, please refer to the full :ref:`user guide <executor-cookboo\n \n .. autosummary::\n    :nosignatures:\n-   :toctree: stubs/executor\n    :template: class.rst\n \n    Executor\n@@ -44,7 +42,6 @@ For further details, please refer to the full :ref:`user guide <executor-cookboo\n \n .. autosummary::\n    :nosignatures:\n-   :toctree: stubs/clients\n    :template: class.rst\n \n    Client\n@@ -64,7 +61,6 @@ For further details, please refer to the full :ref:`user guide <executor-cookboo\n \n .. autosummary::\n    :nosignatures:\n-   :toctree: stubs/internals\n    :template: class.rst\n \n    asyncio.AsyncNewLoopRuntime\n\n\n###\n\n", "completion": "docs: remove broken api sidebar (#<issue-num>)"}
{"prompt": " file path A: jina/clients/__init__.py | file path B: jina/clients/__init__.py\n\n@@ -66,6 +66,21 @@ def Client(\n \n     \"\"\"Convenience function that returns client instance for given protocol.\n \n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Client\n+        from docarray import Document\n+\n+        # select protocol from 'grpc', 'http', or 'websocket'; default is 'grpc'\n+        # select asyncio True of False; default is False\n+        # select host address to connect to\n+        c = Client(\n+            protocol='grpc', asyncio=False, host='grpc://my.awesome.flow:1234'\n+        )  # returns GRPCClient instance\n+        c.post(on='/index', inputs=Document(text='hello!'))\n+\n     :param asyncio: If set, then the input and output of this Client work in an asynchronous manner.\n     :param host: The host address of the runtime, by default it is 0.0.0.0.\n     :param port: The port of the Gateway, which the client should connect to.\n\n---\n file path A: jina/clients/grpc.py | file path B: jina/clients/grpc.py\n\n@@ -3,13 +3,32 @@ from jina.clients.mixin import AsyncPostMixin, HealthCheckMixin, PostMixin\n \n \n class GRPCClient(GRPCBaseClient, PostMixin, HealthCheckMixin):\n-    \"\"\"A client connecting to a Gateway using gRPC protocol.\"\"\"\n+    \"\"\"A client connecting to a Gateway using gRPC protocol.\n+\n+    Instantiate this class through the :meth:`jina.Client` convenience method.\n+\n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Client\n+        from docarray import Document\n+\n+        # select host address to connect to\n+        c = Client(\n+            protocol='grpc', asyncio=False, host='grpc://my.awesome.flow:1234'\n+        )  # returns GRPCClient instance\n+        c.post(on='/index', inputs=Document(text='hello!'))\n+\n+    \"\"\"\n \n \n class AsyncGRPCClient(GRPCBaseClient, AsyncPostMixin, HealthCheckMixin):\n     \"\"\"\n     Asynchronous client connecting to a Gateway using gRPC protocol.\n \n+    Instantiate this class through the :meth:`jina.Client` convenience method.\n+\n     Unlike :class:`GRPCClient`, here :meth:`post` is a coroutine (i.e. declared with the async/await syntax),\n     simply calling them will not schedule them to be executed.\n \n@@ -21,4 +40,26 @@ class AsyncGRPCClient(GRPCBaseClient, AsyncPostMixin, HealthCheckMixin):\n     In this case, users often do **NOT** want to let Jina control the ``asyncio.eventloop``. On contrary, :class:`Client`\n     is controlling and wrapping the event loop internally, making the Client looks synchronous from outside.\n \n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Client\n+        from docarray import Document\n+\n+        # async inputs for the client\n+        async def async_inputs():\n+            for _ in range(10):\n+                yield Document()\n+                await asyncio.sleep(0.1)\n+\n+\n+        # select host address to connect to\n+        c = Client(\n+            protocol='grpc', asyncio=True, host='grpc://my.awesome.flow:1234'\n+        )  # returns AsyncGRPCClient instance\n+\n+        async for resp in client.post(on='/index', async_inputs, request_size=1):\n+            print(resp)\n+\n     \"\"\"\n\n---\n file path A: jina/clients/http.py | file path B: jina/clients/http.py\n\n@@ -9,8 +9,23 @@ from jina.clients.mixin import (\n \n \n class HTTPClient(HTTPBaseClient, PostMixin, MutateMixin, HealthCheckMixin):\n-    \"\"\"\n-    A client connecting to a Gateway using HTTP protocol.\n+    \"\"\"A client connecting to a Gateway using gRPC protocol.\n+\n+    Instantiate this class through the :meth:`jina.Client` convenience method.\n+\n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Client\n+        from docarray import Document\n+\n+        # select host address to connect to\n+        c = Client(\n+            protocol='http', asyncio=False, host='http://my.awesome.flow:1234'\n+        )  # returns HTTPClient instance\n+        c.post(on='/index', inputs=Document(text='hello!'))\n+\n     \"\"\"\n \n \n@@ -20,6 +35,8 @@ class AsyncHTTPClient(\n     \"\"\"\n     Asynchronous client connecting to a Gateway using HTTP protocol.\n \n+    Instantiate this class through the :meth:`jina.Client` convenience method.\n+\n     Unlike :class:`HTTPClient`, here :meth:`post` is a coroutine (i.e. declared with the async/await syntax),\n     simply calling them will not schedule them to be executed.\n \n@@ -31,4 +48,26 @@ class AsyncHTTPClient(\n     In this case, users often do not want to let Jina control the ``asyncio.eventloop``. On contrary, :class:`Client`\n     is controlling and wrapping the event loop internally, making the Client looks synchronous from outside.\n \n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Client\n+        from docarray import Document\n+\n+        # async inputs for the client\n+        async def async_inputs():\n+            for _ in range(10):\n+                yield Document()\n+                await asyncio.sleep(0.1)\n+\n+\n+        # select host address to connect to\n+        c = Client(\n+            protocol='http', asyncio=True, host='http://my.awesome.flow:1234'\n+        )  # returns AsyncHTTPClient instance\n+\n+        async for resp in client.post(on='/index', async_inputs, request_size=1):\n+            print(resp)\n+\n     \"\"\"\n\n---\n file path A: jina/clients/websocket.py | file path B: jina/clients/websocket.py\n\n@@ -3,8 +3,23 @@ from jina.clients.mixin import AsyncPostMixin, HealthCheckMixin, PostMixin\n \n \n class WebSocketClient(WebSocketBaseClient, PostMixin, HealthCheckMixin):\n-    \"\"\"\n-    A client connecting to a Gateway using WebSocket protocol.\n+    \"\"\"A client connecting to a Gateway using WebSocket protocol.\n+\n+    Instantiate this class through the :meth:`jina.Client` convenience method.\n+\n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Client\n+        from docarray import Document\n+\n+        # select host address to connect to\n+        c = Client(\n+            protocol='websocket', asyncio=False, host='ws://my.awesome.flow:1234'\n+        )  # returns WebSocketClient instance\n+        c.post(on='/index', inputs=Document(text='hello!'))\n+\n     \"\"\"\n \n \n@@ -12,6 +27,8 @@ class AsyncWebSocketClient(WebSocketBaseClient, AsyncPostMixin, HealthCheckMixin\n     \"\"\"\n     Asynchronous client connecting to a Gateway using WebSocket protocol.\n \n+    Instantiate this class through the :meth:`jina.Client` convenience method.\n+\n     Unlike :class:`WebSocketClient`, here :meth:`post` is a coroutine (i.e. declared with the async/await syntax),\n     simply calling them will not schedule them to be executed.\n \n@@ -23,4 +40,26 @@ class AsyncWebSocketClient(WebSocketBaseClient, AsyncPostMixin, HealthCheckMixin\n     In this case, users often do not want to let Jina control the ``asyncio.eventloop``. On contrary, :class:`Client`\n     is controlling and wrapping the event loop internally, making the Client looks synchronous from outside.\n \n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Client\n+        from docarray import Document\n+\n+        # async inputs for the client\n+        async def async_inputs():\n+            for _ in range(10):\n+                yield Document()\n+                await asyncio.sleep(0.1)\n+\n+\n+        # select host address to connect to\n+        c = Client(\n+            protocol='websocket', asyncio=True, host='http://ws.awesome.flow:1234'\n+        )  # returns AsyncWebSocketClient instance\n+\n+        async for resp in client.post(on='/index', async_inputs, request_size=1):\n+            print(resp)\n+\n     \"\"\"\n\n---\n file path A: jina/orchestrate/flow/asyncio.py | file path B: jina/orchestrate/flow/asyncio.py\n\n@@ -4,7 +4,7 @@ from jina.orchestrate.flow.base import Flow\n \n class AsyncFlow(AsyncPostMixin, Flow):\n     \"\"\"\n-    Asynchronous version of class:`Flow`. They share the same interface, except\n+    Asynchronous version of :class:`jina.Flow`. They share the same interface, except\n     in :class:`AsyncFlow` :meth:`train`, :meth:`index`, :meth:`search` methods are coroutines\n     (i.e. declared with the async/await syntax), simply calling them will not schedule them to be executed.\n     To actually run a coroutine, user need to put them in an eventloop, e.g. via ``asyncio.run()``,\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -327,6 +327,30 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n \n         \"\"\"Create a Flow. Flow is how Jina streamlines and scales Executors.\n \n+        EXAMPLE USAGE\n+\n+            Python API\n+\n+            .. code-block:: python\n+\n+                from jina import Flow\n+\n+                f = Flow().add(uses='jinahub+docker://SimpleIndexer')  # create Flow and add Executor\n+                with f:\n+                    f.bock()  # serve Flow\n+\n+            To and from YAML configuration\n+\n+            .. code-block:: python\n+\n+                from jina import Flow\n+\n+                f = Flow().add(uses='jinahub+docker://SimpleIndexer')  # create Flow and add Executor\n+                f.save_config('flow.yml')  # save YAML config file\n+                f = Flow.load_config('flow.yml')  # load Flow from YAML config\n+                with f:\n+                    f.bock()  # serve Flow\n+\n         :param asyncio: If set, then the input and output of this Client work in an asynchronous manner.\n         :param host: The host address of the runtime, by default it is 0.0.0.0.\n         :param port: The port of the Gateway, which the client should connect to.\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -76,6 +76,23 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n     \"\"\"\n     The base class of all Executors, can be used to build encoder, indexer, etc.\n \n+    :class:`jina.Executor` as an alias for this class.\n+\n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Executor, requests, Flow\n+\n+\n+        class MyExecutor(Executor):\n+            @requests\n+            def foo(self, docs, **kwargs):\n+                print(docs)  # process docs here\n+\n+\n+        f = Flow().add(uses=Executor)  # you can add your Executor to a Flow\n+\n     Any executor inherited from :class:`BaseExecutor` always has the **meta** defined in :mod:`jina.executors.metas.defaults`.\n \n     All arguments in the :func:`__init__` can be specified with a ``with`` map in the YAML config. Example:\n@@ -83,7 +100,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n     .. highlight:: python\n     .. code-block:: python\n \n-        class MyAwesomeExecutor:\n+        class MyAwesomeExecutor(Executor):\n             def __init__(awesomeness=5):\n                 pass\n \n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -144,6 +144,42 @@ def requests(\n     A class method decorated with plain `@requests` (without `on=`) is the default handler for all endpoints.\n     That means, it is the fallback handler for endpoints that are not found.\n \n+    EXAMPLE USAGE\n+\n+    .. code-block:: python\n+\n+        from jina import Executor, requests, Flow\n+        from docarray import Document\n+\n+\n+        # define Executor with custom `@requests` endpoints\n+        class MyExecutor(Executor):\n+            @requests(on='/index')\n+            def index(self, docs, **kwargs):\n+                print(docs)  # index docs here\n+\n+            @requests(on=['/search', '/query'])\n+            def search(self, docs, **kwargs):\n+                print(docs)  # perform search here\n+\n+            @requests  # default/fallback endpoint\n+            def foo(self, docs, **kwargs):\n+                print(docs)  # process docs here\n+\n+\n+        f = Flow().add(uses=MyExecutor)  # add your Executor to a Flow\n+        with f:\n+            f.post(\n+                on='/index', inputs=Document(text='I am here!')\n+            )  # send doc to `index` method\n+            f.post(\n+                on='/search', inputs=Document(text='Who is there?')\n+            )  # send doc to `search` method\n+            f.post(\n+                on='/query', inputs=Document(text='Who is there?')\n+            )  # send doc to `search` method\n+            f.post(on='/bar', inputs=Document(text='Who is there?'))  # send doc to `foo` method\n+\n     :param func: the method to decorate\n     :param on: the endpoint string, by convention starts with `/`\n     :return: decorated function\n@@ -206,11 +242,61 @@ def monitor(\n     documentation: Optional[str] = None,\n ):\n     \"\"\"\n-    Decorator and context manager that allows monitoring of an Executor. You can access these metrics by enabling the\n-    monitoring on your Executor. It will track the time spend calling the function and the number of times it has been\n+    Decorator and context manager that allows monitoring of an Executor.\n+\n+    You can access these metrics by enabling\n+    monitoring on your Executor. It will track the time spent calling the function and the number of times it has been\n     called. Under the hood it will create a prometheus Summary : https://prometheus.io/docs/practices/histograms/.\n \n-    :warning: Don't use this decorator with the @request decorator as it already handle monitoring under the hood\n+    EXAMPLE USAGE\n+\n+        As decorator\n+\n+        .. code-block:: python\n+\n+            from jina import Executor, monitor\n+\n+\n+            class MyExecutor(Executor):\n+                @requests  # `@requests` are monitored automatically\n+                def foo(self, docs, *args, **kwargs):\n+                    ...\n+                    self.my_method()\n+                    ...\n+\n+                # custom metric for `my_method`\n+                @monitor(name='metric_name', documentation='useful information goes here')\n+                def my_method(self):\n+                    ...\n+\n+        As context manager\n+\n+        .. code-block:: python\n+\n+            from jina import Executor, requests\n+\n+\n+            class MyExecutor(Executor):\n+                @requests  # `@requests` are monitored automatically\n+                def foo(self, docs, *args, **kwargs):\n+                    ...\n+                    # custom metric for code block\n+                    with self.monitor('metric_name', 'useful information goes here'):\n+                        docs = process(docs)\n+\n+        To enable the defined :meth:`monitor` blocks, enable monitoring on the Flow level\n+\n+        .. code-block:: python\n+\n+            from jina import Flow\n+\n+            f = Flow(monitoring=True, port_monitoring=9090).add(\n+                uses=MyExecutor, port_monitoring=9091\n+            )\n+            with f:\n+                ...\n+\n+    :warning: Don't use this decorator in combination with the @request decorator. @request's are already monitored.\n \n     :param name: the name of the metrics, by default it is based on the name of the method it decorates\n     :param documentation:  the description of the metrics, by default it is based on the name of the method it decorates\n\n\n###\n\n", "completion": "docs: examples in docstrings (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/jcloud/advanced.md | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -31,7 +31,7 @@ executors:\n         memory: 8G\n ```\n \n-### `spot` vs `on-demand` capacity\n+## `spot` vs `on-demand` capacity\n \n For cost optimization, `jcloud` tries to deploy all Executors on `spot` capacity. These are ideal for stateless Executors, which can withstand interruptions & restarts. It is recommended to use `on-demand` capacity for stateful Executors (e.g.- indexers) though.\n \n@@ -78,3 +78,15 @@ executors:\n ```{figure} external-executors-multiple.png\n :width: 70%\n ```\n+## Deploy with specific `jina` version\n+\n+To manage `jina` version while deploying a Flow to `jcloud`, you can pass `version` arg in the Flow yaml.\n+\n+```yaml\n+jtype: Flow\n+jcloud:\n+  version: 3.4.11\n+executors:\n+  - name: custom\n+    uses: jinahub+docker://CustomExecutor\n+```\n\n\n###\n\n", "completion": "docs: add jcloud version doc (#<issue-num>)"}
{"prompt": " file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -225,15 +225,15 @@\n         </aside>\n     </div>\n     <qa-bot\n-            title=\"DocArray Bot\"\n-            description=\"The data structure for unstructured data\"\n+            title=\"Jina Bot\"\n+            description=\"Build cross-modal and multi-modal applications on the cloud\"\n     >\n         <template>\n             <dl>\n                 <dt>You can ask questions about our docs. Try:</dt>\n-                <dd>What is a DocumentArray?</dd>\n-                <dd>How to use docarray with Jina?</dd>\n-                <dd>How to find nearest neighbour of Documents?</dd>\n+                <dd>Does Jina support Kubernetes?</dd>\n+                <dd>What are the basic concepts in Jina?</dd>\n+                <dd>How to share my Executor?</dd>\n             </dl>\n         </template>\n     </qa-bot>\n\n\n###\n\n", "completion": "fix(doc): update the description and default questions for qabot (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -194,6 +194,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -14023,3 +14024,36 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```31c98680```](https://github.com/jina-ai/jina/commit/31c98680b16855d271fb299052000aa51cdf9494)] __-__ __docs__: adding jcloud (*Han Xiao*)\n  - [[```24306049```](https://github.com/jina-ai/jina/commit/24306049eba9eb296642e14568e6ab15973bc2ab)] __-__ __version__: the next version will be 3.6.2 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-3></a>\n+## Release Note (`3.6.3`)\n+\n+> Release time: 2022-06-13 18:39:38\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  Jina Dev Bot,  Joan Fontanals,  Johannes Messner,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```6f3a1f91```](https://github.com/jina-ai/jina/commit/6f3a1f9126ad358831a3bc6ac2050918039ad4c0)] __-__ allow Executors as dataclass (#4918) (*Joan Fontanals*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```abd6c278```](https://github.com/jina-ai/jina/commit/abd6c2785cf67b7324b653a1225fa7ac7eb3d79c)] __-__ use random port (#4927) (*Han Xiao*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```91c91166```](https://github.com/jina-ai/jina/commit/91c91166494696bc6629c90adb3cebf65ffd5780)] __-__ minor documenation updates on the get started section (#4922) (*samsja*)\n+ - [[```07f0ef9a```](https://github.com/jina-ai/jina/commit/07f0ef9a8dd52ff64df7b1becfea613f85853193)] __-__ documentation enhancement (#4907) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```55ed566b```](https://github.com/jina-ai/jina/commit/55ed566bb501bc3261370660b7d94ba9a20c83ee)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```f76126ab```](https://github.com/jina-ai/jina/commit/f76126ab0cd88f5c060fa1b53fe59dac120666f7)] __-__ add jina on colab (*Han Xiao*)\n+ - [[```fbb57b2e```](https://github.com/jina-ai/jina/commit/fbb57b2ec58494f6f86f1c17c7ac3263504f261a)] __-__ overload flow add (#4578) (*Joan Fontanals*)\n+ - [[```8a35b997```](https://github.com/jina-ai/jina/commit/8a35b997580d84f0412531c7ff01ec85ae4e3f79)] __-__ update requirement to successfully build docs on local (#4910) (*Johannes Messner*)\n+ - [[```8e19bfdc```](https://github.com/jina-ai/jina/commit/8e19bfdc8f95c209320ab1a2a67216234c44efef)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```3e168dd9```](https://github.com/jina-ai/jina/commit/3e168dd9208365490031345aa0475fbdb4a9a9ce)] __-__ __version__: the next version will be 3.6.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.3'\n+__version__ = '3.6.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.4"}
{"prompt": " file path A: docs/fundamentals/flow/executor-args.md | file path B: docs/fundamentals/flow/executor-args.md\n\n@@ -12,7 +12,7 @@\n | `uses_metas` | Dictionary of keyword arguments that will override the `metas` configuration in `uses` | `object` | `None` |\n | `uses_requests` | Dictionary of keyword arguments that will override the `requests` configuration in `uses` | `object` | `None` |\n | `py_modules` | The customized python modules need to be imported before loading the executor<br><br>Note that the recommended way is to only import a single module - a simple python file, if your<br>executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,<br>which should be structured as a python package. For more details, please see the<br>`Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__ | `array` | `None` |\n-| `port` | The port for input data to bind to, default is a random port between [49152, 65535] | `number` | `None` |\n+| `port` | The port for input data to bind to, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n | `host_in` | The host address for binding to, by default it is 0.0.0.0 | `string` | `0.0.0.0` |\n | `native` | If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime. | `boolean` | `False` |\n | `output_array_type` | The type of array `tensor` and `embedding` will be serialized to.<br><br>Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which can be found <br>`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.<br>Defaults to retaining whatever type is returned by the Executor. | `string` | `None` |\n@@ -30,7 +30,7 @@\n | `shards` | The number of shards in the deployment running at the same time. For more details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies | `number` | `1` |\n | `replicas` | The number of replicas in the deployment | `number` | `1` |\n | `monitoring` | If set, spawn an http server with a prometheus endpoint to expose metrics | `boolean` | `False` |\n-| `port_monitoring` | The port on which the prometheus server is exposed, default port is 9090 | `number` | `9090` |\n+| `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n | `retries` | Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas) | `number` | `-1` |\n | `install_requirements` | If set, install `requirements.txt` in the Hub Executor bundle to local | `boolean` | `False` |\n | `force_update` | If set, always pull the latest Hub Executor bundle even it exists on local | `boolean` | `False` |\n\n---\n file path A: docs/fundamentals/flow/gateway-args.md | file path B: docs/fundamentals/flow/gateway-args.md\n\n@@ -12,7 +12,7 @@\n | `uses_metas` | Dictionary of keyword arguments that will override the `metas` configuration in `uses` | `object` | `None` |\n | `uses_requests` | Dictionary of keyword arguments that will override the `requests` configuration in `uses` | `object` | `None` |\n | `py_modules` | The customized python modules need to be imported before loading the executor<br><br>Note that the recommended way is to only import a single module - a simple python file, if your<br>executor can be defined in a single file, or an ``__init__.py`` file if you have multiple files,<br>which should be structured as a python package. For more details, please see the<br>`Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__ | `array` | `None` |\n-| `port` | The port for input data to bind to, default is a random port between [49152, 65535] | `number` | `None` |\n+| `port` | The port for input data to bind to, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n | `host_in` | The host address for binding to, by default it is 0.0.0.0 | `string` | `0.0.0.0` |\n | `native` | If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime. | `boolean` | `False` |\n | `output_array_type` | The type of array `tensor` and `embedding` will be serialized to.<br><br>Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which can be found <br>`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.<br>Defaults to retaining whatever type is returned by the Executor. | `string` | `None` |\n@@ -43,5 +43,5 @@\n | `shards` | The number of shards in the deployment running at the same time. For more details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies | `number` | `1` |\n | `replicas` | The number of replicas in the deployment | `number` | `1` |\n | `monitoring` | If set, spawn an http server with a prometheus endpoint to expose metrics | `boolean` | `False` |\n-| `port_monitoring` | The port on which the prometheus server is exposed, default port is 9090 | `number` | `9090` |\n+| `port_monitoring` | The port on which the prometheus server is exposed, default is a random port between [49152, 65535] | `number` | `random in [49152, 65535]` |\n | `retries` | Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas) | `number` | `-1` |\n\\ No newline at end of file\n\n---\n file path A: docs/how-to/google-colab.md | file path B: docs/how-to/google-colab.md\n\n@@ -29,5 +29,5 @@ Please follow the walk-through there. Enjoy the free GPU/TPU to build your aweso\n \n \n ```{tip}\n-Hosing service on Google Colab is not recommended if you server aims to be long-live or permanent. It is often used for quick experimentm, demostration or simply leveraging its GPU/TPU. For stable, secure and free hosting of Jina apps, please check out [Jcloud](https://docs.jina.ai/fundamentals/jcloud/).\n+Hosing service on Google Colab is not recommended if you server aims to be long-live or permanent. It is often used for quick experiment, demonstration or leveraging its free GPU/TPU. For stable, secure and free hosting of Jina apps, please check out [Jcloud](https://docs.jina.ai/fundamentals/jcloud/).\n ```\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -112,7 +112,6 @@ __jina_env__ = (\n __default_host__ = _os.environ.get(\n     'JINA_DEFAULT_HOST', '127.0.0.1' if __windows__ else '0.0.0.0'\n )\n-__default_port_monitoring__ = 9090\n __docker_host__ = 'host.docker.internal'\n __default_executor__ = 'BaseExecutor'\n __default_endpoint__ = '/default'\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -36,7 +36,7 @@ from rich.progress import (\n )\n from rich.table import Table\n \n-from jina import __default_host__, __default_port_monitoring__, __docker_host__, helper\n+from jina import __default_host__, __docker_host__, helper\n from jina.clients import Client\n from jina.clients.mixin import AsyncPostMixin, HealthCheckMixin, PostMixin\n from jina.enums import (\n@@ -158,7 +158,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         output_array_type: Optional[str] = None,\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n-        port_monitoring: Optional[int] = 9090,\n+        port_monitoring: Optional[int] = None,\n         prefetch: Optional[int] = 0,\n         protocol: Optional[str] = 'GRPC',\n         proxy: Optional[bool] = False,\n@@ -228,7 +228,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n               JSON dict, {endpoint: PollingType}\n               {'/custom': 'ALL', '/search': 'ANY', '*': 'ANY'}\n         :param port: The port for input data to bind to, default is a random port between [49152, 65535]\n-        :param port_monitoring: The port on which the prometheus server is exposed, default port is 9090\n+        :param port_monitoring: The port on which the prometheus server is exposed, default is a random port between [49152, 65535]\n         :param prefetch: Number of requests fetched from the client before feeding into the first Executor.\n \n               Used to control the speed of data input into a Flow. 0 disables prefetch (disabled by default)\n@@ -609,6 +609,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n             **kwargs,\n         )\n \n+    @allowed_levels([FlowBuildLevel.EMPTY])\n     def needs_all(self, name: str = 'joiner', *args, **kwargs) -> 'Flow':\n         \"\"\"\n         Collect all hanging Deployments so far and add a blocker to the Flow; wait until all handing pods completed.\n@@ -649,7 +650,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         output_array_type: Optional[str] = None,\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n-        port_monitoring: Optional[int] = 9090,\n+        port_monitoring: Optional[int] = None,\n         py_modules: Optional[List[str]] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n@@ -727,7 +728,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n               JSON dict, {endpoint: PollingType}\n               {'/custom': 'ALL', '/search': 'ANY', '*': 'ANY'}\n         :param port: The port for input data to bind to, default is a random port between [49152, 65535]\n-        :param port_monitoring: The port on which the prometheus server is exposed, default port is 9090\n+        :param port_monitoring: The port on which the prometheus server is exposed, default is a random port between [49152, 65535]\n         :param py_modules: The customized python modules need to be imported before loading the executor\n \n           Note that the recommended way is to only import a single module - a simple python file, if your\n@@ -1155,6 +1156,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         self.logger.debug('flow is closed!')\n         self.logger.close()\n \n+    @allowed_levels([FlowBuildLevel.EMPTY, FlowBuildLevel.GRAPH])\n     def start(self):\n         \"\"\"Start to run all Deployments in this Flow.\n \n@@ -1583,16 +1585,14 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n             return False\n \n     @property\n-    def port_monitoring(self) -> int:\n+    def port_monitoring(self) -> Optional[int]:\n         \"\"\"Return if the monitoring is enabled\n         .. # noqa: DAR201\n         \"\"\"\n         if GATEWAY_NAME in self._deployment_nodes:\n             return self[GATEWAY_NAME].args.port_monitoring\n         else:\n-            return self._common_kwargs.get(\n-                'port_monitoring', __default_port_monitoring__\n-            )\n+            return self._common_kwargs.get('port_monitoring', None)\n \n     @property\n     def address_private(self) -> str:\n@@ -1720,14 +1720,9 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n                         '\u00b7'.join(_address),\n                     )\n \n-            return self[GATEWAY_NAME].args.port_monitoring\n-        else:\n-            return self._common_kwargs.get(\n-                'port_monitoring', __default_port_monitoring__\n-            )\n-\n         return address_table\n \n+    @allowed_levels([FlowBuildLevel.RUNNING])\n     def block(\n         self, stop_event: Optional[Union[threading.Event, multiprocessing.Event]] = None\n     ):\n@@ -1909,6 +1904,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         \"\"\"\n         ...\n \n+    @allowed_levels([FlowBuildLevel.EMPTY])\n     def expose_endpoint(self, exec_endpoint: str, **kwargs):\n         \"\"\"Expose an Executor's endpoint (defined by `@requests(on=...)`) to HTTP endpoint for easier access.\n \n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -1,7 +1,7 @@\n \"\"\"Argparser module for Pod runtimes\"\"\"\n import argparse\n \n-from jina import __default_port_monitoring__, helper\n+from jina import helper\n from jina.enums import PodRoleType\n from jina.parsers.helper import _SHOW_ALL_ARGS, KVAppendAction, add_arg_group\n \n@@ -99,9 +99,9 @@ def mixin_pod_parser(parser):\n     gp.add_argument(\n         '--port-monitoring',\n         type=int,\n-        default=__default_port_monitoring__,  # default prometheus server port\n+        default=helper.random_port(),  # default prometheus server port\n         dest='port_monitoring',\n-        help=f'The port on which the prometheus server is exposed, default port is {__default_port_monitoring__} ',\n+        help=f'The port on which the prometheus server is exposed, default is a random port between [49152, 65535]',\n     )\n \n     gp.add_argument(\n\n---\n file path A: scripts/generate-list-args.py | file path B: scripts/generate-list-args.py\n\n@@ -8,8 +8,10 @@ for s in ('flow', 'gateway', 'executor'):\n \n     for k, v in a[f'Jina::{s.capitalize()}']['properties'].items():\n         desc = v[\"description\"].replace(\"\\n\", \"<br>\")\n-        if k == 'port':\n-            v['default'] = None  # avoid random numbers cause devbot forever committing\n+        if k in ('port', 'port_monitoring'):\n+            v[\n+                'default'\n+            ] = 'random in [49152, 65535]'  # avoid random numbers cause devbot forever committing\n         table.append(f'| `{k}` | {desc} | `{v[\"type\"]}` | `{v[\"default\"]}` |')\n \n     with open(f'../docs/fundamentals/flow/{s}-args.md', 'w') as fp:\n\n\n###\n\n", "completion": "fix: use random port (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/architecture-overview.md | file path B: docs/fundamentals/architecture-overview.md\n\n@@ -65,19 +65,19 @@ The following concepts will be covered in the user guide:\n     DocumentArray is a list-like container of multiple Documents. More information can be found in [DocArray's Docs](https://docarray.jina.ai/fundamentals/documentarray/). \n     \n **Executor** \n-    Execurtor is a Python class that has a group of functions using {term}`DocumentArray` as IO. Loosely speaking, each Executor is a microservice. \n+    {class}`~jina.Executor` is a Python class that has a group of functions using {term}`DocumentArray` as IO. Loosely speaking, each Executor is a microservice. \n \n **Flow**\n-    Flow ties multiple Executors together into a logic pipeline to achieve a task. If Executor is a microservice, then Flow is the end-to-end service. \n+    {class}`~jina.Flow` ties multiple {class}`~jina.Executor`s together into a logic pipeline to achieve a task. If Executor is a microservice, then Flow is the end-to-end service. \n \n **Gateway**\n     Gateway is the entrypoint of a {term}`Flow`. It exposes multiple protocols for external communications; it routes all internal traffics.\n     \n **Client**\n-    Client is for connecting to a {term}`Gateway` and sending/receiving data from it.\n+    {class}`~jina.Client` is for connecting to a {term}`Gateway` and sending/receiving data from it.\n \n **Deployment**\n-    Deployment is an abstraction around Executor that lets the {term}`Gateway` communicate with an Executor. It encapsulates and abstracts internal replication details.\n+    Deployment is an abstraction around {class}`~jina.Executor` that lets the {term}`Gateway` communicate with an Executor. It encapsulates and abstracts internal replication details.\n \n **gRPC, Websocket, HTTP**\n     They are network protocols for transmitting data. gRPC is always used between {term}`Gateway` and {term}`Deployment` communication.\n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -17,10 +17,10 @@ hello-jina\n ```\n \n - `app.py` is the entrypoint of your Jina project. You can run it via `python app.py`. \n-- `executor1/` is where we'll write our Executor code.\n-- `config.yml` is the config file for the Executor. It\u2019s where you keep metadata for your Executor, as well as dependencies.\n+- `executor1/` is where we'll write our {class}`~jina.Executor` code.\n+- `config.yml` is the config file for the {class}`~jina.Executor`. It\u2019s where you keep metadata for your Executor, as well as dependencies.\n \n-There may be some other files like `README.md`, `manifest.yml`  `requirements.txt` to provide extra metadata about that Executor. More information {ref}`can be found here<create-executor>`.\n+There may be some other files like `README.md`, `manifest.yml`  `requirements.txt` to provide extra metadata about that {class}`~jina.Executor`. More information {ref}`can be found here<create-executor>`.\n \n ```bash\n cd hello-jina\n@@ -40,7 +40,7 @@ You should see this in your terminal:\n \n ## Adding dependencies\n \n-You can use any third-party Python library in Executor. Let's create `executor1/requirements.txt` and add `pytorch` to it.\n+You can use any third-party Python library in {class}`~jina.Executor`. Let's create `executor1/requirements.txt` and add `pytorch` to it.\n \n Then in `executor.py`, let's add another endpoint `/get-tensor` as follows:\n \n\n\n###\n\n", "completion": "docs: minor documenation updates on the get started section (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/google-colab.md | file path B: docs/how-to/google-colab.md\n\n@@ -17,4 +17,17 @@ Google Colab provides a easy-to-use Jupyter notebook environment with GPU/TPU su\n :width: 70%\n ```\n \n-[Open this notebook on Google Colab to learn more](https://colab.research.google.com/github/jina-ai/jina/blob/master/docs/Using_Jina_on_Colab.ipynb). Enjoy the free GPU/TPU to build your awesome Jina applications!\n\\ No newline at end of file\n+\n+```{button-link} https://colab.research.google.com/github/jina-ai/jina/blob/master/docs/Using_Jina_on_Colab.ipynb\n+:color: primary\n+:align: center\n+\n+{octicon}`link-external` Open the notebook on Google Colab \n+```\n+\n+Please follow the walk-through there. Enjoy the free GPU/TPU to build your awesome Jina applications!\n+\n+\n+```{tip}\n+Hosing service on Google Colab is not recommended if you server aims to be long-live or permanent. It is often used for quick experimentm, demostration or simply leveraging its GPU/TPU. For stable, secure and free hosting of Jina apps, please check out [Jcloud](https://docs.jina.ai/fundamentals/jcloud/).\n+```\n\n---\n file path A: docs/how-to/google-colab.md | file path B: docs/how-to/google-colab.md\n\n@@ -5,7 +5,7 @@\n :scale: 0 %\n ```\n \n-```{figure} img/jina-on-colab.png\n+```{figure} jina-on-colab.png\n :scale: 0 %\n :width: 0 %\n ```\n\n---\n file path A: docs/_static/jina-on-colab.png | file path B: docs/_static/jina-on-colab.png\n\nBinary files /dev/null and b/docs/_static/jina-on-colab.png differ\n\n---\n file path A: docs/how-to/google-colab.md | file path B: docs/how-to/google-colab.md\n\n@@ -1,5 +1,15 @@\n # Use Jina on Colab with GPU/TPU\n \n+```{figure} https://docs.jina.ai/_images/jina-on-colab.png\n+:width: 0 %\n+:scale: 0 %\n+```\n+\n+```{figure} img/jina-on-colab.png\n+:scale: 0 %\n+:width: 0 %\n+```\n+\n Google Colab provides a easy-to-use Jupyter notebook environment with GPU/TPU support. Jina is fully compatible with Google Colab. You can enjoy the following ways of using Jina:\n \n ```{figure} jina-on-colab.svg\n\n---\n file path A: docs/how-to/jina-on-colab.png | file path B: docs/how-to/jina-on-colab.png\n\nBinary files /dev/null and b/docs/how-to/jina-on-colab.png differ\n\n---\n file path A: docs/Using_Jina_on_Colab.ipynb | file path B: docs/Using_Jina_on_Colab.ipynb\n\n@@ -1,30 +1,19 @@\n {\n- \"nbformat\": 4,\n- \"nbformat_minor\": 0,\n- \"metadata\": {\n-  \"colab\": {\n-   \"name\": \"Using Jina on Colab.ipynb\",\n-   \"provenance\": [],\n-   \"collapsed_sections\": [],\n-   \"toc_visible\": true\n-  },\n-  \"kernelspec\": {\n-   \"name\": \"python3\",\n-   \"display_name\": \"Python 3\"\n-  },\n-  \"language_info\": {\n-   \"name\": \"python\"\n-  },\n-  \"accelerator\": \"GPU\"\n- },\n  \"cells\": [\n   {\n    \"cell_type\": \"markdown\",\n+   \"metadata\": {\n+    \"id\": \"TR-nF8awMM1A\",\n+    \"pycharm\": {\n+     \"name\": \"#%% md\\n\"\n+    }\n+   },\n    \"source\": [\n     \"# Using [Jina](https://github.com/jina-ai/jina) on Colab with GPU/TPU support\\n\",\n     \"\\n\",\n     \"In this tutorial, we will cover two ways of using Colab as illustrated below:\\n\",\n     \"\\n\",\n+    \"![](https://raw.githubusercontent.com/jina-ai/jina/master/docs/how-to/jina-on-colab.svg)\\n\",\n     \"\\n\",\n     \"## 1. Change runtime type\\n\",\n     \"\\n\",\n@@ -33,13 +22,7 @@\n     \"\\n\",\n     \"## 2. Install Jina\\n\",\n     \"You will be asked to restart the kernel after installation. Go ahead and click \\\"Restart *Runtime*\\\"\"\n-   ],\n-   \"metadata\": {\n-    \"id\": \"TR-nF8awMM1A\",\n-    \"pycharm\": {\n-     \"name\": \"#%% md\\n\"\n-    }\n-   }\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n@@ -57,47 +40,55 @@\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"## 3. Import\"\n-   ],\n    \"metadata\": {\n     \"id\": \"BoRWbFUHN-4y\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"## 3. Import\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"from jina import Flow, Document, Executor, requests, DocumentArray\\n\",\n-    \"import jina\\n\",\n-    \"\\n\",\n-    \"print(jina.__version__)\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"KaKzywlEKv3q\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"from jina import Flow, Document, Executor, requests, DocumentArray\\n\",\n+    \"import jina\\n\",\n+    \"\\n\",\n+    \"print(jina.__version__)\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"## 4. Build a GPU Executor\"\n-   ],\n    \"metadata\": {\n     \"id\": \"hlwpiW_hOPBt\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"## 4. Build a GPU Executor\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {\n+    \"id\": \"p58WUjjgMgFy\",\n+    \"pycharm\": {\n+     \"name\": \"#%%\\n\"\n+    }\n+   },\n+   \"outputs\": [],\n    \"source\": [\n     \"import torch\\n\",\n     \"\\n\",\n@@ -106,184 +97,182 @@\n     \"  @requests\\n\",\n     \"  def foo(self, docs: DocumentArray, **kwargs):\\n\",\n     \"    docs[0].tags['cuda'] = torch.cuda.is_available()\"\n-   ],\n-   \"metadata\": {\n-    \"id\": \"p58WUjjgMgFy\",\n-    \"pycharm\": {\n-     \"name\": \"#%%\\n\"\n-    }\n-   },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"## 5. Add GPU Executor to a Flow\"\n-   ],\n    \"metadata\": {\n     \"id\": \"u2wjIBQXOXrv\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"## 5. Add GPU Executor to a Flow\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"f = Flow().add(uses=GPUExec)\\n\",\n-    \"\\n\",\n-    \"f.start()\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"3q35cMikLnyA\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"f = Flow().add(uses=GPUExec)\\n\",\n+    \"\\n\",\n+    \"f.start()\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"## 6. Send request to the running Flow\\n\",\n-    \"\\n\",\n-    \"The result should contain a single Document which has `.tags['cuda']` field set to `True` via `GPUExec`. \"\n-   ],\n    \"metadata\": {\n     \"id\": \"_GROx0BnOgdN\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"## 6. Send request to the running Flow\\n\",\n+    \"\\n\",\n+    \"The result should contain a single Document which has `.tags['cuda']` field set to `True` via `GPUExec`. \"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"r = f.post('/', Document())\\n\",\n-    \"print(r[0].tags)\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"ACoTXhn-Lpz5\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"r = f.post('/', Document())\\n\",\n+    \"print(r[0].tags)\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"Now we see that one can directly connect to a running Flow inside Google Colab. The trick here is to use `f.start()` to start the Flow and use `f.close()` to close the Flow. This usage is different than our classic `with` context manager.\"\n-   ],\n    \"metadata\": {\n     \"id\": \"0K3bFdStR09C\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"Now we see that one can directly connect to a running Flow inside Google Colab. The trick here is to use `f.start()` to start the Flow and use `f.close()` to close the Flow. This usage is different than our classic `with` context manager.\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"f.close()\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"FJ6l4bsgLyqz\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"f.close()\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"# Connecting from local to a running Flow on Colab\"\n-   ],\n    \"metadata\": {\n     \"id\": \"hBDjAUkoSNJW\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"# Connecting from local to a running Flow on Colab\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"A more interesting use case is to connect to Colab from a **local** machine. In this case, we need to install `ngrox`.\"\n-   ],\n    \"metadata\": {\n     \"id\": \"sEm8mxdKSa0k\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"A more interesting use case is to connect to Colab from a **local** machine. In this case, we need to install `ngrox`.\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"!pip install pyngrok\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"OvebGiRzXmc4\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"!pip install pyngrok\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"## 1. Expose via HTTP\\n\",\n-    \"\\n\",\n-    \"\\n\",\n-    \"Easiest and most compatible, no registration needed on ngrox. However, HTTP protocol is not performant on large data and streaming.\"\n-   ],\n    \"metadata\": {\n     \"id\": \"0ASjGLBhXono\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"## 1. Expose via HTTP\\n\",\n+    \"\\n\",\n+    \"\\n\",\n+    \"Easiest and most compatible, no registration needed on ngrox. However, HTTP protocol is not performant on large data and streaming.\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"f = Flow(protocol='http', port=54321).add(uses=GPUExec)\\n\",\n-    \"\\n\",\n-    \"f.start()\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"UeXfAwBuSsdY\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"f = Flow(protocol='http', port=54321).add(uses=GPUExec)\\n\",\n+    \"\\n\",\n+    \"f.start()\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"!ngrok http 54321 --log \\\"stdout\\\"\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"5DTM1cQOVSOI\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"!ngrok http 54321 --log \\\"stdout\\\"\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"metadata\": {\n+    \"id\": \"OsKJXEETYIRN\",\n+    \"pycharm\": {\n+     \"name\": \"#%% md\\n\"\n+    }\n+   },\n    \"source\": [\n     \"Notice the last line, you should see something like the following:\\n\",\n     \"\\n\",\n@@ -308,114 +297,114 @@\n     \"Where one can see `\\\"tags\\\":{\\\"cuda\\\":true}` is successfully returned.\\n\",\n     \"\\n\",\n     \"To stop the server, click stop the last cell. Then close the Flow.\"\n-   ],\n-   \"metadata\": {\n-    \"id\": \"OsKJXEETYIRN\",\n-    \"pycharm\": {\n-     \"name\": \"#%% md\\n\"\n-    }\n-   }\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"f.close()\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"iTc0d_Urb9nW\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"f.close()\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"metadata\": {\n+    \"id\": \"wom9p0hJb5f7\",\n+    \"pycharm\": {\n+     \"name\": \"#%% md\\n\"\n+    }\n+   },\n    \"source\": [\n     \"## 2. Expose via gRPC\\n\",\n     \"\\n\",\n     \"Using ngrox to forward gRPC is also possible. But you will need to first sign up at https://dashboard.ngrok.com/signup\\n\",\n     \"\\n\",\n     \"After signing up, you can get a token. Then simply add your token via (replacing `YOUR_TOKEN_HERE`)\"\n-   ],\n-   \"metadata\": {\n-    \"id\": \"wom9p0hJb5f7\",\n-    \"pycharm\": {\n-     \"name\": \"#%% md\\n\"\n-    }\n-   }\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"!ngrok authtoken 2ARf0Y7QrG3E2TsFaX7W3KWvfGD_6R972KKvbqeucpCrCuEHv\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"mGsPDHFIcTL7\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"!ngrok authtoken 2ARf0Y7QrG3E2TsFaX7W3KWvfGD_6R972KKvbqeucpCrCuEHv\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"Now let's start the Flow with gRPC gateway again.\"\n-   ],\n    \"metadata\": {\n     \"id\": \"x7nX4DA3cy2q\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"Now let's start the Flow with gRPC gateway again.\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"f = Flow(port=54321).add(uses=GPUExec)\\n\",\n-    \"\\n\",\n-    \"f.start()\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"eZWf3cJwUDkM\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"f = Flow(port=54321).add(uses=GPUExec)\\n\",\n+    \"\\n\",\n+    \"f.start()\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n-   \"source\": [\n-    \"Let's get its public address via `ngrok`\"\n-   ],\n    \"metadata\": {\n     \"id\": \"KzrbTL3cdIxb\",\n     \"pycharm\": {\n      \"name\": \"#%% md\\n\"\n     }\n-   }\n+   },\n+   \"source\": [\n+    \"Let's get its public address via `ngrok`\"\n+   ]\n   },\n   {\n    \"cell_type\": \"code\",\n-   \"source\": [\n-    \"!ngrok tcp 54321 --log \\\"stdout\\\"\"\n-   ],\n+   \"execution_count\": null,\n    \"metadata\": {\n     \"id\": \"y-dV3792c7K1\",\n     \"pycharm\": {\n      \"name\": \"#%%\\n\"\n     }\n    },\n-   \"execution_count\": null,\n-   \"outputs\": []\n+   \"outputs\": [],\n+   \"source\": [\n+    \"!ngrok tcp 54321 --log \\\"stdout\\\"\"\n+   ]\n   },\n   {\n    \"cell_type\": \"markdown\",\n+   \"metadata\": {\n+    \"id\": \"lYxxAvHtdPY8\",\n+    \"pycharm\": {\n+     \"name\": \"#%% md\\n\"\n+    }\n+   },\n    \"source\": [\n     \"At the last line, you should see something like: \\n\",\n     \"\\n\",\n@@ -447,13 +436,35 @@\n     \"Showing the connection is success!\\n\",\n     \"\\n\",\n     \"Now enjoy the free GPU/TPU to build your awesome Jina applications!\"\n-   ],\n-   \"metadata\": {\n-    \"id\": \"lYxxAvHtdPY8\",\n-    \"pycharm\": {\n-     \"name\": \"#%% md\\n\"\n-    }\n-   }\n+   ]\n+  }\n+ ],\n+ \"metadata\": {\n+  \"accelerator\": \"GPU\",\n+  \"colab\": {\n+   \"collapsed_sections\": [],\n+   \"name\": \"Using Jina on Colab.ipynb\",\n+   \"provenance\": [],\n+   \"toc_visible\": true\n+  },\n+  \"kernelspec\": {\n+   \"display_name\": \"Python 3 (ipykernel)\",\n+   \"language\": \"python\",\n+   \"name\": \"python3\"\n+  },\n+  \"language_info\": {\n+   \"codemirror_mode\": {\n+    \"name\": \"ipython\",\n+    \"version\": 3\n+   },\n+   \"file_extension\": \".py\",\n+   \"mimetype\": \"text/x-python\",\n+   \"name\": \"python\",\n+   \"nbconvert_exporter\": \"python\",\n+   \"pygments_lexer\": \"ipython3\",\n+   \"version\": \"3.7.9\"\n   }\n- ]\n+ },\n+ \"nbformat\": 4,\n+ \"nbformat_minor\": 1\n }\n\\ No newline at end of file\n\n---\n file path A: docs/how-to/google-colab.md | file path B: docs/how-to/google-colab.md\n\n@@ -7,4 +7,4 @@ Google Colab provides a easy-to-use Jupyter notebook environment with GPU/TPU su\n :width: 70%\n ```\n \n-Open this notebook on Google Colab to learn more. Enjoy the free GPU/TPU to build your awesome Jina applications!\n\\ No newline at end of file\n+[Open this notebook on Google Colab to learn more](https://colab.research.google.com/github/jina-ai/jina/blob/master/docs/Using_Jina_on_Colab.ipynb). Enjoy the free GPU/TPU to build your awesome Jina applications!\n\\ No newline at end of file\n\n\n###\n\n", "completion": "chore: add jina on colab"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -787,7 +787,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         \"\"\"\n \n     # overload_inject_end_deployment\n-    @allowed_levels([FlowBuildLevel.EMPTY])\n+    @overload\n     def add(\n         self,\n         *,\n@@ -795,7 +795,7 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         copy_flow: bool = True,\n         deployment_role: 'DeploymentRoleType' = DeploymentRoleType.DEPLOYMENT,\n         **kwargs,\n-    ) -> 'Flow':\n+    ) -> Union['Flow', 'AsyncFlow']:\n         \"\"\"\n         Add a Deployment to the current Flow object and return the new modified Flow object.\n         The attribute of the Deployment can be later changed with :py:meth:`set` or deleted with :py:meth:`remove`\n@@ -807,7 +807,29 @@ class Flow(PostMixin, HealthCheckMixin, JAMLCompatible, ExitStack, metaclass=Flo\n         :param copy_flow: when set to true, then always copy the current Flow and do the modification on top of it then return, otherwise, do in-line modification\n         :param kwargs: other keyword-value arguments that the Deployment CLI supports\n         :return: a (new) Flow object with modification\n+\n+        .. # noqa: DAR202\n+        .. # noqa: DAR101\n+        .. # noqa: DAR003\n         \"\"\"\n+\n+    @allowed_levels([FlowBuildLevel.EMPTY])\n+    def add(\n+        self,\n+        **kwargs,\n+    ) -> Union['Flow', 'AsyncFlow']:\n+        \"\"\"\n+        Add a Deployment to the current Flow object and return the new modified Flow object.\n+        The attribute of the Deployment can be later changed with :py:meth:`set` or deleted with :py:meth:`remove`\n+\n+        .. # noqa: DAR401\n+        :param kwargs: other keyword-value arguments that the Deployment CLI supports\n+        :return: a (new) Flow object with modification\n+        \"\"\"\n+        needs = kwargs.get('needs', None)\n+        copy_flow = kwargs.get('copy_flow', True)\n+        deployment_role = kwargs.get('deployment_role', DeploymentRoleType.DEPLOYMENT)\n+\n         op_flow = copy.deepcopy(self) if copy_flow else self\n \n         # deployment naming logic\n\n\n###\n\n", "completion": "chore: overload flow add (#<issue-num>)"}
{"prompt": " file path A: docs/requirements.txt | file path B: docs/requirements.txt\n\n@@ -1,7 +1,7 @@\n sphinx\n sphinx-argparse==0.3.1\n sphinxcontrib-apidoc==0.3.0\n-sphinx-autodoc-typehints==1.12.0\n+sphinx-autodoc-typehints==1.18.3\n sphinx_markdown_tables==0.0.15\n sphinx_copybutton==0.4.0\n sphinx-notfound-page==0.7.1\n\n\n###\n\n", "completion": "chore: update requirement to successfully build docs on local (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -11,7 +11,7 @@ Executor uses `docarray.DocumentArray` as input and output data structure. Pleas\n {class}`~jina.Executor` is a self-contained component and performs a group of tasks on a `DocumentArray`. \n It encapsulates functions that process `DocumentArray`s. Inside the Executor, these functions are decorated with `@requests`. To create an Executor, you only need to follow three principles:\n \n-1. An `Executor` should subclass directly from the `jina.Executor` class.\n+1. An `Executor` should subclass directly from the `jina.Executor` class. `Executor` can also be a `dataclass`\n 2. An `Executor` class is a bag of functions with shared state or configuration (via `self`); it can contain an arbitrary number of\n   functions with arbitrary names.\n 3. Functions decorated by `@requests` will be invoked according to their `on=` endpoint. These functions can be coroutines (`async def`) or regular functions.\n@@ -26,11 +26,11 @@ You can name your executor class freely.\n \n ### `__init__`\n \n-No need to implement `__init__` if your `Executor` does not contain initial states.\n+No need to implement `__init__` if your `Executor` does not contain initial states or if it is a [dataclass](https://docs.python.org/3/library/dataclasses.html)\n \n-If your executor has `__init__`, it needs to carry `**kwargs` in the signature and call `super().__init__(**kwargs)`\n+If your executor has `__init__`, it needs to carry `**kwargs` in the signature and call `super().__init__(**kwargs)` \n in the body:\n-\n+````{tab} Executor\n ```python\n from jina import Executor\n \n@@ -41,11 +41,24 @@ class MyExecutor(Executor):\n         self.bar = bar\n         self.foo = foo\n ```\n+````\n+\n+````{tab} Executor as dataclass\n+```python\n+from dataclasses import dataclass\n+from jina import Executor\n \n \n+@dataclass\n+class MyExecutor(Executor):\n+    bar: int\n+    foo: str\n+```\n+````\n+\n ````{admonition} What is inside kwargs? \n :class: hint\n-Here, `kwargs` are reserved for Jina to inject `metas` and `requests` (representing the request-to-function mapping) values when the Executor is used inside a Flow.\n+Here, `kwargs` are reserved for Jina to inject `metas` and `requests` (representing the request-to-function mapping) values when the Executor is used inside a Flow. Also when `Executor` is a `dataclass` these parameters are injected by Jina as in the regular case when calling `super().__init__`\n \n You can access the values of these arguments in the `__init__` body via `self.metas`/`self.requests`/`self.runtime_args`, \n or modify their values before passing them to `super().__init__()`.\n@@ -95,6 +108,20 @@ Some of these `arguments` can be used when developing the internal logic of the\n \n These `special` arguments are `workspace`, `requests`, `metas`, `runtime_args`.\n \n+Another alternative, is to declare your `Executor` as a [dataclass](https://docs.python.org/3/library/dataclasses.html). In this case, user does not provide an specific constructor. \n+Then, Jina will inject all these `special` arguments without the need of the user to call any specific method.\n+\n+```python\n+from dataclasses import dataclass\n+from jina import Executor\n+\n+\n+@dataclass\n+class MyExecutor(Executor):\n+    bar: int\n+    foo: str\n+```\n+\n (executor-workspace)=\n ### `workspace`\n \n@@ -161,7 +188,6 @@ The list of the `runtime_args` is:\n \n These can **not** be provided by the user through any API. They are generated by the Flow orchestration.\n \n-\n ## See further\n \n - {ref}`Executor in Flow <executor-in-flow>` \n\n---\n file path A: jina/jaml/parsers/executor/legacy.py | file path B: jina/jaml/parsers/executor/legacy.py\n\n@@ -1,3 +1,4 @@\n+import dataclasses\n import inspect\n from functools import reduce\n from typing import Any, Dict, Optional, Set, Type\n@@ -72,12 +73,24 @@ class LegacyParser(VersionedYAMLParser):\n \n         cls._init_from_yaml = True\n         # tmp_p = {kk: expand_env_var(vv) for kk, vv in data.get('with', {}).items()}\n-        obj = cls(\n-            **data.get('with', {}),\n-            metas=data.get('metas', {}),\n-            requests=data.get('requests', {}),\n-            runtime_args=runtime_args,\n-        )\n+        if dataclasses.is_dataclass(cls):\n+            obj = cls(\n+                **data.get('with', {}),\n+            )\n+            cls.__bases__[0].__init__(\n+                obj,\n+                **data.get('with', {}),\n+                metas=data.get('metas', {}),\n+                requests=data.get('requests', {}),\n+                runtime_args=runtime_args,\n+            )\n+        else:\n+            obj = cls(\n+                **data.get('with', {}),\n+                metas=data.get('metas', {}),\n+                requests=data.get('requests', {}),\n+                runtime_args=runtime_args,\n+            )\n         cls._init_from_yaml = False\n \n         # check if the yaml file used to instanciate 'cls' has arguments that are not in 'cls'\n\n---\n file path A: tests/integration/flow-dry-run/__init__.py | file path B: tests/integration/dataclass_executor/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/dataclass_executor/test_dataclass_executor.py\n\n@@ -0,0 +1,29 @@\n+import dataclasses\n+\n+from docarray import DocumentArray\n+from jina import Executor, Flow, requests\n+\n+\n+def test_executor_dataclass():\n+    @dataclasses.dataclass\n+    class MyDataClassExecutor(Executor):\n+        my_field: str\n+\n+        @requests(on=['/search'])\n+        def baz(self, docs, **kwargs):\n+            for doc in docs:\n+                doc.tags['metas_name'] = self.metas.name\n+                doc.tags['my_field'] = self.my_field\n+\n+    f = Flow().add(\n+        uses=MyDataClassExecutor,\n+        uses_with={'my_field': 'this is my field'},\n+        uses_metas={'name': 'test-name-updated'},\n+        uses_requests={'/foo': 'baz'},\n+    )\n+    with f:\n+        res = f.post(on='/foo', inputs=DocumentArray.empty(2))\n+    assert len(res) == 2\n+    for r in res:\n+        assert r.tags['metas_name'] == 'test-name-updated'\n+        assert r.tags['my_field'] == 'this is my field'\n\n---\n file path A: tests/integration/flow_dry_run/__init__.py | file path B: tests/integration/flow_dry_run/__init__.py\n\n\n---\n file path A: tests/integration/flow-dry-run/test_flow_dry_run.py | file path B: tests/integration/flow_dry_run/test_flow_dry_run.py\n\n\n---\n file path A: tests/integration/monitoring/__init__.py | file path B: tests/integration/monitoring/__init__.py\n\n\n---\n file path A: tests/unit/jaml/test_type_parse.py | file path B: tests/unit/jaml/test_type_parse.py\n\n@@ -1,3 +1,4 @@\n+import dataclasses\n import os\n \n import pytest\n@@ -13,6 +14,15 @@ class MyExecutor(BaseExecutor):\n     pass\n \n \n+@dataclasses.dataclass\n+class MyDataClassExecutor(BaseExecutor):\n+    my_field: str = ''\n+\n+    @requests\n+    def baz(self, **kwargs):\n+        pass\n+\n+\n def test_non_empty_reg_tags():\n     assert JAML.registered_tags()\n     assert __default_executor__ in JAML.registered_tags()\n@@ -175,7 +185,6 @@ def test_parsing_brackets_in_envvar():\n             'VAR1': '{\"1\": \"2\"}',\n         }\n     ):\n-\n         b = JAML.load(flow_yaml, substitute=True)\n         assert b['executors'][0]['env']['var1'] == '{\"1\": \"2\"}'\n         assert b['executors'][0]['env']['var2'] == 'a'\n@@ -213,3 +222,22 @@ def test_jtype(tmpdir):\n \n     assert type(BaseExecutor.load_config(exec_path)) == BaseExecutor\n     assert type(Flow.load_config(flow_path)) == Flow\n+\n+\n+def test_load_dataclass_executor():\n+    executor_yaml = '''\n+        jtype: MyDataClassExecutor\n+        with:\n+            my_field: this is my field\n+        metas:\n+            name: test-name-updated\n+            workspace: test-work-space-updated\n+        requests:\n+            /foo: baz\n+        '''\n+\n+    exec = BaseExecutor.load_config(executor_yaml)\n+    assert exec.my_field == 'this is my field'\n+    assert exec.requests['/foo'] == MyDataClassExecutor.baz\n+    assert exec.metas.name == 'test-name-updated'\n+    assert exec.metas.workspace == 'test-work-space-updated'\n\n\n###\n\n", "completion": "feat: allow Executors as dataclass (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -193,6 +193,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13992,3 +13993,32 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```ba243383```](https://github.com/jina-ai/jina/commit/ba2433836a2dcf9c8df78b0ec6ee9038d8aae7bc)] __-__ remove pages from .github folder (#4898) (*Joan Fontanals*)\n  - [[```c7a06cbd```](https://github.com/jina-ai/jina/commit/c7a06cbdf4453a2af018fb6cc03cea6277e21aef)] __-__ __version__: the next version will be 3.6.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-2></a>\n+## Release Note (`3.6.2`)\n+\n+> Release time: 2022-06-10 16:54:41\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Leon Wolf,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```0338dcd3```](https://github.com/jina-ai/jina/commit/0338dcd3567419d575115e12e5493ac480c27332)] __-__ json schema generation (#4916) (*Han Xiao*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```1ecb95af```](https://github.com/jina-ai/jina/commit/1ecb95af1c74c4824254f5ce52e29575ba839912)] __-__ add arg list to flow yaml  (#4909) (*Han Xiao*)\n+ - [[```26629b2a```](https://github.com/jina-ai/jina/commit/26629b2a818a56fc8f2e801f2ccff904fc23e7e6)] __-__ adding jcloude (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```b90f7534```](https://github.com/jina-ai/jina/commit/b90f75341db976c813b01be48fc701f110826b41)] __-__ __docs__: add banner to the docs (*Han Xiao*)\n+ - [[```ca682192```](https://github.com/jina-ai/jina/commit/ca682192998bfb060dab129e70dee49cf5b3b3d1)] __-__ correct template link to github (#4911) (*Leon Wolf*)\n+ - [[```a65110cd```](https://github.com/jina-ai/jina/commit/a65110cd29c99122925dd746f991d55775eafa50)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```58239747```](https://github.com/jina-ai/jina/commit/5823974704c6bfb9dd7fcc35472877beb2f897d9)] __-__ __docs__: fix gateway status (*Han Xiao*)\n+ - [[```31c98680```](https://github.com/jina-ai/jina/commit/31c98680b16855d271fb299052000aa51cdf9494)] __-__ __docs__: adding jcloud (*Han Xiao*)\n+ - [[```24306049```](https://github.com/jina-ai/jina/commit/24306049eba9eb296642e14568e6ab15973bc2ab)] __-__ __version__: the next version will be 3.6.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.2'\n+__version__ = '3.6.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.3"}
{"prompt": " file path A: docs/fundamentals/flow/yaml-spec.md | file path B: docs/fundamentals/flow/yaml-spec.md\n\n@@ -3,13 +3,40 @@\n \n This page outlines the specification for valid Flow YAML files.\n \n-Such YAML configurations can be used to generate a Flow object via `Flow.load_config('flow.yml')`.\n+Such YAML configurations can be used to generate a Flow object via {meth}`~jina.jaml.JAMLCompatible.load_config`.\n \n-To generate a YAML configuration from a `Flow` Python object, run `f.save_config()`.\n+To generate a YAML configuration from a `Flow` Python object, use {meth}`~jina.jaml.JAMLCompatible.save_config`.\n \n-## Example\n+## YAML completion in IDE\n \n-The following constitutes an example Flow configuration:\n+We provide a [JSON Schema](https://json-schema.org/) for your IDE to enable code completion, syntax validation, members listing and displaying help text. Here is a [video tutorial](https://youtu.be/qOD-6mihUzQ) to walk you through the setup.\n+\n+<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/qOD-6mihUzQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n+\n+\n+### PyCharm users\n+\n+1. Click menu `Preferences` -> `JSON Schema mappings`;\n+2. Add a new schema, in the `Schema File or URL` write `https://api.jina.ai/schemas/latest.json`; select `JSON Schema Version 7`;\n+3. Add a file path pattern and link it to `*.jaml` or `*.jina.yml` or any suffix you commonly used for Jina Flow's YAML.\n+\n+### VSCode users\n+\n+1. Install the extension: `YAML Language Support by Red Hat`;\n+2. In IDE-level `settings.json` add:\n+\n+```json\n+\"yaml.schemas\": {\n+    \"https://api.jina.ai/schemas/latest.json\": [\"/*.jina.yml\", \"/*.jaml\"],\n+}\n+```\n+\n+You can bind Schema to any file suffix you commonly used for Jina Flow's YAML.\n+\n+\n+## Example YAML\n+\n+The following constitutes an example Flow YAML:\n \n ```yaml\n jtype: Flow\n\n---\n file path A: jina/schemas/flow.py | file path B: jina/schemas/flow.py\n\n@@ -3,7 +3,7 @@ from jina_cli.export import api_to_dict\n \n _schema_flow_with = _cli_to_schema(\n     api_to_dict(),\n-    'flow',\n+    ['flow', 'gateway'],\n     allow_addition=False,\n     description='The config of Flow, unrecognized config arguments will be applied to all Deployments',\n )['Jina::Flow']\n@@ -35,6 +35,6 @@ schema_flow = {\n         },\n         'type': 'object',\n         'additionalProperties': False,\n-        'required': ['jtype', 'version', 'deployments'],\n+        'required': ['jtype', 'executors'],\n     }\n }\n\n---\n file path A: jina/schemas/helper.py | file path B: jina/schemas/helper.py\n\n@@ -25,12 +25,14 @@ def _cli_to_schema(\n     namespace='Jina',\n     description='',\n ):\n-    deployment_api = None\n+    deployment_api = []\n+\n+    if not isinstance(target, list):\n+        target = [target]\n \n     for d in api_dict['methods']:\n-        if d['name'] == target:\n-            deployment_api = d['options']\n-            break\n+        if d['name'] in target:\n+            deployment_api.extend(d['options'])\n \n     _schema = {\n         'properties': {},\n@@ -57,4 +59,4 @@ def _cli_to_schema(\n     if required:\n         _schema['required'].extend(required)\n \n-    return {f'{namespace}::{target.capitalize()}': _schema}\n+    return {f'{namespace}::{target[0].capitalize()}': _schema}\n\n\n###\n\n", "completion": "fix: json schema generation (#<issue-num>)"}
{"prompt": " file path A: docs/api.md | file path B: docs/api.md\n\n@@ -1,4 +1,4 @@\n-# Python API\n+# {fab}`python` Python API\n \n This section includes the API documentation from the `jina` codebase. These are automatically extracted from the [docstrings](https://peps.python.org/pep-0257/) in the code.\n \n\n---\n file path A: docs/cli/index.rst | file path B: docs/cli/index.rst\n\n@@ -1,5 +1,5 @@\n-Command-Line Interface\n-======================\n+:octicon:`terminal` Command-Line Interface\n+==========================================\n \n .. argparse::\n    :noepilog:\n\n---\n file path A: docs/envs/index.md | file path B: docs/envs/index.md\n\n@@ -5,24 +5,24 @@ The following environment variables are used internally in Jina.\n \n | Environment variable          | Description |\n |-------------------------------| ----------- |\n-| JINA_AUTH_TOKEN               | If provided, jina hub push would push this Executor to specific account |\n-| JINA_DEFAULT_HOST             | The default host where the server is exposed |\n-| JINA_DEFAULT_TIMEOUT_CTRL     | The default timeout time used by Flow to check the readiness of Executors |\n-| JINA_DEFAULT_WORKSPACE_BASE   | The default workspace folder set to the runtime if none provided through arguments |\n-| JINA_DEPLOYMENT_NAME          | The name of the deployment exposed, used by the Head Runtime in Kubernetes to connect to different deployments |\n-| JINA_DISABLE_UVLOOP           | If set, Jina will not use uvloop event loop for concurrent execution |\n-| JINA_FULL_CLI                 | If set, all the CLI options will be shown in help |\n-| JINA_GATEWAY_IMAGE            | Used when exporting a Flow to Kubernetes or docker-compose to override the default gateway image |\n-| JINA_GRPC_RECV_BYTES          | Set by the grpc service to keep track of the received bytes |\n-| JINA_GRPC_SEND_BYTES          | Set by the grpc service to keep track of the sent bytes  |\n-| JINA_HUBBLE_REGISTRY          | Set it to point to a different Jina Hub registry |\n-| JINA_HUB_CACHE_DIR            | The directory where hub will cache its executors inside JINA_HUB_ROOT |\n-| JINA_HUB_ROOT                 | The base directory for HubIO to store and read files |\n-| JINA_LOG_CONFIG               | The configuration used for the logger |\n-| JINA_LOG_LEVEL                | The logging level used: INFO, DEBUG, WARNING |\n-| JINA_LOG_NO_COLOR             | If set, disables color from rich console |\n-| JINA_MP_START_METHOD          | Sets the multiprocessing start method used by jina |\n-| JINA_RANDOM_PORT_MAX          | The max port number used when selecting random ports to apply for Executors or gateway |\n-| JINA_RANDOM_PORT_MIN          | The min port number used when selecting random ports to apply for Executors or gateway |\n-| JINA_DISABLE_HEALTHCHECK_LOGS | If set, disables the logs when processing health check requests |\n-| JINA_LOCKS_ROOT               | The root folder where file locks for concurrent Executor initialization |\n+| `JINA_AUTH_TOKEN`               | If provided, jina hub push would push this Executor to specific account |\n+| `JINA_DEFAULT_HOST`             | The default host where the server is exposed |\n+| `JINA_DEFAULT_TIMEOUT_CTRL`     | The default timeout time used by Flow to check the readiness of Executors |\n+| `JINA_DEFAULT_WORKSPACE_BASE`   | The default workspace folder set to the runtime if none provided through arguments |\n+| `JINA_DEPLOYMENT_NAME`          | The name of the deployment exposed, used by the Head Runtime in Kubernetes to connect to different deployments |\n+| `JINA_DISABLE_UVLOOP`           | If set, Jina will not use uvloop event loop for concurrent execution |\n+| `JINA_FULL_CLI`                 | If set, all the CLI options will be shown in help |\n+| `JINA_GATEWAY_IMAGE`            | Used when exporting a Flow to Kubernetes or docker-compose to override the default gateway image |\n+| `JINA_GRPC_RECV_BYTES`          | Set by the grpc service to keep track of the received bytes |\n+| `JINA_GRPC_SEND_BYTES`          | Set by the grpc service to keep track of the sent bytes  |\n+| `JINA_HUBBLE_REGISTRY`          | Set it to point to a different Jina Hub registry |\n+| `JINA_HUB_CACHE_DIR`            | The directory where hub will cache its executors inside JINA_HUB_ROOT |\n+| `JINA_HUB_ROOT`                 | The base directory for HubIO to store and read files |\n+| `JINA_LOG_CONFIG`               | The configuration used for the logger |\n+| `JINA_LOG_LEVEL`                | The logging level used: INFO, DEBUG, WARNING |\n+| `JINA_LOG_NO_COLOR`             | If set, disables color from rich console |\n+| `JINA_MP_START_METHOD`          | Sets the multiprocessing start method used by jina |\n+| `JINA_RANDOM_PORT_MAX`          | The max port number used when selecting random ports to apply for Executors or gateway |\n+| `JINA_RANDOM_PORT_MIN`          | The min port number used when selecting random ports to apply for Executors or gateway |\n+| `JINA_DISABLE_HEALTHCHECK_LOGS` | If set, disables the logs when processing health check requests |\n+| `JINA_LOCKS_ROOT`               | The root folder where file locks for concurrent Executor initialization |\n\n---\n file path A: docs/fundamentals/executor/containerize-executor.md | file path B: docs/fundamentals/executor/containerize-executor.md\n\n@@ -1,16 +1,30 @@\n (dockerize-exec)=\n-# Dockerize your Executor\n+# Containerize\n \n-Once you have understood what an `Executor` is and how it can be used inside a `Flow`, you may be interested in wrapping this Executor into a container\n-so that you can isolate its dependencies and make it ready to run in the cloud or in Kubernetes.\n \n-One option is to leverage {ref}`Jina Hub <hub/index>` infrastructure to make sure your Executor can run as a container.\n+````{tip}\n+The recommended way of containerizing an Executor is to leverage {ref}`Jina Hub <jina-hub>` to make sure your Executor can run as a container. It handles auto-provisioning, building, version controlling etc. \n \n-However, you can also build a Docker image yourself and use it like any other Executor. There are some requirements\n+Simply:\n+```bash\n+jina hub new\n+\n+# work on the executor\n+\n+jina hub push .\n+```\n+\n+The image building will happen on the cloud, and available immedidately for other to use.\n+````\n+\n+Once you have understood what an `Executor` is and how it can be used inside a `Flow`, you may be interested in wrapping this Executor into a container so that you can isolate its dependencies and make it ready to run in the cloud or in Kubernetes.\n+\n+\n+You can also build a Docker image yourself and use it like any other Executor. There are some requirements\n on how this image needs to be built, the main ones being:\n \n-- Jina must be installed inside the image\n-- The Jina CLI command to start the Executor has to be the default entrypoint\n+- Jina must be installed inside the image.\n+- The Jina CLI command to start the Executor has to be the default entrypoint.\n \n ## Prerequisites\n \n@@ -44,7 +58,7 @@ When a containerized Executor is run inside a Flow,\n under the hood Jina executes `docker run` with extra arguments.\n \n This means that Jina assumes that whatever runs inside the container, also runs like it would in a regular OS process. Therefore, you need to make sure that\n-the basic entrypoint of the image calls `jina executor` {ref}`CLI <../api/cli>` command.\n+the basic entrypoint of the image calls `jina executor` {ref}`CLI <../api/jina_cli>` command.\n \n ```dockerfile\n ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n@@ -103,7 +117,7 @@ In this case, our Executor has only one requirement besides Jina: `torch`.\n \n In `requirements.txt`, we specify a single requirement:\n \n-```requirements.txt\n+```text\n torch\n ```\n \n\n---\n file path A: docs/fundamentals/executor/executor-run.md | file path B: docs/fundamentals/executor/executor-run.md\n\n@@ -1,4 +1,4 @@\n-## Run\n+# Run\n \n `Executor` objects can be used directly, just like any regular Python object.\n \n@@ -51,7 +51,7 @@ print(docs.embeddings.shape)\n ```\n ````\n \n-### Run async Executors\n+## Run async Executors\n \n \n ```python\n\n---\n file path A: docs/fundamentals/executor/index.md | file path B: docs/fundamentals/executor/index.md\n\n@@ -51,5 +51,5 @@ executor-run\n executor-serve\n yaml-spec\n executor-files\n-dockerize-exec\n+containerize-executor\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -145,7 +145,6 @@ Executor and Flow are the two fundamental concepts in Jina.\n create-flow\n add-executors\n topologies\n-flow-api\n monitoring-flow\n health-check\n when-things-go-wrong\n\n---\n file path A: docs/fundamentals/flow/expose-endpoints.svg | file path B: docs/fundamentals/gateway/expose-endpoints.svg\n\n\n---\n file path A: docs/fundamentals/jcloud/basic.md | file path B: docs/fundamentals/jcloud/basic.md\n\n@@ -166,7 +166,7 @@ You can see the ALIVE Flows deployed by you.\n \n You can also filter your Flows by passing a status:\n \n-```\n+```bash\n jc list --status FAILED\n ```\n \n@@ -177,7 +177,7 @@ jc list --status FAILED\n \n Or see all the flows:\n \n-```\n+```bash\n jc list --status ALL\n ```\n \n\n---\n file path A: docs/get-started/install/troubleshooting.md | file path B: docs/get-started/install/troubleshooting.md\n\n@@ -23,7 +23,7 @@ Building wheels for collected packages: numpy\n \n It could simply be that your local `pip` is too old. Updating it should solve the problem:\n \n-```python\n+```bash\n pip install -U pip\n ```\n \n@@ -58,11 +58,14 @@ Unfortunately, `conda install` is not supported on Windows. You can either do `p\n \n ## Upgrading from Jina 2.x to 3.x\n If you upgraded an existing Jina installation from 2.x to 3.x you may see the following error message:\n-```commandline\n+\n+```text\n OSError: `docarray` dependency is not installed correctly, please reinstall with `pip install -U --force-reinstall docarray`\n ```\n+\n This can be fixed by reinstalling the `docarray` package manually:\n-```commandline\n+\n+```bash\n pip install -U --force-reinstall docarray\n ```\n \n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -55,7 +55,7 @@ In the following sections we will describe how to run standalone Executors via t\n ````{admonition} Advanced deployment options\n :class: seealso\n This tutorial walks through the basics of spawing a standalone (external) Executor. For more advanced options, refer to the\n-{ref}`CLI <api/cli>` and {ref}`Executor API section <serve-executor-standalone>`\n+[CLI](../cli/index.rst) and {ref}`Executor API section <serve-executor-standalone>`\n ````\n \n ## Using Jina Hub\n\n---\n file path A: docs/how-to/index.md | file path B: docs/how-to/index.md\n\n@@ -1,4 +1,4 @@\n-# How-To\n+# {octicon}`book` How-To\n \n Jina is a very powerful framework that can help you build distributed multi-modal and cross-modal applications, from start to finish.\n \n\n---\n file path A: docs/_static/hub-banner.png | file path B: docs/_static/hub-banner.png\n\nBinary files /dev/null and b/docs/_static/hub-banner.png differ\n\n---\n file path A: docs/_static/jcloud-banner.png | file path B: docs/_static/jcloud-banner.png\n\nBinary files /dev/null and b/docs/_static/jcloud-banner.png differ\n\n---\n file path A: docs/fundamentals/executor/hub/img/hub-banner.png | file path B: docs/fundamentals/executor/hub/img/hub-banner.png\n\nBinary files /dev/null and b/docs/fundamentals/executor/hub/img/hub-banner.png differ\n\n---\n file path A: docs/fundamentals/executor/hub/index.md | file path B: docs/fundamentals/executor/hub/index.md\n\n@@ -1,6 +1,16 @@\n (jina-hub)=\n # Hub\n \n+```{figure} https://docs.jina.ai/_images/hub-banner.png\n+:width: 0 %\n+:scale: 0 %\n+```\n+\n+```{figure} img/hub-banner.png\n+:scale: 0 %\n+:width: 0 %\n+```\n+\n Now that you understand that Executor is a building block in Jina, the following questions may arise:\n \n - Can I reuse my Executor in another project?\n\n---\n file path A: docs/fundamentals/jcloud/img/jcloud-banner.png | file path B: docs/fundamentals/jcloud/img/jcloud-banner.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/img/jcloud-banner.png differ\n\n---\n file path A: docs/fundamentals/jcloud/index.md | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -1,5 +1,16 @@\n # JCloud\n \n+```{figure} https://docs.jina.ai/_images/jcloud-banner.png\n+:width: 0 %\n+:scale: 0 %\n+```\n+\n+```{figure} img/jcloud-banner.png\n+:scale: 0 %\n+:width: 0 %\n+```\n+\n+\n After you built a Jina project, the next step is to deploy and host it somewhere. JCloud simplifies deploying and hosting your Jina projects on Jina Cloud. It provides a simple CLI with five commands to manage the lifecycle of your Jina projects.\n \n Strictly speaking JCloud has two parts: the cloud part (i.e. Jina Cloud) and the client part. Specifically, using JCloud means deploying a Jina project with the client to the cloud. This chapter will guide you to use client.\n\n\n###\n\n", "completion": "chore(docs): add banner to the docs"}
{"prompt": " file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -189,7 +189,7 @@\n                     </div>\n                     <div class=\"right-details\">\n                         <div class=\"social-btns\">\n-                            <a class='social-btn' href=\"https://github.com/jina-ai/docarray/\" aria-label=\"GitHub\"\n+                            <a class='social-btn' href=\"https://github.com/jina-ai/jina\" aria-label=\"GitHub\"\n                                target=\"_blank\" rel=\"noreferrer\"> <i class=\"fab fa-github\"></i></a>\n                             <a class='social-btn' href=\"https://slack.jina.ai\" aria-label=\"Slack\" target=\"_blank\"\n                                rel=\"noreferrer\"> <i class=\"fab fa-slack\"></i></a>\n@@ -240,4 +240,4 @@\n </div>\n <img referrerpolicy=\"no-referrer-when-downgrade\"\n      src=\"https://static.scarf.sh/a.png?x-pxid=2823e771-0e1e-4320-8fde-48bc48e53262\"/>\n-{%- endblock %}\n\\ No newline at end of file\n+{%- endblock %}\n\n\n###\n\n", "completion": "chore: correct template link to github (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/containerize-executor.md | file path B: docs/fundamentals/executor/containerize-executor.md\n\n@@ -50,9 +50,8 @@ the basic entrypoint of the image calls `jina executor` {ref}`CLI <../api/cli>`\n ENTRYPOINT [\"jina\", \"executor\", \"--uses\", \"config.yml\"]\n ```\n \n-```{warning} Name your config config.yml\n-Even though you can theoretically name your Executor config file like you want. We **strongly encourage** you to name\n-it `config.yml` otherwise using your containerize Executor with Kubernetes will require extra step.\n+```{tip}\n+We **strongly encourage** you to name the Executor YAML as `config.yml`, otherwise using your containerize Executor with Kubernetes will require extra step.\n ```\n \n ## Example: Dockerized Executor\n\n---\n file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -277,8 +277,8 @@ see their [website](https://www.uvicorn.org/settings/).\n \n ## Get status\n \n-```{warning} Consistent version\n-Even though you can theoretically run Executors and Gateways in different Jina versions, it is recommended for them to work with the same Jina version, and the same as the client used to interact with them.\n+```{tip}\n+Though you can run Executors, Gateway and Client in different Jina versions, it is recommended to work with the same Jina version.\n ```\n \n Gateway provides an endpoint that exposes relevant information about the environment where it runs. \n\n---\n file path A: docs/fundamentals/flow/health-check.md | file path B: docs/fundamentals/flow/health-check.md\n\n@@ -91,10 +91,8 @@ docker pull fullstorydev/grpcurl:latest\n docker run --network='host' fullstorydev/grpcurl -plaintext 127.0.0.1:12345 jina.JinaGatewayDryRunRPC/dry_run\n ```\n The error-free output below signifies a correctly running Flow:\n-```text\n-{\n-  \n-}\n+```json\n+{}\n ```\n \n You can simulate an Executor going offline by killing its process.\n@@ -110,7 +108,7 @@ docker run --network='host' fullstorydev/grpcurl -plaintext 127.0.0.1:12345 jina\n ```\n \n ````{dropdown} Error output\n-```text\n+```json\n {\n   \"code\": \"ERROR\",\n   \"description\": \"failed to connect to all addresses |Gateway: Communication error with deployment at address(es) 0.0.0.0:12346. Head or worker(s) may be down.\",\n@@ -155,8 +153,8 @@ When using HTTP or Websocket as the Gateway protocol, you can use curl to target\n curl http://localhost:12345/dry_run\n ```\n The error-free output below signifies a correctly running Flow:\n-```text\n-{\"code\":0,\"description\":\"\",\"exception\":null}%\n+```json\n+{\"code\":0,\"description\":\"\",\"exception\":null}\n ```\n \n You can simulate an Executor going offline by killing its process.\n@@ -167,8 +165,8 @@ kill -9 $EXECUTOR_PID # in this case we can see in the logs that it is 19059\n \n Then by doing the same check, you will see that the call returns an error:\n \n-```text\n-{\"code\":1,\"description\":\"failed to connect to all addresses |Gateway: Communication error with deployment executor0 at address(es) {'0.0.0.0:12346'}. Head or worker(s) may be down.\",\"exception\":{\"name\":\"InternalNetworkError\",\"args\":[\"failed to connect to all addresses |Gateway: Communication error with deployment executor0 at address(es) {'0.0.0.0:12346'}. Head or worker(s) may be down.\"],\"stacks\":[\"Traceback (most recent call last):\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 726, in task_wrapper\\n    timeout=timeout,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 241, in send_requests\\n    await call_result,\\n\",\"  File \\\"/home/joan/.local/lib/python3.7/site-packages/grpc/aio/_call.py\\\", line 291, in __await__\\n    self._cython_call._status)\\n\",\"grpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNAVAILABLE\\n\\tdetails = \\\"failed to connect to all addresses\\\"\\n\\tdebug_error_string = \\\"{\\\"created\\\":\\\"@1654074272.702044542\\\",\\\"description\\\":\\\"Failed to pick subchannel\\\",\\\"file\\\":\\\"src/core/ext/filters/client_channel/client_channel.cc\\\",\\\"file_line\\\":3134,\\\"referenced_errors\\\":[{\\\"created\\\":\\\"@1654074272.702043378\\\",\\\"description\\\":\\\"failed to connect to all addresses\\\",\\\"file\\\":\\\"src/core/lib/transport/error_utils.cc\\\",\\\"file_line\\\":163,\\\"grpc_status\\\":14}]}\\\"\\n>\\n\",\"\\nDuring handling of the above exception, another exception occurred:\\n\\n\",\"Traceback (most recent call last):\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/http/app.py\\\", line 142, in _flow_health\\n    data_type=DataInputType.DOCUMENT,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/http/app.py\\\", line 399, in _get_singleton_result\\n    async for k in streamer.stream(request_iterator=request_iterator):\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/stream/__init__.py\\\", line 78, in stream\\n    async for response in async_iter:\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/stream/__init__.py\\\", line 154, in _stream_requests\\n    response = self._result_handler(future.result())\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/request_handling.py\\\", line 148, in _process_results_at_end_gateway\\n    partial_responses = await asyncio.gather(*tasks)\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/graph/topology_graph.py\\\", line 128, in _wait_previous_and_send\\n    self._handle_internalnetworkerror(err)\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/graph/topology_graph.py\\\", line 70, in _handle_internalnetworkerror\\n    raise err\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/graph/topology_graph.py\\\", line 125, in _wait_previous_and_send\\n    timeout=self._timeout_send,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 734, in task_wrapper\\n    num_retries=num_retries,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 697, in _handle_aiorpcerror\\n    details=e.details(),\\n\",\"jina.excepts.InternalNetworkError: failed to connect to all addresses |Gateway: Communication error with deployment executor0 at address(es) {'0.0.0.0:12346'}. Head or worker(s) may be down.\\n\"],\"executor\":\"\"}}%\n+```json\n+{\"code\":1,\"description\":\"failed to connect to all addresses |Gateway: Communication error with deployment executor0 at address(es) {'0.0.0.0:12346'}. Head or worker(s) may be down.\",\"exception\":{\"name\":\"InternalNetworkError\",\"args\":[\"failed to connect to all addresses |Gateway: Communication error with deployment executor0 at address(es) {'0.0.0.0:12346'}. Head or worker(s) may be down.\"],\"stacks\":[\"Traceback (most recent call last):\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 726, in task_wrapper\\n    timeout=timeout,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 241, in send_requests\\n    await call_result,\\n\",\"  File \\\"/home/joan/.local/lib/python3.7/site-packages/grpc/aio/_call.py\\\", line 291, in __await__\\n    self._cython_call._status)\\n\",\"grpc.aio._call.AioRpcError: <AioRpcError of RPC that terminated with:\\n\\tstatus = StatusCode.UNAVAILABLE\\n\\tdetails = \\\"failed to connect to all addresses\\\"\\n\\tdebug_error_string = \\\"{\\\"created\\\":\\\"@1654074272.702044542\\\",\\\"description\\\":\\\"Failed to pick subchannel\\\",\\\"file\\\":\\\"src/core/ext/filters/client_channel/client_channel.cc\\\",\\\"file_line\\\":3134,\\\"referenced_errors\\\":[{\\\"created\\\":\\\"@1654074272.702043378\\\",\\\"description\\\":\\\"failed to connect to all addresses\\\",\\\"file\\\":\\\"src/core/lib/transport/error_utils.cc\\\",\\\"file_line\\\":163,\\\"grpc_status\\\":14}]}\\\"\\n>\\n\",\"\\nDuring handling of the above exception, another exception occurred:\\n\\n\",\"Traceback (most recent call last):\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/http/app.py\\\", line 142, in _flow_health\\n    data_type=DataInputType.DOCUMENT,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/http/app.py\\\", line 399, in _get_singleton_result\\n    async for k in streamer.stream(request_iterator=request_iterator):\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/stream/__init__.py\\\", line 78, in stream\\n    async for response in async_iter:\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/stream/__init__.py\\\", line 154, in _stream_requests\\n    response = self._result_handler(future.result())\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/request_handling.py\\\", line 148, in _process_results_at_end_gateway\\n    partial_responses = await asyncio.gather(*tasks)\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/graph/topology_graph.py\\\", line 128, in _wait_previous_and_send\\n    self._handle_internalnetworkerror(err)\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/graph/topology_graph.py\\\", line 70, in _handle_internalnetworkerror\\n    raise err\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/runtimes/gateway/graph/topology_graph.py\\\", line 125, in _wait_previous_and_send\\n    timeout=self._timeout_send,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 734, in task_wrapper\\n    num_retries=num_retries,\\n\",\"  File \\\"/home/joan/jina/jina/jina/serve/networking.py\\\", line 697, in _handle_aiorpcerror\\n    details=e.details(),\\n\",\"jina.excepts.InternalNetworkError: failed to connect to all addresses |Gateway: Communication error with deployment executor0 at address(es) {'0.0.0.0:12346'}. Head or worker(s) may be down.\\n\"],\"executor\":\"\"}}\n ```\n \n (health-check-microservices)=\n@@ -213,7 +211,7 @@ docker pull fullstorydev/grpcurl:latest\n docker run --network='host' fullstorydev/grpcurl -plaintext 127.0.0.1:12346 grpc.health.v1.Health/Check\n ```\n \n-```text\n+```json\n {\n   \"status\": \"SERVING\"\n }\n@@ -237,7 +235,7 @@ With the same Flow as described before, you can use the same way to check the Ga\n docker run --network='host' fullstorydev/grpcurl -plaintext 127.0.0.1:12345 grpc.health.v1.Health/Check\n ```\n \n-```text\n+```json\n {\n   \"status\": \"SERVING\"\n }\n@@ -270,6 +268,6 @@ curl http://localhost:12345\n ```\n \n And you will get a valid empty response indicating the Gateway's ability to serve.\n-```text\n-{}%\n+```json\n+{}\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/envs/index.md | file path B: docs/envs/index.md\n\n@@ -1,28 +1,28 @@\n (jina-env-vars)=\n-# Environment Variables in Jina\n+# Environment Variables\n \n-In Jina there are some environment variables that are used internally.\n+The following environment variables are used internally in Jina.\n \n-| Env variable | Description |\n-| -----  | ----------- |\n-| JINA_AUTH_TOKEN | If provided, jina hub push would push this Executor to specific account |\n-| JINA_DEFAULT_HOST | The default host where the server is exposed |\n-| JINA_DEFAULT_TIMEOUT_CTRL | The default timeout time used by Flow to check the readiness of Executors |\n-| JINA_DEFAULT_WORKSPACE_BASE | The default workspace folder set to the runtime if none provided through arguments |\n-| JINA_DEPLOYMENT_NAME | The name of the deployment exposed, used by the Head Runtime in Kubernetes to connect to different deployments |\n-| JINA_DISABLE_UVLOOP | If set, Jina will not use uvloop event loop for concurrent execution |\n-| JINA_FULL_CLI | If set, all the CLI options will be shown in help |\n-| JINA_GATEWAY_IMAGE | Used when exporting a Flow to Kubernetes or docker-compose to override the default gateway image |\n-| JINA_GRPC_RECV_BYTES | Set by the grpc service to keep track of the received bytes |\n-| JINA_GRPC_SEND_BYTES | Set by the grpc service to keep track of the sent bytes  |\n-| JINA_HUBBLE_REGISTRY | Set it to point to a different Jina Hub registry |\n-| JINA_HUB_CACHE_DIR | The directory where hub will cache its executors inside JINA_HUB_ROOT |\n-| JINA_HUB_ROOT | The base directory for HubIO to store and read files |\n-| JINA_LOG_CONFIG | The configuration used for the logger |\n-| JINA_LOG_LEVEL | The logging level used: INFO, DEBUG, WARNING |\n-| JINA_LOG_NO_COLOR | If set, disables color from rich console |\n-| JINA_MP_START_METHOD | Sets the multiprocessing start method used by jina |\n-| JINA_RANDOM_PORT_MAX | The max port number used when selecting random ports to apply for Executors or gateway |\n-| JINA_RANDOM_PORT_MIN | The min port number used when selecting random ports to apply for Executors or gateway |\n+| Environment variable          | Description |\n+|-------------------------------| ----------- |\n+| JINA_AUTH_TOKEN               | If provided, jina hub push would push this Executor to specific account |\n+| JINA_DEFAULT_HOST             | The default host where the server is exposed |\n+| JINA_DEFAULT_TIMEOUT_CTRL     | The default timeout time used by Flow to check the readiness of Executors |\n+| JINA_DEFAULT_WORKSPACE_BASE   | The default workspace folder set to the runtime if none provided through arguments |\n+| JINA_DEPLOYMENT_NAME          | The name of the deployment exposed, used by the Head Runtime in Kubernetes to connect to different deployments |\n+| JINA_DISABLE_UVLOOP           | If set, Jina will not use uvloop event loop for concurrent execution |\n+| JINA_FULL_CLI                 | If set, all the CLI options will be shown in help |\n+| JINA_GATEWAY_IMAGE            | Used when exporting a Flow to Kubernetes or docker-compose to override the default gateway image |\n+| JINA_GRPC_RECV_BYTES          | Set by the grpc service to keep track of the received bytes |\n+| JINA_GRPC_SEND_BYTES          | Set by the grpc service to keep track of the sent bytes  |\n+| JINA_HUBBLE_REGISTRY          | Set it to point to a different Jina Hub registry |\n+| JINA_HUB_CACHE_DIR            | The directory where hub will cache its executors inside JINA_HUB_ROOT |\n+| JINA_HUB_ROOT                 | The base directory for HubIO to store and read files |\n+| JINA_LOG_CONFIG               | The configuration used for the logger |\n+| JINA_LOG_LEVEL                | The logging level used: INFO, DEBUG, WARNING |\n+| JINA_LOG_NO_COLOR             | If set, disables color from rich console |\n+| JINA_MP_START_METHOD          | Sets the multiprocessing start method used by jina |\n+| JINA_RANDOM_PORT_MAX          | The max port number used when selecting random ports to apply for Executors or gateway |\n+| JINA_RANDOM_PORT_MIN          | The min port number used when selecting random ports to apply for Executors or gateway |\n | JINA_DISABLE_HEALTHCHECK_LOGS | If set, disables the logs when processing health check requests |\n-| JINA_LOCKS_ROOT | The root folder where file locks for concurrent Executor initialization |\n+| JINA_LOCKS_ROOT               | The root folder where file locks for concurrent Executor initialization |\n\n---\n file path A: docs/fundamentals/flow/expose-jina-info.md | file path B: None\n\n@@ -1,98 +0,0 @@\n-# Expose Information on microservices\n-Every Jina Flow consists of a {ref}`number of microservices <architecture-overview>`,\n-each of which may live in different environments, and even run different Jina versions.\n-\n-```{warning} Use same jina version\n-Even though you can theoretically run Executors and Gateways in different Jina versions, it is recommended for them to work with the same Jina version, and the same as the client used to interact with them.\n-```\n-\n-Each Flow microservice provides an endpoint that exposes relevant information about the environment where it runs. \n-\n-This information exposes information in a dict-like structure with the following keys:\n-- jina: A dictionary containing information about the system and the versions of several packages including jina package itself\n-- envs: A dictionary containing all the values if set of the {ref}`environment variables used in Jina <jina-env-vars>`\n-\n-\n-## Access Information of GRPC-based microservices\n-\n-To access this information for any of the GRPC-based microservices of Jina (Executors or Gateway using grpc protocol) you can use any grpc client.\n-\n-To see how this works, first instantiate a Flow with an Executor exposed to an specific port and block it for serving:\n-\n-```python\n-from jina import Flow\n-\n-PROTOCOL = 'grpc'  # it could also be http or websocket\n-\n-with Flow(protocol=PROTOCOL, port=12345).add() as f:\n-    f.block()\n-```\n-\n-Then, you can use [grpcurl](https://github.com/fullstorydev/grpcurl) to hit the gRPC service\n-\n-```shell\n-docker pull fullstorydev/grpcurl:latest\n-docker run --network='host' fullstorydev/grpcurl -plaintext 127.0.0.1:12345 jina.JinaInfoRPC/_status\n-```\n-The error-free output below signifies a correctly running Flow:\n-```text\n-{\n-  \"jina\": {\n-    \"architecture\": \"######\",\n-    \"ci-vendor\": \"######\",\n-    \"docarray\": \"######\",\n-    \"grpcio\": \"######\",\n-    \"jina\": \"######\",\n-    \"jina-proto\": \"######\",\n-    \"jina-vcs-tag\": \"######\",\n-    \"platform\": \"######\",\n-    \"platform-release\": \"######\",\n-    \"platform-version\": \"######\",\n-    \"processor\": \"######\",\n-    \"proto-backend\": \"######\",\n-    \"protobuf\": \"\"######\",\n-    \"python\": \"######\", \n-    \"pyyaml\": \"######\",\n-    \"session-id\": \"######\",\n-    \"uid\": \"######\",\n-    \"uptime\": \"######\",\n-  },\n-  \"envs\": {\n-    \"JINA_AUTH_TOKEN\": \"(unset)\",\n-    \"JINA_DEFAULT_HOST\": \"(unset)\",\n-    \"JINA_DEFAULT_TIMEOUT_CTRL\": \"(unset)\",\n-    \"JINA_DEFAULT_WORKSPACE_BASE\": \"#####\",\n-    \"JINA_DEPLOYMENT_NAME\": \"(unset)\",\n-    \"JINA_DISABLE_HEALTHCHECK_LOGS\": \"(unset)\",\n-    \"JINA_DISABLE_UVLOOP\": \"(unset)\",\n-    \"JINA_EARLY_STOP\": \"(unset)\",\n-    \"JINA_FULL_CLI\": \"(unset)\",\n-    \"JINA_GATEWAY_IMAGE\": \"(unset)\",\n-    \"JINA_GRPC_RECV_BYTES\": \"(unset)\",\n-    \"JINA_GRPC_SEND_BYTES\": \"(unset)\",\n-    \"JINA_HUBBLE_REGISTRY\": \"(unset)\",\n-    \"JINA_HUB_CACHE_DIR\": \"(unset)\",\n-    \"JINA_HUB_NO_IMAGE_REBUILD\": \"(unset)\",\n-    \"JINA_HUB_ROOT\": \"(unset)\",\n-    \"JINA_LOCKS_ROOT\": \"(unset)\",\n-    \"JINA_LOG_CONFIG\": \"(unset)\",\n-    \"JINA_LOG_LEVEL\": \"(unset)\",\n-    \"JINA_LOG_NO_COLOR\": \"(unset)\",\n-    \"JINA_MP_START_METHOD\": \"(unset)\",\n-    \"JINA_RANDOM_PORT_MAX\": \"(unset)\",\n-    \"JINA_RANDOM_PORT_MIN\": \"(unset)\",\n-  }\n-}\n-```\n-\n-## Access Information of Gateway using HTTP/Websocket protocol\n-\n-When using HTTP or Websocket as the Gateway protocol, you can use curl to target the `/status` endpoint and get the Jina info.\n-\n-```shell\n-curl http://localhost:12345/status\n-```\n-\n-```text\n-{\"jina\":{\"jina\":\"######\",\"docarray\":\"######\",\"jina-proto\":\"######\",\"jina-vcs-tag\":\"(unset)\",\"protobuf\":\"######\",\"proto-backend\":\"######\",\"grpcio\":\"######\",\"pyyaml\":\"######\",\"python\":\"######\",\"platform\":\"######\",\"platform-release\":\"######\",\"platform-version\":\"######\",\"architecture\":\"######\",\"processor\":\"######\",\"uid\":\"######\",\"session-id\":\"######\",\"uptime\":\"######\",\"ci-vendor\":\"(unset)\"},\"envs\":{\"JINA_AUTH_TOKEN\":\"(unset)\",\"JINA_DEFAULT_HOST\":\"(unset)\",\"JINA_DEFAULT_TIMEOUT_CTRL\":\"(unset)\",\"JINA_DEFAULT_WORKSPACE_BASE\":\"######\",\"JINA_DEPLOYMENT_NAME\":\"(unset)\",\"JINA_DISABLE_UVLOOP\":\"(unset)\",\"JINA_EARLY_STOP\":\"(unset)\",\"JINA_FULL_CLI\":\"(unset)\",\"JINA_GATEWAY_IMAGE\":\"(unset)\",\"JINA_GRPC_RECV_BYTES\":\"(unset)\",\"JINA_GRPC_SEND_BYTES\":\"(unset)\",\"JINA_HUBBLE_REGISTRY\":\"(unset)\",\"JINA_HUB_CACHE_DIR\":\"(unset)\",\"JINA_HUB_NO_IMAGE_REBUILD\":\"(unset)\",\"JINA_HUB_ROOT\":\"(unset)\",\"JINA_LOG_CONFIG\":\"(unset)\",\"JINA_LOG_LEVEL\":\"(unset)\",\"JINA_LOG_NO_COLOR\":\"(unset)\",\"JINA_MP_START_METHOD\":\"(unset)\",\"JINA_RANDOM_PORT_MAX\":\"(unset)\",\"JINA_RANDOM_PORT_MIN\":\"(unset)\",\"JINA_DISABLE_HEALTHCHECK_LOGS\":\"(unset)\",\"JINA_LOCKS_ROOT\":\"(unset)\"}}%\n-```\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -148,7 +148,6 @@ topologies\n flow-api\n monitoring-flow\n health-check\n-expose-jina-info\n when-things-go-wrong\n yaml-spec\n ```\n\n---\n file path A: docs/fundamentals/gateway/index.md | file path B: docs/fundamentals/gateway/index.md\n\n@@ -18,7 +18,7 @@ For more proper use of the Client, and more information about the Client itself,\n ```\n \n (flow-protocol)=\n-## Serve Flow with different protocols\n+## Supported protocols\n You can use three different protocols to serve the `Flow`: `grpc`,`http` and `websocket`\n \n ````{tab} gRPC\n@@ -209,7 +209,7 @@ with:\n         - fine-tuning\n ```\n ````\n-### Hide default endpoints from HTTP interface\n+### Hide default endpoints\n \n It is possible to hide the default CRUD and debug endpoints in production. This might be useful when the context is not applicable.\n For example, in the code snippet below, we didn't implement any CRUD endpoints for the executor, hence it does not make sense to expose them to public.\n@@ -234,7 +234,7 @@ with:\n After setting up a Flow in this way, the {ref}`default HTTP endpoints <custom-http>` will not be exposed.\n \n (cors)=\n-### Enable Cross-Origin Resource Sharing (CORS)\n+### Enable cross-origin resource sharing\n \n To make a Flow accessible from a website with a different domain, you need to enable [Cross-Origin Resource Sharing (CORS)](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS).\n Among other things, CORS is necessary to provide a {ref}`Swagger UI interface <swagger-ui>` for your Flow.\n@@ -247,7 +247,7 @@ from jina import Flow\n f = Flow(cors=True, protocol='http')\n ```\n \n-### Advanced configuration options\n+### Advanced options\n \n HTTP support in Jina is powered by [Uvicorn](https://www.uvicorn.org/).\n You can configure the Flow's internal Uvicorn sever to your heart's content by passing `uvicorn_kwargs` to the Flow:\n@@ -269,49 +269,116 @@ see their [website](https://www.uvicorn.org/settings/).\n ````\n \n \n-## Add GraphQL endpoint\n \n-````{admonition} Caution\n-:class: caution\n \n-GraphQL support is an optional feature that requires optional dependencies.\n-To install these, run `pip install jina[graphql]` or `pip install jina[all]`.\n \n-Unfortunately, these dependencies are **not available through Conda**. You will have to use `pip` to be able to use GraphQL\n-feature.\n-````\n \n-A Flow can optionally expose a [GraphQL](https://graphql.org/) endpoint, located at `/graphql`.\n-To enable this endpoint, all you need to do is set `expose_graphql_endpoint=True` on your HTTP Flow:\n \n \n-````{tab} Python\n+## Get status\n+\n+```{warning} Consistent version\n+Even though you can theoretically run Executors and Gateways in different Jina versions, it is recommended for them to work with the same Jina version, and the same as the client used to interact with them.\n+```\n+\n+Gateway provides an endpoint that exposes relevant information about the environment where it runs. \n+\n+This information exposes information in a dict-like structure with the following keys:\n+- `jina`: A dictionary containing information about the system and the versions of several packages including jina package itself\n+- `envs`: A dictionary containing all the values if set of the {ref}`environment variables used in Jina <jina-env-vars>`\n+\n+\n+### Use gRPC\n+\n+\n+To see how this works, first instantiate a Flow with an Executor exposed to a specific port and block it for serving:\n \n ```python\n from jina import Flow\n \n-f = Flow(protocol='http', expose_graphql_endpont=True)\n+PROTOCOL = 'grpc'  # it could also be http or websocket\n+\n+with Flow(protocol=PROTOCOL, port=12345).add() as f:\n+    f.block()\n ```\n-````\n \n-````{tab} YAML\n-```yaml\n-jtype: Flow\n-with:\n-  protocol: 'http'\n-  expose_graphql_endpont: True, \n+Then, you can use [grpcurl](https://github.com/fullstorydev/grpcurl)  sending status check request to the Gateway.\n+\n+```shell\n+docker pull fullstorydev/grpcurl:latest\n+docker run --network='host' fullstorydev/grpcurl -plaintext 127.0.0.1:12345 jina.JinaInfoRPC/_status\n+```\n+\n+The error-free output below signifies a correctly running Gateway:\n+\n+```json\n+{\n+  \"jina\": {\n+    \"architecture\": \"######\",\n+    \"ci-vendor\": \"######\",\n+    \"docarray\": \"######\",\n+    \"grpcio\": \"######\",\n+    \"jina\": \"######\",\n+    \"jina-proto\": \"######\",\n+    \"jina-vcs-tag\": \"######\",\n+    \"platform\": \"######\",\n+    \"platform-release\": \"######\",\n+    \"platform-version\": \"######\",\n+    \"processor\": \"######\",\n+    \"proto-backend\": \"######\",\n+    \"protobuf\": \"######\",\n+    \"python\": \"######\", \n+    \"pyyaml\": \"######\",\n+    \"session-id\": \"######\",\n+    \"uid\": \"######\",\n+    \"uptime\": \"######\"\n+  },\n+  \"envs\": {\n+    \"JINA_AUTH_TOKEN\": \"(unset)\",\n+    \"JINA_DEFAULT_HOST\": \"(unset)\",\n+    \"JINA_DEFAULT_TIMEOUT_CTRL\": \"(unset)\",\n+    \"JINA_DEFAULT_WORKSPACE_BASE\": \"#####\",\n+    \"JINA_DEPLOYMENT_NAME\": \"(unset)\",\n+    \"JINA_DISABLE_HEALTHCHECK_LOGS\": \"(unset)\",\n+    \"JINA_DISABLE_UVLOOP\": \"(unset)\",\n+    \"JINA_EARLY_STOP\": \"(unset)\",\n+    \"JINA_FULL_CLI\": \"(unset)\",\n+    \"JINA_GATEWAY_IMAGE\": \"(unset)\",\n+    \"JINA_GRPC_RECV_BYTES\": \"(unset)\",\n+    \"JINA_GRPC_SEND_BYTES\": \"(unset)\",\n+    \"JINA_HUBBLE_REGISTRY\": \"(unset)\",\n+    \"JINA_HUB_CACHE_DIR\": \"(unset)\",\n+    \"JINA_HUB_NO_IMAGE_REBUILD\": \"(unset)\",\n+    \"JINA_HUB_ROOT\": \"(unset)\",\n+    \"JINA_LOCKS_ROOT\": \"(unset)\",\n+    \"JINA_LOG_CONFIG\": \"(unset)\",\n+    \"JINA_LOG_LEVEL\": \"(unset)\",\n+    \"JINA_LOG_NO_COLOR\": \"(unset)\",\n+    \"JINA_MP_START_METHOD\": \"(unset)\",\n+    \"JINA_RANDOM_PORT_MAX\": \"(unset)\",\n+    \"JINA_RANDOM_PORT_MIN\": \"(unset)\"\n+  }\n+}\n ```\n-````\n \n+```{tip}\n+You can also use it to check Executor status, as Executor's communication protocol is gRPC.\n+```\n \n-````{admonition} See Also\n-:class: seealso\n+### Use HTTP/Websocket\n \n-For more details about the Jina GraphQL enpoint, see {ref}`here <flow-graphql>`.\n-````\n+When using HTTP or Websocket as the Gateway protocol, you can use curl to target the `/status` endpoint and get the Jina info.\n+\n+```shell\n+curl http://localhost:12345/status\n+```\n+\n+```json\n+{\"jina\":{\"jina\":\"######\",\"docarray\":\"######\",\"jina-proto\":\"######\",\"jina-vcs-tag\":\"(unset)\",\"protobuf\":\"######\",\"proto-backend\":\"######\",\"grpcio\":\"######\",\"pyyaml\":\"######\",\"python\":\"######\",\"platform\":\"######\",\"platform-release\":\"######\",\"platform-version\":\"######\",\"architecture\":\"######\",\"processor\":\"######\",\"uid\":\"######\",\"session-id\":\"######\",\"uptime\":\"######\",\"ci-vendor\":\"(unset)\"},\"envs\":{\"JINA_AUTH_TOKEN\":\"(unset)\",\"JINA_DEFAULT_HOST\":\"(unset)\",\"JINA_DEFAULT_TIMEOUT_CTRL\":\"(unset)\",\"JINA_DEFAULT_WORKSPACE_BASE\":\"######\",\"JINA_DEPLOYMENT_NAME\":\"(unset)\",\"JINA_DISABLE_UVLOOP\":\"(unset)\",\"JINA_EARLY_STOP\":\"(unset)\",\"JINA_FULL_CLI\":\"(unset)\",\"JINA_GATEWAY_IMAGE\":\"(unset)\",\"JINA_GRPC_RECV_BYTES\":\"(unset)\",\"JINA_GRPC_SEND_BYTES\":\"(unset)\",\"JINA_HUBBLE_REGISTRY\":\"(unset)\",\"JINA_HUB_CACHE_DIR\":\"(unset)\",\"JINA_HUB_NO_IMAGE_REBUILD\":\"(unset)\",\"JINA_HUB_ROOT\":\"(unset)\",\"JINA_LOG_CONFIG\":\"(unset)\",\"JINA_LOG_LEVEL\":\"(unset)\",\"JINA_LOG_NO_COLOR\":\"(unset)\",\"JINA_MP_START_METHOD\":\"(unset)\",\"JINA_RANDOM_PORT_MAX\":\"(unset)\",\"JINA_RANDOM_PORT_MIN\":\"(unset)\",\"JINA_DISABLE_HEALTHCHECK_LOGS\":\"(unset)\",\"JINA_LOCKS_ROOT\":\"(unset)\"}}\n+```\n \n \n-## Custom gRPC compression\n+## Add gRPC compression\n \n Communication between `Executors` inside a `Flow` is done via `grpc`. To optimize the performance and the bandwith of this connections,\n Jina allows the users to specify their (`compression`)[https://grpc.github.io/grpc/python/grpc.html#compression] by passing this `compression` argument to the Flow.\n@@ -325,6 +392,7 @@ f = Flow(compression='Gzip').add(...)\n ```\n \n (flow-tls)=\n+\n ## Enable TLS\n \n You can enable TLS encryption between your Flow's Gateway and a Client, for any of the protocols supported by Jina (HTTP, gRPC, and Websocket).\n@@ -399,7 +467,7 @@ with:\n ```\n ````\n \n-## Set timeouts for requests\n+## Set timeouts\n \n You can set timeouts for sending requests to the Executors within a Flow by passing the `timeout_send` parameter. The timeout is specified in milliseconds. By default, it is `None` and the timeout is disabled.\n \n@@ -412,6 +480,47 @@ with Flow(timeout_send=1000) as f:\n The example above limits every request to the Executors in the Flow to a timeout of 1 second.\n \n \n+## GraphQL support\n+\n+````{admonition} Caution\n+:class: caution\n+\n+GraphQL support is an optional feature that requires optional dependencies.\n+To install these, run `pip install jina[graphql]` or `pip install jina[all]`.\n+\n+Unfortunately, these dependencies are **not available through Conda**. You will have to use `pip` to be able to use GraphQL\n+feature.\n+````\n+\n+A Flow can optionally expose a [GraphQL](https://graphql.org/) endpoint, located at `/graphql`.\n+To enable this endpoint, all you need to do is set `expose_graphql_endpoint=True` on your HTTP Flow:\n+\n+\n+````{tab} Python\n+\n+```python\n+from jina import Flow\n+\n+f = Flow(protocol='http', expose_graphql_endpont=True)\n+```\n+````\n+\n+````{tab} YAML\n+```yaml\n+jtype: Flow\n+with:\n+  protocol: 'http'\n+  expose_graphql_endpont: True, \n+```\n+````\n+\n+\n+````{admonition} See Also\n+:class: seealso\n+\n+For more details about the Jina GraphQL enpoint, see {ref}`here <flow-graphql>`.\n+````\n+\n \n ## See further\n \n\n\n###\n\n", "completion": "chore(docs): fix gateway status"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -37,7 +37,7 @@ Applications built with Jina enjoy the following features out-of-the-box:\n \n \u2601\ufe0f **Cloud-native**\n   - Seamless Docker container integration: sharing, exploring, sandboxing, versioning and dependency control via [Jina Hub](https://hub.jina.ai).\n-  - Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n+  - Fast deployment to Kubernetes, Docker Compose and [Jina Cloud](https://docs.jina.ai/fundamentals/jcloud/).\n   - Full observability via Prometheus and Grafana.\n \n \ud83c\udf71 **Ecosystem**\n\n---\n file path A: docs/fundamentals/jcloud/basic.md | file path B: docs/fundamentals/jcloud/basic.md\n\n@@ -1,5 +1,9 @@\n # Basic\n \n+```{tip}\n+JCloud client is an opensource project. [Check here for its repository](https://github.com/jina-ai/jcloud). \n+```\n+\n ## Install\n \n ```bash\n\n\n###\n\n", "completion": "chore(docs): adding jcloud"}
{"prompt": " file path A: None | file path B: docs/fundamentals/jcloud/advanced.md\n\n@@ -0,0 +1,80 @@\n+# Advanced\n+\n+## Environment variables\n+\n+### A single YAML\n+\n+```bash\n+jc deploy flow.yml --env-file flow.env\n+```\n+\n+\n+### A project folder\n+\n+- You can include your environment variables in the `.env` file in the local project and JCloud will take care of managing them.\n+- You can optionally pass a `custom.env`.\n+  ```bash\n+  jc deploy ./hello --env-file ./hello/custom.env\n+  ```\n+\n+## Fine-grained `resources` request\n+\n+By default, `jcloud` allocates `100M` of RAM to each Executor. There might be cases where your Executor requires more memory. For example, DALLE-mini (generating image from text prompt) would need more than 100M to load the model. You can request higher memory for your Executor using `resources` arg while deploying the Flow (max 16G allowed per Executor).\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: dalle_mini\n+    uses: jinahub+docker://DalleMini\n+    jcloud:\n+      resources:\n+        memory: 8G\n+```\n+\n+### `spot` vs `on-demand` capacity\n+\n+For cost optimization, `jcloud` tries to deploy all Executors on `spot` capacity. These are ideal for stateless Executors, which can withstand interruptions & restarts. It is recommended to use `on-demand` capacity for stateful Executors (e.g.- indexers) though.\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: custom\n+    uses: jinahub+docker://CustomExecutor\n+    jcloud:\n+      capacity: on-demand\n+```\n+\n+## Deploy external executors\n+\n+You can also expose the Executors only by setting `expose_gateway` to `false`. Read more about [External Executors.](https://docs.jina.ai/how-to/external-executor/)\n+\n+```yaml\n+jtype: Flow\n+jcloud:\n+  expose_gateway: false\n+executors:\n+  - name: custom\n+    uses: jinahub+docker://CustomExecutor\n+```\n+\n+```{figure} external-executor.png\n+:width: 70%\n+```\n+\n+\n+Similarly, you can also deploy & expose multiple External Executors.\n+\n+```yaml\n+jtype: Flow\n+jcloud:\n+  expose_gateway: false\n+executors:\n+  - name: custom1\n+    uses: jinahub+docker://CustomExecutor1\n+  - name: custom2\n+    uses: jinahub+docker://CustomExecutor2\n+```\n+\n+```{figure} external-executors-multiple.png\n+:width: 70%\n+```\n\n---\n file path A: None | file path B: docs/fundamentals/jcloud/basic.md\n\n@@ -0,0 +1,182 @@\n+# Basic\n+\n+## Install\n+\n+```bash\n+pip install jcloud\n+jc -h\n+```\n+\n+In case `jc` is already occupied by another tool, please use `jcloud` instead. If your pip install doesn't register bash commands for you, you can run `python -m jcloud -h`.\n+\n+\n+## Login\n+\n+```bash\n+jc login\n+```\n+\n+You can use a Google/GitHub account to register and login. Without logging in, you can't do anything.\n+\n+## Deploy\n+\n+In Jina's idiom, a project is a [Flow](https://docs.jina.ai/fundamentals/flow/), which represents an end-to-end task such as indexing, searching or recommending. In this README, we will use \"project\" and \"Flow\" interchangeably.\n+\n+A Flow can have two types of file structure: a single YAML file or a project folder.\n+\n+### A single YAML file\n+\n+A self-contained YAML file, consisting of all configs at the [Flow](https://docs.jina.ai/fundamentals/flow/)-level and [Executor](https://docs.jina.ai/fundamentals/executor/)-level.\n+\n+> All Executors' `uses` must follow the format `jinahub+docker://MyExecutor` (from [Jina Hub](https://hub.jina.ai)) to avoid any local file dependencies.\n+\n+e.g.-\n+\n+```yaml\n+# flow.yml\n+jtype: Flow\n+executors:\n+  - name: sentencizer\n+    uses: jinahub+docker://Sentencizer\n+```\n+\n+To deploy,\n+\n+```bash\n+jc deploy flow.yml\n+```\n+\n+### A project folder\n+\n+Just like a regular Python project, you can have sub-folders of Executor implementations; and a `flow.yml` on the top-level to connect all Executors together.\n+\n+You can create an example local project using `jc new`. The default structure looks like:\n+\n+```\n+.\n+\u251c\u2500\u2500 .env\n+\u251c\u2500\u2500 executor1\n+\u2502   \u251c\u2500\u2500 config.yml\n+\u2502   \u251c\u2500\u2500 executor.py\n+\u2502   \u2514\u2500\u2500 requirements.txt\n+\u2514\u2500\u2500 flow.yml\n+```\n+\n+where,\n+\n+- `executor1` directory has all Executor related code/config. You can read the best practices for [file structures](https://docs.jina.ai/fundamentals/executor/repository-structure/). Multiple such Executor directories can be created.\n+- `flow.yml` Your Flow YAML.\n+- `.env` All environment variables used during deployment.\n+\n+To deploy,\n+\n+```bash\n+jc deploy ./hello\n+```\n+\n+\n+The Flow is successfully deployed when you see:\n+\n+```{figure} deploy.png\n+:width: 70%\n+```\n+\n+You will get a Flow ID, say `173503c192`. This ID is required to manage, view logs and remove the Flow.\n+\n+As this Flow is deployed with default gRPC gateway (feel free to change it to `http` or `websocket`), you can use `jina.Client` to access it:\n+\n+```python\n+from jina import Client, Document\n+\n+c = Client(host='https://173503c192.wolf.jina.ai')\n+print(c.post('/', Document(text='hello')))\n+```\n+\n+\n+\n+## View logs\n+\n+To watch the logs in realtime:\n+\n+```bash\n+jc logs 173503c192\n+```\n+\n+You can also stream logs for a particular Executor by passing its name:\n+\n+```bash\n+jc logs 173503c192 --executor sentencizer\n+```\n+\n+## Remove Flows\n+\n+You can either remove a single Flow, multiple selected Flows or even all Flows by passing different kind of identifiers.\n+\n+To remove a single Flow:\n+\n+```bash\n+jc remove 173503c192\n+```\n+\n+To remove multiple selected Flows:\n+\n+```bash\n+jc remove 173503c192 887f6313e5 ddb8a2c4ef\n+```\n+\n+To remove all Flows:\n+\n+```bash\n+jc remove all\n+```\n+\n+By default, removing multiple selected / all Flows would be in interactive mode where confirmation will be sent prior to\n+the deletion, to make it non-interactive to better suit your use case, set below environment variable before running the command:\n+\n+```bash\n+export JCLOUD_NO_INTERACTIVE=1\n+```\n+\n+## Get status\n+\n+```bash\n+jc status 173503c192\n+```\n+\n+```{figure} status.png\n+:width: 70%\n+```\n+\n+## List Flows\n+\n+```bash\n+jc list\n+```\n+\n+You can see the ALIVE Flows deployed by you.\n+\n+```{figure} list.png\n+:width: 70%\n+```\n+\n+\n+You can also filter your Flows by passing a status:\n+\n+```\n+jc list --status FAILED\n+```\n+\n+\n+```{figure} list_failed.png\n+:width: 70%\n+```\n+\n+Or see all the flows:\n+\n+```\n+jc list --status ALL\n+```\n+\n+```{figure} list_all.png\n+:width: 70%\n+```\n\n---\n file path A: docs/fundamentals/jcloud/deploy.png | file path B: docs/fundamentals/jcloud/deploy.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/deploy.png differ\n\n---\n file path A: docs/fundamentals/jcloud/external-executor.png | file path B: docs/fundamentals/jcloud/external-executor.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/external-executor.png differ\n\n---\n file path A: docs/fundamentals/jcloud/external-executors-multiple.png | file path B: docs/fundamentals/jcloud/external-executors-multiple.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/external-executors-multiple.png differ\n\n---\n file path A: None | file path B: docs/fundamentals/jcloud/faq.md\n\n@@ -0,0 +1,25 @@\n+# FAQ\n+\n+- **Why does it take a while on every operation of `jcloud`?**\n+\n+  Because the event listener at Jina Cloud is serverless by design, which means it spawns an instance on-demand to process your requests from `jcloud`. Note that operations such as `deploy`, `remove` in `jcloud` are not high-frequency. Hence, having a serverless listener is much more cost-efficient than an always-on listener. The downside is slower operations, nevertheless this does not affect the deployed service. Your deployed service is **always on**.\n+\n+- **How long do you persist my service?**\n+\n+  Forever. Until you manually `remove` it, we will persist your service as long as possible.\n+\n+- **Is everything free?**\n+\n+  Yes! We just need your feedback - use `jc survey` to help us understand your needs.\n+\n+- **How powerful is Jina Cloud?**\n+\n+  Jina Cloud scales according to your need. You can demand for the resources your Flow requires. If there's anything particular you'd be looking for, you can contact us [on Slack](https://slack.jina.ai) or let us know via `jc survey`.\n+\n+- **How can I enable verbose logs with `jcloud`?**\n+\n+  To make the output more verbose, you can add `--loglevel DEBUG` _before_ each CLI subcommand, e.g.\n+\n+  ```bash\n+  jc --loglevel DEBUG deploy toy.yml\n+  ```\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/fundamentals/jcloud/index.md\n\n@@ -0,0 +1,19 @@\n+# JCloud\n+\n+After you built a Jina project, the next step is to deploy and host it somewhere. JCloud simplifies deploying and hosting your Jina projects on Jina Cloud. It provides a simple CLI with five commands to manage the lifecycle of your Jina projects.\n+\n+Strictly speaking JCloud has two parts: the cloud part (i.e. Jina Cloud) and the client part. Specifically, using JCloud means deploying a Jina project with the client to the cloud. This chapter will guide you to use client.\n+\n+```{tip}\n+At this Jina Cloud hosts your Jina project and offers computational and storage resources **for free**!\n+```\n+\n+```{toctree}\n+:hidden:\n+\n+basic\n+advanced\n+faq\n+```\n+\n+\n\n---\n file path A: docs/fundamentals/jcloud/list.png | file path B: docs/fundamentals/jcloud/list.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/list.png differ\n\n---\n file path A: docs/fundamentals/jcloud/list_all.png | file path B: docs/fundamentals/jcloud/list_all.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/list_all.png differ\n\n---\n file path A: docs/fundamentals/jcloud/list_failed.png | file path B: docs/fundamentals/jcloud/list_failed.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/list_failed.png differ\n\n---\n file path A: docs/fundamentals/jcloud/status.png | file path B: docs/fundamentals/jcloud/status.png\n\nBinary files /dev/null and b/docs/fundamentals/jcloud/status.png differ\n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -51,6 +51,7 @@ fundamentals/flow/index\n fundamentals/gateway/index\n fundamentals/flow/client\n fundamentals/executor/hub/index\n+fundamentals/jcloud/index\n how-to/index\n ```\n \n\n---\n file path A: docs/proto/docs.md | file path B: docs/proto/docs.md\n\n@@ -12,6 +12,9 @@\n     - [DataRequestProto.DataContentProto](#jina-DataRequestProto-DataContentProto)\n     - [EndpointsProto](#jina-EndpointsProto)\n     - [HeaderProto](#jina-HeaderProto)\n+    - [JinaInfoProto](#jina-JinaInfoProto)\n+    - [JinaInfoProto.EnvsEntry](#jina-JinaInfoProto-EnvsEntry)\n+    - [JinaInfoProto.JinaEntry](#jina-JinaInfoProto-JinaEntry)\n     - [RelatedEntity](#jina-RelatedEntity)\n     - [RouteProto](#jina-RouteProto)\n     - [StatusProto](#jina-StatusProto)\n@@ -22,6 +25,7 @@\n     - [JinaDataRequestRPC](#jina-JinaDataRequestRPC)\n     - [JinaDiscoverEndpointsRPC](#jina-JinaDiscoverEndpointsRPC)\n     - [JinaGatewayDryRunRPC](#jina-JinaGatewayDryRunRPC)\n+    - [JinaInfoRPC](#jina-JinaInfoRPC)\n     - [JinaRPC](#jina-JinaRPC)\n     - [JinaSingleDataRequestRPC](#jina-JinaSingleDataRequestRPC)\n   \n@@ -150,6 +154,54 @@ Represents a Header.\n \n \n \n+<a name=\"jina-JinaInfoProto\"></a>\n+\n+### JinaInfoProto\n+\n+\n+\n+| Field | Type | Label | Description |\n+| ----- | ---- | ----- | ----------- |\n+| jina | [JinaInfoProto.JinaEntry](#jina-JinaInfoProto-JinaEntry) | repeated | information about the system running and package version information including jina |\n+| envs | [JinaInfoProto.EnvsEntry](#jina-JinaInfoProto-EnvsEntry) | repeated | the environment variable setting |\n+\n+\n+\n+\n+\n+\n+<a name=\"jina-JinaInfoProto-EnvsEntry\"></a>\n+\n+### JinaInfoProto.EnvsEntry\n+\n+\n+\n+| Field | Type | Label | Description |\n+| ----- | ---- | ----- | ----------- |\n+| key | [string](#string) |  |  |\n+| value | [string](#string) |  |  |\n+\n+\n+\n+\n+\n+\n+<a name=\"jina-JinaInfoProto-JinaEntry\"></a>\n+\n+### JinaInfoProto.JinaEntry\n+\n+\n+\n+| Field | Type | Label | Description |\n+| ----- | ---- | ----- | ----------- |\n+| key | [string](#string) |  |  |\n+| value | [string](#string) |  |  |\n+\n+\n+\n+\n+\n+\n <a name=\"jina-RelatedEntity\"></a>\n \n ### RelatedEntity\n@@ -272,6 +324,16 @@ jina gRPC service to expose Endpoints from Executors.\n | dry_run | [.google.protobuf.Empty](#google-protobuf-Empty) | [StatusProto](#jina-StatusProto) |  |\n \n \n+<a name=\"jina-JinaInfoRPC\"></a>\n+\n+### JinaInfoRPC\n+jina gRPC service to expose information about running jina version and environment.\n+\n+| Method Name | Request Type | Response Type | Description |\n+| ----------- | ------------ | ------------- | ------------|\n+| _status | [.google.protobuf.Empty](#google-protobuf-Empty) | [JinaInfoProto](#jina-JinaInfoProto) |  |\n+\n+\n <a name=\"jina-JinaRPC\"></a>\n \n ### JinaRPC\n\n\n###\n\n", "completion": "docs: adding jcloude"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -192,6 +192,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13958,3 +13959,35 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```330ddfcd```](https://github.com/jina-ai/jina/commit/330ddfcde0bad2bac71ea957785e34ec054cb4d2)] __-__ fix doc build (*Han Xiao*)\n  - [[```de25c2b8```](https://github.com/jina-ai/jina/commit/de25c2b88117bb51ab5d48739b8b1cc594aea025)] __-__ __version__: the next version will be 3.5.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-1></a>\n+## Release Note (`3.6.1`)\n+\n+> Release time: 2022-06-09 13:25:12\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Johannes Messner,  Zhaofeng Miao,  Ziniu Yu,  Han Xiao,  Jina Dev Bot,  samsja,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```cd88dace```](https://github.com/jina-ai/jina/commit/cd88dace09eabc9970b7c4bc73500a30f75cf07f)] __-__ add jina info service to all Runtimes (#4902) (*Joan Fontanals*)\n+ - [[```a697bdd9```](https://github.com/jina-ai/jina/commit/a697bdd9d0b521f47cead1b1637767deb404ca6b)] __-__ error handling for executor timeouts (#4899) (*Johannes Messner*)\n+ - [[```b174b5fb```](https://github.com/jina-ai/jina/commit/b174b5fb433aac81c71aef3069266710de80cf51)] __-__ add argument to control number of grpc retries (#4883) (*Johannes Messner*)\n+ - [[```6bf97eb4```](https://github.com/jina-ai/jina/commit/6bf97eb480694c8af78828d67594e24a4e007572)] __-__ avoid warning jcloud arg (#4896) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```e77b8020```](https://github.com/jina-ai/jina/commit/e77b80209dec60bc11787efeb14baa96c840e701)] __-__ __hub__: replace the fomula (#4905) (*Zhaofeng Miao*)\n+ - [[```35a0d78a```](https://github.com/jina-ai/jina/commit/35a0d78ae7dd9ae6e288b787408546a9bd40cc59)] __-__ correct header indention (#4904) (*Ziniu Yu*)\n+ - [[```d34f9161```](https://github.com/jina-ai/jina/commit/d34f9161337fef4f8b8bfc0b620ef0a863094ae5)] __-__ __monitor__: restructure monitor (#4903) (*Han Xiao*)\n+ - [[```17270e27```](https://github.com/jina-ai/jina/commit/17270e27289dd8c59969de1fe00301b6d098b6d8)] __-__ docs improvements (#4900) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```af6e8224```](https://github.com/jina-ai/jina/commit/af6e8224913899a7ea9d3ca7121142620eef33c7)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```efac46a2```](https://github.com/jina-ai/jina/commit/efac46a2ba5641c782eb5aeb62842ab592a18d94)] __-__ fix readme (*Han Xiao*)\n+ - [[```ba243383```](https://github.com/jina-ai/jina/commit/ba2433836a2dcf9c8df78b0ec6ee9038d8aae7bc)] __-__ remove pages from .github folder (#4898) (*Joan Fontanals*)\n+ - [[```c7a06cbd```](https://github.com/jina-ai/jina/commit/c7a06cbdf4453a2af018fb6cc03cea6277e21aef)] __-__ __version__: the next version will be 3.6.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.1'\n+__version__ = '3.6.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.2"}
{"prompt": " file path A: docs/fundamentals/flow/when-things-go-wrong.md | file path B: docs/fundamentals/flow/when-things-go-wrong.md\n\n@@ -23,8 +23,19 @@ In all cases, the {ref}`Jina Client <client>` will raise an Exception.\n \n When an {ref}`Executor or Head <architecture-overview>` can't be reached by the Flow's gateway, it attempts to re-connect\n to the faulty deployment according to a retry policy.\n+The same applies to calls to Executors that time out.\n The specifics of this policy depend on the environment the Flow find itself in, and are outlined below.\n \n+\n+````{admonition} Hint: Prevent Executor timeouts\n+:class: hint\n+If you regularly experience timouts on Executor calls, you may want to consider setting the Flow's `timeout_send` attribute to a larger value.\n+You can do this by setting `Flow(timeout_send=time_in_ms)` in Python\n+or `timeout_send: time_in_ms` in your Flow YAML with-block.\n+\n+Especially neural network forward passes on CPU (and other unusually expensive operations) can lead to timeouts with the default setting.\n+```\n+\n ````{admonition} Hint: Custom retry policy\n :class: hint\n You can override the default retry policy and instead choose a number of retries performed for each Executor.\n@@ -95,13 +106,21 @@ The resulting error message will contain the *network address* of the failing Ex\n If multiple replicas are present, all addresses will be reported - unless the Flow is deployed using Kubernetes, in which\n case the replicas are managed by k8s and only a single address is available.\n \n-Depending on the client-to-gateway protocol, the error message will be returned in one of the following ways:\n+Depending on the client-to-gateway protocol, and they type of error, the error message will be returned in one of the following ways:\n+\n+**Could not connect to Executor:**\n \n - **gRPC**: A response with the gRPC status code 14 (*UNAVAILABLE*) is issued, and the error message is contained in the `details` field\n - **HTTP**: A response with the HTTP status code 503 (*SERVICE_UNAVAILABLE*) is issued, and the error message is contained in `response['header']['status']['description']`\n - **WebSocket**: The stream closes with close code 1011 (*INTERNAL_ERROR*) and the message is contained in the WS close message\n \n-For any of these protocols, the {ref}`Jina Client <client>` will raise a `ConnectionError` containing the error message.\n+**Call to Executor timed out:**\n+\n+- **gRPC**: A response with the gRPC status code 4 (*DEADLINE_EXCEEDED*) is issued, and the error message is contained in the `details` field\n+- **HTTP**: A response with the HTTP status code 504 (*GATEWAY_TIMEOUT*) is issued, and the error message is contained in `response['header']['status']['description']`\n+- **WebSocket**: The stream closes with close code 1011 (*INTERNAL_ERROR*) and the message is contained in the WS close message\n+\n+For any of these scenarios, the {ref}`Jina Client <client>` will raise a `ConnectionError` containing the error message.\n \n ## Debug via breakpoint\n \n\n---\n file path A: jina/clients/base/grpc.py | file path B: jina/clients/base/grpc.py\n\n@@ -114,6 +114,11 @@ class GRPCBaseClient(BaseClient):\n                         f'{msg}\\nThe ongoing request is terminated as the server is not available or closed already.'\n                     )\n                     raise ConnectionError(my_details) from None\n+                elif my_code == grpc.StatusCode.DEADLINE_EXCEEDED:\n+                    self.logger.error(\n+                        f'{msg}\\nThe ongoing request is terminated due to a server-side timeout.'\n+                    )\n+                    raise ConnectionError(my_details) from None\n                 elif my_code == grpc.StatusCode.INTERNAL:\n                     self.logger.error(f'{msg}\\ninternal error on the server side')\n                     raise err\n\n---\n file path A: jina/clients/base/http.py | file path B: jina/clients/base/http.py\n\n@@ -24,7 +24,10 @@ class HTTPBaseClient(BaseClient):\n     def _handle_response_status(self, r_status, r_str, url):\n         if r_status == status.HTTP_404_NOT_FOUND:\n             raise BadClient(f'no such endpoint {url}')\n-        elif r_status == status.HTTP_503_SERVICE_UNAVAILABLE:\n+        elif (\n+            r_status == status.HTTP_503_SERVICE_UNAVAILABLE\n+            or r_status == status.HTTP_504_GATEWAY_TIMEOUT\n+        ):\n             if (\n                 'header' in r_str\n                 and 'status' in r_str['header']\n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -688,9 +688,13 @@ class GrpcConnectionPool:\n         if (\n             e.code() != grpc.StatusCode.UNAVAILABLE\n             and e.code() != grpc.StatusCode.CANCELLED\n+            and e.code() != grpc.StatusCode.DEADLINE_EXCEEDED\n         ):\n             raise\n-        elif e.code() == grpc.StatusCode.UNAVAILABLE and retry_i >= num_retries - 1:\n+        elif (\n+            e.code() == grpc.StatusCode.UNAVAILABLE\n+            or e.code() == grpc.StatusCode.DEADLINE_EXCEEDED\n+        ) and retry_i >= num_retries - 1:\n             self._logger.debug(f'GRPC call failed, retries exhausted')\n             from jina.excepts import InternalNetworkError\n \n\n---\n file path A: jina/serve/runtimes/gateway/graph/topology_graph.py | file path B: jina/serve/runtimes/gateway/graph/topology_graph.py\n\n@@ -67,7 +67,15 @@ class TopologyGraph:\n             if err_code == grpc.StatusCode.UNAVAILABLE:\n                 err._details = (\n                     err.details()\n-                    + f' |Gateway: Communication error with deployment {self.name} at address(es) {err.dest_addr}. Head or worker(s) may be down.'\n+                    + f' |Gateway: Communication error with deployment {self.name} at address(es) {err.dest_addr}. '\n+                    f'Head or worker(s) may be down.'\n+                )\n+                raise err\n+            elif err_code == grpc.StatusCode.DEADLINE_EXCEEDED:\n+                err._details = (\n+                    err.details()\n+                    + f'|Gateway: Connection with deployment {self.name} at address(es) {err.dest_addr} could be established, but timed out.'\n+                    f' You can increase the allowed time by setting `timeout_send` in your Flow YAML `with` block or Flow `__init__()` method.'\n                 )\n                 raise err\n             else:\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -108,6 +108,7 @@ def get_fastapi_app(\n             return {}\n \n         from docarray import DocumentArray\n+\n         from jina.proto import jina_pb2\n         from jina.serve.executors import __dry_run_endpoint__\n         from jina.serve.runtimes.gateway.http.models import PROTO_TO_PYDANTIC_MODELS\n@@ -204,7 +205,14 @@ def get_fastapi_app(\n                     request_generator(**req_generator_input)\n                 )\n             except InternalNetworkError as err:\n-                response.status_code = status.HTTP_503_SERVICE_UNAVAILABLE\n+                import grpc\n+\n+                if err.code() == grpc.StatusCode.UNAVAILABLE:\n+                    response.status_code = status.HTTP_503_SERVICE_UNAVAILABLE\n+                elif err.code() == grpc.StatusCode.DEADLINE_EXCEEDED:\n+                    response.status_code = status.HTTP_504_GATEWAY_TIMEOUT\n+                else:\n+                    response.status_code = status.HTTP_500_INTERNAL_SERVER_ERROR\n                 result = bd  # send back the request\n                 result['header'] = _generate_exception_header(\n                     err\n@@ -302,6 +310,7 @@ def get_fastapi_app(\n             from dataclasses import asdict\n \n             import strawberry\n+            from docarray import DocumentArray\n             from docarray.document.strawberry_type import (\n                 JSONScalar,\n                 StrawberryDocument,\n@@ -309,8 +318,6 @@ def get_fastapi_app(\n             )\n             from strawberry.fastapi import GraphQLRouter\n \n-            from docarray import DocumentArray\n-\n             async def get_docs_from_endpoint(\n                 data, target_executor, parameters, exec_endpoint\n             ):\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/app.py | file path B: jina/serve/runtimes/gateway/websocket/app.py\n\n@@ -2,6 +2,7 @@ import argparse\n from typing import TYPE_CHECKING, Any, AsyncIterator, Dict, List, Optional, Union\n \n from docarray import DocumentArray\n+\n from jina.clients.request import request_generator\n from jina.enums import DataInputType, WebsocketSubProtocols\n from jina.excepts import InternalNetworkError\n@@ -182,11 +183,20 @@ def get_fastapi_app(\n             async for msg in streamer.stream(request_iterator=req_iter()):\n                 await manager.send(websocket, msg)\n         except InternalNetworkError as err:\n+            import grpc\n+\n             manager.disconnect(websocket)\n+            fallback_msg = (\n+                f'Connection to deployment at {err.dest_addr} timed out. You can adjust `timeout_send` attribute.'\n+                if err.code() == grpc.StatusCode.DEADLINE_EXCEEDED\n+                else f'Network error while connecting to deployment at {err.dest_addr}. It may be down.'\n+            )\n             msg = (\n                 err.details()\n-                if _fits_ws_close_msg(err.details())  # some messages are too long\n-                else f'Network error while connecting to deployment at {err.dest_addr}. It may be down.'\n+                if _fits_ws_close_msg(\n+                    err.details()\n+                )  # some messages are too long for ws closing message\n+                else fallback_msg\n             )\n             await websocket.close(code=status.WS_1011_INTERNAL_ERROR, reason=msg)\n         except WebSocketDisconnect:\n@@ -205,6 +215,7 @@ def get_fastapi_app(\n             return request_dict\n \n     from docarray import DocumentArray\n+\n     from jina.proto import jina_pb2\n     from jina.serve.executors import __dry_run_endpoint__\n     from jina.serve.runtimes.gateway.http.models import PROTO_TO_PYDANTIC_MODELS\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -202,9 +202,15 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n         return await self.process_data([request], context)\n \n     def _handle_internalnetworkerror(self, err, context, response):\n-        context.set_details(\n-            f'|Head: Failed to connect to worker (Executor) pod at address {err.dest_addr}. It may be down.'\n-        )\n+        err_code = err.code()\n+        if err_code == grpc.StatusCode.UNAVAILABLE:\n+            context.set_details(\n+                f'|Head: Failed to connect to worker (Executor) pod at address {err.dest_addr}. It may be down.'\n+            )\n+        elif err_code == grpc.StatusCode.DEADLINE_EXCEEDED:\n+            context.set_details(\n+                f'|Head: Connection to worker (Executor) pod at address {err.dest_addr} could be established, but timed out.'\n+            )\n         context.set_code(err.code())\n         self.logger.error(f'Error while getting responses from Pods: {err.details()}')\n         if err.request_id:\n\n---\n file path A: None | file path B: tests/integration/gateway_clients/test_executor_timeout_failures.py\n\n@@ -0,0 +1,52 @@\n+import multiprocessing\n+import time\n+\n+import pytest\n+\n+from jina import Client, Document, Executor, Flow, requests\n+\n+\n+class SlowExecutor(Executor):\n+    @requests\n+    def foo(self, *args, **kwargs):\n+        time.sleep(0.2)\n+\n+\n+def _test_error(flow_kwargs, add_kwargs, error_port=None):\n+    f = Flow(**flow_kwargs).add(**add_kwargs)\n+    with f:\n+        with pytest.raises(ConnectionError) as err_info:\n+            f.index(inputs=[])\n+    if error_port:\n+        assert str(error_port) in err_info.value.args[0]\n+\n+\n+@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+def test_headless_exec_timeout(port_generator, protocol):\n+    exec_port = port_generator()\n+    flow_kwargs = {'timeout_send': 1, 'protocol': protocol}\n+    add_kwargs = {'uses': SlowExecutor, 'port': exec_port}\n+\n+    # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n+    p = multiprocessing.Process(\n+        target=_test_error, args=(flow_kwargs, add_kwargs, exec_port)\n+    )\n+    p.start()\n+    p.join()\n+    assert (\n+        p.exitcode == 0\n+    )  # if exitcode != 0 then test in other process did not pass and this should fail\n+\n+\n+@pytest.mark.parametrize('protocol', ['grpc', 'http', 'websocket'])\n+def test_headfull_exec_timeout(port_generator, protocol):\n+    flow_kwargs = {'timeout_send': 1, 'protocol': protocol}\n+    add_kwargs = {'uses': SlowExecutor, 'shards': 2}\n+\n+    # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n+    p = multiprocessing.Process(target=_test_error, args=(flow_kwargs, add_kwargs))\n+    p.start()\n+    p.join()\n+    assert (\n+        p.exitcode == 0\n+    )  # if exitcode != 0 then test in other process did not pass and this should fail\n\n\n###\n\n", "completion": "feat: error handling for executor timeouts (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/hub/index.md | file path B: docs/fundamentals/executor/hub/index.md\n\n@@ -42,7 +42,7 @@ A list of environment variables which takes effects during Jina Hub operations.\n \n ### `JINA_HUB_ROOT`\n \n-**Define the place where the Executor package cache lives.** Default value is `Path.home().joinpath('.jina', 'hub-packages')`\n+**Define the place where the Executor package cache lives.** Default value is `~/.jina/hub-packages`\n \n ````{admonition} Hint\n :class: hint\n@@ -51,7 +51,7 @@ You don't have permissions to create a directory in the home folder sometime. Th\n \n ### `JINA_HUB_CACHE_DIR`\n \n-**Define the place where the cache is stored during the downloading.** The cache will be deleted after finishing the download. Default value is `Path(os.environ.get('JINA_HUB_ROOT')).joinpath('.cache')`. By default, it will be a subfolder of `JINA_HUB_ROOT`. You can specify its value separately if you want.\n+**Define the place where the cache is stored during the downloading.** The cache will be deleted after downloading. Default value is `${JINA_HUB_ROOT}/.cache`.\n \n \n ```{toctree}\n\n\n###\n\n", "completion": "docs(hub): replace the fomula (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/yaml-spec.md | file path B: docs/fundamentals/flow/yaml-spec.md\n\n@@ -68,12 +68,12 @@ This means that the following variable substitutions are supported:\n \n Use `${{ ENV.VAR }}` to refer to the environment variable `VAR`.\n \n-## Context variables\n+### Context variables\n \n Use `${{ CONTEXT.VAR }}` to refer to the context variable `VAR`.\n Context variables can be passed to `f.load_config(..., context=...)` in the form of a Python dictionary.\n \n-## Relative paths\n+### Relative paths\n \n Use `${{root.path.to.var}}` to refer to the variable `var` within the same YAML file, found at the provided path in the file's structure.\n Note that the only difference between environment variable syntax and relative path syntax is the omission of spaces in the latter.\n\n\n###\n\n", "completion": "docs: correct header indention (#<issue-num>)"}
{"prompt": " file path A: docs/api.md | file path B: docs/api.md\n\n@@ -5,5 +5,5 @@ This section includes the API documentation from the `jina` codebase. These are\n ```{toctree}\n \n api/jina\n-api/cli\n+api/jina_cli\n ```\n\n---\n file path A: docs/fundamentals/executor/monitoring-executor.md | file path B: docs/fundamentals/executor/monitoring-executor.md\n\n@@ -1,6 +1,9 @@\n (monitoring-executor)=\n # Monitor\n \n+By default, every method which is decorated by the `@requests` decorator will be monitored, it will create a\n+[Prometheus Summary](https://prometheus.io/docs/concepts/metric_types/#summary) which will keep track of the time of \n+the execution of the method.\n \n This section documents the ability to add custom monitoring to the Executor with the Grafana/Prometheus.\n \n@@ -9,6 +12,8 @@ the full power of the [Prometheus Client](https://github.com/prometheus/client_p\n for each of your Executors. We provide a convenient wrapper as well, i.e `@monitor()`, which let you easily monitor\n sub-method of your Executor. \n \n+When the monitoring is enabled each Executor will expose its \n+own metrics. This means that in practice each of the Executors will expose a Prometheus endpoint using the [Prometheus Client](https://github.com/prometheus/client_python).\n \n ```{admonition} Full detail on monitoring\n :class: seealso\n@@ -16,12 +21,6 @@ This section describes how to define and use **custom** metrics. To use the defa\n please refer to {ref}`this <monitoring-flow>` section.\n ```\n \n-When the monitoring is enabled each Executor will expose its \n-own metrics. This means that in practice each of the Executors will expose a Prometheus endpoint using the [Prometheus Client](https://github.com/prometheus/client_python).\n-\n-By default, every method which is decorated by the `@requests` decorator will be monitored, it will create a\n-[Prometheus Summary](https://prometheus.io/docs/concepts/metric_types/#summary) which will keep track of the time of \n-the execution of the method.\n \n ## Define custom metrics\n \n@@ -33,12 +32,28 @@ image embedding. By using custom metrics on these two tasks you can identify pot\n \n Overall the ability to add custom metrics allows you to have the full flexibility on the monitoring of your Executor.\n \n-### Defining custom metrics with `@monitor`\n+### Use context manager\n \n-````{admonition} Using @monitor\n-:class: hint\n-Adding the custom monitoring on a method is as straightforward as decorating the method with `@monitor` \n-````\n+You can use `self.monitor` to monitor the internal blocks of your function:\n+\n+```python\n+from jina import Executor, requests\n+\n+\n+class MyExecutor(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        with self.monitor('processing_seconds', 'Time processing my document'):\n+            docs = process(docs)\n+        print(docs.texts)\n+        with self.monitor('update_seconds', 'Time updates my document'):\n+            docs = update(docs)\n+```\n+\n+\n+### Use `@monitor` decorator\n+\n+Adding the custom monitoring on a method is as straightforward as decorating the method with `@monitor`.\n \n ```python\n from jina import Executor, monitor\n@@ -64,30 +79,51 @@ def method(self):\n     ...\n ```\n \n-You can as well monitor internal part of your executor with a Context Manager:\n+````{admonition} respect Prometheus naming\n+:class: caution\n+You should respect Prometheus naming [conventions](https://prometheus.io/docs/practices/naming/#metric-names). \n+therefore because `@monitor` creates a [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) under the hood\n+your metrics name should finish with `seconds`\n+````\n \n-```python\n-from jina import Executor, requests\n+### Use Prometheus client\n \n+Under the hood, the monitoring feature of the Executor is handled by the \n+Python [Prometheus-client](https://github.com/prometheus/client_python). The `@monitor` decorator is a convenient tool\n+to monitor sub-methods of an Executor, but you might need more flexibility and that is why you can access the Prometheus\n+client directly from the Executor to define every kind of metric supported by Prometheus.\n \n-def process():\n-    ...\n+Let's see it in an example\n+\n+\n+```python\n+from jina import requests, Executor, DocumentArray\n+\n+from prometheus_client import Counter\n \n \n class MyExecutor(Executor):\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self.counter = Counter(\n+            name='my_count_total',\n+            documentation='my count',\n+            registry=self.runtime_args.metrics_registry,\n+        )\n+\n     @requests\n-    def foo(self, docs, **kwargs):\n-        with self.monitor('processing_seconds', 'Time processing my document'):\n-            docs = process(docs)\n+    def encode(self, docs: DocumentArray, **kwargs):\n+        self.counter.inc(len(docs))\n ```\n \n-````{admonition} respect Prometheus naming\n+This will create a Prometheus [Counter](https://prometheus.io/docs/concepts/metric_types/#counter). \n+\n+````{admonition} Directly using the Prometheus client\n :class: caution\n-You should respect Prometheus naming [conventions](https://prometheus.io/docs/practices/naming/#metric-names). \n-therefore because `@monitor` creates a [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) under the hood\n-your metrics name should finish with `seconds`\n+You need to pass the metrics registry from the Executor when creating custom metrics directly with the Prometheus client.\n ````\n \n+\n ## Example\n \n Let's take an example to illustrate custom metrics:\n@@ -164,43 +200,6 @@ class MyExecutor(Executor):\n ```\n ````\n \n-### Defining custom metrics directly with the Prometheus client\n-\n-Under the hood, the monitoring feature of the Executor is handled by the \n-Python [Prometheus-client](https://github.com/prometheus/client_python). The `@monitor` decorator is a convenient tool\n-to monitor sub-methods of an Executor, but you might need more flexibility and that is why you can access the Prometheus\n-client directly from the Executor to define every kind of metric supported by Prometheus.\n-\n-Let's see it in an example\n-\n-\n-```python\n-from jina import requests, Executor, DocumentArray\n-\n-from prometheus_client import Counter\n-\n-\n-class MyExecutor(Executor):\n-    def __init__(self, *args, **kwargs):\n-        super().__init__(*args, **kwargs)\n-        self.counter = Counter(\n-            name='my_count_total',\n-            documentation='my count',\n-            registry=self.runtime_args.metrics_registry,\n-        )\n-\n-    @requests\n-    def encode(self, docs: DocumentArray, **kwargs):\n-        self.counter.inc(len(docs))\n-```\n-\n-This will create a Prometheus [Counter](https://prometheus.io/docs/concepts/metric_types/#counter). \n-\n-````{admonition} Directly using the Prometheus client\n-:class: caution\n-You need to pass the metrics registry from the Executor when creating custom metrics directly with the Prometheus client.\n-````\n-\n \n ## See further\n \n\n\n###\n\n", "completion": "docs(monitor): restructure monitor (#<issue-num>)"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -18,7 +18,7 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a PoC into a production-ready service in just minutes. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n+Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a PoC into a production-ready service. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n <sub><sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup></sub>\n \n\n---\n file path A: docs/fundamentals/flow/health-check.md | file path B: docs/fundamentals/flow/health-check.md\n\n@@ -1,4 +1,4 @@\n-# Health & readiness check\n+# Readiness & health check\n Every Jina Flow consists of a {ref}`number of microservices <architecture-overview>`,\n each of which have to be healthy before the Flow is ready to receive requests.\n \n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -1,4 +1,4 @@\n-# Create New Project\n+# Create Project\n \n Let\u2019s write a small application with our new Jina development environment. To start, we'll use Jina CLI to make a new project for us. In your terminal of choice run:\n \n\n---\n file path A: docs/fundamentals/flow/health-check.md | file path B: docs/fundamentals/flow/health-check.md\n\n@@ -1,4 +1,4 @@\n-# Health and readiness check\n+# Health & readiness check\n Every Jina Flow consists of a {ref}`number of microservices <architecture-overview>`,\n each of which have to be healthy before the Flow is ready to receive requests.\n \n\n---\n file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -1,11 +1,13 @@\n (executor)=\n \n+\n+# Basic\n+\n+\n ```{tip}\n Executor uses `docarray.DocumentArray` as input and output data structure. Please first [read DocArray's docs](https://docarray.jina.ai) to get an impression how does it work.   \n ```\n \n-# Basic\n-\n {class}`~jina.Executor` is a self-contained component and performs a group of tasks on a `DocumentArray`. \n It encapsulates functions that process `DocumentArray`s. Inside the Executor, these functions are decorated with `@requests`. To create an Executor, you only need to follow three principles:\n \n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.12'\n+__version__ = '3.5.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -39,7 +39,6 @@ exclude_patterns = [\n     'tests',\n     'page_templates',\n     '.github',\n-    'api'\n ]\n pygments_style = 'rainbow_dash'\n html_theme = 'furo'\n\n---\n file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -1,5 +1,9 @@\n (executor)=\n \n+```{tip}\n+Executor uses `docarray.DocumentArray` as input and output data structure. Please first [read DocArray's docs](https://docarray.jina.ai) to get an impression how does it work.   \n+```\n+\n # Basic\n \n {class}`~jina.Executor` is a self-contained component and performs a group of tasks on a `DocumentArray`. \n\n---\n file path A: docs/fundamentals/clean-code.md | file path B: docs/fundamentals/clean-code.md\n\n@@ -6,8 +6,7 @@ tips to help you write beautiful and efficient code.\n ## Clean import\n \n ```python\n-from docarray import Document, DocumentArray\n-from jina import Executor, Flow, requests\n+from jina import Executor, Flow, requests, Document, DocumentArray\n ```\n is often all you need. Copy-paste it as the first line of your code.\n \n@@ -19,8 +18,8 @@ Use a [Python generator](https://docs.python.org/3/glossary.html#term-generator)\n ---\n emphasize-lines: 3, 4, 5\n ---\n-from docarray import Document\n-from jina import Flow\n+\n+from jina import Flow, Document\n \n def my_input():\n    for _ in range(1000):\n@@ -34,8 +33,7 @@ with f:\n \n ````{tab} \ud83d\ude14 Don't\n ```python\n-from docarray import Document, DocumentArray\n-from jina import Flow\n+from jina import Flow, Document, DocumentArray\n \n my_input = DocumentArray([Document() for _ in range(1000)])\n \n@@ -54,8 +52,8 @@ with f:\n ---\n emphasize-lines: 10\n ---\n-from docarray import Document\n-from jina import Flow\n+\n+from jina import Flow, Document\n \n def my_input():\n    for _ in range(1000):\n@@ -73,8 +71,8 @@ with f:\n ---\n emphasize-lines: 10\n ---\n-from docarray import Document\n-from jina import Flow\n+\n+from jina import Flow, Document\n \n def my_input():\n    for _ in range(1000):\n@@ -184,50 +182,6 @@ class MyExecutor(Executor):\n ```\n ````\n \n-(debug-executor)=\n-## Debug Executor outside of a Flow\n-\n-To debug an `Executor`, there is no need to use it in the Flow. Simply initiate it as an object and call its method.\n-````{tab} \u2705 Do\n-```python\n-from docarray import Document, DocumentArrayMemmap\n-from jina import Executor, requests\n-\n-\n-class MyExec(Executor):\n-    @requests\n-    def foo(self, docs, **kwargs):\n-        for d in docs:\n-            d.text = 'hello world'\n-\n-\n-m = MyExec()\n-da = DocumentArray([Document(text='test')])\n-m.foo(da)\n-print(da)\n-```\n-````\n-\n-````{tab} \ud83d\ude14 Don't\n-```python\n-from docarray import Document, DocumentArray\n-from jina import Executor, requests, Flow\n-\n-\n-class MyExec(Executor):\n-    @requests\n-    def foo(self, docs, **kwargs):\n-        for d in docs:\n-            d.text = 'hello world'\n-\n-\n-da = DocumentArray([Document(text='test')])\n-\n-with Flow().add(uses=MyExec) as f:\n-    f.post('/', da, on_done=print)\n-```\n-````\n-\n \n ## Send `parameters`-only request\n    \n@@ -371,6 +325,7 @@ class SecondExecutor(Executor):\n ````{tab} \ud83d\ude14 Don't\n \n ```python\n+\n from jina import Executor, requests\n \n class FirstExecutor(Executor):\n\n---\n file path A: docs/fundamentals/executor/monitoring-executor.md | file path B: docs/fundamentals/executor/monitoring-executor.md\n\n@@ -64,6 +64,23 @@ def method(self):\n     ...\n ```\n \n+You can as well monitor internal part of your executor with a Context Manager:\n+\n+```python\n+from jina import Executor, requests\n+\n+\n+def process():\n+    ...\n+\n+\n+class MyExecutor(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        with self.monitor('processing_seconds', 'Time processing my document'):\n+            docs = process(docs)\n+```\n+\n ````{admonition} respect Prometheus naming\n :class: caution\n You should respect Prometheus naming [conventions](https://prometheus.io/docs/practices/naming/#metric-names). \n@@ -98,11 +115,12 @@ The encode function is composed of two sub-functions.\n \n By default, only the `encode` function will be monitored. \n \n+````{tab} Decorator\n ```{code-block} python\n ---\n-emphasize-lines: 6, 10\n+emphasize-lines: 5, 9\n ---\n-from jina import requests,monitor, Executor, DocumentArray\n+from jina import requests, monitor, Executor, DocumentArray\n \n class MyExecutor(Executor):\n \n@@ -119,7 +137,32 @@ class MyExecutor(Executor):\n         docs.tensors = self.preprocessing(docs)\n         docs.embedding = self.model_inference(docs.tensors)\n ```\n+````\n+\n+````{tab} Context manager\n+\n+```{code-block} python\n+---\n+emphasize-lines: 13, 15\n+---\n+from jina import requests, Executor, DocumentArray\n+\n+def preprocessing(self, docs: DocumentArray):\n+    ...\n+\n+def model_inference(self, tensor):\n+    ...\n+\n+class MyExecutor(Executor):\n \n+    @requests\n+    def encode(self, docs: DocumentArray, **kwargs):\n+        with self.monitor('preprocessing_seconds', 'Time preprocessing the requests'):\n+            docs.tensors = preprocessing(docs)\n+        with self.monitor('model_inference_seconds', 'Time doing inference the requests'):\n+            docs.embedding = model_inference(docs.tensors)\n+```\n+````\n \n ### Defining custom metrics directly with the Prometheus client\n \n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -166,8 +166,7 @@ jina executor --uses my-exec.yml --port 12345\n Now that your Executor is up and running, we can tap into it just like before, and even use it from two different Flows.\n \n ```python\n-from jina import Flow\n-from docarray import Document, DocumentArray\n+from jina import Flow, Document, DocumentArray\n \n f1 = Flow().add(host='localhost', port=12345, external=True)\n f2 = Flow().add(host='localhost', port=12345, external=True)\n\n---\n file path A: docs/how-to/gpu-executor.md | file path B: docs/how-to/gpu-executor.md\n\n@@ -417,8 +417,8 @@ Here's how we need to modify our `main.py` script to use a GPU-base containerize\n ---\n emphasize-lines: 12\n ---\n-from docarray import Document, DocumentArray\n-from jina import Flow\n+\n+from jina import Flow, Document, DocumentArray\n \n from executor import SentenceEncoder\n \n\n---\n file path A: docs/how-to/monitoring.md | file path B: docs/how-to/monitoring.md\n\n@@ -167,8 +167,7 @@ You should query your Flow generate the first metrics. Othewise the dashboard wi\n You can query the flow by doing :\n \n ```python\n-from jina import Client\n-from docarray import DocumentArray\n+from jina import Client, DocumentArray\n \n client = Client(port=51000)\n client.index(inputs=DocumentArray.empty(size=4))\n\n---\n file path A: docs/how-to/sandbox.md | file path B: docs/how-to/sandbox.md\n\n@@ -14,8 +14,7 @@ Here is a graph to show the difference between using and not using Sandbox.\n ## Use\n \n ```python\n-from docarray import Document\n-from jina import Flow\n+from jina import Flow, Document\n \n f = Flow().add(uses='jinahub+sandbox://Hello')\n \n\n---\n file path A: docs/how-to/scale-out.md | file path B: docs/how-to/scale-out.md\n\n@@ -38,8 +38,7 @@ This could become a performance bottleneck to your search system.\n The Executor looks like this:\n \n ```python\n-from jina import Executor, requests\n-from docarray import Document\n+from jina import Executor, requests, Document\n \n from sklearn.feature_extraction.text import TfidfVectorizer\n from sklearn.datasets import fetch_20newsgroups\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -274,6 +274,20 @@ Behind this smooth experience is advanced management of Executors:\n \n ### Fast-lane to cloud-native\n \n+Using Kubernetes becomes easy:\n+\n+```bash\n+jina export kubernetes flow.yml ./my-k8s\n+kubectl apply -R -f my-k8s\n+```\n+\n+Using Docker Compose becomes easy:\n+\n+```bash\n+jina export docker-compose flow.yml docker-compose.yml\n+docker-compose up\n+```\n+\n Using Prometheus becomes easy:\n \n ```python\n@@ -297,21 +311,8 @@ Using Grafana becomes easy, just [download this JSON](https://github.com/jina-ai\n <a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/grafana.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"70%\"></a>\n </p>\n \n-Using Kubernetes becomes easy:\n-\n-```bash\n-jina export kubernetes flow.yml ./my-k8s\n-kubectl apply -R -f my-k8s\n-```\n-\n-Using Docker Compose becomes easy:\n-\n-```bash\n-jina export docker-compose flow.yml docker-compose.yml\n-docker-compose up\n-```\n \n-Which cloud-native technology is still challenging to you? [Tell us](https://github.com/jina-ai/jina/issues), we will handle the complexity and make it easy for you.\n+What cloud-native technology is still challenging to you? [Tell us](https://github.com/jina-ai/jina/issues), we will handle the complexity and make it easy for you.\n \n <!-- start support-pitch -->\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -294,7 +294,7 @@ class MyExec(Executor):\n Using Grafana becomes easy, just [download this JSON](https://github.com/jina-ai/example-grafana-prometheus/blob/main/grafana-dashboards/flow.json) and import it into Grafana:\n \n <p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/grafana.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"100%\"></a>\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/grafana.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"70%\"></a>\n </p>\n \n Using Kubernetes becomes easy:\n\n---\n file path A: .github/readme/grafana.png | file path B: .github/readme/grafana.png\n\nBinary files /dev/null and b/.github/readme/grafana.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -274,9 +274,44 @@ Behind this smooth experience is advanced management of Executors:\n \n ### Fast-lane to cloud-native\n \n-tba\n+Using Prometheus becomes easy:\n \n+```python\n+from jina import Executor, requests, DocumentArray\n+\n+\n+class MyExec(Executor):\n+    @requests\n+    def encode(self, docs: DocumentArray, **kwargs):\n+        with self.monitor('preprocessing_seconds', 'Time preprocessing the requests'):\n+            docs.tensors = preprocessing(docs)\n+        with self.monitor(\n+            'model_inference_seconds', 'Time doing inference the requests'\n+        ):\n+            docs.embedding = model_inference(docs.tensors)\n+```\n+\n+Using Grafana becomes easy, just [download this JSON](https://github.com/jina-ai/example-grafana-prometheus/blob/main/grafana-dashboards/flow.json) and import it into Grafana:\n+\n+<p align=\"center\">\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/grafana.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"100%\"></a>\n+</p>\n+\n+Using Kubernetes becomes easy:\n+\n+```bash\n+jina export kubernetes flow.yml ./my-k8s\n+kubectl apply -R -f my-k8s\n+```\n+\n+Using Docker Compose becomes easy:\n+\n+```bash\n+jina export docker-compose flow.yml docker-compose.yml\n+docker-compose up\n+```\n \n+Which cloud-native technology is still challenging to you? [Tell us](https://github.com/jina-ai/jina/issues), we will handle the complexity and make it easy for you.\n \n <!-- start support-pitch -->\n \n\n---\n file path A: .github/readme/scalability-banner.png | file path B: .github/readme/scalability-banner.png\n\nBinary files a/.github/readme/scalability-banner.png and b/.github/readme/scalability-banner.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -67,6 +67,7 @@ Document, Executor and Flow are three fundamental concepts in Jina.\n - [**Executor**](https://docs.jina.ai/fundamentals/executor/) is a group of functions with Documents as IO.\n - [**Flow**](https://docs.jina.ai/fundamentals/flow/) ties Executors together into a pipeline and exposes it with an API gateway.\n \n+---\n \n <p align=\"center\">\n <a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/no-complexity-banner.png?raw=true\" alt=\"Jina: No Infrastructure Complexity, High Engineering Efficiency\" width=\"100%\"></a>\n@@ -110,6 +111,8 @@ At the last line we see its output `['hello, world!hello, world!', 'hello, world\n \n While one could use standard Python with the same number of lines and get the same output, Jina accelerates time to market of your application by making it more scalable and cloud-native. Jina also handles the infrastructure complexity in production and other Day-2 operations so that you can focus on the data application itself.  \n \n+---\n+\n <p align=\"center\">\n <a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/scalability-banner.png?raw=true\" alt=\"Jina: Scalability and concurrency at ease\" width=\"100%\"></a>\n </p>\n@@ -228,7 +231,7 @@ executors:\n - The communication between clients and the API gateway is duplex.\n - The API gateway allows you to route request to a specific Executor while other parts of the Flow are still busy, via `.post(..., target_executor=...)`\n \n-\n+---\n \n <p align=\"center\">\n <a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/container-banner.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"100%\"></a>\n@@ -263,6 +266,7 @@ Behind this smooth experience is advanced management of Executors:\n - Automatically resolve version conflicts and dependencies;\n - Instant delivery of any Executor via Sandbox without pulling anything to local.\n \n+---\n \n <p align=\"center\">\n <a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/cloud-native-banner.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"100%\"></a>\n\n---\n file path A: .github/readme/cloud-native-banner.png | file path B: .github/readme/cloud-native-banner.png\n\nBinary files /dev/null and b/.github/readme/cloud-native-banner.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -264,6 +264,10 @@ Behind this smooth experience is advanced management of Executors:\n - Instant delivery of any Executor via Sandbox without pulling anything to local.\n \n \n+<p align=\"center\">\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/cloud-native-banner.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"100%\"></a>\n+</p>\n+\n ### Fast-lane to cloud-native\n \n tba\n\n---\n file path A: .github/readme/container-banner.png | file path B: .github/readme/container-banner.png\n\nBinary files a/.github/readme/container-banner.png and b/.github/readme/container-banner.png differ\n\n---\n file path A: .github/readme/container-banner.png | file path B: .github/readme/container-banner.png\n\nBinary files a/.github/readme/container-banner.png and b/.github/readme/container-banner.png differ\n\n---\n file path A: .github/readme/container-banner.png | file path B: .github/readme/container-banner.png\n\nBinary files /dev/null and b/.github/readme/container-banner.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -228,9 +228,15 @@ executors:\n - The communication between clients and the API gateway is duplex.\n - The API gateway allows you to route request to a specific Executor while other parts of the Flow are still busy, via `.post(..., target_executor=...)`\n \n-### Seamless Docker integration\n \n-Without having to worry about dependencies, you can easily share your Executors with others and use public/private Executors in your project thanks to [Jina Hub](https://hub.jina.ai).\n+\n+<p align=\"center\">\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/container-banner.png?raw=true\" alt=\"Jina: Seamless Container Integration\" width=\"100%\"></a>\n+</p>\n+\n+### Seamless Container integration\n+\n+Without having to worry about dependencies, you can easily share your Executors with others; or use public/private Executors in your project thanks to [Jina Hub](https://hub.jina.ai).\n \n To create an Executor:\n \n@@ -252,9 +258,10 @@ To use a Hub Executor in your Flow:\n | Python | `.add(uses='jinahub+docker://MyExecutor')` | `.add(uses='jinahub+sandbox://MyExecutor')` | `.add(uses='jinahub://MyExecutor')` |\n \n Behind this smooth experience is advanced management of Executors:\n-- Store, build and deploy Executors cost-efficiently;\n+- Automated builds on the cloud\n+- Store, deploy, and deliver Executors cost-efficiently;\n - Automatically resolve version conflicts and dependencies;\n-- Serverless sandbox allows one to immediately use an Executor on the cloud without pulling anything to local.\n+- Instant delivery of any Executor via Sandbox without pulling anything to local.\n \n \n ### Fast-lane to cloud-native\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -230,7 +230,32 @@ executors:\n \n ### Seamless Docker integration\n \n-tba\n+Without having to worry about dependencies, you can easily share your Executors with others and use public/private Executors in your project thanks to [Jina Hub](https://hub.jina.ai).\n+\n+To create an Executor:\n+\n+```bash\n+jina hub new \n+```\n+\n+To push it to Jina Hub:\n+\n+```bash\n+jina hub push .\n+```\n+\n+To use a Hub Executor in your Flow:\n+\n+|        | Docker container                           | Sandbox                                     | Source                              |\n+|--------|--------------------------------------------|---------------------------------------------|-------------------------------------|\n+| YAML   | `uses: jinahub+docker://MyExecutor`        | `uses: jinahub+sandbox://MyExecutor`        | `uses: jinahub://MyExecutor`        |\n+| Python | `.add(uses='jinahub+docker://MyExecutor')` | `.add(uses='jinahub+sandbox://MyExecutor')` | `.add(uses='jinahub://MyExecutor')` |\n+\n+Behind this smooth experience is advanced management of Executors:\n+- Store, build and deploy Executors cost-efficiently;\n+- Automatically resolve version conflicts and dependencies;\n+- Serverless sandbox allows one to immediately use an Executor on the cloud without pulling anything to local.\n+\n \n ### Fast-lane to cloud-native\n \n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -472,6 +472,7 @@ metas:\n     def _prettyprint_result(self, console, image):\n         # TODO: only support single executor now\n \n+        from rich import box\n         from rich.panel import Panel\n         from rich.table import Table\n \n@@ -480,15 +481,16 @@ metas:\n         visibility = image['visibility']\n         tag = self.args.tag[0] if self.args.tag else None\n \n-        table = Table.grid()\n-        table.add_column(width=20, no_wrap=True)\n-        table.add_column(style='cyan', no_wrap=True)\n+        table = Table(box=box.SIMPLE, show_header=False)\n+        table.add_column(no_wrap=True)\n+        table.add_column(no_wrap=True)\n+        if 'name' in image:\n+            table.add_row(':name_badge: Name', image['name'])\n+\n         table.add_row(\n             ':link: Hub URL',\n             f'[link=https://hub.jina.ai/executor/{uuid8}/]https://hub.jina.ai/executor/{uuid8}/[/link]',\n         )\n-        if 'name' in image:\n-            table.add_row(':name_badge: Name', image['name'])\n \n         if secret:\n             table.add_row(':lock: Secret', secret)\n@@ -520,48 +522,36 @@ metas:\n         return uuid8, secret\n \n     def _get_prettyprint_usage(self, console, executor_name, usage_kind=None):\n+        from rich import box\n         from rich.panel import Panel\n         from rich.syntax import Syntax\n+        from rich.table import Table\n \n-        flow_plain = f'''from jina import Flow\n-\n-f = Flow().add(uses='jinahub://{executor_name}')\n-'''\n-\n-        flow_docker = f'''from jina import Flow\n-\n-f = Flow().add(uses='jinahub+docker://{executor_name}')\n-'''\n+        param_str = Table(\n+            box=box.SIMPLE,\n+        )\n+        param_str.add_column('')\n+        param_str.add_column('YAML')\n+        param_str.add_column('Python')\n+        param_str.add_row(\n+            'Container',\n+            Syntax(f\"uses: jinahub+docker://{executor_name}\", 'yaml'),\n+            Syntax(f\".add(uses='jinahub+docker://{executor_name}')\", 'python'),\n+        )\n \n-        flow_sandbox = f'''from jina import Flow\n+        param_str.add_row(\n+            'Sandbox',\n+            Syntax(f\"uses: jinahub+sandbox://{executor_name}\", 'yaml'),\n+            Syntax(f\".add(uses='jinahub+sandbox://{executor_name}')\", 'python'),\n+        )\n \n-f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n-'''\n-        panels = [\n-            Panel(\n-                Syntax(\n-                    p[0],\n-                    'python',\n-                    theme='monokai',\n-                    word_wrap=True,\n-                ),\n-                title=p[1],\n-                width=80,\n-                expand=False,\n-            )\n-            for p in [\n-                (flow_plain, 'Use via source'),\n-                (flow_docker, 'Use in Docker'),\n-                (flow_sandbox, 'Use in Sandbox'),\n-            ]\n-        ]\n+        param_str.add_row(\n+            'Source',\n+            Syntax(f\"uses: jinahub://{executor_name}\", 'yaml'),\n+            Syntax(f\".add(uses='jinahub://{executor_name}')\", 'python'),\n+        )\n \n-        if usage_kind == 'docker':\n-            console.print(panels[1])\n-        elif usage_kind == 'source':\n-            console.print(panels[0])\n-        else:\n-            console.print(*reversed(panels))\n+        console.print(Panel(param_str, title='Usage', expand=False, width=100))\n \n     @staticmethod\n     @disk_cache_offline(cache_file=str(get_cache_db()))\n\n---\n file path A: .github/readme/scalability-banner.png | file path B: .github/readme/scalability-banner.png\n\nBinary files a/.github/readme/scalability-banner.png and b/.github/readme/scalability-banner.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -120,7 +120,7 @@ The example above can be refactored into a Python Executor file and a Flow YAML\n \n <table>\n <tr>\n-<th> toy.yml </th> \n+<th> <code>toy.yml</code> </th> \n <th> executor.py </th>\n </tr>\n <tr>\n@@ -186,7 +186,7 @@ This simple refactoring allows developers to write an application in the client-\n \n <table>\n <tr>\n-<th> toy.yml </th> \n+<th> <code>toy.yml</code> </th> \n <th> Flowchart </th>\n </tr>\n <tr>\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -173,6 +173,20 @@ jina flow --uses toy.yml\n \n The server is successfully started, and you can now use a client to query it.\n \n+```python\n+from jina import Client, Document\n+\n+c = Client(host='grpc://0.0.0.0:51000')\n+c.post('/', Document())\n+```\n+\n+This simple refactoring allows developers to write an application in the client-server style. The separation of Flow YAML and Executor Python file does not only make the project more maintainable but also brings scalability and concurrency to the next level:\n+- The data flow on the server is non-blocking and async. New request is handled immediately when an Executor is free, regardless if previous request is still being processed.\n+- Scalability can be easily achieved by setting `replicas: ` in YAML/Python. Load-balancing is automatically added to ensure the maximum throughput.\n+- You now have an API gateway that supports gRPC (default), Websockets, and HTTP protocols with TLS.\n+- The communication between clients and the API gateway is duplex.\n+- The API gateway allows you to route request to a specific Executor while other parts of the Flow are still busy, via `.post(..., target_executor=...)`\n+\n ### Seamless Docker integration\n \n tba\n\n---\n file path A: docs/fundamentals/architecture-overview.md | file path B: docs/fundamentals/architecture-overview.md\n\n@@ -1,8 +1,6 @@\n (architecture-overview)=\n # Architecture Overview\n \n-{ref}`Executor <executor>` and {ref}`Flow <flow>` are the two fundamental concepts in Jina. \n-\n The figure below shows details on how the Flow and Executor abstractions translate into concrete microservices, providing all the \n serving and scaling features of Jina.\n \n@@ -18,7 +16,7 @@ In fact, you might notice how some naming and concepts are inspired by the Kuber\n \n The following concepts may appear in the docs, but you don't need to master them as they are mainly designed for advanced or internal use:\n \n-  - **Gateway**: The Gateway is a service started by the Flow which is responsible for exposing the `HTTP`, `WebSocker` or `gRPC` endpoints to the client. It is the service that the clients of your app will actually talk to. Additionally, it keeps knowledge of the topology of the Flow to guarantee that the `Documents` are processed by the Executors in the proper order. It communicates with the Deployments via `gRPC`\n+  - **Gateway**: The Gateway is a service started by the Flow which is responsible for exposing the `HTTP`, `Websocket` or `gRPC` endpoints to the client. It is the service that the clients of your app will actually talk to. Additionally, it keeps knowledge of the topology of the Flow to guarantee that the `Documents` are processed by the Executors in the proper order. It communicates with the Deployments via `gRPC`.\n \n   - **Deployment**: Deployment is an abstraction around Executor that lets the `Gateway` communicate with an Executor. It encapsulates and abstracts internal replication details.\n \n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -58,19 +58,20 @@ class MyExecutor(Executor):\n             doc.tensor = torch.tensor(np.random.random([10, 2]))\n ```\n \n-## A small Jina application\n+## A dummy Jina application\n \n \n-Now let's write a small application with our new dependency. In our `app.py`, add the following code:\n+Now let's write a dummy application with our new dependency. In our `app.py`, add the following code:\n \n ```python\n from jina import Flow, Document\n \n f = Flow().add(uses='executor1/config.yml')\n \n-with f:\n-    da = f.post('/get-tensor', [Document(), Document()])\n-    print(da.tensors)\n+if __name__ == '__main__':\n+    with f:\n+        da = f.post('/get-tensor', [Document(), Document()])\n+        print(da.tensors)\n ```\n \n Once we save that, we can run our application by typing:\n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -39,13 +39,14 @@ Now that you\u2019re set up, let\u2019s dive into more of how Jina works and how to bu\n \n get-started/install/index\n get-started/create-app\n+fundamentals/architecture-overview\n ```\n \n ```{toctree}\n :caption: User Guides\n :hidden:\n \n-fundamentals/architecture-overview\n+\n fundamentals/executor/index\n fundamentals/flow/index\n fundamentals/clean-code\n\n---\n file path A: docs/get-started/migrate.md | file path B: docs/get-started/migrate.md\n\n@@ -1,4 +1,4 @@\n-# Migration to Jina 3\n+# Migrate Jina 2 to Jina 3\n \n Jina 3 comes with many improvements but to be able to enjoy them, you will also have to make some\n tweaks to your existing Jina 2 code.\n\n---\n file path A: docs/get-started/neural-search.md | file path B: None\n\n@@ -1,30 +0,0 @@\n-# What is Neural Search?\n-\n-The core idea of neural search is to leverage state-of-the-art deep neural networks to build *every* component of a search system. In short, **neural search is deep neural network-powered information retrieval.** In academia, it's often called *neural information retrieval*, but we think the phrase is too wordy so we coined it as neural search [back in 2019](https://hanxiao.io/2019/07/29/Generic-Neural-Elastic-Search-From-bert-as-service-and-Go-Way-Beyond/).\n-\n-## What can it do?\n-\n-Thanks to recent advances in deep neural networks, a neural search system can go way beyond simple text search. It enables advanced intelligence on all kinds of unstructured data, such as **images**, **audio**, **video**, **PDF**, **3D mesh**, **you name it**.\n-\n-For example, retrieving animation according to some beats; finding the best-fit memes according to some jokes; scanning a table with your iPhone's LiDAR camera and finding similar furniture at IKEA. Neural search systems enable what traditional search can't: multi/cross-modal data retrieval.\n-\n-## Think outside the (search) box\n-\n-Many neural search-powered applications do not have a search box: \n-\n-- A **question-answering chatbot** can be powered by neural search: by first indexing all hard-coded QA pairs and then semantically mapping user dialog to those pairs. \n-- A **smart speaker** can be powered by neural search: by applying STT (speech-to-text) and semantically mapping text to internal commands.\n-- A **recommendation system** can be powered by neural search: by embedding user-item information into vectors and finding top-K nearest neighbours of a user/item.\n-\n-Neural search creates a new way to comprehend the world. It is creating new doors that lead to new businesses. \n-\n-## Seize tomorrow today\n-\n-Has neural search been solved and is it widely applicable? Not quite yet - but we're working on it. Compared to traditional symbolic search,\n-building a neural search system can seem daunting for the following reasons:\n-- takes much more time to develop due to the complexity of AI and system engineering;\n-- suffers from a fragmented tech stack and [glue code](https://en.wikipedia.org/wiki/Glue_code);\n-- is computationally demanding and can be very inefficient;\n-- is hard to sustain when facing the accelerated innovation in deep learning.\n-\n-[That's why we built Jina](https://github.com/jina-ai/jina), an easier way to build scalable and sustainable neural search systems on the cloud.\n\n---\n file path A: docs/get-started/what-is-jina.md | file path B: None\n\n@@ -1,66 +0,0 @@\n-# What is Jina?\n-\n-Jina is a neural search framework written in Python that helps developers build neural search applications that can be easily scaled and deployed in the Cloud.\n-\n-\n-\n-Jina empowers developers to focus on their business logic, by guiding them with abstractions that will help to modularize, serve and scale applications in the cloud.\n-\n-Jina can help you in every phase of the development cycle, from prototyping to deployment. It is designed to provide a unified experience when developing your solutions locally and in the cloud. It builds your applications with a set of separate microservices that can be scaled independently and easily.\n-\n-As part of [Jina AI ecosystem](https://jina.ai/), Jina brings your search to production. [**DocArray**](https://docarray.jina.ai/) to serve as the main data structure; [**Jina Hub**](https://hub.jina.ai/) to share, containerize and reuse components of the search pipelines.\n-\n-\n-\n-## Design \n-\n-Jina is designed as a lean and easy-to-use framework. There are only two main concepts to learn:\n-\n-- {ref}`Executor <executor-cookbook>` is a self-contained component and performs a group of tasks on [Documents](https://docarray.jina.ai/).\n-- {ref}`Flow <flow-cookbook>` ties Executors together into a processing pipeline, provides scalability and facilitates deployments in the cloud.\n-\n-\n-# Comparing to Alternatives\n-\n-Sometimes the question arises of how Jina compares to different libraries and frameworks. Here we want to shed light on some of the\n-most commonly-drawn comparisons:\n-\n-## Comparing to MLOps frameworks\n-\n-At first glance, Jina and MLOps frameworks such as **MLFlow**, **KubeFlow** or **RayWorkflow** may seem quite similar:\n-They all have complex pipelines, or *Flows*, through which data can be processed.\n-At closer inspection, though, standard MLOps frameworks are quite different from Jina, because they were *designed with\n-a different purpose in mind*.\n-\n-Usually, MLOps frameworks are geared towards scheduling and operating individual jobs relating to training,\n-hyperparameter tuning, and other machine learning tasks.\n-These jobs are commonly very time-consuming, and create artifacts which trigger events.\n-\n-In contrast, Jina is a tool to *build and serve neural search applications as microservices*.\n-Microservices communicate through the network in a *streaming* fashion: Every microservice (called **Executor**) in a\n-**Flow** constantly receives and continuously processes data, in the form of **Documents**.\n-\n-## Comparing to model serving frameworks\n-\n-Jina's ability to scale and replicate its *Executor* microservices might sound reminiscent of model serving frameworks\n-such as **Seldon Core**.\n-\n-Seldon is designed to serve and expose machine learning models of different kinds, such as classifiers, regressors and others.\n-This is done by deploying model artifacts from different ML frameworks in predefined ways.\n-\n-Jina, on the other hand, is built from the ground up for *end-to-end neural search applications*, and brings along an\n-entire neural search ecosystem, including [DocArray](https://docarray.jina.ai/) and [Finetuner](https://finetuner.jina.ai/).\n-Furthermore, Jina gives *all the power to the user*, letting them define their own logic, in a Pythonic way.\n-\n-## Comparing to vector databases\n-\n-Another natural comparison within the neural search ecosystem is between Jina and vector databases.\n-\n-The main distinction is the following: Jina is **not** a vector database. \n-\n-Jina is a *neural search framework* to build complete *end-to-end search applications*.\n-With the power of *DocumentArray* and *Executors*, Jina allows the user to integrate external vector databases into a\n-complete search application.\n- \n-In summary, Jina takes care of the complete neural search pipeline and lets users integrate their own custom logic\n-and persistence layer into their applications.\n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -7,35 +7,23 @@\n \n ## Install\n \n-1. Make sure that you have Python 3.7+ installed on Linux/MacOS/{ref}`Windows <jina-on-windows>`.\n-\n-    ````{tab} via PyPI\n-    ```shell\n-    pip install -U jina\n-    ```\n-    ````\n-    ````{tab} via Conda\n-    ```shell\n-    conda install jina -c conda-forge\n-    ```\n-    ````\n-    ````{tab} via Docker\n-    ```shell\n-    docker pull jinaai/jina:latest\n-    ```\n-    ````\n-\n-2. That\u2019s it!\n-   ````{tab} Run natively\n-   ```shell\n-   jina -v\n-   ```\n-   ````\n-   ````{tab} Run in Docker\n-   ```shell\n-   docker run jinaai/jina:latest -v\n-   ```\n-   ````\n+Make sure that you have Python 3.7+ installed on Linux/MacOS/{ref}`Windows <jina-on-windows>`.\n+\n+````{tab} via PyPI\n+```shell\n+pip install -U jina\n+```\n+````\n+````{tab} via Conda\n+```shell\n+conda install jina -c conda-forge\n+```\n+````\n+````{tab} via Docker\n+```shell\n+docker pull jinaai/jina:latest\n+```\n+````\n \n Now that you\u2019re set up, let\u2019s dive into more of how Jina works and how to build great apps.\n \n@@ -46,11 +34,9 @@ Now that you\u2019re set up, let\u2019s dive into more of how Jina works and how to bu\n ```\n \n ```{toctree}\n-:caption: Get started\n+:caption: Get Started\n :hidden:\n \n-get-started/neural-search\n-get-started/what-is-jina\n get-started/install/index\n get-started/create-app\n ```\n@@ -74,14 +60,21 @@ how-to/executor\n \n \n ```{toctree}\n-:caption: Developer Reference\n+:caption: Developer References\n :hidden:\n :maxdepth: 1\n \n-get-started/migrate\n api\n cli/index\n proto/docs\n+```\n+\n+```{toctree}\n+:caption: Legacy Support\n+:hidden:\n+:maxdepth: 1\n+\n+get-started/migrate\n Jina 2 Documentation <https://docs2.jina.ai/>\n ```\n \n\n---\n file path A: jina/serve/runtimes/base.py | file path B: jina/serve/runtimes/base.py\n\n@@ -5,16 +5,17 @@ from jina.logging.logger import JinaLogger\n \n \n class BaseRuntime:\n-    \"\"\"A Jina Runtime is a procedure that blocks the main process once running (i.e. :meth:`run_forever`),\n+    \"\"\"\n+    A Jina Runtime is a procedure that blocks the main process once running (i.e. :meth:`run_forever`),\n     therefore should be put into a separated thread/process, or inside the main process of a docker container.\n-     Any program/library/package/module that blocks the main process, can be formulated into a :class:`BaseRuntime` class\n-     and then be started from a :class:`Pod`.\n+    Any program/library/package/module that blocks the main process, can be formulated into a :class:`BaseRuntime` class\n+    and then be started from a :class:`Pod`.\n \n-     In the sequel, we call the main process/thread as ``M``, the process/thread blocked :class:`Runtime` as ``S``.\n+    In the sequel, we call the main process/thread as ``M``, the process/thread blocked :class:`Runtime` as ``S``.\n \n-     In Jina, a :class:`Pod` object is used to manage a :class:`Runtime` object's lifecycle. A :class:`Pod`\n-     acts as a :class:`multiprocessing.Process` or :class:`threading.Thread`, it starts from ``M`` and once the\n-     ``S`` is spawned, it uses :class:`Runtime` as a context manager:\n+    In Jina, a :class:`Pod` object is used to manage a :class:`Runtime` object's lifecycle. A :class:`Pod`\n+    acts as a :class:`multiprocessing.Process` or :class:`threading.Thread`, it starts from ``M`` and once the\n+    ``S`` is spawned, it uses :class:`Runtime` as a context manager:\n \n         0. :meth:`__init__`\n \n@@ -26,16 +27,16 @@ class BaseRuntime:\n         3. When an error occurs during `run_forever` or `cancel` signal is reached by the `runtime`. The `run_forever` method is cancelled and\n         the managed context is closed. The `__exit__` of `Runtime` guarantees that the `Runtime` is properly shut by calling `teardown`.\n \n-     The :meth:`__init__` and :meth:`teardown` pair together, which defines instructions that will be executed before\n-     and after. In subclasses, `teardown` is optional.\n+    The :meth:`__init__` and :meth:`teardown` pair together, which defines instructions that will be executed before\n+    and after. In subclasses, `teardown` is optional.\n \n-     In order to cancel the `run_forever` method of a `Runtime`, you can use their `static` `cancel` method that will make sure that the runtime is properly cancelled.\n+    In order to cancel the `run_forever` method of a `Runtime`, you can use their `static` `cancel` method that will make sure that the runtime is properly cancelled.\n \n-        - Use :class:`threading.Event` or `multiprocessing.Event`, while :meth:`run_forever` polls for this event\n-        - Use :class:`GrpcConnectionPool` to send a TERMINATE message, while :meth:`run_forever` polls for this message\n+    - Use :class:`threading.Event` or `multiprocessing.Event`, while :meth:`run_forever` polls for this event\n+    - Use :class:`GrpcConnectionPool` to send a TERMINATE message, while :meth:`run_forever` polls for this message\n \n-     Note, another way to jump out from :meth:`run_forever` is raise exceptions from it. This will immediately move to\n-     :meth:`teardown`.\n+    Note, another way to jump out from :meth:`run_forever` is raise exceptions from it. This will immediately move to\n+    :meth:`teardown`.\n \n      .. note::\n         Rule of thumb on exception handling: if you are not sure if you should handle exception inside\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -171,7 +171,7 @@ jina flow --uses toy.yml\n <a href=\"#\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/flow-block.png?raw=true\" alt=\"Running a simple hello-world program\" width=\"50%\"></a>\n </p>\n \n-The service is successfully started, and you can now use a client to query it.\n+The server is successfully started, and you can now use a client to query it.\n \n ### Seamless Docker integration\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -168,11 +168,10 @@ jina flow --uses toy.yml\n ```\n \n <p align=\"center\">\n-<a href=\"#\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/flow-block.png?raw=true\" alt=\"Running a simple hello-world program\" width=\"60%\"></a>\n+<a href=\"#\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/flow-block.png?raw=true\" alt=\"Running a simple hello-world program\" width=\"50%\"></a>\n </p>\n \n-\n-tba\n+The service is successfully started, and you can now use a client to query it.\n \n ### Seamless Docker integration\n \n\n---\n file path A: .github/readme/flow-block.png | file path B: .github/readme/flow-block.png\n\nBinary files /dev/null and b/.github/readme/flow-block.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -116,6 +116,62 @@ While one could use standard Python with the same number of lines and get the sa\n \n ### Scalability and concurrency at ease\n \n+The example above can be refactored into a Python Executor file and a Flow YAML file:\n+\n+<table>\n+<tr>\n+<th> toy.yml </th> \n+<th> executor.py </th>\n+</tr>\n+<tr>\n+<td> \n+\n+```yaml\n+jtype: Flow\n+with:\n+  port: 51000\n+  protocol: grpc\n+executors:\n+- uses: MyExec\n+  name: e1\n+  py_modules:\n+    - executor.py\n+- uses: MyExec\n+  name: e2\n+  py_modules:\n+    - executor.py\n+```\n+     \n+</td>\n+<td>\n+\n+```python\n+from jina import DocumentArray, Executor, requests\n+\n+\n+class MyExec(Executor):\n+    @requests\n+    async def foo(self, docs: DocumentArray, **kwargs):\n+        for d in docs:\n+            d.text += 'hello, world!'\n+```\n+\n+</td>\n+</tr>\n+</table>\n+\n+\n+Run the following command in the terminal:\n+\n+```bash\n+jina flow --uses toy.yml\n+```\n+\n+<p align=\"center\">\n+<a href=\"#\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/flow-block.png?raw=true\" alt=\"Running a simple hello-world program\" width=\"60%\"></a>\n+</p>\n+\n+\n tba\n \n ### Seamless Docker integration\n\n---\n file path A: .github/readme/scalability-banner.png | file path B: .github/readme/scalability-banner.png\n\nBinary files /dev/null and b/.github/readme/scalability-banner.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -110,6 +110,10 @@ At the last line we see its output `['hello, world!hello, world!', 'hello, world\n \n While one could use standard Python with the same number of lines and get the same output, Jina accelerates time to market of your application by making it more scalable and cloud-native. Jina also handles the infrastructure complexity in production and other Day-2 operations so that you can focus on the data application itself.  \n \n+<p align=\"center\">\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/scalability-banner.png?raw=true\" alt=\"Jina: Scalability and concurrency at ease\" width=\"100%\"></a>\n+</p>\n+\n ### Scalability and concurrency at ease\n \n tba\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -118,7 +118,7 @@ tba\n \n tba\n \n-### Easy deployment to the cloud\n+### Fast-lane to cloud-native\n \n tba\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -112,10 +112,15 @@ While one could use standard Python with the same number of lines and get the sa\n \n ### Scalability and concurrency at ease\n \n+tba\n+\n ### Seamless Docker integration\n \n+tba\n+\n ### Easy deployment to the cloud\n \n+tba\n \n \n \n@@ -123,14 +128,11 @@ While one could use standard Python with the same number of lines and get the sa\n \n ## Support\n \n-- Check out the [Learning Bootcamp](https://learn.jina.ai) to get started with Jina.\n-- Join our [Slack community](https://slack.jina.ai) to chat to our engineers about your use cases, questions, and support queries.\n-- Join our [Engineering All Hands](https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne) meet-up to\n-  discuss your use case and learn Jina's new features.\n+- Join our [Slack community](https://slack.jina.ai) and chat with other community members about ideas.\n+- Join our [Engineering All Hands](https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne) meet-up to discuss your use case and learn Jina's new features.\n     - **When?** The second Tuesday of every month\n     - **Where?**\n-      Zoom ([see our public calendar](https://calendar.google.com/calendar/embed?src=c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com&ctz=Europe%2FBerlin)/[.ical](https://calendar.google.com/calendar/ical/c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com/public/basic.ics)/[Meetup\n-      group](https://www.meetup.com/jina-community-meetup/))\n+      Zoom ([see our public events calendar](https://calendar.google.com/calendar/embed?src=c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com&ctz=Europe%2FBerlin)/[.ical](https://calendar.google.com/calendar/ical/c_1t5ogfp2d45v8fit981j08mcm4%40group.calendar.google.com/public/basic.ics))\n       and [live stream on YouTube](https://youtube.com/c/jina-ai)\n - Subscribe to the latest video tutorials on our [YouTube channel](https://youtube.com/c/jina-ai)\n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -110,136 +110,12 @@ At the last line we see its output `['hello, world!hello, world!', 'hello, world\n \n While one could use standard Python with the same number of lines and get the same output, Jina accelerates time to market of your application by making it more scalable and cloud-native. Jina also handles the infrastructure complexity in production and other Day-2 operations so that you can focus on the data application itself.  \n \n-\n+### Scalability and concurrency at ease\n \n ### Seamless Docker integration\n \n-You can containerize the Executors and use them in a sandbox thanks to [Hub](https://hub.jina.ai).\n-\n-1. Move each `Executor` class to a separate folder with one Python file in each:\n-   - `PreprocImg` -> \ud83d\udcc1 `preproc_img/exec.py`\n-   - `EmbedImg` -> \ud83d\udcc1 `embed_img/exec.py`\n-   - `MatchImg` -> \ud83d\udcc1 `match_img/exec.py`\n-2. Create a `requirements.txt` in `embed_img` as it requires `torchvision`.\n-\n-    ```text\n-    .\n-    \u251c\u2500\u2500 embed_img\n-    \u2502     \u251c\u2500\u2500 exec.py  # copy-paste codes of ImageEmbeddingExecutor\n-    \u2502     \u2514\u2500\u2500 requirements.txt  # add the requirement `torchvision`\n-    \u2514\u2500\u2500 match_img\n-          \u2514\u2500\u2500 exec.py  # copy-paste codes of IndexExecutor\n-    \u2514\u2500\u2500 preproc_img\n-          \u2514\u2500\u2500 exec.py  # copy-paste codes of IndexExecutor\n-    ```\n-3. Push all Executors to the [Hub](https://hub.jina.ai):\n-    ```bash\n-    jina hub push preproc_img\n-    jina hub push embed_img\n-    jina hub push match_img\n-    ```\n-   You will get three Hub Executors that can be used via Sandbox, Docker container or source code. \n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-hub-push.png?raw=true\" alt=\"Jina hub push gives you the sandbox\" width=\"70%\"></a>\n-</p>\n-\n-4. In particular, Sandbox hosts your Executor on Jina Cloud and allows you to use it from your local machine:\n-    ```python\n-    from docarray import DocumentArray\n-    from jina import Flow\n-\n-    index_data = DocumentArray.pull(\n-        'demo-leftda', show_progress=True\n-    )  # Download the dataset as shown in the tutorial above\n-\n-    f = Flow().add(uses='jinahub+sandbox://2k7gsejl')\n-\n-    with f:\n-        print(f.post('/', index_data[:10]))\n-    ```\n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img alt=\"Shell outputs running docker-compose\" src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-sandbox-play.png?raw=ture\" title=\"outputs of docker-compose\" width=\"90%\"></a>\n-</p>\n-\n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-banner3.svg?raw=true\" alt=\"Containerize, share and play in one-place like a pro\" width=\"100%\"></a>\n-</p>\n-\n-\n-### Deploy the service via Docker Compose\n+### Easy deployment to the cloud\n \n-1. Now that all Executors are in containers, we can easily use Docker Compose to orchestrate the Flow:\n-\n-    ```python\n-    f = (\n-        Flow(port=12345)\n-        .add(uses='jinahub+docker://1ylut0gf')\n-        .add(uses='jinahub+docker://258lzh3c')\n-    )\n-    f.to_docker_compose_yaml()  # By default, stored at `docker-compose.yml`\n-    ```\n-\n-2. Now in the console run:\n-\n-    ```shell\n-    docker-compose up\n-    ```\n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img alt=\"Shell outputs running docker-compose\" src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-docker-compose.png?raw=ture\" title=\"She;; outputs of docker-compose\"  width=\"85%\"></a>\n-</p>\n-\n-### Deploy the service via Kubernetes\n-\n-1. Create a Kubernetes cluster and get credentials (example in GCP, [more K8s providers here](https://docs.jina.ai/advanced/experimental/kubernetes/#preliminaries)):\n-    ```bash\n-    gcloud container clusters create test --machine-type e2-highmem-2  --num-nodes 1 --zone europe-west3-a\n-    gcloud container clusters get-credentials test --zone europe-west3-a --project jina-showcase\n-    ```\n-\n-2. Create a namespace `flow-k8s-namespace` for demonstration purpose:\n-    ```bash\n-    kubectl create namespace flow-k8s-namespace\n-    ```\n-\n-3. Generate the kubernetes configuration files using one line of code:\n-    ```python\n-    f.to_kubernetes_yaml('./k8s_config', k8s_namespace='flow-k8s-namespace')\n-    ```\n-    \n-4. Your `k8s_config` folder will look like the following:\n-    ```shell\n-    k8s_config\n-    \u251c\u2500\u2500 executor0\n-    \u2502     \u251c\u2500\u2500 executor0-head.yml\n-    \u2502     \u2514\u2500\u2500 executor0.yml\n-    \u251c\u2500\u2500 executor1\n-    \u2502     \u251c\u2500\u2500 executor1-head.yml\n-    \u2502     \u2514\u2500\u2500 executor1.yml\n-    \u2514\u2500\u2500 gateway\n-          \u2514\u2500\u2500 gateway.yml\n-    ```\n-\n-5. Use `kubectl` to deploy your neural search application: \n-\n-    ```shell\n-    kubectl apply -R -f ./k8s_config\n-    ```\n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img alt=\"Shell outputs running k8s\" src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-k8s.png?raw=ture\" title=\"kubernetes outputs\" width=\"70%\"></a>\n-</p>\n-\n-6. Run port forwarding so that you can send requests to your Kubernetes application from local CLI : \n-\n-    ```shell\n-    kubectl port-forward svc/gateway -n flow-k8s-namespace 12345:12345\n-    ```\n-\n-Now we have the service up running in Kubernetes!\n \n \n \n@@ -264,11 +140,3 @@ Jina is backed by [Jina AI](https://jina.ai) and licensed under [Apache-2.0](./L\n [We are actively hiring](https://jobs.jina.ai) AI engineers, solution engineers to build the next neural search ecosystem in open source.\n \n <!-- end support-pitch -->\n-\n-## Contribute\n-\n-We welcome all kinds of contributions from the open-source community, individuals and partners. We owe our success to your active involvement.\n-\n-- [Release cycles and development stages](RELEASE.md)\n-- [Contributing guidelines](CONTRIBUTING.md)\n-- [Code of conduct](.github/CODE_OF_CONDUCT.md)\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -112,160 +112,7 @@ While one could use standard Python with the same number of lines and get the sa\n \n \n \n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-banner1.svg?raw=true\" alt=\"Get started with Jina to build production-ready neural search solution via ResNet in less than 20 minutes\" width=\"100%\"></a>\n-</p>\n-\n-### Build a service from scratch\n-\n-<sup>\n-Preliminaries: <a href=\"https://pytorch.org/get-started/locally/\">install PyTorch & Torchvision</a>\n-</sup>\n-\n-1. Import what we need.\n-    ```python\n-    from docarray import Document, DocumentArray\n-    from jina import Executor, Flow, requests\n-    ```\n-2. Copy-paste the preprocessing step and wrap it via `Executor`:\n-    ```python\n-    class PreprocImg(Executor):\n-        @requests\n-        async def foo(self, docs: DocumentArray, **kwargs):\n-            for d in docs:\n-                (\n-                    d.load_uri_to_image_tensor(200, 200)  # load\n-                    .set_image_tensor_normalization()  # normalize color\n-                    .set_image_tensor_channel_axis(\n-                        -1, 0\n-                    )  # switch color axis for the PyTorch model later\n-                )\n-    ```\n-3. Copy-paste the embedding step and wrap it via `Executor`:\n-    \n-    ```python   \n-    class EmbedImg(Executor):\n-        def __init__(self, **kwargs):\n-            super().__init__(**kwargs)\n-            import torchvision\n-            self.model = torchvision.models.resnet50(pretrained=True)        \n-   \n-        @requests\n-        async def foo(self, docs: DocumentArray, **kwargs):\n-            docs.embed(self.model)\n-    ```\n-4. Wrap the matching step into an `Executor`:\n-    ```python\n-    class MatchImg(Executor):\n-        _da = DocumentArray()\n-\n-        @requests(on='/index')\n-        async def index(self, docs: DocumentArray, **kwargs):\n-            self._da.extend(docs)\n-            docs.clear()  # clear content to save bandwidth\n-\n-        @requests(on='/search')\n-        async def foo(self, docs: DocumentArray, **kwargs):\n-            docs.match(self._da, limit=9)\n-            del docs[...][:, ('embedding', 'tensor')]  # save bandwidth as it is not needed\n-    ```\n-5. Connect all `Executor`s in a `Flow`, scale embedding to 3:\n-    ```python\n-    f = (\n-        Flow(port=12345)\n-        .add(uses=PreprocImg)\n-        .add(uses=EmbedImg, replicas=3)\n-        .add(uses=MatchImg)\n-    )\n-    ```\n-    Plot it via `f.plot('flow.svg')` and you get:\n-    \n-    <p align=\"center\">\n-    <img src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-flow-plot.svg?raw=true\" title=\"Jina Flow.plot visualization\" width=\"65%\">\n-    </p>\n-    \n-6. Download the image dataset.\n-\n-\n-<table>\n-<tr>\n-<th> Pull from Cloud </th> \n-<th> Manually download, unzip and load </th>\n-</tr>\n-<tr>\n-<td> \n-\n-```python\n-index_data = DocumentArray.pull('demo-leftda', show_progress=True)\n-```\n-     \n-</td>\n-<td>\n-\n-1. Download `left.zip` from [Google Drive](https://sites.google.com/view/totally-looks-like-dataset)\n-2. Unzip all images to `./left/`\n-3. Load into DocumentArray\n-    ```python\n-    index_data = DocumentArray.from_files('left/*.jpg')\n-    ```\n-\n-</td>\n-</tr>\n-</table>\n-\n-    \n-7. Index image data:\n-    ```python\n-    with f:\n-        f.post(\n-            '/index',\n-            index_data,\n-            show_progress=True,\n-            request_size=8,\n-        )\n-        f.block()\n-    ```\n-\n-The full indexing on 6,000 images should take ~8 minutes on a MacBook Air 2020.\n-\n-Now you can use a Python client to access the service:\n-\n-```python\n-from jina import Client\n-\n-c = Client(port=12345)  # connect to localhost:12345\n-print(c.post('/search', index_data[0])['@m'])  # '@m' is the matches-selector\n-```\n-\n-To switch from gRPC interface to REST API, you can simply set `protocol = 'http'`:\n-\n-```python\n-with f:\n-    ...\n-    f.protocol = 'http'\n-    f.block()\n-```\n-\n-Now you can query it via `curl`:\n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-curl.png?raw=true\" alt=\"Use curl to query image search service built by Jina & ResNet50\" width=\"80%\"></a>\n-</p>\n-\n-Or go to `http://0.0.0.0:12345/docs` and test requests via a Swagger UI:\n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-swagger-ui.gif?raw=true\" alt=\"Visualize visual similar images in Jina using ResNet50\" width=\"60%\"></a>\n-</p>\n-\n-\n-\n-\n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/images/readme-banner2.svg?raw=true\" alt=\"Get started with Jina to build production-ready neural search solution via ResNet in less than 20 minutes\" width=\"100%\"></a>\n-</p>\n-\n-### Play with Containerized Executors\n+### Seamless Docker integration\n \n You can containerize the Executors and use them in a sandbox thanks to [Hub](https://hub.jina.ai).\n \n@@ -401,8 +248,7 @@ Now we have the service up running in Kubernetes!\n ## Support\n \n - Check out the [Learning Bootcamp](https://learn.jina.ai) to get started with Jina.\n-- Join our [Slack community](https://slack.jina.ai) to chat to our engineers about your use cases, questions, and\n-  support queries.\n+- Join our [Slack community](https://slack.jina.ai) to chat to our engineers about your use cases, questions, and support queries.\n - Join our [Engineering All Hands](https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne) meet-up to\n   discuss your use case and learn Jina's new features.\n     - **When?** The second Tuesday of every month\n@@ -415,16 +261,14 @@ Now we have the service up running in Kubernetes!\n ## Join Us\n \n Jina is backed by [Jina AI](https://jina.ai) and licensed under [Apache-2.0](./LICENSE).\n-[We are actively hiring](https://jobs.jina.ai) AI engineers, solution engineers to build the next neural search\n-ecosystem in open source.\n+[We are actively hiring](https://jobs.jina.ai) AI engineers, solution engineers to build the next neural search ecosystem in open source.\n \n <!-- end support-pitch -->\n \n ## Contribute\n \n-We welcome all kinds of contributions from the open-source community, individuals and partners. We owe our success to\n-your active involvement.\n+We welcome all kinds of contributions from the open-source community, individuals and partners. We owe our success to your active involvement.\n \n - [Release cycles and development stages](RELEASE.md)\n - [Contributing guidelines](CONTRIBUTING.md)\n-- [Code of conduct](https://github.com/jina-ai/jina/blob/master/.github/CODE_OF_CONDUCT.md)\n+- [Code of conduct](.github/CODE_OF_CONDUCT.md)\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -68,6 +68,10 @@ Document, Executor and Flow are three fundamental concepts in Jina.\n - [**Flow**](https://docs.jina.ai/fundamentals/flow/) ties Executors together into a pipeline and exposes it with an API gateway.\n \n \n+<p align=\"center\">\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/no-complexity-banner.png?raw=true\" alt=\"Jina: No Infrastructure Complexity, High Engineering Efficiency\" width=\"100%\"></a>\n+</p>\n+\n ### Hello world example\n \n Leveraging these three concepts, let's look at a simple example below:\n@@ -106,11 +110,6 @@ At the last line we see its output `['hello, world!hello, world!', 'hello, world\n \n While one could use standard Python with the same number of lines and get the same output, Jina accelerates time to market of your application by making it more scalable and cloud-native. Jina also handles the infrastructure complexity in production and other Day-2 operations so that you can focus on the data application itself.  \n \n-<p align=\"center\">\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/no-complexity-banner.png?raw=true\" alt=\"Jina: No Infrastructure Complexity, High Engineering Efficiency\" width=\"100%\"></a>\n-</p>\n-\n-Leveraging these three concepts, let's build a simple image search service, as a \"productization\" of [DocArray README](https://github.com/jina-ai/docarray#a-complete-workflow-of-visual-search). \n \n \n <p align=\"center\">\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -104,7 +104,7 @@ Running it gives you:\n At the last line we see its output `['hello, world!hello, world!', 'hello, world!hello, world!']`.\n \n \n-While one could use standard Python with the same number of lines and get the same output, Jina accelerate time to market of your application by making it more scalable and cloud-native. Jina handles the infrastructure complexity in production and other Day-2 operations so that you can focus on the data application itself.  \n+While one could use standard Python with the same number of lines and get the same output, Jina accelerates time to market of your application by making it more scalable and cloud-native. Jina also handles the infrastructure complexity in production and other Day-2 operations so that you can focus on the data application itself.  \n \n <p align=\"center\">\n <a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/no-complexity-banner.png?raw=true\" alt=\"Jina: No Infrastructure Complexity, High Engineering Efficiency\" width=\"100%\"></a>\n\n---\n file path A: .github/readme/no-complexity-banner.png | file path B: .github/readme/no-complexity-banner.png\n\nBinary files /dev/null and b/.github/readme/no-complexity-banner.png differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -23,7 +23,7 @@ Jina is a framework that empowers anyone to build cross-modal and multi-modal<su\n Applications built with Jina enjoy the following features out-of-the-box:\n \n \ud83c\udf0c **Universal**\n-  - Build applications that deliver fresh insights from multiple data types such as text, image, audio, video, 3D mesh, PDF.\n+  - Build applications that deliver fresh insights from multiple data types such as text, image, audio, video, 3D mesh, PDF with [Jina AI's DocArray](https://docarray.jina.ai).\n   - Support all mainstream deep learning frameworks.\n   - Polyglot gateway that supports gRPC, Websockets, HTTP, GraphQL protocols with TLS.\n \n@@ -92,7 +92,7 @@ with f:\n \n - The first line imports three concepts we just introduced;\n - `MyExec` defines an async function `foo` that receives `DocumentArray` from network requests and appends `\"hello, world\"` to `.text`;\n-- `f` defines a Flow streamlined two Executors;\n+- `f` defines a Flow streamlined two Executors in a chain;\n - The `with` block opens the Flow, sends an empty DocumentArray to the Flow, and prints the result.\n \n Running it gives you:\n@@ -104,6 +104,12 @@ Running it gives you:\n At the last line we see its output `['hello, world!hello, world!', 'hello, world!hello, world!']`.\n \n \n+While one could use standard Python with the same number of lines and get the same output, Jina accelerate time to market of your application by making it more scalable and cloud-native. Jina handles the infrastructure complexity in production and other Day-2 operations so that you can focus on the data application itself.  \n+\n+<p align=\"center\">\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/no-complexity-banner.png?raw=true\" alt=\"Jina: No Infrastructure Complexity, High Engineering Efficiency\" width=\"100%\"></a>\n+</p>\n+\n Leveraging these three concepts, let's build a simple image search service, as a \"productization\" of [DocArray README](https://github.com/jina-ai/docarray#a-complete-workflow-of-visual-search). \n \n \n\n---\n file path A: .github/readme/run-hello-world.gif | file path B: .github/readme/run-hello-world.gif\n\nBinary files /dev/null and b/.github/readme/run-hello-world.gif differ\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -18,7 +18,7 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n+Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a PoC into a production-ready service in just minutes. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n \n Applications built with Jina enjoy the following features out-of-the-box:\n \n@@ -67,6 +67,43 @@ Document, Executor and Flow are three fundamental concepts in Jina.\n - [**Executor**](https://docs.jina.ai/fundamentals/executor/) is a group of functions with Documents as IO.\n - [**Flow**](https://docs.jina.ai/fundamentals/flow/) ties Executors together into a pipeline and exposes it with an API gateway.\n \n+\n+### Hello world example\n+\n+Leveraging these three concepts, let's look at a simple example below:\n+\n+```python\n+from jina import DocumentArray, Executor, Flow, requests\n+\n+\n+class MyExec(Executor):\n+    @requests\n+    async def foo(self, docs: DocumentArray, **kwargs):\n+        for d in docs:\n+            d.text += 'hello, world!'\n+\n+\n+f = Flow().add(uses=MyExec).add(uses=MyExec)\n+\n+with f:\n+    r = f.post('/', DocumentArray.empty(2))\n+    print(r.texts)\n+```\n+\n+- The first line imports three concepts we just introduced;\n+- `MyExec` defines an async function `foo` that receives `DocumentArray` from network requests and appends `\"hello, world\"` to `.text`;\n+- `f` defines a Flow streamlined two Executors;\n+- The `with` block opens the Flow, sends an empty DocumentArray to the Flow, and prints the result.\n+\n+Running it gives you:\n+\n+<p align=\"center\">\n+<a href=\"#\"><img src=\"https://github.com/jina-ai/jina/blob/master/.github/readme/run-hello-world.gif?raw=true\" alt=\"Running a simple hello-world program\" width=\"70%\"></a>\n+</p>\n+\n+At the last line we see its output `['hello, world!hello, world!', 'hello, world!hello, world!']`.\n+\n+\n Leveraging these three concepts, let's build a simple image search service, as a \"productization\" of [DocArray README](https://github.com/jina-ai/docarray#a-complete-workflow-of-visual-search). \n \n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -18,7 +18,9 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. Jina handles the infrastructure complexity, and makes the advanced solution engineering and cloud-native technologies accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n+Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. Jina handles the infrastructure complexity, making advanced solution engineering and cloud-native technologies accessible to every developer. \n+\n+Applications built with Jina enjoy the following features out-of-the-box:\n \n \ud83c\udf0c **Universal**\n   - Build applications that deliver fresh insights from multiple data types such as text, image, audio, video, 3D mesh, PDF.\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -18,15 +18,15 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. It simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n+Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. Jina handles the infrastructure complexity, and makes the advanced solution engineering and cloud-native technologies accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n \n \ud83c\udf0c **Universal**\n-  - Versatile on all modalities and data types, such as text, image, audio, video, 3D mesh, PDF.\n+  - Build applications that deliver fresh insights from multiple data types such as text, image, audio, video, 3D mesh, PDF.\n   - Support all mainstream deep learning frameworks.\n   - Polyglot gateway that supports gRPC, Websockets, HTTP, GraphQL protocols with TLS.\n \n \u26a1 **Performance**\n-  - Intuitive design pattern for building high-performance microservices.\n+  - Intuitive design pattern for high-performance microservices.\n   - Scaling at ease: set replicas, sharding in one line. \n   - Duplex streaming between client and server.\n   - Async and non-blocking data processing over dynamic flows.\n@@ -36,6 +36,9 @@ Jina is a framework that empowers anyone to build cross-modal and multi-modal<su\n   - Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n   - Full observability via Prometheus and Grafana.\n \n+\ud83c\udf71 **Ecosystem**\n+  - Improved engineering efficiency thanks to the Jina AI ecosystem, so you can focus on innovating with the data applications you build.\n+\n <sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup>\n \n <!-- end jina-description -->\n\n---\n file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -24,7 +24,7 @@ ARG PIP_INSTALL_PERF\n LABEL org.opencontainers.image.vendor=\"Jina AI Limited\" \\\n       org.opencontainers.image.licenses=\"Apache 2.0\" \\\n       org.opencontainers.image.title=\"Jina\" \\\n-      org.opencontainers.image.description=\"Building cross-modal and multi-modal applications on the cloud\" \\\n+      org.opencontainers.image.description=\"Build cross-modal and multi-modal applications on the cloud\" \\\n       org.opencontainers.image.authors=\"hello@jina.ai\" \\\n       org.opencontainers.image.url=\"https://github.com/jina-ai/jina\" \\\n       org.opencontainers.image.documentation=\"https://docs.jina.ai\"\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -1,11 +1,11 @@\n <p align=\"center\">\n <br><br><br>\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: Building cross-modal and multi-modal applications on the cloud\" width=\"150px\"></a>\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: Build cross-modal and multi-modal applications on the cloud\" width=\"150px\"></a>\n <br><br><br>\n </p>\n \n <p align=\"center\">\n-<b>Building cross-modal and multi-modal applications on the cloud</b>\n+<b>Build cross-modal and multi-modal applications on the cloud</b>\n </p>\n \n \n\n---\n file path A: cli/export.py | file path B: cli/export.py\n\n@@ -18,7 +18,7 @@ def api_to_dict(show_all_args: bool = False):\n \n     all_d = {\n         'name': 'Jina',\n-        'description': 'Building cross-modal and multi-modal applications on the cloud',\n+        'description': 'Build cross-modal and multi-modal applications on the cloud',\n         'license': 'Apache 2.0',\n         'vendor': 'Jina AI Limited',\n         'source': 'https://github.com/jina-ai/jina/tree/'\n\n---\n file path A: conda/meta.yaml | file path B: conda/meta.yaml\n\n@@ -121,7 +121,7 @@ about:\n   license: Apache-2.0\n   license_family: Apache\n   license_file: LICENSE\n-  summary: Building cross-modal and multi-modal applications on the cloud\n+  summary: Build cross-modal and multi-modal applications on the cloud\n   doc_url: https://docs.jina.ai\n \n extra:\n\n---\n file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -190,7 +190,7 @@\n     </div>\n     <qa-bot\n         title=\"Jina Bot\"\n-        description=\"Building cross-modal and multi-modal applications on the cloud\"\n+        description=\"Build cross-modal and multi-modal applications on the cloud\"\n     >\n         <template>\n             <dl>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -171,8 +171,8 @@ ogp_custom_meta_tags = [\n     '<meta name=\"twitter:card\" content=\"summary_large_image\">',\n     '<meta name=\"twitter:site\" content=\"@JinaAI_\">',\n     '<meta name=\"twitter:creator\" content=\"@JinaAI_\">',\n-    '<meta name=\"description\" content=\"Building cross-modal and multi-modal applications on the cloud\">',\n-    '<meta property=\"og:description\" content=\"Building cross-modal and multi-modal applications on the cloud\">',\n+    '<meta name=\"description\" content=\"Build cross-modal and multi-modal applications on the cloud\">',\n+    '<meta property=\"og:description\" content=\"Build cross-modal and multi-modal applications on the cloud\">',\n     '''\n     <!-- Global site tag (gtag.js) - Google Analytics -->\n <script async src=\"https://www.googletagmanager.com/gtag/js?id=G-48ZDWC8GT6\"></script>\n\n---\n file path A: scripts/create-conda-recipe.py | file path B: scripts/create-conda-recipe.py\n\n@@ -166,7 +166,7 @@ recipe_object = {\n         'license': 'Apache-2.0',\n         'license_family': 'Apache',\n         'license_file': 'LICENSE',\n-        'summary': 'Building cross-modal and multi-modal applications on the cloud',\n+        'summary': 'Build cross-modal and multi-modal applications on the cloud',\n         'doc_url': 'https://docs.jina.ai',\n     },\n     'extra': {\n\n---\n file path A: setup.py | file path B: setup.py\n\n@@ -145,7 +145,7 @@ setup(\n     packages=find_packages(),\n     version=__version__,\n     include_package_data=True,\n-    description='Building cross-modal and multi-modal applications on the cloud',\n+    description='Build cross-modal and multi-modal applications on the cloud',\n     author='Jina AI',\n     author_email='hello@jina.ai',\n     license='Apache 2.0',\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -27,7 +27,7 @@ Jina is a framework that empowers anyone to build cross-modal and multi-modal<su\n \n \u26a1 **Performance**\n   - Intuitive design pattern for building high-performance microservices.\n-  - Scaling at ease: set replicas, sharding via one parameter. \n+  - Scaling at ease: set replicas, sharding in one line. \n   - Duplex streaming between client and server.\n   - Async and non-blocking data processing over dynamic flows.\n \n@@ -54,15 +54,13 @@ pip install jina\n ## Get Started\n \n \n-\n-\n ### Basic Concepts\n \n Document, Executor and Flow are three fundamental concepts in Jina.\n \n-- [**Document**](https://docarray.jina.ai/) is a data structure contains multi-modal data.\n-- [**Executor**](https://docs.jina.ai/fundamentals/executor/) is a self-contained component and performs a group of tasks on Documents.\n-- [**Flow**](https://docs.jina.ai/fundamentals/flow/) ties Executors together into a processing pipeline, provides scalability and facilitates deployments in the cloud.\n+- [**Document**](https://docarray.jina.ai/) is the fundamental data structure.\n+- [**Executor**](https://docs.jina.ai/fundamentals/executor/) is a group of functions with Documents as IO.\n+- [**Flow**](https://docs.jina.ai/fundamentals/flow/) ties Executors together into a pipeline and exposes it with an API gateway.\n \n Leveraging these three concepts, let's build a simple image search service, as a \"productization\" of [DocArray README](https://github.com/jina-ai/docarray#a-complete-workflow-of-visual-search). \n \n\n---\n file path A: README.md | file path B: README.md\n\n@@ -36,7 +36,7 @@ Jina is a framework that empowers anyone to build cross-modal and multi-modal<su\n   - Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n   - Full observability via Prometheus and Grafana.\n \n-<sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a></sup>\n+<sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a>.</sup>\n \n <!-- end jina-description -->\n \n@@ -46,10 +46,9 @@ Jina is a framework that empowers anyone to build cross-modal and multi-modal<su\n \n ```bash\n pip install jina\n-jina -v\n ```\n \n-More install [can be found in the docs](https://docs.jina.ai/get-started/install/).\n+[More install options can be found in the docs](https://docs.jina.ai/get-started/install/).\n \n \n ## Get Started\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -18,7 +18,7 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup>[*]</sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. It simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n+Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup><a href=\"#example-application\">[*]</a></sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. It simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n \n \ud83c\udf0c **Universal**\n   - Versatile on all modalities and data types, such as text, image, audio, video, 3D mesh, PDF.\n@@ -36,7 +36,7 @@ Jina is a framework that empowers anyone to build cross-modal and multi-modal<su\n   - Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n   - Full observability via Prometheus and Grafana.\n \n-<sup>[*] Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a></sup>\n+<sup><a id=\"example-application\">[*]</a> Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a></sup>\n \n <!-- end jina-description -->\n \n\n---\n file path A: .github/workflows/codeql-analysis.yml | file path B: .github/workflows/codeql-analysis.yml\n\n@@ -22,6 +22,10 @@ on:\n \n jobs:\n   analyze:\n+    if: |\n+      !startsWith(github.event.head_commit.message, 'chore') &&\n+      !startsWith(github.event.head_commit.message, 'build: hotfix') &&\n+      !endsWith(github.event.head_commit.message, 'reformatted by jina-dev-bot')\n     name: Analyze\n     runs-on: ubuntu-latest\n     permissions:\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -18,24 +18,26 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. It simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n+Jina is a framework that empowers anyone to build cross-modal and multi-modal<sup>[*]</sup> applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. It simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n \n-\ud83c\udf0c **Universal**:\n+\ud83c\udf0c **Universal**\n   - Versatile on all modalities and data types, such as text, image, audio, video, 3D mesh, PDF.\n   - Support all mainstream deep learning frameworks.\n   - Polyglot gateway that supports gRPC, Websockets, HTTP, GraphQL protocols with TLS.\n \n-\u26a1 **Performance**:\n+\u26a1 **Performance**\n   - Intuitive design pattern for building high-performance microservices.\n   - Scaling at ease: set replicas, sharding via one parameter. \n   - Duplex streaming between client and server.\n   - Async and non-blocking data processing over dynamic flows.\n \n-\u2601\ufe0f **Cloud-native**:\n+\u2601\ufe0f **Cloud-native**\n   - Seamless Docker integration: sharing, exploring, sandboxing, versioning and dependency control via [Jina Hub](https://hub.jina.ai).\n   - Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n   - Full observability via Prometheus and Grafana.\n \n+<sup>[*] Example cross-modal application: <a href=\"https://github.com/jina-ai/dalle-flow/\">DALL\u00b7E Flow</a>; example multi-modal services: <a href=\"https://github.com/jina-ai/clip-as-service/\">CLIP-as-service</a>, <a href=\"https://github.com/jina-ai/now/\">Jina Now</a></sup>\n+\n <!-- end jina-description -->\n \n ## [Documentation](https://docs.jina.ai)\n\n---\n file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -24,7 +24,7 @@ ARG PIP_INSTALL_PERF\n LABEL org.opencontainers.image.vendor=\"Jina AI Limited\" \\\n       org.opencontainers.image.licenses=\"Apache 2.0\" \\\n       org.opencontainers.image.title=\"Jina\" \\\n-      org.opencontainers.image.description=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\" \\\n+      org.opencontainers.image.description=\"Building cross-modal and multi-modal applications on the cloud\" \\\n       org.opencontainers.image.authors=\"hello@jina.ai\" \\\n       org.opencontainers.image.url=\"https://github.com/jina-ai/jina\" \\\n       org.opencontainers.image.documentation=\"https://docs.jina.ai\"\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -1,11 +1,11 @@\n <p align=\"center\">\n <br><br><br>\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\" width=\"150px\"></a>\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: Building cross-modal and multi-modal applications on the cloud\" width=\"150px\"></a>\n <br><br><br>\n </p>\n \n <p align=\"center\">\n-<b>The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud</b>\n+<b>Building cross-modal and multi-modal applications on the cloud</b>\n </p>\n \n \n\n---\n file path A: cli/export.py | file path B: cli/export.py\n\n@@ -18,7 +18,7 @@ def api_to_dict(show_all_args: bool = False):\n \n     all_d = {\n         'name': 'Jina',\n-        'description': 'The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud',\n+        'description': 'Building cross-modal and multi-modal applications on the cloud',\n         'license': 'Apache 2.0',\n         'vendor': 'Jina AI Limited',\n         'source': 'https://github.com/jina-ai/jina/tree/'\n\n---\n file path A: conda/meta.yaml | file path B: conda/meta.yaml\n\n@@ -121,7 +121,7 @@ about:\n   license: Apache-2.0\n   license_family: Apache\n   license_file: LICENSE\n-  summary: The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\n+  summary: Building cross-modal and multi-modal applications on the cloud\n   doc_url: https://docs.jina.ai\n \n extra:\n\n---\n file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -190,7 +190,7 @@\n     </div>\n     <qa-bot\n         title=\"Jina Bot\"\n-        description=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\"\n+        description=\"Building cross-modal and multi-modal applications on the cloud\"\n     >\n         <template>\n             <dl>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -171,8 +171,8 @@ ogp_custom_meta_tags = [\n     '<meta name=\"twitter:card\" content=\"summary_large_image\">',\n     '<meta name=\"twitter:site\" content=\"@JinaAI_\">',\n     '<meta name=\"twitter:creator\" content=\"@JinaAI_\">',\n-    '<meta name=\"description\" content=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\">',\n-    '<meta property=\"og:description\" content=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\">',\n+    '<meta name=\"description\" content=\"Building cross-modal and multi-modal applications on the cloud\">',\n+    '<meta property=\"og:description\" content=\"Building cross-modal and multi-modal applications on the cloud\">',\n     '''\n     <!-- Global site tag (gtag.js) - Google Analytics -->\n <script async src=\"https://www.googletagmanager.com/gtag/js?id=G-48ZDWC8GT6\"></script>\n\n---\n file path A: scripts/create-conda-recipe.py | file path B: scripts/create-conda-recipe.py\n\n@@ -166,7 +166,7 @@ recipe_object = {\n         'license': 'Apache-2.0',\n         'license_family': 'Apache',\n         'license_file': 'LICENSE',\n-        'summary': 'The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud',\n+        'summary': 'Building cross-modal and multi-modal applications on the cloud',\n         'doc_url': 'https://docs.jina.ai',\n     },\n     'extra': {\n\n---\n file path A: setup.py | file path B: setup.py\n\n@@ -145,7 +145,7 @@ setup(\n     packages=find_packages(),\n     version=__version__,\n     include_package_data=True,\n-    description='The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud',\n+    description='Building cross-modal and multi-modal applications on the cloud',\n     author='Jina AI',\n     author_email='hello@jina.ai',\n     license='Apache 2.0',\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -18,7 +18,7 @@\n \n <!-- start jina-description -->\n \n-Jina is a framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. Jina simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Specially, applications built with Jina enjoy the following features out-of-the-box:\n+Jina is a framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. It simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Applications built with Jina enjoy the following features out-of-the-box:\n \n \ud83c\udf0c **Universal**:\n   - Versatile on all modalities and data types, such as text, image, audio, video, 3D mesh, PDF.\n@@ -26,7 +26,7 @@ Jina is a framework that empowers anyone to build cross-modal and multi-modal ap\n   - Polyglot gateway that supports gRPC, Websockets, HTTP, GraphQL protocols with TLS.\n \n \u26a1 **Performance**:\n-  - Intuitive design pattern for building high-performant microservices.\n+  - Intuitive design pattern for building high-performance microservices.\n   - Scaling at ease: set replicas, sharding via one parameter. \n   - Duplex streaming between client and server.\n   - Async and non-blocking data processing over dynamic flows.\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -20,16 +20,21 @@\n \n Jina is a framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. Jina simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Specially, applications built with Jina enjoy the following features out-of-the-box:\n \n-- \ud83c\udf0c Versatile on all modalities and data types, such as text, image, audio, video, 3D mesh, PDF.\n-- \ud83e\udde0 Support all mainstream deep learning frameworks. \n-- \ud83d\udee3\ufe0f Intuitive design pattern for building high-performant microservices.\n-- \ud83c\udd99 Scaling at ease: set replicas, sharding via one parameter. \n-- \ud83d\udce1 Universal gateway that supports gRPC, Websockets, HTTP, GraphQL protocols with TLS.\n-- \ud83d\udd01 Duplex streaming between client and server.\n-- \u26a1 Async and non-blocking data processing over dynamic flows.\n-- \ud83d\udc33 Seamless Docker integration: sharing, exploring, sandboxing, versioning and dependency control via [Jina Hub](https://hub.jina.ai).\n-- \u2388 Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n-- \ud83d\udc41\ufe0f Full observability via Prometheus and Grafana.\n+\ud83c\udf0c **Universal**:\n+  - Versatile on all modalities and data types, such as text, image, audio, video, 3D mesh, PDF.\n+  - Support all mainstream deep learning frameworks.\n+  - Polyglot gateway that supports gRPC, Websockets, HTTP, GraphQL protocols with TLS.\n+\n+\u26a1 **Performance**:\n+  - Intuitive design pattern for building high-performant microservices.\n+  - Scaling at ease: set replicas, sharding via one parameter. \n+  - Duplex streaming between client and server.\n+  - Async and non-blocking data processing over dynamic flows.\n+\n+\u2601\ufe0f **Cloud-native**:\n+  - Seamless Docker integration: sharing, exploring, sandboxing, versioning and dependency control via [Jina Hub](https://hub.jina.ai).\n+  - Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n+  - Full observability via Prometheus and Grafana.\n \n <!-- end jina-description -->\n \n\n\n###\n\n", "completion": "chore: fix readme"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -838,6 +838,8 @@ class ArgNamespace:\n             args += positional_args\n         p_args, unknown_args = parser.parse_known_args(args)\n         unknown_args = list(filter(lambda x: x.startswith('--'), unknown_args))\n+        if '--jcloud' in unknown_args:\n+            unknown_args.remove('--jcloud')\n         if warn_unknown and unknown_args:\n             _leftovers = set(unknown_args)\n             if fallback_parsers:\n\n\n###\n\n", "completion": "feat: avoid warning jcloud arg (#<issue-num>)"}
{"prompt": " file path A: .github/pages/hello-world.md | file path B: None\n\n@@ -1 +0,0 @@\n-This cookbook is deprecated. The content is revised and moved to https://docs.jina.ai/get-started/hello-world/\n\n\n###\n\n", "completion": "chore: remove pages from .github folder (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -191,6 +191,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13930,3 +13931,29 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```d6a09588```](https://github.com/jina-ai/jina/commit/d6a095884e5c5689bdd7d2e2be7b4abd685874c8)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d50fc367```](https://github.com/jina-ai/jina/commit/d50fc3679dc4476525d293eeeded16b593df7826)] __-__ __version__: the next version will be 3.4.12 (*Jina Dev Bot*)\n \n+<a name=release-note-3-6-0></a>\n+## Release Note (`3.6.0`)\n+\n+> Release time: 2022-06-08 09:17:47\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals Martinez,  Joan Fontanals,  Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```ef662b52```](https://github.com/jina-ai/jina/commit/ef662b529b2a2eecea7bb99759a9f7b9d86d3062)] __-__ add grpc health checking (#4779) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```b03dd65b```](https://github.com/jina-ai/jina/commit/b03dd65b6ee0630b09c506a7974efe2865b38f36)] __-__ bump version (*Joan Fontanals Martinez*)\n+ - [[```9a4fe0c3```](https://github.com/jina-ai/jina/commit/9a4fe0c3bc5881fd3c880891d116ea371ecbdb4e)] __-__ fix docs banner (*Han Xiao*)\n+ - [[```43e7404f```](https://github.com/jina-ai/jina/commit/43e7404fef88959088c99d67978b40b771503021)] __-__ fix docs wordings (*Han Xiao*)\n+ - [[```8f744904```](https://github.com/jina-ai/jina/commit/8f744904419d3e2d7b8f02deb678594193c8a706)] __-__ add docker docs (*Han Xiao*)\n+ - [[```0258541d```](https://github.com/jina-ai/jina/commit/0258541d0c74ddfabd79b301d83fee1d6c76e203)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```4c16fc7a```](https://github.com/jina-ai/jina/commit/4c16fc7a768f970f9e897d0cf3c5156db89a8c8f)] __-__ fix readme (*Han Xiao*)\n+ - [[```330ddfcd```](https://github.com/jina-ai/jina/commit/330ddfcde0bad2bac71ea957785e34ec054cb4d2)] __-__ fix doc build (*Han Xiao*)\n+ - [[```de25c2b8```](https://github.com/jina-ai/jina/commit/de25c2b88117bb51ab5d48739b8b1cc594aea025)] __-__ __version__: the next version will be 3.5.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.6.0'\n+__version__ = '3.6.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.6.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.5.1'\n+__version__ = '3.6.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: bump version"}
{"prompt": " file path A: docs/_static/banner.png | file path B: docs/_static/banner.png\n\nBinary files a/docs/_static/banner.png and b/docs/_static/banner.png differ\n\n---\n file path A: docs/fundamentals/architecture-overview.md | file path B: docs/fundamentals/architecture-overview.md\n\n@@ -1,5 +1,5 @@\n (architecture-overview)=\n-# Architecture Overview\n+# Concepts Overview\n \n The figure below shows details on how the Flow and Executor abstractions translate into concrete microservices, providing all the \n serving and scaling features of Jina.\n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -1,4 +1,4 @@\n-# Create a New Project\n+# Create New Project\n \n Let\u2019s write a small application with our new Jina development environment. To start, we'll use Jina CLI to make a new project for us. In your terminal of choice run:\n \n\n---\n file path A: docs/index.md | file path B: docs/index.md\n\n@@ -39,14 +39,13 @@ Now that you\u2019re set up, let\u2019s dive into more of how Jina works and how to bu\n \n get-started/install/index\n get-started/create-app\n-fundamentals/architecture-overview\n ```\n \n ```{toctree}\n :caption: User Guides\n :hidden:\n \n-\n+fundamentals/architecture-overview\n fundamentals/executor/index\n fundamentals/flow/index\n fundamentals/gateway/index\n\n\n###\n\n", "completion": "chore: fix docs banner"}
{"prompt": " file path A: docs/fundamentals/architecture-overview.md | file path B: docs/fundamentals/architecture-overview.md\n\n@@ -9,7 +9,7 @@ serving and scaling features of Jina.\n :align: center\n ```\n \n-You will not need to understand every detail of this architecture in order to build your first Neural Search app using Jina.\n+You will not need to understand every detail of this architecture in order to build your first multi-modal/cross-modal app using Jina.\n But it is useful in order to understand how Jina works, regardless of whether your microservice app runs locally,\n is orchestrated only by the Flow object itself, or is deployed using a cloud-native infrastructure such as Kubernetes.\n In fact, you might notice how some naming and concepts are inspired by the Kubernetes architecture.\n\n---\n file path A: docs/fundamentals/executor/index.md | file path B: docs/fundamentals/executor/index.md\n\n@@ -8,14 +8,14 @@ You can create an Executor by extending the `Executor` class and adding logic to\n \n ## Why should you use Executors?\n \n-Once you have learned `DocumentArray`, you can use all its power and expressiveness to build a neural search application.\n+Once you have learned `DocumentArray`, you can use all its power and expressiveness to build a multi-modal/cross-modal application.\n But what if you want to go bigger? Organize your code into modules, serve and scale them independently as microservices? That's exactly what Executors enable you to do.\n \n - Executors let you organize your DocumentArray-based functions into logical entities that can share configuration state, following OOP.\n \n - Executors convert your local functions into functions that can be distributed inside a Flow.\n \n-- Executors inside a Flow can process multiple DocumentArrays concurrently, and be deployed easily to the cloud as part of your neural search application.\n+- Executors inside a Flow can process multiple DocumentArrays concurrently, and be deployed easily to the cloud as part of your multi-modal/cross-modal application.\n \n - Executors can be easily containerized and shared with your colleagues using `jina hub push/pull`\n \n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -1,7 +1,7 @@\n (flow-cookbook)=\n # Flow\n \n-A {class}`~jina.Flow` orchestrates Executors into a processing pipeline to build a neural search application.\n+A {class}`~jina.Flow` orchestrates Executors into a processing pipeline to build a multi-modal/cross-modal application.\n Documents \"flow\" through the created pipeline and are processed by Executors.\n \n You can think of Flow as an interface to configure and launch your {ref}`microservice architecture <architecture-overview>`,\n@@ -25,7 +25,7 @@ The most important methods of the `Flow` object are the following:\n \n ## Why should you use a Flow?\n \n-Once you have learned DocumentArray and Executor, you are able to split your neural search application into different independent modules and services.\n+Once you have learned DocumentArray and Executor, you are able to split your multi-modal/cross-modal application into different independent modules and services.\n But you need to chain them together in order to bring real value and to build and serve an application. That's exactly what Flows enable you to do.\n \n - Flows connect microservices (Executors) to build a service with proper client/server style interface over HTTP, gRPC, or Websocket\n\n---\n file path A: docs/how-to/docker-compose.md | file path B: docs/how-to/docker-compose.md\n\n@@ -1,7 +1,7 @@\n (docker-compose)=\n # How to deploy with Docker Compose\n \n-Jina is a cloud-native neural search framework. Therefore, one of the simplest ways of either prototyping or serving in\n+One of the simplest ways of either prototyping or serving in\n production is to run your `Flow` with `docker-compose`.\n \n A `Flow` is composed of `Executors` which run Python code\n\n---\n file path A: docs/how-to/index.md | file path B: docs/how-to/index.md\n\n@@ -1,6 +1,6 @@\n-# {octicon}`book;1em;sd-text-info` How-To\n+# How-To\n \n-Jina is a very powerful framework that can help you build distributed neural search applications, from start to finish.\n+Jina is a very powerful framework that can help you build distributed multi-modal and cross-modal applications, from start to finish.\n \n ```{admonition} See Also\n :class: seealso\n\n\n###\n\n", "completion": "chore: fix docs wordings"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -12,7 +12,6 @@\n <p align=center>\n <a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n-<a href=\"https://hub.docker.com/r/jinaai/jina/tags\"><img src=\"https://img.shields.io/docker/v/jinaai/jina?color=%23099cec&amp;label=Docker&amp;logo=docker&amp;logoColor=white&amp;sort=semver&amp;style=flat-square\" alt=\"Docker Image Version (latest semver)\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.0k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n </p>\n\n---\n file path A: docs/get-started/install/docker.md | file path B: docs/get-started/install/docker.md\n\n@@ -1,4 +1,4 @@\n-## Docker image\n+# Docker image\n \n Our universal Docker image is ready-to-use on linux/amd64 and linux/arm64. The Docker image name always starts with `jinaai/jina` followed by a tag composed of three parts:\n \n@@ -27,7 +27,7 @@ Examples:\n - `jinaai/jina:latest`: the latest release with Python 3.7 and the entrypoint of `jina`\n - `jinaai/jina:master`: the master with Python 3.7 and the entrypoint of `jina`\n \n-### Image alias and updates\n+## Image alias and updates\n \n | Event | Updated images | Aliases |\n | --- | --- | --- |\n@@ -39,7 +39,11 @@ Examples:\n   - `{extra} = [\"\", \"-devel\", \"-standard\", \"-perf\"]`\n \n \n-### Image size on different tags\n+## Image size on different tags\n+\n+```{warning}\n+[Due to a known bug in shields.io/Docker Hub API](https://github.com/badges/shields/issues/7583), the following badge may show \"invalid\" status randomly.\n+```\n \n |Image Size|\n | ---|\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -12,6 +12,7 @@\n <p align=center>\n <a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n+<a href=\"https://hub.docker.com/r/jinaai/jina/tags\"><img src=\"https://img.shields.io/docker/v/jinaai/jina?color=%23099cec&amp;label=Docker&amp;logo=docker&amp;logoColor=white&amp;sort=semver&amp;style=flat-square\" alt=\"Docker Image Version (latest semver)\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.0k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n </p>\n\n---\n file path A: None | file path B: docs/get-started/install/docker.md\n\n@@ -0,0 +1,69 @@\n+## Docker image\n+\n+Our universal Docker image is ready-to-use on linux/amd64 and linux/arm64. The Docker image name always starts with `jinaai/jina` followed by a tag composed of three parts:\n+\n+```text\n+jinaai/jina:{version}{python_version}{extra}\n+```\n+\n+- `{version}`: The version of Jina. Possible values:\n+    - `latest`: the last release;\n+    - `master`: the master branch of `jina-ai/jina` repository;\n+    - `x.y.z`: the release of a particular version;\n+    - `x.y`: the alias to the last `x.y.z` patch release, i.e. `x.y` = `x.y.max(z)`;\n+- `{python_version}`: The Python version of the image. Possible values:\n+    - ` `, `-py37`: Python 3.7;\n+    - `-py38` for Python 3.8;\n+    - `-py39` for Python 3.9;\n+- `{extra}`: the extra dependency installed along with Jina. Possible values:\n+    - ` `: Jina is installed inside the image with minimum dependencies `pip install jina`;\n+    - `-perf`: Jina is installed inside the image via `pip install jina`. It includes all performance dependencies; \n+    - `-standard`: Jina is installed inside the image via `pip install jina`. It includes all recommended dependencies;  \n+    - `-devel`: Jina is installed inside the image via `pip install \"jina[devel]\"`. It includes `standard` plus some extra dependencies;\n+\n+Examples:\n+\n+- `jinaai/jina:0.9.6`: the `0.9.6` release with Python 3.7 and the entrypoint of `jina`.\n+- `jinaai/jina:latest`: the latest release with Python 3.7 and the entrypoint of `jina`\n+- `jinaai/jina:master`: the master with Python 3.7 and the entrypoint of `jina`\n+\n+### Image alias and updates\n+\n+| Event | Updated images | Aliases |\n+| --- | --- | --- |\n+| On Master Merge | `jinaai/jina:master{python_version}{extra}` | |\n+| On `x.y.z` release | `jinaai/jina:x.y.z{python_version}{extra}` | `jinaai/jina:latest{python_version}{extra}`, `jinaai/jina:x.y{python_version}{extra}` |\n+\n+12 images are built, i.e. taking the combination of:\n+  - `{python_version} = [\"-py37\", \"-py38\", \"-py39\"]`\n+  - `{extra} = [\"\", \"-devel\", \"-standard\", \"-perf\"]`\n+\n+\n+### Image size on different tags\n+\n+|Image Size|\n+| ---|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest?label=jinaai%2Fjina%3Alatest&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py38?label=jinaai%2Fjina%3Alatest-py38&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py39?label=jinaai%2Fjina%3Alatest-py39&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-devel?label=jinaai%2Fjina%3Alatest-devel&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-perf?label=jinaai%2Fjina%3Alatest-perf&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-standard?label=jinaai%2Fjina%3Alatest-standard&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py38-devel?label=jinaai%2Fjina%3Alatest-py38-devel&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py38-perf?label=jinaai%2Fjina%3Alatest-py38-perf&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py38-standard?label=jinaai%2Fjina%3Alatest-py38-standard&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py39-devel?label=jinaai%2Fjina%3Alatest-py39-devel&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py39-perf?label=jinaai%2Fjina%3Alatest-py39-perf&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/latest-py39-standard?label=jinaai%2Fjina%3Alatest-py39-standard&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master?label=jinaai%2Fjina%3Amaster&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py38?label=jinaai%2Fjina%3Amaster-py38&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py39?label=jinaai%2Fjina%3Amaster-py39&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-devel?label=jinaai%2Fjina%3Amaster-devel&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-perf?label=jinaai%2Fjina%3Amaster-perf&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-standard?label=jinaai%2Fjina%3Amaster-standard&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py38-devel?label=jinaai%2Fjina%3Amaster-py38-devel&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py38-perf?label=jinaai%2Fjina%3Amaster-py38-perf&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py38-standard?label=jinaai%2Fjina%3Amaster-py38-standard&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py39-devel?label=jinaai%2Fjina%3Amaster-py39-devel&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py39-perf?label=jinaai%2Fjina%3Amaster-py39-perf&logo=docker)|\n+|![](https://img.shields.io/docker/image-size/jinaai/jina/master-py39-standard?label=jinaai%2Fjina%3Amaster-py39-standard&logo=docker)|\n\n---\n file path A: docs/get-started/install/index.md | file path B: docs/get-started/install/index.md\n\n@@ -4,6 +4,7 @@\n ```{toctree}\n :hidden:\n \n+docker\n windows\n troubleshooting\n ```\n\\ No newline at end of file\n\n---\n file path A: docs/get-started/install/windows.md | file path B: docs/get-started/install/windows.md\n\n@@ -1,5 +1,5 @@\n (jina-on-windows)=\n-# Jina on Windows\n+# On Windows\n \n You can install and use Jina on Windows.\n \n\n\n###\n\n", "completion": "chore: add docker docs"}
{"prompt": " file path A: .github/workflows/force-docs-build.yml | file path B: .github/workflows/force-docs-build.yml\n\n@@ -38,7 +38,7 @@ jobs:\n           mkdir gen-html\n           cd docs\n           pip install -r requirements.txt\n-          pip install furo==2021.10.9\n+          pip install --pre -U furo\n           export NUM_RELEASES=2\n           bash makedoc.sh local-only\n           cd ./_build/dirhtml/\n\n\n###\n\n", "completion": "chore: fix doc build"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -190,6 +190,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13896,3 +13897,35 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```cfb97363```](https://github.com/jina-ai/jina/commit/cfb973631fbee824873276792c19bc1fd0ab5ed3)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```dc8b2cfb```](https://github.com/jina-ai/jina/commit/dc8b2cfb6ea83510b15af14969b9e1b49181ee21)] __-__ __version__: the next version will be 3.4.11 (*Jina Dev Bot*)\n \n+<a name=release-note-3-5-0></a>\n+## Release Note (`3.5.0`)\n+\n+> Release time: 2022-06-07 22:01:28\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```6fa5342d```](https://github.com/jina-ai/jina/commit/6fa5342d3ba0f005b2a3365dcde71a1182cd5004)] __-__ custom monitoring with context manager (#4892) (*samsja*)\n+ - [[```385d6b4b```](https://github.com/jina-ai/jina/commit/385d6b4bc7de703d87fb9efd950c0c50e1cefc11)] __-__ avoid concurrent init for replicas in same machine (#4861) (*Joan Fontanals*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```16b16b07```](https://github.com/jina-ai/jina/commit/16b16b07a66cd5a8fc7cca1d3f1c378a9c63d38c)] __-__ rename cli to jina_cli (#4890) (*Han Xiao*)\n+ - [[```5f06cff0```](https://github.com/jina-ai/jina/commit/5f06cff0fbaee8834824508199a4f2b89e7ba09e)] __-__ remove hello worlds (#4869) (*Han Xiao*)\n+ - [[```1b05b842```](https://github.com/jina-ai/jina/commit/1b05b842d7a2c851b5de2150591198ad0d9987dc)] __-__ remove unnecessary code (#4865) (*Han Xiao*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```abe735f6```](https://github.com/jina-ai/jina/commit/abe735f6509847378233ec8275e41103c86662e8)] __-__ update test path findings (#4870) (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```98beb57b```](https://github.com/jina-ai/jina/commit/98beb57b7d4f57f837529f15503e44c594bf130b)] __-__ fix readme (*Han Xiao*)\n+ - [[```d6a09588```](https://github.com/jina-ai/jina/commit/d6a095884e5c5689bdd7d2e2be7b4abd685874c8)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d50fc367```](https://github.com/jina-ai/jina/commit/d50fc3679dc4476525d293eeeded16b593df7826)] __-__ __version__: the next version will be 3.4.12 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.5.0'\n+__version__ = '3.5.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.5.1"}
{"prompt": " file path A: docs/fundamentals/executor/monitoring-executor.md | file path B: docs/fundamentals/executor/monitoring-executor.md\n\n@@ -41,13 +41,17 @@ Adding the custom monitoring on a method is as straightforward as decorating the\n ````\n \n ```python\n-from jina import Executor, monitor\n+from jina import Executor, monitor, requests\n \n \n class MyExecutor(Executor):\n     @monitor()\n     def my_method(self):\n         ...\n+\n+    @requests\n+    def foo(self, **kwargs):\n+        self.my_method()\n ```\n \n This will create a [Prometheus summary](https://prometheus.io/docs/concepts/metric_types/#summary)\n@@ -64,6 +68,25 @@ def method(self):\n     ...\n ```\n \n+You can as well monitor internal part of your executor with a Context Manager:\n+\n+```python\n+from jina import Executor, requests\n+from docarray import DocumentArray\n+\n+\n+def process():\n+    ...\n+\n+\n+class MyExecutor(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        with self.monitor('processing_seconds', 'Time processing my document'):\n+            docs = process(docs)\n+```\n+\n+\n ````{admonition} respect Prometheus naming\n :class: caution\n You should respect Prometheus naming [conventions](https://prometheus.io/docs/practices/naming/#metric-names). \n@@ -99,11 +122,13 @@ The encode function is composed of two sub-functions.\n \n By default, only the `encode` function will be monitored. \n \n+````{tab} Decorator\n+\n ```{code-block} python\n ---\n emphasize-lines: 6, 10\n ---\n-from jina import requests,monitor,Executor\n+from jina import requests,monitor, Executor\n from docarray import DocumentArray\n \n class MyExecutor(Executor):\n@@ -121,6 +146,32 @@ class MyExecutor(Executor):\n         docs.tensors = self.preprocessing(docs)\n         docs.embedding = self.model_inference(docs.tensors)\n ```\n+````\n+\n+````{tab} Context Manager\n+```{code-block} python\n+---\n+emphasize-lines: 14, 16\n+---\n+from jina import requests, Executor\n+from docarray import DocumentArray\n+\n+def preprocessing(self, docs: DocumentArray):\n+    ...\n+\n+def model_inference(self, tensor):\n+    ...\n+\n+class MyExecutor(Executor):\n+\n+    @requests\n+    def encode(self, docs: DocumentArray, **kwargs):\n+        with self.monitor('preprocessing_seconds', 'Time preprocessing the requests'):\n+            docs.tensors = preprocessing(docs)\n+        with self.monitor('model_inference_seconds', 'Time doing inference the requests'):\n+            docs.embedding = model_inference(docs.tensors)\n+```\n+````\n \n \n ### Defining custom metrics directly with the Prometheus client\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -490,7 +490,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n         )\n \n-    def get_metrics(\n+    def monitor(\n         self, name: Optional[str] = None, documentation: Optional[str] = None\n     ) -> Optional['Summary']:\n         \"\"\"\n@@ -512,6 +512,6 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                     namespace='jina',\n                     labelnames=('runtime_name',),\n                 ).labels(self.runtime_args.name)\n-            return self._metrics_buffer[name]\n+            return self._metrics_buffer[name].time()\n         else:\n-            return None\n+            return contextlib.nullcontext()\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -229,12 +229,7 @@ def monitor(\n \n         @functools.wraps(func)\n         def _f(self, *args, **kwargs):\n-            metric = self.get_metrics(name_, documentation_)\n-\n-            if metric:\n-                with metric.time():\n-                    return func(self, *args, **kwargs)\n-            else:\n+            with self.monitor(name_, documentation_):\n                 return func(self, *args, **kwargs)\n \n         return _f\n\n---\n file path A: tests/integration/monitoring/test_executor.py | file path B: tests/integration/monitoring/test_executor.py\n\n@@ -34,15 +34,15 @@ def test_decorator_interface(port_generator):\n     class DummyExecutor(Executor):\n         @requests(on='/foo')\n         def foo(self, docs, **kwargs):\n-            self._proces(docs)\n-            self.proces_2(docs)\n+            self._process(docs)\n+            self.process_2(docs)\n \n         @monitor(name='metrics_name', documentation='metrics description')\n-        def _proces(self, docs):\n+        def _process(self, docs):\n             ...\n \n         @monitor()\n-        def proces_2(self, docs):\n+        def process_2(self, docs):\n             ...\n \n     port = port_generator()\n@@ -56,6 +56,44 @@ def test_decorator_interface(port_generator):\n             resp.content\n         )\n         assert (\n-            f'jina_proces_2_seconds_count{{runtime_name=\"executor0/rep-0\"}} 1.0'\n+            f'jina_process_2_seconds_count{{runtime_name=\"executor0/rep-0\"}} 1.0'\n+            in str(resp.content)\n+        )\n+\n+\n+def test_context_manager_interface(port_generator):\n+    class DummyExecutor(Executor):\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+\n+            with self.monitor(\n+                name='process_seconds', documentation='process time in seconds '\n+            ):\n+                self._process(docs)\n+\n+            with self.monitor(\n+                name='process_2_seconds', documentation='process 2 time in seconds '\n+            ):\n+                self.process_2(docs)\n+\n+        def _process(self, docs):\n+            ...\n+\n+        def process_2(self, docs):\n+            ...\n+\n+    port = port_generator()\n+    with Flow(monitoring=True, port_monitoring=port_generator()).add(\n+        uses=DummyExecutor, monitoring=True, port_monitoring=port\n+    ) as f:\n+        f.post('/foo', inputs=DocumentArray.empty(4))\n+\n+        resp = req.get(f'http://localhost:{port}/')\n+        assert (\n+            f'jina_process_seconds_count{{runtime_name=\"executor0/rep-0\"}} 1.0'\n+            in str(resp.content)\n+        )\n+        assert (\n+            f'jina_process_2_seconds_count{{runtime_name=\"executor0/rep-0\"}} 1.0'\n             in str(resp.content)\n         )\n\n---\n file path A: tests/unit/serve/runtimes/worker/test_worker_runtime.py | file path B: tests/unit/serve/runtimes/worker/test_worker_runtime.py\n\n@@ -393,14 +393,14 @@ async def test_decorator_monitoring(port_generator):\n         @requests\n         def foo(self, docs, **kwargs):\n             self._proces(docs)\n-            self.proces_2(docs)\n+            self.process_2(docs)\n \n         @monitor(name='metrics_name', documentation='metrics description')\n         def _proces(self, docs):\n             ...\n \n         @monitor()\n-        def proces_2(self, docs):\n+        def process_2(self, docs):\n             ...\n \n     port = port_generator()\n@@ -444,3 +444,70 @@ async def test_decorator_monitoring(port_generator):\n     runtime_thread.join()\n \n     assert not AsyncNewLoopRuntime.is_ready(f'{args.host}:{args.port}')\n+\n+\n+@pytest.mark.asyncio\n+@pytest.mark.slow\n+@pytest.mark.timeout(5)\n+async def test_decorator_monitoring(port_generator):\n+    class DummyExecutor(Executor):\n+        @requests\n+        def foo(self, docs, **kwargs):\n+\n+            with self.monitor(\n+                name='process_seconds', documentation='process time in seconds '\n+            ):\n+                self._proces(docs)\n+\n+            with self.monitor(\n+                name='process_2_seconds', documentation='process 2 time in seconds '\n+            ):\n+                self.process_2(docs)\n+\n+        def _proces(self, docs):\n+            ...\n+\n+        def process_2(self, docs):\n+            ...\n+\n+    port = port_generator()\n+    args = set_pod_parser().parse_args(\n+        ['--monitoring', '--port-monitoring', str(port), '--uses', 'DummyExecutor']\n+    )\n+\n+    cancel_event = multiprocessing.Event()\n+\n+    def start_runtime(args, cancel_event):\n+        with WorkerRuntime(args, cancel_event=cancel_event) as runtime:\n+            runtime.run_forever()\n+\n+    runtime_thread = Process(\n+        target=start_runtime,\n+        args=(args, cancel_event),\n+        daemon=True,\n+    )\n+    runtime_thread.start()\n+\n+    assert AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'{args.host}:{args.port}',\n+        ready_or_shutdown_event=Event(),\n+    )\n+\n+    assert AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'{args.host}:{args.port}',\n+        ready_or_shutdown_event=Event(),\n+    )\n+\n+    await GrpcConnectionPool.send_request_async(\n+        _create_test_data_message(), f'{args.host}:{args.port}', timeout=1.0\n+    )\n+\n+    resp = req.get(f'http://localhost:{port}/')\n+    assert f'jina_process_seconds_count{{runtime_name=\"None\"}} 1.0' in str(resp.content)\n+\n+    cancel_event.set()\n+    runtime_thread.join()\n+\n+    assert not AsyncNewLoopRuntime.is_ready(f'{args.host}:{args.port}')\n\n\n###\n\n", "completion": "feat: custom monitoring with context manager (#<issue-num>)"}
{"prompt": " file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -24,7 +24,7 @@ ARG PIP_INSTALL_PERF\n LABEL org.opencontainers.image.vendor=\"Jina AI Limited\" \\\n       org.opencontainers.image.licenses=\"Apache 2.0\" \\\n       org.opencontainers.image.title=\"Jina\" \\\n-      org.opencontainers.image.description=\"Cloud-native neural search framework for any kind of data\" \\\n+      org.opencontainers.image.description=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\" \\\n       org.opencontainers.image.authors=\"hello@jina.ai\" \\\n       org.opencontainers.image.url=\"https://github.com/jina-ai/jina\" \\\n       org.opencontainers.image.documentation=\"https://docs.jina.ai\"\n\n---\n file path A: README.md | file path B: README.md\n\n@@ -1,11 +1,11 @@\n <p align=\"center\">\n <br><br><br>\n-<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: Jina is a cloud-native neural search framework\" width=\"150px\"></a>\n+<a href=\"https://docs.jina.ai\"><img src=\"https://github.com/jina-ai/jina/blob/master/docs/_static/logo-light.svg?raw=true\" alt=\"Jina logo: The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\" width=\"150px\"></a>\n <br><br><br>\n </p>\n \n <p align=\"center\">\n-<b>Cloud-Native Neural Search<sup><a href=\"https://docs.jina.ai/get-started/neural-search/\">?</a></sup> Framework for <i>Any</i> Kind of Data</b>\n+<b>The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud</b>\n </p>\n \n \n@@ -13,40 +13,42 @@\n <a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n-<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n+<a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-3.0k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n </p>\n \n <!-- start jina-description -->\n \n-Jina is a neural search framework that empowers anyone to build SOTA and scalable neural search applications in minutes.\n+Jina is a framework that empowers anyone to build cross-modal and multi-modal applications on the cloud. It uplifts a local PoC into a production-ready service in just minutes. Jina simplifies the advanced solution engineering and cloud-native technologies, making them accessible to every developer. Specially, applications built with Jina enjoy the following features out-of-the-box:\n \n-\u23f1\ufe0f **Save time** - *The* design pattern of neural search systems. Quickly build solutions for indexing, querying, understanding multi-/cross-modal data such as video, image, text, audio, source code, PDF. Get it up and running right now using [Jina NOW](https://github.com/jina-ai/now)\n-\n-\ud83c\udf29\ufe0f **Local & cloud friendly** - Distributed architecture, scalable & cloud-native from day one. Same developer experience on local, [Docker Compose](https://docs.jina.ai/how-to/docker-compose/), [Kubernetes](https://docs.jina.ai/how-to/kubernetes/).\n-\n-\ud83d\ude80 **Serve, scale & share** - Serve a local project with HTTP, WebSockets or gRPC endpoints in just minutes. Scale your neural search applications to meet your availability and throughput requirements. Share and reuse building blocks from [Hub](https://hub.jina.ai).\n-\n-\ud83c\udf71 **Own your stack** - Keep end-to-end stack ownership of your solution. Avoid integration pitfalls you get with fragmented, multi-vendor, generic legacy tools. Enjoy the integration with the neural search ecosystem including [DocArray](https://docarray.jina.ai), [Hub](https://hub.jina.ai) and [Finetuner](https://finetuner.jina.ai).\n+- \ud83c\udf0c Versatile on all modalities and data types, such as text, image, audio, video, 3D mesh, PDF.\n+- \ud83e\udde0 Support all mainstream deep learning frameworks. \n+- \ud83d\udee3\ufe0f Intuitive design pattern for building high-performant microservices.\n+- \ud83c\udd99 Scaling at ease: set replicas, sharding via one parameter. \n+- \ud83d\udce1 Universal gateway that supports gRPC, Websockets, HTTP, GraphQL protocols with TLS.\n+- \ud83d\udd01 Duplex streaming between client and server.\n+- \u26a1 Async and non-blocking data processing over dynamic flows.\n+- \ud83d\udc33 Seamless Docker integration: sharing, exploring, sandboxing, versioning and dependency control via [Jina Hub](https://hub.jina.ai).\n+- \u2388 Fast deployment to Kubernetes, Docker Compose and Jina Cloud.\n+- \ud83d\udc41\ufe0f Full observability via Prometheus and Grafana.\n \n <!-- end jina-description -->\n \n+## [Documentation](https://docs.jina.ai)\n+\n ## Install \n \n ```bash\n pip install jina\n+jina -v\n ```\n \n-For Jina 2.x users, please uninstall it via `pip uninstall jina` before installing Jina 3. Please also read [the 2 to 3 migration guide](https://docs.jina.ai/get-started/migrate/).\n-\n-More install options including Conda, Docker, and Windows [can be found here](https://docs.jina.ai/get-started/install/).\n+More install [can be found in the docs](https://docs.jina.ai/get-started/install/).\n \n-## [Documentation](https://docs.jina.ai)\n \n ## Get Started\n \n \n \n-We promise you can build a **scalable** ResNet-powered image search **service** in 20 minutes or less, **from scratch to Kubernetes**. If not, you can forget about Jina.\n \n ### Basic Concepts\n \n\n---\n file path A: cli/export.py | file path B: cli/export.py\n\n@@ -18,7 +18,7 @@ def api_to_dict(show_all_args: bool = False):\n \n     all_d = {\n         'name': 'Jina',\n-        'description': 'Cloud-native neural search framework for any kind of data',\n+        'description': 'The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud',\n         'license': 'Apache 2.0',\n         'vendor': 'Jina AI Limited',\n         'source': 'https://github.com/jina-ai/jina/tree/'\n@@ -55,9 +55,10 @@ def api_to_dict(show_all_args: bool = False):\n \n \n def _export_parser_args(parser_fn, type_as_str: bool = False, **kwargs):\n-    from jina.enums import BetterEnum\n     from argparse import _StoreAction, _StoreTrueAction\n-    from jina.parsers.helper import KVAppendAction, _SHOW_ALL_ARGS\n+\n+    from jina.enums import BetterEnum\n+    from jina.parsers.helper import _SHOW_ALL_ARGS, KVAppendAction\n \n     port_attr = ('help', 'choices', 'default', 'required', 'option_strings', 'dest')\n     parser = parser_fn(**kwargs)\n\n---\n file path A: conda/meta.yaml | file path B: conda/meta.yaml\n\n@@ -121,7 +121,7 @@ about:\n   license: Apache-2.0\n   license_family: Apache\n   license_file: LICENSE\n-  summary: Jina is the cloud-native neural search framework for any kind of data\n+  summary: The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\n   doc_url: https://docs.jina.ai\n \n extra:\n\n---\n file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -190,7 +190,7 @@\n     </div>\n     <qa-bot\n         title=\"Jina Bot\"\n-        description=\"The cloud-native neural search framework\"\n+        description=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\"\n     >\n         <template>\n             <dl>\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -171,8 +171,8 @@ ogp_custom_meta_tags = [\n     '<meta name=\"twitter:card\" content=\"summary_large_image\">',\n     '<meta name=\"twitter:site\" content=\"@JinaAI_\">',\n     '<meta name=\"twitter:creator\" content=\"@JinaAI_\">',\n-    '<meta name=\"description\" content=\"Jina is the cloud-native neural search solution powered by the state-of-the-art AI and deep learning\">',\n-    '<meta property=\"og:description\" content=\"Jina is the cloud-native neural search solution powered by the state-of-the-art AI and deep learning\">',\n+    '<meta name=\"description\" content=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\">',\n+    '<meta property=\"og:description\" content=\"The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud\">',\n     '''\n     <!-- Global site tag (gtag.js) - Google Analytics -->\n <script async src=\"https://www.googletagmanager.com/gtag/js?id=G-48ZDWC8GT6\"></script>\n@@ -203,8 +203,8 @@ def configure_qa_bot_ui(app):\n \n def setup(app):\n     from sphinx.domains.python import PyField\n-    from sphinx.util.docfields import Field\n     from sphinx.locale import _\n+    from sphinx.util.docfields import Field\n \n     app.add_object_type(\n         'confval',\n\n---\n file path A: scripts/create-conda-recipe.py | file path B: scripts/create-conda-recipe.py\n\n@@ -166,7 +166,7 @@ recipe_object = {\n         'license': 'Apache-2.0',\n         'license_family': 'Apache',\n         'license_file': 'LICENSE',\n-        'summary': 'Jina is the cloud-native neural search framework for any kind of data',\n+        'summary': 'The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud',\n         'doc_url': 'https://docs.jina.ai',\n     },\n     'extra': {\n\n---\n file path A: scripts/get-all-test-paths.sh | file path B: scripts/get-all-test-paths.sh\n\n@@ -1,15 +1,17 @@\n #!/usr/bin/env bash\n-\n set -ex\n+if [[ $1 == \"windows\" ]]; then\n+    declare -a array2=( $(ls -d tests/{unit}/*/ | grep -v '__pycache__'| grep -v 'unit/serve' | grep -v 'unit/orchestrate'))\n+    declare -a array3=( $(ls -d tests/{unit}/orchestrate/*/ | grep -v '__pycache__'))\n+    declare -a array4=( $(ls -d tests/{unit}/serve/*/ | grep -v '__pycache__'))\n+    dest1=( \"${array2[@]}\" \"${array3[@]}\" \"${array4[@]}\" )\n+    printf '%s\\n' \"${dest1[@]}\" | jq -R . | jq -cs .\n+else\n+    declare -a array1=( \"tests/unit/*.py\" \"tests/integration/*.py\")\n+    declare -a array2=( $(ls -d tests/{unit,integration}/*/ | grep -v '__pycache__' | grep -v 'unit/serve' | grep -v 'unit/orchestrate'))\n+    declare -a array3=( $(ls -d tests/unit/orchestrate/*/ | grep -v '__pycache__'))\n+    declare -a array4=( $(ls -d tests/unit/serve/*/ | grep -v '__pycache__'))\n+    dest=( \"${array1[@]}\" \"${array2[@]}\" \"${array3[@]}\" \"${array4[@]}\" )\n \n-BATCH_SIZE=5\n-#declare -a array1=( \"tests/unit/test_*.py\" )\n-#declare -a array2=( $(ls -d tests/unit/*/ | grep -v '__pycache__' | grep -v 'array') )\n-#declare -a array3=( \"tests/unit/array/*.py\" )\n-declare -a mixins=( $(find tests -name \"test_*.py\") )\n-declare -a array4=( \"$(echo \"${mixins[@]}\" | xargs -n$BATCH_SIZE)\" )\n-# array5 is currently empty because in the array/ directory, mixins is the only directory\n-# but add the following in case new directories are created in array/\n-dest=( \"${array1[@]}\" \"${array2[@]}\" \"${array3[@]}\" \"${array4[@]}\" \"${array5[@]}\" )\n-\n-printf '%s\\n' \"${dest[@]}\" | jq -R . | jq -cs .\n+    printf '%s\\n' \"${dest[@]}\" | jq -R . | jq -cs .\n+fi\n\\ No newline at end of file\n\n---\n file path A: setup.py | file path B: setup.py\n\n@@ -145,7 +145,7 @@ setup(\n     packages=find_packages(),\n     version=__version__,\n     include_package_data=True,\n-    description='Jina is the cloud-native neural search framework for any kind of data',\n+    description='The Framework for Building Cross-Modal and Multi-Modal Applications on the Cloud',\n     author='Jina AI',\n     author_email='hello@jina.ai',\n     license='Apache 2.0',\n@@ -195,6 +195,6 @@ setup(\n         'Source': 'https://github.com/jina-ai/jina/',\n         'Tracker': 'https://github.com/jina-ai/jina/issues',\n     },\n-    keywords='jina cloud-native neural-search query search index elastic neural-network encoding '\n-    'embedding serving docker container image video audio deep-learning',\n+    keywords='jina cloud-native cross-modal multi-modal neural-search query search index elastic neural-network encoding '\n+    'embedding serving docker container image video audio deep-learning ',\n )\n\n\n###\n\n", "completion": "ci: update test path findings (#<issue-num>)"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -106,6 +106,7 @@ __jina_env__ = (\n     'JINA_RANDOM_PORT_MIN',\n     'JINA_VCS_VERSION',\n     'JINA_DISABLE_HEALTHCHECK_LOGS',\n+    'JINA_LOCKS_ROOT',\n )\n \n __default_host__ = _os.environ.get(\n\n---\n file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -16,7 +16,6 @@ from functools import lru_cache, wraps\n from pathlib import Path\n from typing import Dict, Optional, Tuple\n from urllib.parse import urljoin, urlparse\n-from urllib.request import Request, urlopen\n \n from jina import __resources_path__\n from jina.enums import BetterEnum\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -13,7 +13,12 @@ from jina.helper import ArgNamespace, T, iscoroutinefunction, typename\n from jina.importer import ImportExtensions\n from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n from jina.logging.logger import JinaLogger\n-from jina.serve.executors.decorators import requests, store_init_kwargs, wrap_func\n+from jina.serve.executors.decorators import (\n+    avoid_concurrent_lock_cls,\n+    requests,\n+    store_init_kwargs,\n+    wrap_func,\n+)\n \n if TYPE_CHECKING:\n     from prometheus_client import Summary\n@@ -59,6 +64,7 @@ class ExecutorType(type(JAMLCompatible), type):\n                     f'please add `**kwargs` to your __init__ function'\n                 )\n             wrap_func(cls, ['__init__'], store_init_kwargs)\n+            wrap_func(cls, ['__init__'], avoid_concurrent_lock_cls(cls))\n \n             reg_cls_set.add(cls_id)\n             setattr(cls, '_registered_class', reg_cls_set)\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -1,16 +1,33 @@\n \"\"\"Decorators and wrappers designed for wrapping :class:`BaseExecutor` functions. \"\"\"\n import functools\n import inspect\n-from functools import wraps\n+import os\n+from contextlib import nullcontext\n+from pathlib import Path\n from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Sequence, Union\n \n from jina.helper import convert_tuple_to_list, iscoroutinefunction\n+from jina.importer import ImportExtensions\n from jina.serve.executors.metas import get_default_metas\n \n if TYPE_CHECKING:\n     from jina import DocumentArray\n \n \n+@functools.lru_cache()\n+def _get_locks_root() -> Path:\n+    locks_root = Path(\n+        os.environ.get(\n+            'JINA_LOCKS_ROOT', Path.home().joinpath('.jina').joinpath('locks')\n+        )\n+    )\n+\n+    if not locks_root.exists():\n+        locks_root.mkdir(parents=True, exist_ok=True)\n+\n+    return locks_root\n+\n+\n def wrap_func(cls, func_lst, wrapper):\n     \"\"\"Wrapping a class method only once, inherited but not overridden method will not be wrapped again\n \n@@ -31,7 +48,7 @@ def store_init_kwargs(func: Callable) -> Callable:\n     :return: the wrapped function\n     \"\"\"\n \n-    @wraps(func)\n+    @functools.wraps(func)\n     def arg_wrapper(self, *args, **kwargs):\n         if func.__name__ != '__init__':\n             raise TypeError(\n@@ -62,6 +79,51 @@ def store_init_kwargs(func: Callable) -> Callable:\n     return arg_wrapper\n \n \n+def avoid_concurrent_lock_cls(cls):\n+    \"\"\"Wraps a function to lock a filelock for concurrent access with the name of the class to which it applies, to avoid deadlocks\n+    :param cls: the class to which is applied, only when the class corresponds to the instance type, this filelock will apply\n+    :return: the wrapped function\n+    \"\"\"\n+\n+    def avoid_concurrent_lock_wrapper(func: Callable) -> Callable:\n+        \"\"\"Wrap the function around a File Lock to make sure that the function is run by a single replica in the same machine\n+        :param func: the function to decorate\n+        :return: the wrapped function\n+        \"\"\"\n+\n+        @functools.wraps(func)\n+        def arg_wrapper(self, *args, **kwargs):\n+            if func.__name__ != '__init__':\n+                raise TypeError(\n+                    'this decorator should only be used on __init__ method of an executor'\n+                )\n+\n+            if self.__class__ == cls:\n+                file_lock = nullcontext()\n+                with ImportExtensions(\n+                    required=False,\n+                    help_text=f'FileLock is needed to guarantee non-concurrent initialization of replicas in the same '\n+                    f'machine.',\n+                ):\n+                    import filelock\n+\n+                    locks_root = _get_locks_root()\n+\n+                    lock_file = locks_root.joinpath(f'{self.__class__.__name__}.lock')\n+\n+                    file_lock = filelock.FileLock(lock_file, timeout=-1)\n+\n+                with file_lock:\n+                    f = func(self, *args, **kwargs)\n+                return f\n+            else:\n+                return func(self, *args, **kwargs)\n+\n+        return arg_wrapper\n+\n+    return avoid_concurrent_lock_wrapper\n+\n+\n def requests(\n     func: Callable[\n         [\n\n---\n file path A: tests/integration/high_order_matches/test_document.py | file path B: tests/integration/high_order_matches/test_document.py\n\n@@ -1,5 +1,4 @@\n-from jina import Flow\n-from jina import Document, Executor, Client, requests\n+from jina import Client, Document, Executor, Flow, requests\n \n exposed_port = 12345\n \n@@ -33,9 +32,8 @@ def test_single_executor():\n     )\n \n     with f:\n-        results = Client(port=exposed_port, return_responses=True).post(\n-            on='index',\n-            inputs=Document(),\n+        results = Client(port=exposed_port).post(\n+            on='index', inputs=Document(), return_responses=True\n         )\n     validate_results(results)\n \n@@ -49,8 +47,7 @@ def test_multi_executor():\n     )\n \n     with f:\n-        results = Client(port=exposed_port, return_responses=True).post(\n-            on='index',\n-            inputs=Document(),\n+        results = Client(port=exposed_port).post(\n+            on='index', inputs=Document(), return_responses=True\n         )\n     validate_results(results)\n\n\n###\n\n", "completion": "feat: avoid concurrent init for replicas in same machine (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -189,6 +189,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13866,3 +13867,31 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```a6e64553```](https://github.com/jina-ai/jina/commit/a6e645539fa30cea496cbee5d687d9d02a39949b)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```b3b3a44f```](https://github.com/jina-ai/jina/commit/b3b3a44f64b80d4f7bd0b4be39f63e7df7b6cbe1)] __-__ __version__: the next version will be 3.4.10 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-11></a>\n+## Release Note (`3.4.11`)\n+\n+> Release time: 2022-06-03 05:59:18\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Johannes Messner,  samsja,  Florian H\u00f6nicke,  Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```2eee78d5```](https://github.com/jina-ai/jina/commit/2eee78d51752e2fae8f89b0b72ad2736941347a2)] __-__ client default port  (#4855) (*samsja*)\n+ - [[```99c8b0cc```](https://github.com/jina-ai/jina/commit/99c8b0cc0784b62deb57c5a0a29ce7c1473fa58b)] __-__ pass tls to the deployment (#4849) (*samsja*)\n+ - [[```7c4c39a9```](https://github.com/jina-ai/jina/commit/7c4c39a9d82c58ef2493c21a288c755901a9594e)] __-__ do not deploy sandbox on init (#4844) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```d435f858```](https://github.com/jina-ai/jina/commit/d435f8586dc55c2f940d4a895faed739cfdbf0cb)] __-__ document behaviour when things go wrong and redo k8s howto (#4842) (*Johannes Messner*)\n+ - [[```528a0b6c```](https://github.com/jina-ai/jina/commit/528a0b6c39f8700b7b2799bd9ea146f73cc20557)] __-__ add default port client (#4858) (*samsja*)\n+ - [[```3bf1c866```](https://github.com/jina-ai/jina/commit/3bf1c8663a56df1b47b97ba8dc94448d1b42bb6d)] __-__ add jina now (#4847) (*Florian H\u00f6nicke*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```cfb97363```](https://github.com/jina-ai/jina/commit/cfb973631fbee824873276792c19bc1fd0ab5ed3)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```dc8b2cfb```](https://github.com/jina-ai/jina/commit/dc8b2cfb6ea83510b15af14969b9e1b49181ee21)] __-__ __version__: the next version will be 3.4.11 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.11'\n+__version__ = '3.4.12'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.12"}
{"prompt": " file path A: docs/fundamentals/executor/containerize-executor.md | file path B: docs/fundamentals/executor/containerize-executor.md\n\n@@ -1,3 +1,4 @@\n+(dockerize-exec)=\n # Dockerize your Executor\n \n Once you have understood what an `Executor` is and how it can be used inside a `Flow`, you may be interested in wrapping this Executor into a container\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -146,6 +146,7 @@ flow-api\n access-flow-api\n client\n monitoring-flow\n+when-things-go-wrong\n yaml-spec\n remarks\n ```\n\n---\n file path A: None | file path B: docs/fundamentals/flow/when-things-go-wrong.md\n\n@@ -0,0 +1,94 @@\n+(flow-error-handling)=\n+# Error handling\n+\n+When building a complex solution, unfortunately things go wrong sometimes.\n+Jina does its best to recover from failures, handle them gracefully, and report useful failure information to the user.\n+\n+The following outlines a number of (more or less) common failure cases, and explains how Jina responds to each one of them.\n+\n+## Exceptions in Executor code\n+\n+In general there are two places where an Executor level error can be introduced.\n+\n+If an Executor's `__init__` method raises and Exception, the Flow cannot start.\n+In this case this Exception is gets raised by the Executor runtime, and the Flow throws a `RuntimeFailToStart` Exception.\n+\n+If one of the Executor's `@requests` methods raises and Exception, the offending error message gets added to the response\n+and is sent back to the client.\n+If the gRPC or WebSocket protocols are used, the networking stream is not interrupted and can accept further requests.\n+\n+In all cases, the {ref}`Jina Client <client>` will raise an Exception.\n+\n+## Network errors\n+\n+When an {ref}`Executor or Head <architecture-overview>` can't be reached by the Flow's gateway, it attempts to re-connect\n+to the faulty deployment according to a retry policy.\n+The specifics of this policy depend on the environment the Flow find itself in, and are outlined below.\n+\n+If, during the complete execution of this policy, no successful call to any Executor replica could be made, the request is aborted\n+and the failure is {ref}`reported to the client <failure-reporting>`.\n+\n+### Request retries: Local deployment\n+\n+If a Flow is deployed locally (with or without {ref}`containerized Executors <dockerize-exec>`), the following policy\n+for failed requests applies on a per-Executor basis:\n+\n+- If there are multiple replicas of the target Executor, try each replica at least once, or until the request succeeds\n+- Irrespective of the number of replicas, try the request at least 3 times, or until it succeeds. If there are fewer than 3 replicas, try them in a round-robin fashion\n+\n+### Request retries: Deployment with Kubernetes\n+\n+If a Flow is {ref}`deployed in Kubernetes <kubernetes>` without a service mesh, retries cannot be distributed to different replicas of the same Executor.\n+\n+````{admonition} See Also\n+:class: seealso\n+\n+The impossibility of retries across different replicas is a limitation of Kubernetes in combination with gRPC.\n+If you want to learn more about this limitation, see [this](https://kubernetes.io/blog/2018/11/07/grpc-load-balancing-on-kubernetes-without-tears/) Kubernetes Blog post.\n+\n+An easy way to overcome this limitation is to use a service mesh like [Linkerd](https://linkerd.io/).\n+````\n+\n+Concretely, this results in the following per-Executor retry policy:\n+\n+- Try the request 3 times, or until it succeeds, always on the same replica of the Executor\n+\n+### Request retries: Deployment with Kubernetes and service mesh\n+\n+A Kubernetes service mesh can enable load balancing, and thus retries, between replicas of an Executor.\n+\n+````{admonition} Hint\n+:class: hint\n+While Jina supports any service mesh, the output of `f.to_k8s_yaml()` already includes the necessary annotations for [Linkerd](https://linkerd.io/).\n+````\n+\n+If a service mesh is installed alongside Jina in the Kubernetes cluster, the following retry policy applies for each Executor:\n+\n+- Try the request at least 3 times, or until it succeeds\n+- Distribute the requests to the replicas according to the service mesh's configuration\n+\n+\n+````{admonition} Caution\n+:class: caution\n+\n+Many service meshes have the ability to perform retries themselves.\n+Be careful about setting up service mesh level retries in combination with Jina, as it may lead to unwanted behaviour in combination with\n+Jina's own retry policy.\n+````\n+\n+(failure-reporting)=\n+### Failure reporting\n+\n+If the retry policy is exhausted for a given request, the error is reported back to the corresponding client.\n+\n+The resulting error message will contain the *network address* of the failing Executor.\n+If multiple replicas are present, all addresses will be reported - unless the Flow is deployed using Kubernetes, in which\n+case the replicas are managed by k8s and only a single address is available.\n+\n+Depending on the client-to-gateway protocol, the error message will be returned in one of the following ways:\n+\n+- **gRPC**: A response with the gRPC status code 14 (*UNAVAILABLE*) is issued, and the error message is contained in the `details` field\n+- **HTTP**: A response with the HTTP status code 503 (*SERVICE_UNAVAILABLE*) is issued, and the error message is contained in `response['header']['status']['description']`\n+- **WebSocket**: The stream closes with close code 1011 (*INTERNAL_ERROR*) and the message is contained in the WS close message\n+\n+For any of these protocols, the {ref}`Jina Client <client>` will raise a `ConnectionError` containing the error message.\n\\ No newline at end of file\n\n---\n file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -7,7 +7,7 @@ A `Flow` is composed of `Executors` which run Python code\n defined to operate on a `DocumentArray`. These Executors live in different runtimes depending on how you want to deploy\n your Flow. \n \n-When deployed in Kubernetes, these Executors will run inside Kubernetes Pods as containers and their lifetime will be handled\n+When deployed in Kubernetes, these Executors will run inside Kubernetes Pods as containers and their lifetime will be orchestrated\n by Kubernetes.\n \n Deploying a Flow in Kubernetes is the recommended way of using Jina in production.\n@@ -42,7 +42,7 @@ To generate YAML configurations for Kubernetes from a Jina Flow, one just needs\n flow.to_k8s_yaml('flow_k8s_configuration')\n ```\n \n-This will create a folder 'flow_k8s_configuration' with a set of Kubernetes YAML configurations for all the deployments composing the Flow\n+This will create a folder `flow_k8s_configuration` with a set of Kubernetes YAML configurations for all the deployments composing the Flow\n \n ````{admonition} Hint\n :class: hint\n@@ -114,9 +114,9 @@ Here are some managed `Kubernetes` cluster solutions you could use:\n - [Digital Ocean](https://www.digitalocean.com/products/kubernetes/)\n ```\n \n-### Indexing and searching images using CLIP image encoder and PQLiteIndexer\n+### Indexing and searching images using CLIP image encoder and ANNLite\n \n-This example shows how to build and deploy a Flow in Kubernetes with [`CLIPImageEncoder`](https://hub.jina.ai/executor/0hnlmu3q) as encoder and [`PQLiteIndexer`](https://hub.jina.ai/executor/pn1qofsj) as indexer.\n+This example shows how to build and deploy a Flow in Kubernetes with [`CLIPImageEncoder`](https://hub.jina.ai/executor/0hnlmu3q) as encoder and [`ANNLiteIndexer`](https://hub.jina.ai/executor/pn1qofsj) as indexer.\n \n ```python\n from jina import Flow\n@@ -126,7 +126,7 @@ f = (\n     .add(name='encoder', uses='jinahub+docker://CLIPEncoder', replicas=2)\n     .add(\n         name='indexer',\n-        uses='jinahub+docker://PQLiteIndexer',\n+        uses='jinahub+docker://ANNLiteIndexer',\n         uses_with={'dim': 512},\n         shards=2,\n     )\n@@ -147,8 +147,7 @@ You should expect the following file structure generated:\n     \u251c\u2500\u2500 gateway\n     \u2502   \u2514\u2500\u2500 gateway.yml\n     \u2514\u2500\u2500 encoder\n-    \u2502   \u251c\u2500\u2500 encoder.yml\n-    \u2502   \u2514\u2500\u2500 encoder-head.yml\n+    \u2502   \u2514\u2500\u2500 encoder.yml\n     \u2514\u2500\u2500 indexer\n         \u251c\u2500\u2500 indexer-0.yml\n         \u251c\u2500\u2500 indexer-1.yml\n@@ -178,36 +177,64 @@ kubectl get pods -n custom-namespace\n NAME                              READY   STATUS    RESTARTS   AGE\n encoder-8b5575cb9-bh2x8           1/1     Running   0          60m\n encoder-8b5575cb9-gx78g           1/1     Running   0          60m\n-encoder-head-55bbb477ff-p2bmk   1/1     Running   0          60m\n gateway-7df8765bd9-xf5tf          1/1     Running   0          60m\n indexer-0-8f676fc9d-4fh52         1/1     Running   0          60m\n indexer-1-55b6cc9dd8-gtpf6        1/1     Running   0          60m\n-indexer-head-6fcc679d95-8mrm6   1/1     Running   0          60m\n+indexer-head-6fcc679d95-8mrm6     1/1     Running   0          60m\n ```\n \n Note that the Jina gateway was deployed with name `gateway-7df8765bd9-xf5tf`.\n \n Once we see that all the Deployments in the Flow are ready, we can start indexing documents.\n \n-```python\n-import portforward\n+First, you need to forward the Kubernetes services to your local machine by doing\n+\n+```bash \n+kubectl port-forward svc/gateway 8080:8080\n+```\n+\n+Now you can define a Client to connect to your Flow running in Kubernetes:\n \n+```python\n from jina.clients import Client\n+\n+client = Client(host='http://localhost:8080')\n+```\n+\n+Then you can index the set of images that you want to search:\n+\n+```python\n from docarray import DocumentArray\n \n-with portforward.forward('custom-namespace', 'gateway-7df8765bd9-xf5tf', 8080, 8080):\n-    client = Client(host='localhost', port=8080)\n-    client.show_progress = True\n-    docs = client.post(\n-        '/index',\n-        inputs=DocumentArray.from_files('./imgs/*.png').apply(\n-            lambda d: d.convert_uri_to_datauri()\n-        ),\n-    )\n+da = DocumentArray.pull('demo-da-images-jina', show_progress=True)\n+\n+da_query = da[0:1]  # one document for query\n+da_index = da[1:]  # the rest is for indexing\n \n-    print(f' Indexed documents: {len(docs)}')\n+indexed_docs = client.index(inputs=da_index)\n+print(f'Indexed Documents: {len(indexed_docs)}')\n ```\n \n+```shell\n+Indexed Documents: 99\n+```\n+\n+We indexer 99 Documents !\n+\n+Then, search for the closest image to our query image:\n+\n+```python\n+queried_docs = client.search(inputs=da_query)\n+\n+matches = queried_docs[0].matches\n+print(f'Matched Documents: {len(matches)}')\n+```\n+\n+```shell\n+Matched Documents: 10\n+```\n+Now have the list of the 10 closest image to the query !\n+\n (kubernetes-expose)=\n ## Exposing your Flow\n The previous examples use port-forwarding to index documents to the Flow. \n@@ -233,22 +260,14 @@ export EXTERNAL_IP=`kubectl get service gateway-exposed -n custom-namespace -o=j\n The client sends an image to the exposed `Flow` on `$EXTERNAL_IP` and retrieves the matches retrieved from the Flow.\n Finally, it prints the uri of the closest matches.\n \n+You will need to configure your Client to connect to the Flow via the external IP by doing:\n+\n ```python\n import os\n-\n from jina.clients import Client\n-from docarray import DocumentArray\n \n host = os.environ['EXTERNAL_IP']\n port = 80\n \n client = Client(host=host, port=port)\n-client.show_progress = True\n-docs = DocumentArray.from_files(\"./imgs/*.png\").apply(\n-    lambda d: d.convert_uri_to_datauri()\n-)\n-queried_docs = client.post(\"/search\", inputs=docs)\n-\n-matches = queried_docs[0].matches\n-print(f\"Matched documents: {len(matches)}\")\n ```\n\\ No newline at end of file\n\n\n###\n\n", "completion": "docs: document behaviour when things go wrong and redo k8s howto (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -29,6 +29,12 @@ All af these have to match the Flow and how it was set up:\n * the `host` and the `port` as exposed by the Flow\n * if it needs to use `TLS` encryption\n \n+    \n+````{Hint} Default port\n+The default port for the Client is `80` unless you are using `TLS` encryption it will be `443`\n+````\n+\n+\n You can define these parameters by passing a valid URI scheme as part of the `host` argument:\n \n ````{tab} TLS disabled\n\n\n###\n\n", "completion": "docs: add default port client (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1527,13 +1527,30 @@ def get_rich_console():\n \n from jina.parsers import set_client_cli_parser\n \n+__default_port_client__ = 80\n+__default_port_tls_client__ = 443\n \n-def parse_client(kwargs):\n+\n+def parse_client(kwargs) -> Namespace:\n+    \"\"\"\n+    Parse the kwargs for the Client\n+\n+    :param kwargs: kwargs to be parsed\n+\n+    :return: parsed argument.\n+    \"\"\"\n     kwargs = _parse_kwargs(kwargs)\n-    return ArgNamespace.kwargs2namespace(\n+    args = ArgNamespace.kwargs2namespace(\n         kwargs, set_client_cli_parser(), warn_unknown=True\n     )\n \n+    if not args.port:\n+        args.port = (\n+            __default_port_client__ if not args.tls else __default_port_tls_client__\n+        )\n+\n+    return args\n+\n \n def _parse_kwargs(kwargs: Dict[str, Any]) -> Dict[str, Any]:\n     if 'host' in kwargs.keys():\n@@ -1554,18 +1571,11 @@ def _parse_kwargs(kwargs: Dict[str, Any]) -> Dict[str, Any]:\n                 elif value:\n                     kwargs[key] = value\n \n-    kwargs = _add_default_port_tls(kwargs)\n     kwargs = _delete_host_slash(kwargs)\n \n     return kwargs\n \n \n-def _add_default_port_tls(kwargs: Dict[str, Any]) -> Dict[str, Any]:\n-    if ('tls' in kwargs) and ('port' not in kwargs):\n-        kwargs['port'] = 443\n-    return kwargs\n-\n-\n def _delete_host_slash(kwargs: Dict[str, Any]) -> Dict[str, Any]:\n     if 'host' in kwargs:\n         if kwargs['host'][-1] == '/':\n\n---\n file path A: jina/parsers/orchestrate/runtimes/remote.py | file path B: jina/parsers/orchestrate/runtimes/remote.py\n\n@@ -23,7 +23,7 @@ def mixin_client_gateway_parser(parser):\n     gp.add_argument(\n         '--port',\n         type=int,\n-        default=helper.random_port(),\n+        default=None,\n         help='The port of the Gateway, which the client should connect to.',\n     )\n \n\n---\n file path A: tests/unit/clients/test_interface.py | file path B: tests/unit/clients/test_interface.py\n\n@@ -37,7 +37,7 @@ def test_host_unpacking(protocol, gateway_type, tls, hostname):\n \n @pytest.mark.parametrize('protocol', ['https', 'grpcs', 'wss'])\n @pytest.mark.parametrize('port', [1234, None])\n-def test_host_unpacking(protocol, port):\n+def test_host_unpacking_port_tls(protocol, port):\n \n     port_scheme = f':{port}' if port else ''\n \n@@ -48,9 +48,9 @@ def test_host_unpacking(protocol, port):\n     assert c.args.port == port if port else 443\n \n \n-@pytest.mark.parametrize('protocol', ['https', 'grpcs', 'wss'])\n+@pytest.mark.parametrize('protocol', ['http', 'grpc', 'ws'])\n @pytest.mark.parametrize('port', [1234, None])\n-def test_host_unpacking(protocol, port):\n+def test_host_unpacking_port(protocol, port):\n \n     port_scheme = f':{port}' if port else ''\n \n@@ -58,7 +58,7 @@ def test_host_unpacking(protocol, port):\n \n     c = Client(host=host)\n \n-    assert c.args.port == port if port else 443\n+    assert c.args.port == port if port else 80\n \n \n def test_delete_slash_host():\n@@ -70,7 +70,7 @@ def test_delete_slash_host():\n     assert c.args.host == 'localhost'\n \n \n-def test_host_unpacking_port():\n+def test_host_unpacking_basic():\n \n     protocol = 'http'\n     hostname = 'localhost'\n\n\n###\n\n", "completion": "fix: client default port  (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -304,6 +304,7 @@ ac_table = {\n             '--when',\n             '--external',\n             '--deployment-role',\n+            '--tls',\n         ],\n         'client': [\n             '--help',\n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -297,7 +297,8 @@ class Deployment(BaseDeployment):\n         \"\"\"\n         has_cert = getattr(self.args, 'ssl_certfile', None) is not None\n         has_key = getattr(self.args, 'ssl_keyfile', None) is not None\n-        return self.is_sandbox or (has_cert and has_key)\n+        tls = getattr(self.args, 'tls', False)\n+        return tls or self.is_sandbox or (has_cert and has_key)\n \n     @property\n     def external(self) -> bool:\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -660,6 +660,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         timeout_ctrl: Optional[int] = 60,\n         timeout_ready: Optional[int] = 600000,\n         timeout_send: Optional[int] = None,\n+        tls: Optional[bool] = False,\n         upload_files: Optional[List[str]] = None,\n         uses: Optional[Union[str, Type['BaseExecutor'], dict]] = 'BaseExecutor',\n         uses_after: Optional[Union[str, Type['BaseExecutor'], dict]] = None,\n@@ -741,6 +742,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         :param timeout_ctrl: The timeout in milliseconds of the control request, -1 for waiting forever\n         :param timeout_ready: The timeout in milliseconds of a Pod waits for the runtime to be ready, -1 for waiting forever\n         :param timeout_send: The timeout in milliseconds used when sending data requests to Executors, -1 means no timeout, disabled by default\n+        :param tls: If set, connect to deployment using tls encryption\n         :param upload_files: The files on the host to be uploaded to the remote\n           workspace. This can be useful when your Deployment has more\n           file dependencies beyond a single YAML file, e.g.\n\n---\n file path A: jina/parsers/orchestrate/deployment.py | file path B: jina/parsers/orchestrate/deployment.py\n\n@@ -52,3 +52,10 @@ def mixin_base_deployment_parser(parser):\n         if _SHOW_ALL_ARGS\n         else argparse.SUPPRESS,\n     )\n+\n+    gp.add_argument(\n+        '--tls',\n+        action='store_true',\n+        default=False,\n+        help='If set, connect to deployment using tls encryption',\n+    )\n\n\n###\n\n", "completion": "fix: pass tls to the deployment (#<issue-num>)"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -20,7 +20,7 @@\n \n Jina is a neural search framework that empowers anyone to build SOTA and scalable neural search applications in minutes.\n \n-\u23f1\ufe0f **Save time** - *The* design pattern of neural search systems. Quickly build solutions for indexing, querying, understanding multi-/cross-modal data such as video, image, text, audio, source code, PDF.\n+\u23f1\ufe0f **Save time** - *The* design pattern of neural search systems. Quickly build solutions for indexing, querying, understanding multi-/cross-modal data such as video, image, text, audio, source code, PDF. Get it up and running right now using [Jina NOW](https://github.com/jina-ai/now)\n \n \ud83c\udf29\ufe0f **Local & cloud friendly** - Distributed architecture, scalable & cloud-native from day one. Same developer experience on local, [Docker Compose](https://docs.jina.ai/how-to/docker-compose/), [Kubernetes](https://docs.jina.ai/how-to/kubernetes/).\n \n\n\n###\n\n", "completion": "docs: add jina now (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -248,6 +248,7 @@ class Deployment(BaseDeployment):\n         self.head_pod = None\n         self.shards = {}\n         self.update_pod_args()\n+        self._sandbox_deployed = False\n \n     def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n         super().__exit__(exc_type, exc_val, exc_tb)\n@@ -261,8 +262,11 @@ class Deployment(BaseDeployment):\n         else:\n             self.pod_args = self._parse_args(self.args)\n \n+    def update_sandbox_args(self):\n+        \"\"\"Update args of all its pods based on the host and port returned by Hubble\"\"\"\n         if self.is_sandbox:\n             host, port = HubIO.deploy_public_sandbox(self.args)\n+            self._sandbox_deployed = True\n             self.first_pod_args.host = host\n             self.first_pod_args.port = port\n             if self.head_args:\n@@ -515,6 +519,9 @@ class Deployment(BaseDeployment):\n             If one of the :class:`Pod` fails to start, make sure that all of them\n             are properly closed.\n         \"\"\"\n+        if self.is_sandbox and not self._sandbox_deployed:\n+            self.update_sandbox_args()\n+\n         if self.pod_args['uses_before'] is not None:\n             _args = self.pod_args['uses_before']\n             if getattr(self.args, 'noblock_on_start', False):\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1027,6 +1027,9 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         if op_flow.args.inspect == FlowInspectType.COLLECT:\n             op_flow.gather_inspect(copy_flow=False)\n \n+        for deployment in self._deployment_nodes.values():\n+            deployment.update_sandbox_args()\n+\n         if GATEWAY_NAME not in op_flow._deployment_nodes:\n             op_flow._add_gateway(\n                 needs={op_flow._last_deployment},\n\n\n###\n\n", "completion": "fix: do not deploy sandbox on init (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -188,6 +188,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13839,3 +13840,28 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```a2b5e304```](https://github.com/jina-ai/jina/commit/a2b5e304f0881b0bbbc57a624f6682cf6d58790e)] __-__ Revert &#34;ci: add create-release.yml (#4759)&#34; (#4835) (*Han Xiao*)\n  - [[```f053d764```](https://github.com/jina-ai/jina/commit/f053d764cd96f1faba336ed9ff50ab82debafaa1)] __-__ __version__: the next version will be 3.4.9 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-10></a>\n+## Release Note (`3.4.10`)\n+\n+> Release time: 2022-05-30 06:57:45\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Deepankar Mahapatro,  samsja,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```b780b797```](https://github.com/jina-ai/jina/commit/b780b7971fe4ba64d1b4b97a70d74e27a23ea03e)] __-__ __websocket__: http healthcheck endpoint (#4836) (*Deepankar Mahapatro*)\n+ - [[```ed626d99```](https://github.com/jina-ai/jina/commit/ed626d991eb9059035786b99ae0fb0e77475b0d3)] __-__ __http__: disable healthcheck access logs with env (#4814) (*Deepankar Mahapatro*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```9d792ad9```](https://github.com/jina-ai/jina/commit/9d792ad9536c44fcf051eab4d1832740f957b9a1)] __-__ remove tag from save config yaml (#4809) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```a6e64553```](https://github.com/jina-ai/jina/commit/a6e645539fa30cea496cbee5d687d9d02a39949b)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```b3b3a44f```](https://github.com/jina-ai/jina/commit/b3b3a44f64b80d4f7bd0b4be39f63e7df7b6cbe1)] __-__ __version__: the next version will be 3.4.10 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.10'\n+__version__ = '3.4.11'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.11"}
{"prompt": " file path A: jina/serve/runtimes/gateway/websocket/__init__.py | file path B: jina/serve/runtimes/gateway/websocket/__init__.py\n\n@@ -1,4 +1,5 @@\n import asyncio\n+import logging\n import os\n \n from jina import __default_host__\n@@ -47,6 +48,16 @@ class WebSocketGatewayRuntime(GatewayRuntime):\n                 \"\"\"\n                 await self.main_loop()\n \n+        if 'JINA_DISABLE_HEALTHCHECK_LOGS' in os.environ:\n+\n+            class _EndpointFilter(logging.Filter):\n+                def filter(self, record: logging.LogRecord) -> bool:\n+                    # NOTE: space is important after `GET /`, else all logs will be disabled.\n+                    return record.getMessage().find(\"GET / \") == -1\n+\n+            # Filter out healthcheck endpoint `GET /`\n+            logging.getLogger(\"uvicorn.access\").addFilter(_EndpointFilter())\n+\n         from jina.helper import extend_rest_interface\n \n         uvicorn_kwargs = self.args.uvicorn_kwargs or {}\n\n---\n file path A: jina/serve/runtimes/gateway/websocket/app.py | file path B: jina/serve/runtimes/gateway/websocket/app.py\n\n@@ -130,6 +130,18 @@ def get_fastapi_app(\n \n     streamer.Call = streamer.stream\n \n+    @app.get(\n+        path='/',\n+        summary='Get the health of Jina service',\n+    )\n+    async def _health():\n+        \"\"\"\n+        Get the health of this Jina service.\n+        .. # noqa: DAR201\n+\n+        \"\"\"\n+        return {}\n+\n     @app.on_event('shutdown')\n     async def _shutdown():\n         await connection_pool.close()\n\n---\n file path A: tests/unit/serve/runtimes/gateway/http/test_app.py | file path B: tests/unit/serve/runtimes/gateway/http/test_app.py\n\n@@ -275,9 +275,25 @@ def test_app_models_acceptance(docs_input):\n     assert DocumentArray.from_dict(r.json()['data'])[0].text == 'text_input'\n \n \n-def test_healthcheck_logs(capfd):\n+@pytest.fixture\n+def health_check_env():\n+    _prev_loglevel = os.environ.get('JINA_LOG_LEVEL', None)\n     os.environ['JINA_LOG_LEVEL'] = 'INFO'\n+    os.environ['JINA_DISABLE_HEALTHCHECK_LOGS'] = '1'\n+    yield\n+    os.environ['JINA_LOG_LEVEL'] = _prev_loglevel\n+    os.environ.pop('JINA_DISABLE_HEALTHCHECK_LOGS')\n+\n \n+@pytest.fixture\n+def no_health_check_env():\n+    _prev_loglevel = os.environ.get('JINA_LOG_LEVEL', None)\n+    os.environ['JINA_LOG_LEVEL'] = 'INFO'\n+    yield\n+    os.environ['JINA_LOG_LEVEL'] = _prev_loglevel\n+\n+\n+def test_healthcheck_logs_http(capfd, no_health_check_env):\n     f = Flow(protocol='http', port=12345).add()\n     with f:\n         req.get('http://localhost:12345/')\n@@ -288,10 +304,7 @@ def test_healthcheck_logs(capfd):\n     assert '\"GET /docs HTTP/1.1\" 200 OK' in out\n \n \n-def test_no_healthcheck_logs_with_env(capfd):\n-    os.environ['JINA_LOG_LEVEL'] = 'INFO'\n-    os.environ['JINA_DISABLE_HEALTHCHECK_LOGS'] = '1'\n-\n+def test_no_healthcheck_logs_http_with_env(capfd, health_check_env):\n     f = Flow(protocol='http', port=12345).add()\n     with f:\n         req.get('http://localhost:12345/')\n@@ -300,3 +313,23 @@ def test_no_healthcheck_logs_with_env(capfd):\n     out, _ = capfd.readouterr()\n     assert '\"GET / HTTP/1.1\" 200 OK' not in out\n     assert '\"GET /docs HTTP/1.1\" 200 OK' in out\n+\n+\n+def test_healthcheck_logs_websocket(capfd, no_health_check_env):\n+    f = Flow(protocol='websocket', port=12345).add()\n+    with f:\n+        req.get('http://localhost:12345/')\n+        f.post('/', inputs=DocumentArray.empty())\n+\n+    out, _ = capfd.readouterr()\n+    assert '\"GET / HTTP/1.1\" 200 OK' in out\n+\n+\n+def test_healthcheck_logs_websocket_with_env(capfd, health_check_env):\n+    f = Flow(protocol='websocket', port=12345).add()\n+    with f:\n+        f.post('/', inputs=DocumentArray.empty())\n+        req.get('http://localhost:12345/')\n+\n+    out, _ = capfd.readouterr()\n+    assert '\"GET / HTTP/1.1\" 200 OK' not in out\n\n\n###\n\n", "completion": "feat(websocket): http healthcheck endpoint (#<issue-num>)"}
{"prompt": " file path A: jina/jaml/__init__.py | file path B: jina/jaml/__init__.py\n\n@@ -554,8 +554,16 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n         \"\"\"\n         from jina.jaml.parsers import get_parser\n \n-        tmp = get_parser(cls, version=data._version).dump(data)\n-        return representer.represent_mapping('!' + cls.__name__, tmp)\n+        config_dict = get_parser(cls, version=data._version).dump(data)\n+        config_dict_with_jtype = {\n+            'jtype': cls.__name__\n+        }  # specifies the type of Jina object that is represented\n+        config_dict_with_jtype.update(config_dict)\n+        # To maintain compatibility with off-the-shelf parsers we don't want any tags ('!...') to show up in the output\n+        # Since pyyaml insists on receiving a tag, we need to pass the default map tag. This won't show up in the output\n+        return representer.represent_mapping(\n+            representer.DEFAULT_MAPPING_TAG, config_dict_with_jtype\n+        )\n \n     @classmethod\n     def _from_yaml(cls, constructor: FullConstructor, node):\n\n---\n file path A: tests/unit/jaml/test_type_parse.py | file path B: tests/unit/jaml/test_type_parse.py\n\n@@ -1,6 +1,7 @@\n import os\n \n import pytest\n+import yaml\n \n from jina import Flow, __default_executor__, requests\n from jina.excepts import BadConfigSource\n@@ -190,3 +191,25 @@ def test_exception_invalid_yaml():\n \n     with pytest.raises(BadConfigSource):\n         Flow.load_config(yaml)\n+\n+\n+def test_jtype(tmpdir):\n+    flow_path = os.path.join(tmpdir, 'flow.yml')\n+    exec_path = os.path.join(tmpdir, 'exec.yml')\n+\n+    f = Flow()\n+    f.save_config(flow_path)\n+    with open(flow_path, 'r') as file:\n+        conf = yaml.safe_load(file)\n+        assert 'jtype' in conf\n+        assert conf['jtype'] == 'Flow'\n+\n+    e = BaseExecutor()\n+    e.save_config(exec_path)\n+    with open(exec_path, 'r') as file:\n+        conf = yaml.safe_load(file)\n+        assert 'jtype' in conf\n+        assert conf['jtype'] == 'BaseExecutor'\n+\n+    assert type(BaseExecutor.load_config(exec_path)) == BaseExecutor\n+    assert type(Flow.load_config(flow_path)) == Flow\n\n\n###\n\n", "completion": "fix: remove tag from save config yaml (#<issue-num>)"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -105,6 +105,7 @@ __jina_env__ = (\n     'JINA_RANDOM_PORT_MAX',\n     'JINA_RANDOM_PORT_MIN',\n     'JINA_VCS_VERSION',\n+    'JINA_DISABLE_HEALTHCHECK_LOGS',\n )\n \n __default_host__ = _os.environ.get(\n\n---\n file path A: jina/serve/runtimes/gateway/http/__init__.py | file path B: jina/serve/runtimes/gateway/http/__init__.py\n\n@@ -1,4 +1,5 @@\n import asyncio\n+import logging\n import os\n \n from jina import __default_host__\n@@ -47,6 +48,16 @@ class HTTPGatewayRuntime(GatewayRuntime):\n                 \"\"\"\n                 await self.main_loop()\n \n+        if 'JINA_DISABLE_HEALTHCHECK_LOGS' in os.environ:\n+\n+            class _EndpointFilter(logging.Filter):\n+                def filter(self, record: logging.LogRecord) -> bool:\n+                    # NOTE: space is important after `GET /`, else all logs will be disabled.\n+                    return record.getMessage().find(\"GET / \") == -1\n+\n+            # Filter out healthcheck endpoint `GET /`\n+            logging.getLogger(\"uvicorn.access\").addFilter(_EndpointFilter())\n+\n         from jina.helper import extend_rest_interface\n \n         uvicorn_kwargs = self.args.uvicorn_kwargs or {}\n\n---\n file path A: tests/unit/serve/runtimes/gateway/http/test_app.py | file path B: tests/unit/serve/runtimes/gateway/http/test_app.py\n\n@@ -273,3 +273,30 @@ def test_app_models_acceptance(docs_input):\n         r = req.post(f'http://localhost:{f.port}/index', json=docs_input)\n \n     assert DocumentArray.from_dict(r.json()['data'])[0].text == 'text_input'\n+\n+\n+def test_healthcheck_logs(capfd):\n+    os.environ['JINA_LOG_LEVEL'] = 'INFO'\n+\n+    f = Flow(protocol='http', port=12345).add()\n+    with f:\n+        req.get('http://localhost:12345/')\n+        req.get('http://localhost:12345/docs')\n+\n+    out, _ = capfd.readouterr()\n+    assert '\"GET / HTTP/1.1\" 200 OK' in out\n+    assert '\"GET /docs HTTP/1.1\" 200 OK' in out\n+\n+\n+def test_no_healthcheck_logs_with_env(capfd):\n+    os.environ['JINA_LOG_LEVEL'] = 'INFO'\n+    os.environ['JINA_DISABLE_HEALTHCHECK_LOGS'] = '1'\n+\n+    f = Flow(protocol='http', port=12345).add()\n+    with f:\n+        req.get('http://localhost:12345/')\n+        req.get('http://localhost:12345/docs')\n+\n+    out, _ = capfd.readouterr()\n+    assert '\"GET / HTTP/1.1\" 200 OK' not in out\n+    assert '\"GET /docs HTTP/1.1\" 200 OK' in out\n\n\n###\n\n", "completion": "feat(http): disable healthcheck access logs with env (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -187,6 +187,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13816,3 +13817,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```eae5d07f```](https://github.com/jina-ai/jina/commit/eae5d07f352ceb26502373c11259c2d751c71eeb)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```0b2bd2a4```](https://github.com/jina-ai/jina/commit/0b2bd2a405f6c0fc57d2bf7cb42b29af280bc0b9)] __-__ __version__: the next version will be 3.4.8 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-9></a>\n+## Release Note (`3.4.9`)\n+\n+> Release time: 2022-05-26 11:40:41\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```674e8121```](https://github.com/jina-ai/jina/commit/674e8121fb5dfdac4ce88a8ade1d248d16b75617)] __-__ success box ui (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```a2b5e304```](https://github.com/jina-ai/jina/commit/a2b5e304f0881b0bbbc57a624f6682cf6d58790e)] __-__ Revert &#34;ci: add create-release.yml (#4759)&#34; (#4835) (*Han Xiao*)\n+ - [[```f053d764```](https://github.com/jina-ai/jina/commit/f053d764cd96f1faba336ed9ff50ab82debafaa1)] __-__ __version__: the next version will be 3.4.9 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.9'\n+__version__ = '3.4.10'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.10"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1635,7 +1635,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                 )\n             address_table.add_row(\n                 ':speech_balloon:',\n-                'Swagger UI',\n+                'Swagger UI [dim](/docs)[/]',\n                 '\u00b7'.join(_address),\n             )\n \n@@ -1651,7 +1651,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n             address_table.add_row(\n                 ':books:',\n-                'Redoc',\n+                'Redoc [dim](/redoc)[/]',\n                 '\u00b7'.join(_address),\n             )\n \n@@ -1668,7 +1668,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n                 address_table.add_row(\n                     ':strawberry:',\n-                    'GraphQL UI',\n+                    'GraphQL UI [dim](/graphql)[/]',\n                     '\u00b7'.join(_address),\n                 )\n \n@@ -1687,7 +1687,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                 if deployment.args.monitoring:\n                     address_table.add_row(\n                         ':bar_chart:',\n-                        f'Monitor [b]{name}[/]',\n+                        f'Monitor [b]{name}:{deployment.args.port_monitoring}[/]',\n                         '\u00b7'.join(_address),\n                     )\n \n\n\n###\n\n", "completion": "fix: success box ui"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -186,6 +186,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13786,3 +13787,32 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```2950d640```](https://github.com/jina-ai/jina/commit/2950d64073783bc1885ea39727661bc0a14fc668)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```5c72155f```](https://github.com/jina-ai/jina/commit/5c72155faee74423638ca7a72a5086cc4bf14106)] __-__ __version__: the next version will be 3.4.7 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-8></a>\n+## Release Note (`3.4.8`)\n+\n+> Release time: 2022-05-26 11:15:35\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Joan Fontanals,  AlaeddineAbdessalem,  Jina Dev Bot,  samsja,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```d7998903```](https://github.com/jina-ai/jina/commit/d7998903a24c8c223a92be802896288fdf97b7b4)] __-__ cuda visible device (#4834) (*Han Xiao*)\n+ - [[```65daf752```](https://github.com/jina-ai/jina/commit/65daf752e330842ddeab847beb47caff78500992)] __-__ fix protobuf dependency (#4830) (*AlaeddineAbdessalem*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```7ad728d0```](https://github.com/jina-ai/jina/commit/7ad728d0e00c085dd19d0b9f2511264857cb65bb)] __-__ __docs__: update docker compose docs (#4820) (*samsja*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```0a8a4fa6```](https://github.com/jina-ai/jina/commit/0a8a4fa6d9aeddc2a1271b7db16c8cac8b66b2b5)] __-__ fix tests because join disappeared (#4832) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```eae5d07f```](https://github.com/jina-ai/jina/commit/eae5d07f352ceb26502373c11259c2d751c71eeb)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```0b2bd2a4```](https://github.com/jina-ai/jina/commit/0b2bd2a405f6c0fc57d2bf7cb42b29af280bc0b9)] __-__ __version__: the next version will be 3.4.8 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.8'\n+__version__ = '3.4.9'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.9"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -639,7 +639,12 @@ class Deployment(BaseDeployment):\n         :param replicas: the number of replicas\n         :return: a map from replica id to device id\n         \"\"\"\n-        if device_str and device_str.startswith('RR') and replicas >= 1:\n+        if (\n+            device_str\n+            and isinstance(device_str, str)\n+            and device_str.startswith('RR')\n+            and replicas >= 1\n+        ):\n             try:\n                 num_devices = str(subprocess.check_output(['nvidia-smi', '-L'])).count(\n                     'UUID'\n\n\n###\n\n", "completion": "fix: cuda visible device (#<issue-num>)"}
{"prompt": " file path A: tests/unit/orchestrate/flow/flow-construct/test_flow.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow.py\n\n@@ -80,7 +80,7 @@ def test_flow_identical(tmpdir):\n         .add(name='chunk_seg', shards=3)\n         .add(name='wqncode1', shards=2)\n         .add(name='encode2', shards=2, needs='chunk_seg')\n-        .join(['wqncode1', 'encode2'])\n+        .needs(['wqncode1', 'encode2'])\n     )\n \n     a.save_config(os.path.join(str(tmpdir), 'test2.yml'))\n@@ -132,7 +132,7 @@ def test_py_client():\n \n \n def test_dry_run_with_two_pathways_diverging_at_gateway():\n-    f = Flow().add(name='r2').add(name='r3', needs='gateway').join(['r2', 'r3'])\n+    f = Flow().add(name='r2').add(name='r3', needs='gateway').needs(['r2', 'r3'])\n \n     with f:\n         _validate_flow(f)\n@@ -144,7 +144,7 @@ def test_dry_run_with_two_pathways_diverging_at_non_gateway():\n         .add(name='r1')\n         .add(name='r2')\n         .add(name='r3', needs='r1')\n-        .join(['r2', 'r3'])\n+        .needs(['r2', 'r3'])\n     )\n \n     with f:\n@@ -156,7 +156,7 @@ def test_refactor_num_part():\n         Flow()\n         .add(name='r1', needs='gateway')\n         .add(name='r2', needs='gateway')\n-        .join(['r1', 'r2'])\n+        .needs(['r1', 'r2'])\n     )\n \n     with f:\n@@ -169,7 +169,7 @@ def test_refactor_num_part_proxy():\n         .add(name='r1')\n         .add(name='r2', needs='r1')\n         .add(name='r3', needs='r1')\n-        .join(['r2', 'r3'])\n+        .needs(['r2', 'r3'])\n     )\n \n     with f:\n@@ -231,7 +231,7 @@ def test_flow_with_publish_driver(protocol):\n         Flow(protocol=protocol)\n         .add(name='r2', uses=DummyOneHotTextEncoder)\n         .add(name='r3', uses=DummyOneHotTextEncoder, needs='gateway')\n-        .join(needs=['r2', 'r3'])\n+        .needs(needs=['r2', 'r3'])\n     )\n \n     with f:\n@@ -399,7 +399,7 @@ def test_socket_types_2_remote_one_local():\n         .add(name='executor1', host='0.0.0.1')\n         .add(name='executor2', shards=2, host='0.0.0.2')\n         .add(name='executor3', shards=2, host='1.2.3.4', needs=['gateway'])\n-        .join(name='join', needs=['executor2', 'executor3'])\n+        .needs(name='join', needs=['executor2', 'executor3'])\n     )\n \n     f.build()\n@@ -413,7 +413,7 @@ def test_socket_types_2_remote_one_local_input_socket_pull_connect_from_remote()\n         .add(name='executor1', host='0.0.0.1')\n         .add(name='executor2', shards=2, host='0.0.0.2')\n         .add(name='executor3', shards=2, host='1.2.3.4', needs=['gateway'])\n-        .join(name='join', needs=['executor2', 'executor3'])\n+        .needs(name='join', needs=['executor2', 'executor3'])\n     )\n \n     f.build()\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py\n\n@@ -36,7 +36,7 @@ def test_visualization_plot_twice(tmpdir):\n         .add(name='pod_a')\n         .plot(output=os.path.join(tmpdir, 'flow1.svg'))\n         .add(name='pod_b', needs='gateway')\n-        .join(needs=['pod_a', 'pod_b'])\n+        .needs(['pod_a', 'pod_b'])\n         .plot(output=os.path.join(tmpdir, 'flow2.svg'))\n     )\n \n@@ -50,7 +50,7 @@ def test_visualization_plot_in_middle(tmpdir):\n         .add(name='pod_a')\n         .plot(output=os.path.join(tmpdir, 'flow3.svg'))\n         .add(name='pod_b', needs='gateway')\n-        .join(needs=['pod_a', 'pod_b'])\n+        .needs(['pod_a', 'pod_b'])\n     )\n \n     assert os.path.exists(os.path.join(tmpdir, 'flow3.svg'))\n\n---\n file path A: tests/unit/yaml/examples/faces/flow-index.yml | file path B: tests/unit/yaml/examples/faces/flow-index.yml\n\n@@ -4,20 +4,20 @@ metas:\n   prefetch: 10\n executors:\n   - name: loader\n-    parallel: 4\n+    shards: 4\n     read_only: true\n   - name: flipper\n-    parallel: 4\n+    shards: 4\n     read_only: true\n   - name: normalizer\n-    parallel: 4\n+    shards: 4\n     read_only: true\n   - name: encoder\n-    parallel: 4\n+    shards: 4\n     timeout_ready: 600000\n     read_only: true\n   - name: chunk_indexer\n-    parallel: 1\n+    shards: 1\n   - name: doc_indexer\n     needs: loader\n   - name: join_all\n\n---\n file path A: tests/unit/yaml/examples/faces/flow-query.yml | file path B: tests/unit/yaml/examples/faces/flow-query.yml\n\n@@ -6,20 +6,20 @@ with:\n executors:\n   - name: loader\n     read_only: true\n-    parallel: 4\n+    shards: 4\n   - name: flipper\n-    parallel: 4\n+    shards: 4\n     read_only: true\n   - name: normalizer\n     read_only: true\n-    parallel: 4\n+    shards: 4\n   - name: encoder\n     timeout_ready: 600000\n-    parallel: 4\n+    shards: 4\n     read_only: true\n   - name: chunk_indexer\n     polling: all\n-    parallel: 1\n+    shards: 1\n   - name: ranker\n   - name: doc_indexer\n-    parallel: 1\n+    shards: 1\n\n---\n file path A: tests/unit/yaml/examples/faiss/flow-index.yml | file path B: tests/unit/yaml/examples/faiss/flow-index.yml\n\n@@ -4,11 +4,11 @@ metas:\n   prefetch: 10\n executors:\n   - name: crafter\n-    parallel: 4\n+    shards: 4\n   - name: encoder\n-    parallel: 4\n+    shards: 4\n   - name: faiss_indexer\n-    parallel: 1\n+    shards: 1\n   - name: doc_indexer\n     needs: crafter\n   - name: join_all\n\n---\n file path A: tests/unit/yaml/examples/faiss/flow-query.yml | file path B: tests/unit/yaml/examples/faiss/flow-query.yml\n\n@@ -4,13 +4,13 @@ with:\n   read_only: true\n executors:\n   - name: crafter\n-    parallel: 4\n+    shards: 4\n   - name: encoder\n-    parallel: 4\n+    shards: 4\n   - name: faiss_indexer\n-    parallel: 1\n+    shards: 1\n     timeout_ready: 10000\n     volumes: './workspace'\n   - name: ranker\n   - name: doc_indexer\n-    parallel: 1\n+    shards: 1\n\n---\n file path A: tests/unit/yaml/test-flow-v1.yml | file path B: tests/unit/yaml/test-flow-v1.yml\n\n@@ -4,12 +4,12 @@ with:\n   sse_logger: false\n executors:\n   - name: chunk_seg\n-    parallel: 3\n+    shards: 3\n   - name: wqncode1\n-    parallel: 2\n+    shards: 2\n     needs: chunk_seg\n   - name: encode2\n-    parallel: 2\n+    shards: 2\n     needs: chunk_seg\n   - name: joiner\n     needs: [wqncode1, encode2]\n\n---\n file path A: tests/unit/yaml/test-flow.yml | file path B: tests/unit/yaml/test-flow.yml\n\n@@ -4,12 +4,12 @@ with:\n   sse_logger: false\n executors:\n   - name: chunk_seg\n-    parallel: 3\n+    shards: 3\n   - name: wqncode1\n-    parallel: 2\n+    shards: 2\n     needs: chunk_seg\n   - name: encode2\n-    parallel: 2\n+    shards: 2\n     needs: chunk_seg\n   - name: joiner\n     needs: [wqncode1, encode2]\n\n---\n file path A: tests/unit/yaml/test_flow_visualization.yml | file path B: tests/unit/yaml/test_flow_visualization.yml\n\n@@ -7,7 +7,7 @@ executors:\n     read_only: true\n   - name: image_encoder\n     read_only: true\n-    parallel: 4\n+    shards: 4\n   - name: image_vector_indexer\n     read_only: true\n   - name: image_kv_indexer\n@@ -15,7 +15,7 @@ executors:\n   - name: text_encoder\n     timeout_ready: 600000\n     read_only: true\n-    parallel: 4\n+    shards: 4\n     needs: [gateway]\n   - name: text_indexer\n     read_only: true\n\n\n###\n\n", "completion": "test: fix tests because join disappeared (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -26,7 +26,7 @@\n # demo: required for the hello world demos\n \n numpy:                      core\n-protobuf>=3.19.1:           core\n+protobuf>=3.19.1,<=3.20.1:  core\n grpcio>=1.46.0:             core\n grpcio-reflection>=1.46.0:  core\n pyyaml>=5.3.1:              core\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -26,7 +26,7 @@\n # demo: required for the hello world demos\n \n numpy:                      core\n-protobuf>=3.19.1:           core\n+protobuf>=3.19.1,<=3.20.1:  core\n grpcio>=1.46.0:             core\n grpcio-reflection>=1.46.0:  core\n pyyaml>=5.3.1:              core\n\n\n###\n\n", "completion": "fix: fix protobuf dependency (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/docker-compose.md | file path B: docs/how-to/docker-compose.md\n\n@@ -12,9 +12,15 @@ By default, if you are serving your Flow locally they will live within processes\n because Jina is cloud native your Flow can easily manage Executors that live in containers and that are\n orchestrated by your favorite tools. One of the simplest is Docker Compose which is supported out of the box. \n \n-You can use this with one line:\n+You can deploy a FLow with Docker Compose with one line:\n \n-```python\n+\n+```{code-block} python\n+---\n+emphasize-lines: 3\n+---\n+from jina import Flow\n+flow = Flow(...).add(...).add(...)\n flow.to_docker_compose_yaml('docker-compose.yml')\n ```\n \n@@ -28,57 +34,64 @@ All Executors in the Flow should be used with `jinahub+docker://...` or `docker:\n ```{caution}\n If you are using Executor which rely on docker image built with a jina version prior to 3.1.3, please remove the \n health check from the dump yaml file as they are only compatible with 3.1.3+ otherwise your docker compose services will \n-always be `unhealthy\n-```\n-## Example: Indexing and searching images using CLIP image encoder and PQLiteIndexer\n-\n-\n-### Deploy your Flow\n-\n-\n-```{admonition} Caution\n-:class: caution\n-First ensure [`Docker Compose`](https://docs.docker.com/compose/install/) is installed locally.\n+always be `unhealthy`\n ```\n+## Example: Indexing and searching images using CLIPEncoder and ANNLiteIndexer\n \n-```{admonition} Caution\n-:class: caution\n-Before starting this example, make sure that CLIPImageEncoder and PQLiteIndexer images are already pulled to your local machine.\n-\n-You can use:\n-\n-`jina hub pull jinahub+docker://CLIPImageEncoder`\n-`jina hub pull jinahub+docker://PQLiteIndexer`\n-```\n+To follow this how-to, you should first ensure that [`Docker Compose`](https://docs.docker.com/compose/install/) is installed locally.\n \n This example shows how to build and deploy a Flow with Docker Compose, using [`CLIPImageEncoder`](https://hub.jina.ai/executor/0hnlmu3q)\n as an image encoder and [`PQLiteIndexer`](https://hub.jina.ai/executor/pn1qofsj) as an indexer to perform fast nearest\n neighbor retrieval on image embeddings.\n \n+### Deploy your Flow\n+\n+First let's define the Flow.\n+\n+````{tab} Python\n ```python\n from jina import Flow\n \n-f = (\n+flow = (\n     Flow(port=8080, protocol='http')\n-    .add(name='encoder', uses='jinahub+docker://CLIPImageEncoder', replicas=2)\n+    .add(name='encoder', uses='jinahub+docker://CLIPEncoder', replicas=2)\n     .add(\n         name='indexer',\n-        uses='jinahub+docker://PQLiteIndexer',\n+        uses='jinahub+docker://AnnLiteIndexer',\n         uses_with={'dim': 512},\n         shards=2,\n     )\n )\n ```\n+````\n+````{tab} YAML\n+\n+```yaml\n+jtype: Flow\n+with:\n+  port: 8080\n+  protocol: http\n+executors:\n+- name: encoder\n+  uses: jinahub+docker://CLIPEncoder\n+  replicas: 2\n+- name: indexer\n+  uses: jinahub+docker://AnnLiteIndexer\n+  uses_with:\n+    dim: 512\n+  shards: 2\n+```\n+````\n \n Now, we can generate Docker Compose YAML configuration from the Flow:\n \n ```python\n-f.to_docker_compose_yaml('docker-compose.yml')\n+flow.to_docker_compose_yaml('docker-compose.yml')\n ```\n \n ````{admonition} Hint\n :class: hint\n-You can use a custom Docker image for the Gateway service. Just set the envrironment variable `JINA_GATEWAY_IMAGE` to the desired image before generating the configuration.\n+You can use a custom jina Docker image for the Gateway service. Just set the envrironment variable `JINA_GATEWAY_IMAGE` to the desired image before generating the configuration.\n ````\n \n let's take a look at the generated compose file:\n@@ -86,15 +99,13 @@ let's take a look at the generated compose file:\n version: '3.3'\n ...\n services:\n-  encoder-head:   # # # # # # # # # # # \n-                  #                   #   \n-  encoder-rep-0:  #   Encoder         #\n-                  #                   #\n+  encoder-rep-0:  # # # # # # # # # # #          \n+                  #     Encoder       #\n   encoder-rep-1:  # # # # # # # # # # #\n \n-  indexer-head:   # # # # # # # # # # # \n-                  #                   #   \n-  indexer-0:      #   Indexer         #\n+  indexer-head:   # # # # # # # # # # #          \n+                  #                   #\n+  indexer-0:      #     Indexer       #\n                   #                   #\n   indexer-1:      # # # # # # # # # # #\n \n@@ -104,27 +115,25 @@ services:\n     - 8080:8080\n ```\n \n-```{admonition} Caution\n+```{tip} \n :class: caution\n The default compose file generated by the Flow contains no special configuration or settings. You may want to \n adapt it to your own needs.\n ```\n \n-Here you can see that 7 services will be created:\n+Here you can see that 5 services will be created:\n \n - 1 for the `gateway` which is the entrypoint of the `Flow`.\n-- 3 associated with the encoder: one for the Head and two for the Replicas.\n+- 2 associated with the encoder for the two Replicas.\n - 3 associated with the indexer, one for the Head and two for the Shards.\n \n-Now, you can deploy this Flow to your cluster:\n+Now, you can deploy this Flow :\n \n ```shell\n docker-compose -f docker-compose.yml up\n ```\n \n-### Use your search engine and query your Flow\n-\n-Now that your Flow is up and running in your docker-compose you can to query it:\n+### Query your Flow\n \n Once we see that all the services in the Flow are ready, we can start sending index and search requests.\n \n@@ -132,37 +141,43 @@ First let's define a client:\n ```python\n from jina.clients import Client\n \n-client = Client(host='localhost', protocol='http', port=8080)\n-client.show_progress = True\n+client = Client(host='http://localhost:8080')\n ```\n \n Then let's index the set of images we want to search:\n \n-```{admonition} Caution\n-:class: caution\n-Before using your Flow, ensure you have several `.jpg` images in the `./imgs` folder.\n-```\n-\n ```python\n from docarray import DocumentArray\n \n-indexing_documents = DocumentArray.from_files('./imgs/*.jpg').apply(\n-    lambda d: d.load_uri_to_image_tensor()\n-)\n+da = DocumentArray.pull('demo-da-images-jina', show_progress=True)\n \n-indexed_docs = client.post('/index', inputs=indexing_documents)\n+da_query = da[0:1]  # one document for query\n+da_index = da[1:]  # the rest is for indexing\n \n+indexed_docs = client.index(inputs=da_index)\n print(f'Indexed Documents: {len(indexed_docs)}')\n ```\n \n+```shell\n+Indexed Documents: 99\n+```\n+\n+We indexer 99 Documents !\n+\n Then let's search for the closest image to our query image:\n \n ```python\n-query_doc = indexing_documents[0]\n-queried_docs = client.post(\"/search\", inputs=[query_doc])\n+queried_docs = client.search(inputs=da_query)\n \n matches = queried_docs[0].matches\n-print(f'Matched documents: {len(matches)}')\n+print(f'Matched Documents: {len(matches)}')\n ```\n \n \n+```shell\n+Matched Documents: 10\n+```\n+\n+Now have the list of the 10 closest image to the query !\n+\n+\n\n\n###\n\n", "completion": "refactor(docs): update docker compose docs (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -185,6 +185,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13759,3 +13760,28 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```174dbde1```](https://github.com/jina-ai/jina/commit/174dbde1922b422b934e0ed0d7ea910657ecb510)] __-__ add security analysis (*Han Xiao*)\n  - [[```93db296a```](https://github.com/jina-ai/jina/commit/93db296a365a6805f0c55d8ae5078734d6cd00d0)] __-__ __version__: the next version will be 3.4.6 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-7></a>\n+## Release Note (`3.4.7`)\n+\n+> Release time: 2022-05-24 07:44:20\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Ahmet T\u00fcrkmen,  Mohammad Kalim Akram,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```b70da3b4```](https://github.com/jina-ai/jina/commit/b70da3b4ab84e12fe4b7e0f1ffc3a2e3c2828ed3)] __-__ add missing logo file (#4822) (*Mohammad Kalim Akram*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```1ec26558```](https://github.com/jina-ai/jina/commit/1ec26558a446a89917f0cb80f9aec7b73b9c20ba)] __-__ add create-release.yml (#4759) (*Ahmet T\u00fcrkmen*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```75c6413f```](https://github.com/jina-ai/jina/commit/75c6413fdbb7bf2daf68a06c28fd348c21dde0cb)] __-__ fix docarray dependency (*Han Xiao*)\n+ - [[```2950d640```](https://github.com/jina-ai/jina/commit/2950d64073783bc1885ea39727661bc0a14fc668)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```5c72155f```](https://github.com/jina-ai/jina/commit/5c72155faee74423638ca7a72a5086cc4bf14106)] __-__ __version__: the next version will be 3.4.7 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.7'\n+__version__ = '3.4.8'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -31,13 +31,13 @@ grpcio>=1.46.0:             core\n grpcio-reflection>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray:                   core\n+docarray>=0.13.14:          core\n lz4<3.1.2:                  perf, standard,devel\n uvloop:                     perf, standard,devel\n prometheus_client:          perf, standard,devel\n fastapi>=0.76.0:            standard,devel, demo\n uvicorn[standard]:          standard,devel, demo\n-docarray[common]:           standard,devel\n+docarray[common]>=0.13.14:  standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.8"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -31,13 +31,13 @@ grpcio>=1.46.0:             core\n grpcio-reflection>=1.46.0:  core\n pyyaml>=5.3.1:              core\n packaging>=20.0:            core\n-docarray:                   core\n+docarray>=0.13.14:          core\n lz4<3.1.2:                  perf, standard,devel\n uvloop:                     perf, standard,devel\n prometheus_client:          perf, standard,devel\n fastapi>=0.76.0:            standard,devel, demo\n uvicorn[standard]:          standard,devel, demo\n-docarray[common]:           standard,devel\n+docarray[common]>=0.13.14:  standard,devel\n docker:                     standard,devel\n pathspec:                   standard,devel\n cryptography:               standard,devel\n\n\n###\n\n", "completion": "chore: fix docarray dependency"}
{"prompt": " file path A: None | file path B: .github/workflows/create-release.yml\n\n@@ -0,0 +1,47 @@\n+\n+name: Create Release\n+\n+on:\n+  workflow_dispatch:\n+    inputs:\n+      release_token:\n+        description: 'Your release token'\n+        required: true\n+      triggered_by:\n+        description: 'TAG | MANUAL'\n+        required: false\n+        default: TAG\n+\n+jobs:\n+  token-check:\n+    runs-on: ubuntu-latest\n+    steps:\n+      - run: echo \"success!\"\n+        if: \"${{ github.event.inputs.release_token }} == ${{ env.release_token }}\"\n+        env:\n+          release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n+\n+  create-release:\n+    needs: token-check\n+    runs-on: ubuntu-latest\n+    steps:\n+      - name: Checkout code\n+        uses: actions/checkout@v2\n+        with:\n+          ref: 'master'\n+      - uses: actions/setup-python@v2\n+        with:\n+          python-version: 3.7\n+      - run: |\n+          python scripts/get-last-release-note.py\n+      - name: Create Release\n+        id: create_release\n+        uses: actions/create-release@v1\n+        env:\n+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # This token is provided by Actions, you do not need to create your own token\n+        with:\n+          tag_name: ${{ github.ref }}\n+          release_name: \ud83d\udcab Patch ${{ github.ref }}\n+          body_path: 'tmp.md'\n+          draft: false\n+          prerelease: false\n\n---\n file path A: .github/workflows/force-docker-build.yml | file path B: .github/workflows/force-docker-build.yml\n\n@@ -148,4 +148,16 @@ jobs:\n             PIP_INSTALL_PERF=${{env.JINA_PIP_INSTALL_PERF}}\n             PY_VERSION=${{matrix.py_version}}\n             PIP_TAG=${{matrix.pip_tag}}\n-          target: ${{env.BUILD_TARGET}}\n\\ No newline at end of file\n+          target: ${{env.BUILD_TARGET}}\n+\n+  create-release:\n+    runs-on: ubuntu-latest\n+    steps:\n+      - uses: benc-uk/workflow-dispatch@v1\n+        if: ${{ inputs.triggered_by == 'TAG' }}\n+        with:\n+          workflow: Create Release\n+          token: ${{ secrets.JINA_DEV_BOT }}\n+          inputs: '{ \"release_token\": \"${{ env.release_token }}\", \"triggered_by\": \"TAG\"}'\n+        env:\n+          release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n\\ No newline at end of file\n\n---\n file path A: .github/workflows/tag.yml | file path B: .github/workflows/tag.yml\n\n@@ -81,28 +81,3 @@ jobs:\n           inputs: '{ \"release_token\": \"${{ env.release_token }}\", \"triggered_by\": \"TAG\"}'\n         env:\n           release_token: ${{ secrets.JINA_CORE_RELEASE_TOKEN }}\n-\n-  create-release:\n-    needs: update-doc\n-    runs-on: ubuntu-latest\n-    steps:\n-      - name: Checkout code\n-        uses: actions/checkout@v2\n-        with:\n-          ref: 'master'\n-      - uses: actions/setup-python@v2\n-        with:\n-          python-version: 3.7\n-      - run: |\n-          python scripts/get-last-release-note.py\n-      - name: Create Release\n-        id: create_release\n-        uses: actions/create-release@v1\n-        env:\n-          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # This token is provided by Actions, you do not need to create your own token\n-        with:\n-          tag_name: ${{ github.ref }}\n-          release_name: \ud83d\udcab Patch ${{ github.ref }}\n-          body_path: 'tmp.md'\n-          draft: false\n-          prerelease: false\n\n\n###\n\n", "completion": "ci: add create-release.yml (#<issue-num>)"}
{"prompt": " file path A: None | file path B: docs/_static/now-dark.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"600px\" height=\"600px\" viewBox=\"0 0 600 600\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>Now_Yellow</title>\n+    <g id=\"Now_Yellow\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4-2\u5907\u4efd-3\" transform=\"translate(82.000000, 60.000000)\" fill=\"#FBCB67\">\n+            <path d=\"M24.0530695,0.125986108 C37.2076731,0.125986108 47.8937333,10.5173911 48.1061391,23.4121591 L48.1019736,456.914918 C47.7824556,469.716458 37.1392225,480 24.0530695,480 C10.898466,480 0.212405744,469.608595 0,456.713827 L0.00416544778,23.2110678 C0.323683496,10.4095281 10.9669166,0.125986108 24.0530695,0.125986108 Z\" id=\"\u5f62\u72b6\" fill-rule=\"nonzero\"></path>\n+            <path d=\"M411.940511,0.61997208 C425.095115,0.61997208 435.781175,11.0113771 435.996803,23.9061451 L435.996803,456.627184 C435.996803,469.511053 425.599758,479.74296 412.694666,479.952062 C398.873868,479.306735 388.000249,467.913553 388.000249,454.077697 L388.000249,21.9573791 L388.000249,21.9573791 C389.194217,9.98033318 399.455558,0.61997208 411.940511,0.61997208 Z\" id=\"\u8def\u5f84\" fill-rule=\"nonzero\"></path>\n+            <path d=\"M108.327258,69.1546886 L344.251064,308.665267 C346.462453,310.910277 347.702011,313.935055 347.702011,317.086294 L347.702011,407.383132 C347.702011,414.010549 342.329428,419.383132 335.702011,419.383132 C332.383093,419.383132 329.212387,418.008573 326.943609,415.586204 L91.2224528,163.907248 C89.1470959,161.691394 87.9887699,158.771262 87.9808952,155.735302 L87.7782455,77.6068411 C87.7610554,70.9794464 93.119685,65.5929461 99.7470797,65.575756 C102.971844,65.5673916 106.064265,66.8572909 108.327258,69.1546886 Z\" id=\"\u8def\u5f84\" fill-rule=\"nonzero\"></path>\n+            <path d=\"M294.790636,479.873988 L101.501306,478.311882 C93.92346,478.311882 87.7632895,472.420771 87.7002349,465.115303 L87.702472,258.238612 C87.6408416,250.891166 93.7690349,244.886717 101.390175,244.82644 C105.356945,244.796374 109.145675,246.412706 111.789597,249.263858 L305.078467,457.702655 C310.158091,463.180419 309.669922,471.590992 303.98811,476.488195 C301.458348,478.668618 298.183973,479.873988 294.790636,479.873988 Z\" id=\"\u8def\u5f84-11\u5907\u4efd\"></path>\n+            <path d=\"M136.847144,0 L333.71245,0 C341.33384,0 347.512196,5.95647666 347.512196,13.304163 L347.512196,222.446734 C347.512196,229.79442 341.33384,235.750897 333.71245,235.750897 C329.820234,235.750897 326.109007,234.166247 323.493341,231.387459 L126.628034,22.244888 C121.506273,16.8037145 121.929517,8.38987303 127.573375,3.45204698 C130.112456,1.23059855 133.418404,0 136.847144,0 Z\" id=\"\u8def\u5f84-11\u5907\u4efd-2\"></path>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/_static/now-light.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"600px\" height=\"600px\" viewBox=\"0 0 600 600\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>Now_Light_PureColor</title>\n+    <g id=\"Now_Light_PureColor\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4-2\u5907\u4efd-3\" transform=\"translate(82.000000, 60.000000)\" fill=\"#009191\">\n+            <path d=\"M24.0530695,0.125986108 C37.2076731,0.125986108 47.8937333,10.5173911 48.1061391,23.4121591 L48.1019736,456.914918 C47.7824556,469.716458 37.1392225,480 24.0530695,480 C10.898466,480 0.212405744,469.608595 0,456.713827 L0.00416544778,23.2110678 C0.323683496,10.4095281 10.9669166,0.125986108 24.0530695,0.125986108 Z\" id=\"\u5f62\u72b6\" fill-rule=\"nonzero\"></path>\n+            <path d=\"M411.940511,0.61997208 C425.095115,0.61997208 435.781175,11.0113771 435.996803,23.9061451 L435.996803,456.627184 C435.996803,469.511053 425.599758,479.74296 412.694666,479.952062 C398.873868,479.306735 388.000249,467.913553 388.000249,454.077697 L388.000249,21.9573791 L388.000249,21.9573791 C389.194217,9.98033318 399.455558,0.61997208 411.940511,0.61997208 Z\" id=\"\u8def\u5f84\" fill-rule=\"nonzero\"></path>\n+            <path d=\"M108.327258,69.1546886 L344.251064,308.665267 C346.462453,310.910277 347.702011,313.935055 347.702011,317.086294 L347.702011,407.383132 C347.702011,414.010549 342.329428,419.383132 335.702011,419.383132 C332.383093,419.383132 329.212387,418.008573 326.943609,415.586204 L91.2224528,163.907248 C89.1470959,161.691394 87.9887699,158.771262 87.9808952,155.735302 L87.7782455,77.6068411 C87.7610554,70.9794464 93.119685,65.5929461 99.7470797,65.575756 C102.971844,65.5673916 106.064265,66.8572909 108.327258,69.1546886 Z\" id=\"\u8def\u5f84\" fill-rule=\"nonzero\"></path>\n+            <path d=\"M294.790636,479.873988 L101.501306,478.311882 C93.92346,478.311882 87.7632895,472.420771 87.7002349,465.115303 L87.702472,258.238612 C87.6408416,250.891166 93.7690349,244.886717 101.390175,244.82644 C105.356945,244.796374 109.145675,246.412706 111.789597,249.263858 L305.078467,457.702655 C310.158091,463.180419 309.669922,471.590992 303.98811,476.488195 C301.458348,478.668618 298.183973,479.873988 294.790636,479.873988 Z\" id=\"\u8def\u5f84-11\u5907\u4efd\"></path>\n+            <path d=\"M136.847144,0 L333.71245,0 C341.33384,0 347.512196,5.95647666 347.512196,13.304163 L347.512196,222.446734 C347.512196,229.79442 341.33384,235.750897 333.71245,235.750897 C329.820234,235.750897 326.109007,234.166247 323.493341,231.387459 L126.628034,22.244888 C121.506273,16.8037145 121.929517,8.38987303 127.573375,3.45204698 C130.112456,1.23059855 133.418404,0 136.847144,0 Z\" id=\"\u8def\u5f84-11\u5907\u4efd-2\"></path>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n\n###\n\n", "completion": "docs: add missing logo file (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -184,6 +184,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13735,3 +13736,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```94153117```](https://github.com/jina-ai/jina/commit/9415311721dce65b512243216fe6790574745456)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```3c7d0b3e```](https://github.com/jina-ai/jina/commit/3c7d0b3ed0b39edffcddcc645d5d1acf5a00ea34)] __-__ __version__: the next version will be 3.4.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-6></a>\n+## Release Note (`3.4.6`)\n+\n+> Release time: 2022-05-23 19:21:36\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```049666d9```](https://github.com/jina-ai/jina/commit/049666d92f4c467d6430aa14d858156c0b0cab56)] __-__ code review (#4821) (*Han Xiao*)\n+ - [[```688370db```](https://github.com/jina-ai/jina/commit/688370dbc43536f8bcd8d1b16572530bb750fb0f)] __-__ __dockerfile__: install security updates in docker image (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```174dbde1```](https://github.com/jina-ai/jina/commit/174dbde1922b422b934e0ed0d7ea910657ecb510)] __-__ add security analysis (*Han Xiao*)\n+ - [[```93db296a```](https://github.com/jina-ai/jina/commit/93db296a365a6805f0c55d8ae5078734d6cd00d0)] __-__ __version__: the next version will be 3.4.6 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.6'\n+__version__ = '3.4.7'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.7"}
{"prompt": " file path A: None | file path B: .github/workflows/codeql-analysis.yml\n\n@@ -0,0 +1,72 @@\n+# For most projects, this workflow file will not need changing; you simply need\n+# to commit it to your repository.\n+#\n+# You may wish to alter this file to override the set of languages analyzed,\n+# or to provide custom queries or build logic.\n+#\n+# ******** NOTE ********\n+# We have attempted to detect the languages in your repository. Please check\n+# the `language` matrix defined below to confirm you have the correct set of\n+# supported CodeQL languages.\n+#\n+name: \"CodeQL\"\n+\n+on:\n+  push:\n+    branches: [ master ]\n+  pull_request:\n+    # The branches below must be a subset of the branches above\n+    branches: [ master ]\n+  schedule:\n+    - cron: '26 16 * * 0'\n+\n+jobs:\n+  analyze:\n+    name: Analyze\n+    runs-on: ubuntu-latest\n+    permissions:\n+      actions: read\n+      contents: read\n+      security-events: write\n+\n+    strategy:\n+      fail-fast: false\n+      matrix:\n+        language: [ 'python' ]\n+        # CodeQL supports [ 'cpp', 'csharp', 'go', 'java', 'javascript', 'python', 'ruby' ]\n+        # Learn more about CodeQL language support at https://aka.ms/codeql-docs/language-support\n+\n+    steps:\n+    - name: Checkout repository\n+      uses: actions/checkout@v3\n+\n+    # Initializes the CodeQL tools for scanning.\n+    - name: Initialize CodeQL\n+      uses: github/codeql-action/init@v2\n+      with:\n+        languages: ${{ matrix.language }}\n+        # If you wish to specify custom queries, you can do so here or in a config file.\n+        # By default, queries listed here will override any specified in a config file.\n+        # Prefix the list here with \"+\" to use these queries and those in the config file.\n+        \n+        # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs\n+        # queries: security-extended,security-and-quality\n+\n+        \n+    # Autobuild attempts to build any compiled languages  (C/C++, C#, or Java).\n+    # If this step fails, then you should remove it and run the build manually (see below)\n+    - name: Autobuild\n+      uses: github/codeql-action/autobuild@v2\n+\n+    # \u2139\ufe0f Command-line programs to run using the OS shell.\n+    # \ud83d\udcda See https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsrun\n+\n+    #   If the Autobuild fails above, remove it and uncomment the following three lines. \n+    #   modify them (or add more) to build your code if your project, please refer to the EXAMPLE below for guidance.\n+\n+    # - run: |\n+    #   echo \"Run, Build Application using script\"\n+    #   ./location_of_script_within_repo/buildscript.sh\n+\n+    - name: Perform CodeQL Analysis\n+      uses: github/codeql-action/analyze@v2\n\n\n###\n\n", "completion": "chore: add security analysis"}
{"prompt": " file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -41,6 +41,7 @@ COPY extra-requirements.txt setup.py /tmp/\n RUN cd /tmp/ && \\\n     # apt latest security packages should be install before pypi package\n     if [ -n \"${APT_PACKAGES}\" ]; then apt-get update && apt-get upgrade -y && \\\n+    apt-get --only-upgrade install openssl libssl1.1 -y && \\\n     apt-get install --no-install-recommends -y ${APT_PACKAGES}; fi && \\\n     if [ -n \"${PIP_TAG}\" ]; then pip install --default-timeout=1000 --compile --extra-index-url $PIP_EXTRA_INDEX_URL \".[${PIP_TAG}]\" ; fi && \\\n     pip install --default-timeout=1000 --compile --extra-index-url ${PIP_EXTRA_INDEX_URL} . && \\\n\n---\n file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -39,8 +39,8 @@ ENV PIP_NO_CACHE_DIR=1 \\\n COPY extra-requirements.txt setup.py /tmp/\n \n RUN cd /tmp/ && \\\n-    # apt package should be install before pypi package\n-    if [ -n \"${APT_PACKAGES}\" ]; then apt-get update && apt list --upgradable | grep security |cut -d\\/ -f1|xargs sudo apt-get install -y && \\\n+    # apt latest security packages should be install before pypi package\n+    if [ -n \"${APT_PACKAGES}\" ]; then apt-get update && apt-get upgrade -y && \\\n     apt-get install --no-install-recommends -y ${APT_PACKAGES}; fi && \\\n     if [ -n \"${PIP_TAG}\" ]; then pip install --default-timeout=1000 --compile --extra-index-url $PIP_EXTRA_INDEX_URL \".[${PIP_TAG}]\" ; fi && \\\n     pip install --default-timeout=1000 --compile --extra-index-url ${PIP_EXTRA_INDEX_URL} . && \\\n\n---\n file path A: Dockerfiles/debianx.Dockerfile | file path B: Dockerfiles/debianx.Dockerfile\n\n@@ -40,7 +40,8 @@ COPY extra-requirements.txt setup.py /tmp/\n \n RUN cd /tmp/ && \\\n     # apt package should be install before pypi package\n-    if [ -n \"${APT_PACKAGES}\" ]; then apt-get update && apt-get install --no-install-recommends -y ${APT_PACKAGES}; fi && \\\n+    if [ -n \"${APT_PACKAGES}\" ]; then apt-get update && apt list --upgradable | grep security |cut -d\\/ -f1|xargs sudo apt-get install -y && \\\n+    apt-get install --no-install-recommends -y ${APT_PACKAGES}; fi && \\\n     if [ -n \"${PIP_TAG}\" ]; then pip install --default-timeout=1000 --compile --extra-index-url $PIP_EXTRA_INDEX_URL \".[${PIP_TAG}]\" ; fi && \\\n     pip install --default-timeout=1000 --compile --extra-index-url ${PIP_EXTRA_INDEX_URL} . && \\\n     # now remove apt packages\n\n\n###\n\n", "completion": "fix(dockerfile): install security updates in docker image"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -183,6 +183,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13694,3 +13695,43 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```32d85a50```](https://github.com/jina-ai/jina/commit/32d85a502438a6a99c886e2d4e974db213a025ef)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```2b5efac1```](https://github.com/jina-ai/jina/commit/2b5efac1478f33134d481e8cf9fcc7b405c58515)] __-__ __version__: the next version will be 3.4.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-5></a>\n+## Release Note (`3.4.5`)\n+\n+> Release time: 2022-05-23 12:00:14\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  Johannes Messner,  ZiniuYu,  Joan Fontanals,  Zhaofeng Miao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```9c1fda96```](https://github.com/jina-ai/jina/commit/9c1fda96718b2e775fdcd06dc9b8bbfc673c1248)] __-__ __executor__: add self logger to executor (#4818) (*Han Xiao*)\n+ - [[```e553d913```](https://github.com/jina-ai/jina/commit/e553d913eb2526c1dc8f32c56c0faa53531c505b)] __-__ smart replica retry (#4794) (*Johannes Messner*)\n+ - [[```a9ed27ed```](https://github.com/jina-ai/jina/commit/a9ed27ed72d35af9b7c0757b87ce13dbc2f8d12e)] __-__ add additional metrics (#4789) (*samsja*)\n+ - [[```c88d2cf5```](https://github.com/jina-ai/jina/commit/c88d2cf571f9756f4526eba156008c2e2b88fcbb)] __-__ __hubble__: use fixed domain for hubble api (#4804) (*Zhaofeng Miao*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```aa2d7c8d```](https://github.com/jina-ai/jina/commit/aa2d7c8d4cf2d3e9b9f5d4315ce24f2f6a3276a3)] __-__ __dockerfile__: install security updates in docker image (*Han Xiao*)\n+ - [[```87de3c09```](https://github.com/jina-ai/jina/commit/87de3c09766335624f97bc9254d51cbb9bd8fff0)] __-__ define metrics in worker before grpc server (#4816) (*samsja*)\n+ - [[```a2bc2302```](https://github.com/jina-ai/jina/commit/a2bc2302112074fe447fbd1f810da65fb23c2bc2)] __-__ avoid closing loop at fork time (#4803) (*Joan Fontanals*)\n+ - [[```3fb3b419```](https://github.com/jina-ai/jina/commit/3fb3b419c48b016c55bcc63b1d75097d0ff397df)] __-__ warn user when calling load config from flow instance (#4787) (*samsja*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```93f06fc5```](https://github.com/jina-ai/jina/commit/93f06fc533730b6bfa3836c3873524089ad72004)] __-__ simplify event loop usage (#4811) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```3a7d95b6```](https://github.com/jina-ai/jina/commit/3a7d95b6cdedb525b1ddb4dc58faf0d7ef55afa7)] __-__ add specification of executor and flow yaml (#4795) (*Johannes Messner*)\n+ - [[```10ab59f1```](https://github.com/jina-ai/jina/commit/10ab59f143a244a72db891d486ac92a0ea5e6de5)] __-__ fix Flow docs typo (#4815) (*ZiniuYu*)\n+ - [[```15d83ba8```](https://github.com/jina-ai/jina/commit/15d83ba87dfef748b732dcc1fd41ad5f719ac467)] __-__ round robin gpu scheduling  (#4805) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```94153117```](https://github.com/jina-ai/jina/commit/9415311721dce65b512243216fe6790574745456)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```3c7d0b3e```](https://github.com/jina-ai/jina/commit/3c7d0b3ed0b39edffcddcc645d5d1acf5a00ea34)] __-__ __version__: the next version will be 3.4.5 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.5'\n+__version__ = '3.4.6'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.6"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -12,12 +12,14 @@ from jina.enums import BetterEnum\n from jina.helper import ArgNamespace, T, iscoroutinefunction, typename\n from jina.importer import ImportExtensions\n from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n+from jina.logging.logger import JinaLogger\n from jina.serve.executors.decorators import requests, store_init_kwargs, wrap_func\n \n if TYPE_CHECKING:\n-    from docarray import DocumentArray\n     from prometheus_client import Summary\n \n+    from docarray import DocumentArray\n+\n __all__ = ['BaseExecutor', 'ReducerExecutor']\n \n \n@@ -107,6 +109,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         self._add_requests(requests)\n         self._add_runtime_args(runtime_args)\n         self._init_monitoring()\n+        self.logger = JinaLogger(self.__class__.__name__)\n \n     def _add_runtime_args(self, _runtime_args: Optional[Dict]):\n         if _runtime_args:\n\n\n###\n\n", "completion": "feat(executor): add self logger to executor (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -32,8 +32,6 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         \"\"\"\n         Start the DataRequestHandler and wait for the GRPC and Monitoring servers to start\n         \"\"\"\n-        await self._async_setup_grpc_server()\n-\n         if self.metrics_registry:\n             with ImportExtensions(\n                 required=True,\n@@ -55,6 +53,8 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         else:\n             self._summary_time = contextlib.nullcontext()\n \n+        await self._async_setup_grpc_server()\n+\n     async def _async_setup_grpc_server(self):\n         \"\"\"\n         Start the DataRequestHandler and wait for the GRPC server to start\n\n\n###\n\n", "completion": "fix: define metrics in worker before grpc server (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/index.md | file path B: docs/fundamentals/executor/index.md\n\n@@ -50,4 +50,5 @@ repository-structure\n hub/index\n containerize-executor\n monitoring-executor\n+yaml-spec\n ```\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/fundamentals/executor/yaml-spec.md\n\n@@ -0,0 +1,48 @@\n+(executor-yaml-spec)=\n+# YAML specification\n+\n+This page outlines the specification for valid Executor YAML files.\n+\n+Such YAML configurations can be used in a Flow via `Flow().add(uses='exec.yml')`, or loaded directly via `BaseExecutor.load_config('exec.yml')`.\n+\n+Note that Executor YAML configurations always refer back to an Executor defined in a Python file.\n+\n+## Example\n+\n+The following constitutes an example Executor configuration:\n+\n+`exec.yml`/`exec.yaml`:\n+```yaml\n+jtype: MyExecutor\n+with:\n+  match_args: {}\n+py_modules:\n+  - executor.py\n+metas:\n+  name: Indexer\n+  description: Indexes all documents\n+```\n+\n+## Fields\n+\n+### `jtype`\n+String specifying the Python type of the Executor. Used to locate the correct class in the Python files given by `py_modules`.\n+\n+### `with`\n+Collection containing keyword arguments passed to the Executor's `__init__()` method. Valid values depend on the Executor.\n+\n+### `py_modules`\n+List of strings defining the Python dependencies of the Executor. Most notably this must include the\n+Python file that contains the Executor definition itself, as well as any other files imported by this.\n+\n+### `metas`\n+Collection containing meta information about the Executor.\n+\n+**`name`**\n+\n+String that defines the name of the Executor.\n+\n+**`description`**\n+\n+String that describes the Executor.\n+\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -146,5 +146,6 @@ flow-api\n access-flow-api\n client\n monitoring-flow\n+yaml-spec\n remarks\n ```\n\n---\n file path A: None | file path B: docs/fundamentals/flow/yaml-spec.md\n\n@@ -0,0 +1,80 @@\n+(flow-yaml-spec)=\n+# YAML specification\n+\n+This page outlines the specification for valid Flow YAML files.\n+\n+Such YAML configurations can be used to generate a Flow object via `Flow.load_config('flow.yml')`.\n+\n+To generate a YAML configuration from a `Flow` Python object, run `f.save_config()`.\n+\n+## Example\n+\n+The following constitutes an example Flow configuration:\n+\n+`flow.yml`/`flow.yaml`:\n+```yaml\n+jtype: Flow\n+version: '1'\n+with:\n+  protocol: http\n+executors:\n+# inline Executor YAML\n+- name: firstexec\n+  uses:\n+    jtype: MyExec\n+    py_modules:\n+      - executor.py\n+# reference to Executor YAML\n+- name: secondexec\n+  uses: indexer.yml\n+  workspace: /home/my/workspace\n+# reference to Executor Python class\n+- name: thirdexec\n+  uses: CustomExec  # located in executor.py\n+```\n+\n+## Fields\n+\n+### `jtype`\n+String that is always set to \"Flow\", indicating the corresponding Python class.\n+\n+### `version`\n+String indicating the version of the Flow.\n+\n+### `with`\n+Keyword arguments passed to the Flow `__init__()` method. A complete list of these arguments can be found [here](https://docs.jina.ai/api/jina.orchestrate.flow.base/#jina.orchestrate.flow.base.Flow),\n+or by running `jina flow --help`.\n+\n+### `executors`\n+Collection of Executors used in the Flow.\n+Each item in the collection corresponds to on `f.add()` call and specifies one Executor.\n+\n+All keyword arguments passed to the Flow `add()` method can be added.\n+A complete list of these arguments can be found [here](https://docs.jina.ai/api/jina.orchestrate.flow.base/#jina.orchestrate.flow.base.Flow.add).\n+\n+**`uses`**\n+\n+`uses` can take a direct reference to a Python class, or a path to an Executor YAML specification, equivalently the `f.add(uses=...)` pattern.\n+\n+Alternatively, an Executor YAML configuration can be proved directly inline in the Flow YAML configuration, like shown in the example above.\n+\n+\n+## Variables\n+\n+Jina Flow YAMLs support variables and variable substitution according to the [Github Actions syntax](https://docs.github.com/en/actions/learn-github-actions/environment-variables).\n+\n+This means that the following variable substitutions are supported:\n+\n+### Environment variables\n+\n+Use `${{ ENV.VAR }}` to refer to the environment variable `VAR`.\n+\n+## Context variables\n+\n+Use `${{ CONTEXT.VAR }}` to refer to the context variable `VAR`.\n+Context variables can be passed to `f.load_config(..., context=...)` in the form of a Python dictionary.\n+\n+## Relative paths\n+\n+Use `${{root.path.to.var}}` to refer to the variable `var` within the same YAML file, found at the provided path in the file's structure.\n+Note that the only difference between environment variable syntax and relative path syntax is the omission of spaces in the latter.\n\n\n###\n\n", "completion": "docs: add specification of executor and flow yaml (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/flow-api.md | file path B: docs/fundamentals/flow/flow-api.md\n\n@@ -10,7 +10,7 @@ There are two ways of defining a Flow, either directly from the Python API or us\n ```{admonition} Jina Client\n :class: caution\n \n-To showcase the workings of Flow, the examples below use a Client connecting to it, all from withing the same Pyhon script.\n+To showcase the workings of Flow, the examples below use a Client connecting to it, all from withing the same Python script.\n \n In most cases, this is not how a real user would access a Flow. Rather, they would use one of {ref}`several ways of connecting over a network<access-flow-api>`.\n This does not affect how you have to configure your Flow API, so the examples here should translate seamlessly.\n\n\n###\n\n", "completion": "docs: fix Flow docs typo (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -675,6 +675,76 @@ Flow with 3 replicas of slow_encoder and 1 replica of fast_indexer\n The above Flow will create a topology with three Replicas of Executor `slow_encoder`. The `Flow` will send every \n request to exactly one of the three instances. Then the replica will send its result to `fast_indexer`.\n \n+\n+### Replicate on multiple GPUs\n+\n+In certain situations, you may want to replicate your Executor so that each replica uses a different GPU on your machine.\n+To achieve this, you need to tell the Flow to leverage multiple GPUs, by passing `CUDA_VISIBLE_DEVICES=RR` as an environment variable.\n+The Flow will then assign each available GPU to replicas in a round-robin fashion.\n+\n+```{caution} \n+Replicate on multiple GPUs by using `CUDA_VISIBLE_DEVICES=RR` should only be used locally.  \n+```\n+\n+```{tip}\n+When working in Kubernetes or with Docker Compose you shoud allocate GPU ressources to each replica directly in the configuration files.\n+```\n+\n+For example, if you have 3 GPUs and one of your Executor has 5 replicas then \n+\n+````{tab} Python\n+ In a `flow.py` file \n+```python\n+from jina import Flow\n+\n+with Flow().add(\n+    uses='jinahub://CLIPEncoder', replicas=5, install_requirements=True\n+) as f:\n+    f.block()\n+```\n+\n+```shell\n+CUDA_VISIBLE_DEVICES=RR python flow.py\n+```\n+````\n+\n+````{tab} YAML\n+In a `flow.yaml` file\n+```yaml\n+jtype: Flow\n+executors:\n+- uses: jinahub://CLIPEncoder\n+  install_requirements: True\n+  replicas: 5  \n+```\n+\n+```shell\n+CUDA_VISIBLE_DEVICES=RR jina flow --uses flow.yaml\n+```\n+````\n+\n+The Flow will assign GPU devices in the following round-robin fashion:\n+\n+| GPU device | Replica ID |\n+|------------|------------|\n+| 0          | 0          |\n+| 1          | 1          |\n+| 2          | 2          |\n+| 0          | 3          |\n+| 1          | 4          |\n+\n+ \n+You can also restrict the visible devices in round-robin assignment by `CUDA_VISIBLE_DEVICES=RR0:2`, where `0:2` has the same meaning as Python slice. This will create the following assignment:\n+\n+| GPU device | Replica ID |\n+|------------|------------|\n+| 0          | 0          |\n+| 1          | 1          |\n+| 0          | 2          |\n+| 1          | 3          |\n+| 0          | 4          |\n+\n+\n (partition-data-by-using-shards)=\n ### Partition data by using Shards\n \n\n---\n file path A: docs/proto/docs.md | file path B: docs/proto/docs.md\n\n@@ -11,6 +11,7 @@\n     - [DataRequestListProto](#jina-DataRequestListProto)\n     - [DataRequestProto](#jina-DataRequestProto)\n     - [DataRequestProto.DataContentProto](#jina-DataRequestProto-DataContentProto)\n+    - [EndpointsProto](#jina-EndpointsProto)\n     - [HeaderProto](#jina-HeaderProto)\n     - [RelatedEntity](#jina-RelatedEntity)\n     - [RouteProto](#jina-RouteProto)\n@@ -22,6 +23,7 @@\n   \n     - [JinaControlRequestRPC](#jina-JinaControlRequestRPC)\n     - [JinaDataRequestRPC](#jina-JinaDataRequestRPC)\n+    - [JinaDiscoverEndpointsRPC](#jina-JinaDiscoverEndpointsRPC)\n     - [JinaRPC](#jina-JinaRPC)\n     - [JinaSingleDataRequestRPC](#jina-JinaSingleDataRequestRPC)\n   \n@@ -129,6 +131,21 @@ Represents a DataRequest\n \n \n \n+<a name=\"jina-EndpointsProto\"></a>\n+\n+### EndpointsProto\n+Represents the set of Endpoints exposed by an Executor\n+\n+\n+| Field | Type | Label | Description |\n+| ----- | ---- | ----- | ----------- |\n+| endpoints | [string](#string) | repeated | list of endpoints exposed by an Executor |\n+\n+\n+\n+\n+\n+\n <a name=\"jina-HeaderProto\"></a>\n \n ### HeaderProto\n@@ -282,6 +299,16 @@ jina gRPC service for DataRequests.\n | process_data | [DataRequestListProto](#jina-DataRequestListProto) | [DataRequestProto](#jina-DataRequestProto) | Used for passing DataRequests to the Executors |\n \n \n+<a name=\"jina-JinaDiscoverEndpointsRPC\"></a>\n+\n+### JinaDiscoverEndpointsRPC\n+jina gRPC service to expose Endpoints from Executors.\n+\n+| Method Name | Request Type | Response Type | Description |\n+| ----------- | ------------ | ------------- | ------------|\n+| endpoint_discovery | [.google.protobuf.Empty](#google-protobuf-Empty) | [EndpointsProto](#jina-EndpointsProto) |  |\n+\n+\n <a name=\"jina-JinaRPC\"></a>\n \n ### JinaRPC\n\n\n###\n\n", "completion": "docs: round robin gpu scheduling  (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1001,23 +1001,6 @@ def _update_policy():\n             )\n \n \n-def _close_loop():\n-    try:\n-        loop = asyncio.get_event_loop()\n-        if not loop.is_closed():\n-            loop.close()\n-    except RuntimeError:\n-        # there is no loop, so nothing to do here\n-        pass\n-\n-\n-# workaround for asyncio loop and fork issue: https://github.com/python/cpython/issues/66197\n-# we close the loop after forking to avoid reusing the parents process loop\n-# a new loop should be created in the child process\n-if not __windows__:\n-    os.register_at_fork(after_in_child=_close_loop)\n-\n-\n def get_or_reuse_loop():\n     \"\"\"\n     Get a new eventloop or reuse the current opened eventloop.\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -2,8 +2,6 @@ import argparse\n import json\n from typing import TYPE_CHECKING, Dict, List, Optional\n \n-from docarray import Document\n-\n from jina import __version__\n from jina.clients.request import request_generator\n from jina.enums import DataInputType\n@@ -285,7 +283,6 @@ def get_fastapi_app(\n             from dataclasses import asdict\n \n             import strawberry\n-            from docarray import DocumentArray\n             from docarray.document.strawberry_type import (\n                 JSONScalar,\n                 StrawberryDocument,\n@@ -293,6 +290,8 @@ def get_fastapi_app(\n             )\n             from strawberry.fastapi import GraphQLRouter\n \n+            from docarray import DocumentArray\n+\n             async def get_docs_from_endpoint(\n                 data, target_executor, parameters, exec_endpoint\n             ):\n\n---\n file path A: tests/integration/gateway_clients/test_streaming.py | file path B: tests/integration/gateway_clients/test_streaming.py\n\n@@ -329,9 +329,9 @@ def test_multiple_clients(prefetch, protocol, monkeypatch, simple_graph_dict_ind\n         for i in range(1000, 1000 + MALICIOUS_CLIENT_NUM_DOCS):\n             yield get_document(i)\n \n-    def client(gen, port, protocol):\n-        Client(protocol=protocol, port=port, return_responses=True).post(\n-            on='/index', inputs=gen, request_size=1\n+    def client(gen, port):\n+        Client(protocol=protocol, port=port).post(\n+            on='/index', inputs=gen, request_size=1, return_responses=True\n         )\n \n     monkeypatch.setattr(\n@@ -357,7 +357,7 @@ def test_multiple_clients(prefetch, protocol, monkeypatch, simple_graph_dict_ind\n     # Each client sends `GOOD_CLIENT_NUM_DOCS` (20) requests and sleeps after each request.\n     for i in range(GOOD_CLIENTS):\n         cp = multiprocessing.Process(\n-            target=partial(client, good_client_gen, port, protocol),\n+            target=partial(client, good_client_gen, port),\n             name=f'goodguy_{i}',\n         )\n         cp.start()\n@@ -365,7 +365,7 @@ def test_multiple_clients(prefetch, protocol, monkeypatch, simple_graph_dict_ind\n \n     # and 1 malicious client, sending lot of requests (trying to block others)\n     cp = multiprocessing.Process(\n-        target=partial(client, malicious_client_gen, port, protocol),\n+        target=partial(client, malicious_client_gen, port),\n         name='badguy',\n     )\n     cp.start()\n\n---\n file path A: tests/integration/streaming/test_clients_streaming.py | file path B: tests/integration/streaming/test_clients_streaming.py\n\n@@ -1,12 +1,14 @@\n+import asyncio\n import os\n-import time, asyncio\n-from typing import List\n+import time\n from datetime import datetime\n from functools import partial\n from multiprocessing import Process, current_process\n+from typing import List\n \n import pytest\n-from jina import Flow, Document, DocumentArray, Executor, requests, Client\n+\n+from jina import Client, Document, DocumentArray, Executor, Flow, requests\n \n INPUT_LEN = 4\n INPUT_GEN_SLEEP_TIME = 1\n@@ -197,10 +199,17 @@ class Indexer(Executor):\n         return DocumentArray(Document(tags={'ids': self.docs[:, 'id']}))\n \n \n+@pytest.fixture()\n+def info_log_level():\n+    log_level = os.environ['JINA_LOG_LEVEL']\n+    os.environ['JINA_LOG_LEVEL'] = 'INFO'\n+    yield\n+    os.environ['JINA_LOG_LEVEL'] = log_level\n+\n+\n @pytest.mark.parametrize('prefetch', [0, 5])\n @pytest.mark.parametrize('protocol', ['websocket', 'http', 'grpc'])\n-def test_multiple_clients(prefetch, protocol):\n-    os.environ['JINA_LOG_LEVEL'] = 'INFO'\n+def test_multiple_clients(prefetch, protocol, info_log_level):\n     GOOD_CLIENTS = 5\n     GOOD_CLIENT_NUM_DOCS = 20\n     MALICIOUS_CLIENT_NUM_DOCS = 50\n@@ -220,9 +229,9 @@ def test_multiple_clients(prefetch, protocol):\n         for i in range(1000, 1000 + MALICIOUS_CLIENT_NUM_DOCS):\n             yield get_document(i)\n \n-    def client(gen, port, protocol):\n-        Client(protocol=protocol, port=port, return_responses=True).post(\n-            on='/index', inputs=gen, request_size=1\n+    def client(gen, port):\n+        Client(protocol=protocol, port=port).post(\n+            on='/index', inputs=gen, request_size=1, return_responses=True\n         )\n \n     pool: List[Process] = []\n@@ -232,7 +241,7 @@ def test_multiple_clients(prefetch, protocol):\n         # Each client sends `GOOD_CLIENT_NUM_DOCS` (20) requests and sleeps after each request.\n         for i in range(GOOD_CLIENTS):\n             p = Process(\n-                target=partial(client, good_client_gen, f.port, protocol),\n+                target=partial(client, good_client_gen, f.port),\n                 name=f'goodguy_{i}',\n             )\n             p.start()\n@@ -240,7 +249,7 @@ def test_multiple_clients(prefetch, protocol):\n \n         # and 1 malicious client, sending lot of requests (trying to block others)\n         p = Process(\n-            target=partial(client, malicious_client_gen, f.port, protocol),\n+            target=partial(client, malicious_client_gen, f.port),\n             name='badguy',\n         )\n         p.start()\n@@ -250,35 +259,31 @@ def test_multiple_clients(prefetch, protocol):\n             p.join()\n \n         order_of_ids = list(\n-            Client(protocol=protocol, port=f.port, return_responses=True)\n-            .post(on='/status', inputs=[Document()])[0]\n+            Client(protocol=protocol, port=f.port)\n+            .post(on='/status', inputs=[Document()], return_responses=True)[0]\n             .docs[0]\n             .tags['ids']\n         )\n-        # There must be total 150 docs indexed.\n-        assert (\n-            len(order_of_ids)\n-            == GOOD_CLIENTS * GOOD_CLIENT_NUM_DOCS + MALICIOUS_CLIENT_NUM_DOCS\n-        )\n+    # There must be total 150 docs indexed.\n+    assert (\n+        len(order_of_ids)\n+        == GOOD_CLIENTS * GOOD_CLIENT_NUM_DOCS + MALICIOUS_CLIENT_NUM_DOCS\n+    )\n \n-        \"\"\"\n-        If prefetch is set, each Client is allowed (max) 5 requests at a time.\n-        Since requests are controlled, `badguy` has to do the last 20 requests.\n-        \n-        If prefetch is disabled, clients can freeflow requests. No client is blocked. \n-        Hence last 20 requests go from `goodguy`.\n-        (Ideally last 30 requests should be validated, to avoid flaky CI, we test last 20)\n-\n-        When there are no rules, badguy wins! With rule, you find balance in the world.        \n-        \"\"\"\n-        if protocol == 'http':\n-            # There's no prefetch for http.\n-            assert set(map(lambda x: x.split('_')[0], order_of_ids[-20:])) == {\n-                'goodguy'\n-            }\n-        elif prefetch == 5:\n-            assert set(map(lambda x: x.split('_')[0], order_of_ids[-20:])) == {'badguy'}\n-        elif prefetch == 0:\n-            assert set(map(lambda x: x.split('_')[0], order_of_ids[-20:])) == {\n-                'goodguy'\n-            }\n+    \"\"\"\n+    If prefetch is set, each Client is allowed (max) 5 requests at a time.\n+    Since requests are controlled, `badguy` has to do the last 20 requests.\n+    \n+    If prefetch is disabled, clients can freeflow requests. No client is blocked. \n+    Hence last 20 requests go from `goodguy`.\n+    (Ideally last 30 requests should be validated, to avoid flaky CI, we test last 20)\n+\n+    When there are no rules, badguy wins! With rule, you find balance in the world.        \n+    \"\"\"\n+    if protocol == 'http':\n+        # There's no prefetch for http.\n+        assert set(map(lambda x: x.split('_')[0], order_of_ids[-20:])) == {'goodguy'}\n+    elif prefetch == 5:\n+        assert set(map(lambda x: x.split('_')[0], order_of_ids[-20:])) == {'badguy'}\n+    elif prefetch == 0:\n+        assert set(map(lambda x: x.split('_')[0], order_of_ids[-20:])) == {'goodguy'}\n\n\n###\n\n", "completion": "fix: avoid closing loop at fork time (#<issue-num>)"}
{"prompt": " file path A: jina/clients/base/websocket.py | file path B: jina/clients/base/websocket.py\n\n@@ -112,7 +112,7 @@ class WebSocketBaseClient(BaseClient):\n                     end_of_iter_handler=_handle_end_of_iter,\n                 )\n \n-                receive_task = get_or_reuse_loop().create_task(_receive())\n+                receive_task = asyncio.create_task(_receive())\n \n                 if receive_task.done():\n                     raise RuntimeError(\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1287,23 +1287,19 @@ def iscoroutinefunction(func: Callable):\n def run_async(func, *args, **kwargs):\n     \"\"\"Generalized asyncio.run for jupyter notebook.\n \n-    When running inside jupyter, an eventloop is already exist, can't be stopped, can't be killed.\n+    When running inside jupyter, an eventloop already exists, can't be stopped, can't be killed.\n     Directly calling asyncio.run will fail, as This function cannot be called when another asyncio event loop\n     is running in the same thread.\n \n     .. see_also:\n         https://stackoverflow.com/questions/55409641/asyncio-run-cannot-be-called-from-a-running-event-loop\n \n-    call `run_async(my_function, any_event_loop=True, *args, **kwargs)` to enable run with any eventloop\n-\n     :param func: function to run\n     :param args: parameters\n     :param kwargs: key-value parameters\n     :return: asyncio.run(func)\n     \"\"\"\n \n-    any_event_loop = kwargs.pop('any_event_loop', False)\n-\n     class _RunThread(threading.Thread):\n         \"\"\"Create a running thread when in Jupyter notebook.\"\"\"\n \n@@ -1319,7 +1315,7 @@ def run_async(func, *args, **kwargs):\n     if loop and loop.is_running():\n         # eventloop already exist\n         # running inside Jupyter\n-        if any_event_loop or is_jupyter():\n+        if is_jupyter():\n             thread = _RunThread()\n             thread.start()\n             thread.join()\n@@ -1340,7 +1336,7 @@ def run_async(func, *args, **kwargs):\n                 'please report this issue here: https://github.com/jina-ai/jina'\n             )\n     else:\n-        return get_or_reuse_loop().run_until_complete(func(*args, **kwargs))\n+        return asyncio.run(func(*args, **kwargs))\n \n \n def slugify(value):\n\n\n###\n\n", "completion": "refactor: simplify event loop usage (#<issue-num>)"}
{"prompt": " file path A: jina/excepts.py | file path B: jina/excepts.py\n\n@@ -1,4 +1,6 @@\n \"\"\"This modules defines all kinds of exceptions raised in Jina.\"\"\"\n+from typing import Set, Union\n+\n import grpc.aio\n \n \n@@ -84,13 +86,13 @@ class InternalNetworkError(grpc.aio.AioRpcError, BaseJinaException):\n         self,\n         og_exception: grpc.aio.AioRpcError,\n         request_id: str = '',\n-        dest_addr: str = '',\n+        dest_addr: Union[str, Set[str]] = {''},\n         details: str = '',\n     ):\n         \"\"\"\n         :param og_exception: the original exception that caused the network error\n         :param request_id: id of the request that caused the error\n-        :param dest_addr: destination (microservice) address of the problematic network call\n+        :param dest_addr: destination (microservice) address(es) of the problematic network call(s)\n         :param details: details of the error\n         \"\"\"\n         self.og_exception = og_exception\n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -3,7 +3,7 @@ import contextlib\n import ipaddress\n import os\n from collections import defaultdict\n-from typing import Dict, List, Optional, Tuple\n+from typing import Dict, List, Optional, Set, Tuple\n from urllib.parse import urlparse\n \n import grpc\n@@ -310,6 +310,7 @@ class GrpcConnectionPool:\n             entity_id: Optional[int] = None,\n             increase_access_count: bool = True,\n         ) -> ReplicaList:\n+            # returns all replicas of a given deployment, using a given shard\n             if deployment in self._deployments:\n                 type_ = 'heads' if head else 'shards'\n                 if entity_id is None and head:\n@@ -324,6 +325,8 @@ class GrpcConnectionPool:\n                 return None\n \n         def get_replicas_all_shards(self, deployment: str) -> List[ReplicaList]:\n+            # returns all replicas of a given deployment, for all available shards\n+            # result is a list of 'shape' (num_shards, num_replicas), containing all replicas for all shards\n             replicas = []\n             if deployment in self._deployments:\n                 for shard_id in self._deployments[deployment]['shards']:\n@@ -527,18 +530,20 @@ class GrpcConnectionPool:\n         results = []\n         connections = []\n         if polling_type == PollingType.ANY:\n-            connection_list = self._connections.get_replicas(deployment, head, shard_id)\n-            if connection_list:\n-                connections.append(connection_list.get_next_connection())\n+            replica_list = self._connections.get_replicas(deployment, head, shard_id)\n+            if replica_list:\n+                connections.append(replica_list)\n         elif polling_type == PollingType.ALL:\n-            connection_lists = self._connections.get_replicas_all_shards(deployment)\n-            for connection_list in connection_lists:\n-                connections.append(connection_list.get_next_connection())\n+            shard_replica_lists = self._connections.get_replicas_all_shards(deployment)\n+            for replica_list in shard_replica_lists:\n+                connections.append(replica_list)\n         else:\n             raise ValueError(f'Unsupported polling type {polling_type}')\n \n-        for connection in connections:\n-            task = self._send_requests(requests, connection, endpoint, timeout=timeout)\n+        for replica_list in connections:\n+            task = self._send_requests(\n+                requests, replica_list, endpoint, timeout=timeout\n+            )\n             results.append(task)\n \n         return results\n@@ -611,8 +616,7 @@ class GrpcConnectionPool:\n         \"\"\"\n         replicas = self._connections.get_replicas(deployment, head, shard_id)\n         if replicas:\n-            connection = replicas.get_next_connection()\n-            return self._send_requests(requests, connection, endpoint, timeout=timeout)\n+            return self._send_requests(requests, replicas, endpoint, timeout=timeout)\n         else:\n             self._logger.debug(\n                 f'no available connections for deployment {deployment} and shard {shard_id}'\n@@ -682,7 +686,8 @@ class GrpcConnectionPool:\n         e: AioRpcError,\n         retry_i: int = 0,\n         request_id: str = '',\n-        dest_addr: str = '',\n+        dest_addr: Set[str] = {''},\n+        num_retries: int = 3,\n     ):\n         # connection failures and cancelled requests should be retried\n         # all other cases should not be retried and will be raised immediately\n@@ -707,13 +712,14 @@ class GrpcConnectionPool:\n             )\n         else:\n             self._logger.debug(\n-                f'GRPC call failed with code {e.code()}, retry attempt {retry_i + 1}/3'\n+                f'GRPC call failed with code {e.code()}, retry attempt {retry_i + 1}/{num_retries}.'\n+                f' Trying next replica, if available.'\n             )\n \n     def _send_requests(\n         self,\n         requests: List[Request],\n-        connection: ConnectionStubs,\n+        connections: ReplicaList,\n         endpoint: Optional[str] = None,\n         timeout: Optional[float] = None,\n     ) -> asyncio.Task:\n@@ -721,9 +727,13 @@ class GrpcConnectionPool:\n         # the grpc call function is not a coroutine but some _AioCall\n         async def task_wrapper():\n             metadata = (('endpoint', endpoint),) if endpoint else None\n-            for i in range(3):\n+            tried_addresses = set()\n+            num_retries = max(3, len(connections.get_all_connections()))\n+            for i in range(num_retries):\n+                current_connection = connections.get_next_connection()\n+                tried_addresses.add(current_connection.address)\n                 try:\n-                    return await connection.send_requests(\n+                    return await current_connection.send_requests(\n                         requests=requests,\n                         metadata=metadata,\n                         compression=self.compression,\n@@ -734,7 +744,8 @@ class GrpcConnectionPool:\n                         e=e,\n                         retry_i=i,\n                         request_id=requests[0].request_id,\n-                        dest_addr=connection.address,\n+                        dest_addr=tried_addresses,\n+                        num_retries=num_retries,\n                     )\n \n         return asyncio.create_task(task_wrapper())\n\n---\n file path A: jina/serve/runtimes/gateway/graph/topology_graph.py | file path B: jina/serve/runtimes/gateway/graph/topology_graph.py\n\n@@ -65,7 +65,7 @@ class TopologyGraph:\n             if err_code == grpc.StatusCode.UNAVAILABLE:\n                 err._details = (\n                     err.details()\n-                    + f' |Gateway: Communication error with deployment {self.name} at address {err.dest_addr}. Head or worker may be down.'\n+                    + f' |Gateway: Communication error with deployment {self.name} at address(es) {err.dest_addr}. Head or worker(s) may be down.'\n                 )\n                 raise err\n             else:\n\n---\n file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -98,7 +98,7 @@ class RequestHandler:\n                 if err_code == grpc.StatusCode.UNAVAILABLE:\n                     err._details = (\n                         err.details()\n-                        + f' |Gateway: Communication error with deployment at address {err.dest_addr}. Head or worker may be down.'\n+                        + f' |Gateway: Communication error with deployment at address(es) {err.dest_addr}. Head or worker(s) may be down.'\n                     )\n                     raise err\n                 else:\n\n---\n file path A: tests/integration/runtimes/test_network_failures.py | file path B: tests/integration/runtimes/test_network_failures.py\n\n@@ -71,11 +71,14 @@ def _send_request(gateway_port, protocol):\n     )\n \n \n-def _test_error(gateway_port, error_port, protocol):\n+def _test_error(gateway_port, error_ports, protocol):\n+    if not isinstance(error_ports, list):\n+        error_ports = [error_ports]\n     with pytest.raises(ConnectionError) as err_info:  # assert correct error is thrown\n         _send_request(gateway_port, protocol)\n-    # assert error message contains the port of the broken executor\n-    assert str(error_port) in err_info.value.args[0]\n+    # assert error message contains the port(s) of the broken executor(s)\n+    for port in error_ports:\n+        assert str(port) in err_info.value.args[0]\n \n \n @pytest.mark.parametrize(\n@@ -141,7 +144,6 @@ async def test_runtimes_headless_topology(\n             # so in this case, the actual request will fail, not the discovery, which is handled differently by Gateway\n             worker_process.terminate()  # kill worker\n             worker_process.join()\n-            print(f'worker is alive: {worker_process.is_alive()}')\n             assert not worker_process.is_alive()\n         # ----------- 2. test that gateways remain alive -----------\n         # just do the same again, expecting the same failure\n@@ -411,3 +413,116 @@ async def test_runtimes_graphql(port_generator):\n         worker_process.terminate()\n         gateway_process.join()\n         worker_process.join()\n+\n+\n+@pytest.mark.asyncio\n+async def test_replica_retry(port_generator):\n+    # test that if one replica is down, the other replica(s) will be used\n+    # create gateway and workers manually, then terminate worker process to provoke an error\n+    worker_ports = [port_generator() for _ in range(3)]\n+    worker0_port, worker1_port, worker2_port = worker_ports\n+    gateway_port = port_generator()\n+    graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\n+    pod_addresses = f'{{\"pod0\": [\"0.0.0.0:{worker0_port}\", \"0.0.0.0:{worker1_port}\", \"0.0.0.0:{worker2_port}\"]}}'\n+\n+    worker_processes = []\n+    for p in worker_ports:\n+        worker_processes.append(_create_worker(p))\n+        time.sleep(0.1)\n+        AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+            timeout=5.0,\n+            ctrl_address=f'0.0.0.0:{p}',\n+            ready_or_shutdown_event=multiprocessing.Event(),\n+        )\n+\n+    gateway_process = _create_gateway(\n+        gateway_port, graph_description, pod_addresses, 'grpc'\n+    )\n+    AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'0.0.0.0:{gateway_port}',\n+        ready_or_shutdown_event=multiprocessing.Event(),\n+    )\n+\n+    try:\n+        # ----------- 1. ping Flow once to trigger endpoint discovery -----------\n+        # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n+        p = multiprocessing.Process(target=_send_request, args=(gateway_port, 'grpc'))\n+        p.start()\n+        p.join()\n+        assert p.exitcode == 0\n+        # kill second worker, which would be responsible for the second call (round robin)\n+        worker_processes[1].terminate()\n+        worker_processes[1].join()\n+        # ----------- 2. test that redundant replicas take over -----------\n+        # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n+        p = multiprocessing.Process(target=_send_request, args=(gateway_port, 'grpc'))\n+        p.start()\n+        p.join()\n+        assert p.exitcode == 0\n+    except Exception:\n+        assert False\n+    finally:  # clean up runtimes\n+        gateway_process.terminate()\n+        gateway_process.join()\n+        for p in worker_processes:\n+            p.terminate()\n+            p.join()\n+\n+\n+@pytest.mark.asyncio\n+async def test_replica_retry_all_fail(port_generator):\n+    # test that if one replica is down, the other replica(s) will be used\n+    # create gateway and workers manually, then terminate worker process to provoke an error\n+    worker_ports = [port_generator() for _ in range(3)]\n+    worker0_port, worker1_port, worker2_port = worker_ports\n+    gateway_port = port_generator()\n+    graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\n+    pod_addresses = f'{{\"pod0\": [\"0.0.0.0:{worker0_port}\", \"0.0.0.0:{worker1_port}\", \"0.0.0.0:{worker2_port}\"]}}'\n+\n+    worker_processes = []\n+    for p in worker_ports:\n+        worker_processes.append(_create_worker(p))\n+        time.sleep(0.1)\n+        AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+            timeout=5.0,\n+            ctrl_address=f'0.0.0.0:{p}',\n+            ready_or_shutdown_event=multiprocessing.Event(),\n+        )\n+\n+    gateway_process = _create_gateway(\n+        gateway_port, graph_description, pod_addresses, 'grpc'\n+    )\n+    AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'0.0.0.0:{gateway_port}',\n+        ready_or_shutdown_event=multiprocessing.Event(),\n+    )\n+\n+    try:\n+        # ----------- 1. ping Flow once to trigger endpoint discovery -----------\n+        # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n+        p = multiprocessing.Process(target=_send_request, args=(gateway_port, 'grpc'))\n+        p.start()\n+        p.join()\n+        assert p.exitcode == 0\n+        # kill all workers\n+        for p in worker_processes:\n+            p.terminate()\n+            p.join()\n+        # ----------- 2. test that call fails with informative error message -----------\n+        # we have to do this in a new process because otherwise grpc will be sad and everything will crash :(\n+        p = multiprocessing.Process(\n+            target=_test_error, args=(gateway_port, worker_ports, 'grpc')\n+        )\n+        p.start()\n+        p.join()\n+        assert p.exitcode == 0\n+    except Exception:\n+        assert False\n+    finally:  # clean up runtimes\n+        gateway_process.terminate()\n+        gateway_process.join()\n+        for p in worker_processes:\n+            p.terminate()\n+            p.join()\n\n\n###\n\n", "completion": "feat: smart replica retry (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/monitoring-flow.md | file path B: docs/fundamentals/flow/monitoring-flow.md\n\n@@ -100,10 +100,12 @@ Because not all Pods have the same role, they expose different kinds of metrics:\n \n ### Gateway Pods\n \n-| Metrics name                       | Metrics type                                                         | Description                                                                                                                                                                                                                                                                |\n-|------------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n-| `jina_receiving_request_seconds`   | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between receiving a request from the client and sending back the response.                                                                                                                                                                    |\n-| `jina_sending_request_seconds`     | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between sending a downstream request to an Executor/Head and receiving the response back.                                                                                                                                                         |\n+| Metrics name                        | Metrics type                                                         | Description                                                                                                         |\n+|-------------------------------------|----------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------|\n+| `jina_receiving_request_seconds`    | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between receiving a request from the client and sending back the response.                |\n+| `jina_sending_request_seconds`      | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the time elapsed between sending a downstream request to an Executor/Head and receiving the response back. |\n+| `jina_number_of_pending_requests`       | [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge)     | Count the number of pending requests                                                                                |\n+\n \n ```{seealso} \n You can find more information on the different type of metrics in Prometheus [here](https://prometheus.io/docs/concepts/metric_types/#metric-types)\n@@ -123,6 +125,9 @@ You can find more information on the different type of metrics in Prometheus [he\n | `jina_receiving_request_seconds` | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measure the time elapsed between receiving a request from the gateway (or the head) and sending back the response. |\n | `jina_process_request_seconds`   | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measure the time spend calling the requested method                                                                   |\n | `jina_document_processed_total`  | [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) | Counts the number of Documents processed by an Executor                                                                 |\n+| `request_size_bytes`             | [Summary](https://prometheus.io/docs/concepts/metric_types/#summary) | Measures the size of the requests in Bytes\n+\n+\n \n ```{seealso} \n Beyond monitoring every endpoint of an Executor you can define {ref}`custom metrics <monitoring-executor>`for you \n\n---\n file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -30,7 +30,7 @@ class RequestHandler:\n         metrics_registry: Optional['CollectorRegistry'] = None,\n         runtime_name: Optional[str] = None,\n     ):\n-        self.request_init_time = {} if metrics_registry else None\n+        self._request_init_time = {} if metrics_registry else None\n         self._executor_endpoint_mapping = None\n \n         if metrics_registry:\n@@ -38,9 +38,9 @@ class RequestHandler:\n                 required=True,\n                 help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n             ):\n-                from prometheus_client import Summary\n+                from prometheus_client import Gauge, Summary\n \n-            self._summary = Summary(\n+            self._receiving_request_metrics = Summary(\n                 'receiving_request_seconds',\n                 'Time spent processing request',\n                 registry=metrics_registry,\n@@ -48,8 +48,17 @@ class RequestHandler:\n                 labelnames=('runtime_name',),\n             ).labels(runtime_name)\n \n+            self._pending_requests_metrics = Gauge(\n+                'number_of_pending_requests',\n+                'Number of pending requests',\n+                registry=metrics_registry,\n+                namespace='jina',\n+                labelnames=('runtime_name',),\n+            ).labels(runtime_name)\n+\n         else:\n-            self._summary = None\n+            self._receiving_request_metrics = None\n+            self._pending_requests_metrics = None\n \n     def handle_request(\n         self, graph: 'TopologyGraph', connection_pool: 'GrpcConnectionPool'\n@@ -100,8 +109,10 @@ class RequestHandler:\n                 self._executor_endpoint_mapping[node.name] = endp.endpoints\n \n         def _handle_request(request: 'Request') -> 'asyncio.Future':\n-            if self._summary:\n-                self.request_init_time[request.request_id] = time.time()\n+            if self._receiving_request_metrics:\n+                self._request_init_time[request.request_id] = time.time()\n+            if self._pending_requests_metrics:\n+                self._pending_requests_metrics.inc()\n             # important that the gateway needs to have an instance of the graph per request\n             request_graph = copy.deepcopy(graph)\n \n@@ -194,11 +205,14 @@ class RequestHandler:\n                 if route.executor == 'gateway':\n                     route.end_time.GetCurrentTime()\n \n-            if self._summary:\n-                init_time = self.request_init_time.pop(\n+            if self._receiving_request_metrics:\n+                init_time = self._request_init_time.pop(\n                     result.request_id\n-                )  # need to pop otherwise it stay in memory for ever\n-                self._summary.observe(time.time() - init_time)\n+                )  # need to pop otherwise it stays in memory forever\n+                self._receiving_request_metrics.observe(time.time() - init_time)\n+\n+            if self._pending_requests_metrics:\n+                self._pending_requests_metrics.dec()\n \n             return result\n \n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -49,7 +49,7 @@ class DataRequestHandler:\n                 required=True,\n                 help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n             ):\n-                from prometheus_client import Counter\n+                from prometheus_client import Counter, Summary\n \n                 self._counter = Counter(\n                     'document_processed',\n@@ -58,8 +58,17 @@ class DataRequestHandler:\n                     labelnames=('executor_endpoint', 'executor', 'runtime_name'),\n                     registry=metrics_registry,\n                 )\n+\n+                self._request_size_metrics = Summary(\n+                    'request_size_bytes',\n+                    'The request size in Bytes',\n+                    namespace='jina',\n+                    labelnames=('executor_endpoint', 'executor', 'runtime_name'),\n+                    registry=metrics_registry,\n+                )\n         else:\n             self._counter = None\n+            self._request_size_metrics = None\n \n     def _load_executor(self, metrics_registry: Optional['CollectorRegistry'] = None):\n         \"\"\"\n@@ -121,6 +130,15 @@ class DataRequestHandler:\n             )\n             return requests[0]\n \n+        if self._request_size_metrics:\n+\n+            for req in requests:\n+                self._request_size_metrics.labels(\n+                    requests[0].header.exec_endpoint,\n+                    self._executor.__class__.__name__,\n+                    self.args.name,\n+                ).observe(req.nbytes)\n+\n         params = self._parse_params(requests[0].parameters, self._executor.metas.name)\n         docs = DataRequestHandler.get_docs_from_request(\n             requests,\n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -1,3 +1,4 @@\n+import multiprocessing\n import time\n \n import pytest\n@@ -152,3 +153,100 @@ def test_disable_monitoring_on_gatway_only(port_generator, executor):\n \n         resp = req.get(f'http://localhost:{port1}/')  # enable on port0\n         assert resp.status_code == 200\n+\n+\n+def test_requests_size(port_generator, executor):\n+    port0 = port_generator()\n+    port1 = port_generator()\n+\n+    with Flow(monitoring=True, port_monitoring=port0).add(\n+        uses=executor, port_monitoring=port1\n+    ) as f:\n+\n+        f.post('/foo', inputs=DocumentArray.empty(size=1))\n+\n+        resp = req.get(f'http://localhost:{port1}/')  # enable on port0\n+        assert resp.status_code == 200\n+\n+        assert (\n+            f'jina_request_size_bytes_count{{executor=\"DummyExecutor\",executor_endpoint=\"/foo\",runtime_name=\"executor0/rep-0\"}} 1.0'\n+            in str(resp.content)\n+        )\n+\n+        def _get_request_bytes_size():\n+            resp = req.get(f'http://localhost:{port1}/')  # enable on port0\n+\n+            resp_lines = str(resp.content).split('\\\\n')\n+            byte_line = [\n+                line\n+                for line in resp_lines\n+                if 'jina_request_size_bytes_sum{executor=\"DummyExecutor\"' in line\n+            ]\n+\n+            return float(byte_line[0][-5:])\n+\n+        measured_request_bytes_sum_init = _get_request_bytes_size()\n+        f.post('/foo', inputs=DocumentArray.empty(size=1))\n+        measured_request_bytes_sum = _get_request_bytes_size()\n+\n+        assert measured_request_bytes_sum > measured_request_bytes_sum_init\n+\n+\n+def test_pending_request(port_generator):\n+    port0 = port_generator()\n+    port1 = port_generator()\n+\n+    class SlowExecutor(Executor):\n+        @requests\n+        def foo(self, docs, **kwargs):\n+            time.sleep(5)\n+\n+    with Flow(monitoring=True, port_monitoring=port0).add(\n+        uses=SlowExecutor, port_monitoring=port1\n+    ) as f:\n+\n+        def _send_request():\n+            f.search(inputs=DocumentArray.empty(size=1))\n+\n+        def _assert_pending_value(val: str):\n+            resp = req.get(f'http://localhost:{port0}/')\n+            assert resp.status_code == 200\n+            assert (\n+                f'jina_number_of_pending_requests{{runtime_name=\"gateway/rep-0/GRPCGatewayRuntime\"}} {val}'\n+                in str(resp.content)\n+            )\n+\n+        _assert_while = lambda: _assert_pending_value(\n+            '1.0'\n+        )  # while the request is being processed the counter is at one\n+        _assert_after = lambda: _assert_pending_value(\n+            '0.0'\n+        )  # but before and after it is at 0\n+        _assert_before = lambda: _assert_pending_value(\n+            '0.0'\n+        )  # but before and after it is at 0\n+\n+        p_send = multiprocessing.Process(target=_send_request)\n+        p_before = multiprocessing.Process(target=_assert_before)\n+        p_while = multiprocessing.Process(target=_assert_while)\n+\n+        p_before.start()\n+        time.sleep(1)\n+        p_send.start()\n+        time.sleep(1)\n+        p_while.start()\n+\n+        for p in [p_before, p_send, p_while]:\n+            p.join()\n+\n+        exitcodes = []\n+        for p in [p_before, p_send, p_while]:\n+            p.terminate()\n+            exitcodes.append(\n+                p.exitcode\n+            )  # collect the exit codes and assert after all of them have been terminated, to avoid timeouts\n+\n+        for code in exitcodes:\n+            assert not code\n+\n+        _assert_after()\n\n\n###\n\n", "completion": "feat: add additional metrics (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1,6 +1,7 @@\n import argparse\n import base64\n import copy\n+import inspect\n import json\n import multiprocessing\n import os\n@@ -8,6 +9,7 @@ import sys\n import threading\n import time\n import uuid\n+import warnings\n from collections import OrderedDict\n from contextlib import ExitStack\n from typing import (\n@@ -2037,3 +2039,15 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         :param kwargs: new network settings\n         \"\"\"\n         self._common_kwargs.update(kwargs)\n+\n+    def __getattribute__(self, item):\n+        obj = super().__getattribute__(item)\n+\n+        if (\n+            item == 'load_config' and inspect.ismethod(obj) and obj.__self__ is Flow\n+        ):  # check if obj load config call from an instance and not the Class\n+            warnings.warn(\n+                \"Calling load_config from a Flow instance will override all of the instance's initial parameters. We recommend to use `Flow.load_config(...)` instead\"\n+            )\n+\n+        return obj\n\n---\n file path A: None | file path B: tests/integration/issues/github_4773/config.yaml\n\n@@ -0,0 +1 @@\n+jtype: Flow\n\n---\n file path A: None | file path B: tests/integration/issues/github_4773/test_load_config.py\n\n@@ -0,0 +1,16 @@\n+import warnings\n+\n+import pytest\n+\n+from jina import Flow\n+\n+\n+def test_load_config_instance():\n+    with pytest.warns(UserWarning):  # assert that a warning has been emited\n+        f = Flow().load_config('config.yaml')\n+\n+\n+def test_load_config_class():  # assert that no warnings were emited\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\")\n+        f = Flow.load_config('config.yaml')\n\n---\n file path A: tests/integration/override_config_params/worker/test_override_config_params.py | file path B: tests/integration/override_config_params/worker/test_override_config_params.py\n\n@@ -2,8 +2,7 @@ import os\n \n import pytest\n \n-from jina import Executor, Client, requests\n-from jina import Flow, Document\n+from jina import Client, Document, Executor, Flow, requests\n \n cur_dir = os.path.dirname(os.path.abspath(__file__))\n exposed_port = 12345\n@@ -13,7 +12,7 @@ exposed_port = 12345\n def flow(request):\n     flow_src = request.param\n     if flow_src == 'flow-yml':\n-        return Flow().load_config(os.path.join(cur_dir, 'flow.yml'))\n+        return Flow.load_config(os.path.join(cur_dir, 'flow.yml'))\n     elif flow_src == 'uses-yml':\n         return Flow(port=exposed_port).add(\n             uses=os.path.join(cur_dir, 'default_config.yml'),\n\n---\n file path A: tests/unit/parsers/test_warnings.py | file path B: tests/unit/parsers/test_warnings.py\n\n@@ -1,6 +1,6 @@\n import pytest\n \n-from jina import Flow, Executor\n+from jina import Executor, Flow\n \n \n class MyExecutor(Executor):\n@@ -16,7 +16,7 @@ with:\n     foo: bar\n     '''\n     with pytest.warns(UserWarning, match='ignored unknown') as record:\n-        Flow().load_config(yaml)\n+        Flow.load_config(yaml)\n     assert len(record) == 1\n     assert record[0].message.args[0].startswith('ignored unknown')\n \n@@ -28,7 +28,7 @@ executors:\n     - foo: bar\n     '''\n     with pytest.warns(UserWarning, match='ignored unknown') as record:\n-        Flow().load_config(yaml)\n+        Flow.load_config(yaml)\n     assert len(record) == 1\n     assert record[0].message.args[0].startswith('ignored unknown')\n \n@@ -41,7 +41,7 @@ executors:\n         foo: bar\n     '''\n     with pytest.warns(UserWarning, match='ignored unknown') as record:\n-        Flow().load_config(yaml)\n+        Flow.load_config(yaml)\n     assert len(record) == 1\n     assert record[0].message.args[0].startswith('ignored unknown')\n \n@@ -54,7 +54,7 @@ executors:\n         foo: bar\n     '''\n     with pytest.warns(None, match='ignored unknown') as record:\n-        Flow().load_config(yaml)\n+        Flow.load_config(yaml)\n     assert len(record) == 0\n \n \n@@ -65,7 +65,7 @@ executors:\n     - override_with: 1\n     '''\n     with pytest.warns(None, match='ignored unknown') as record:\n-        Flow().load_config(yaml)\n+        Flow.load_config(yaml)\n     assert len(record) == 1\n \n \n@@ -79,7 +79,7 @@ executors:\n             name: MyExecutor\n     '''\n     with pytest.warns(None, match='ignored unknown') as record:\n-        with Flow().load_config(yaml):\n+        with Flow.load_config(yaml):\n             pass\n     assert len(record) == 0\n \n\n\n###\n\n", "completion": "fix: warn user when calling load config from flow instance (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -94,27 +94,11 @@ def get_download_cache_dir() -> Path:\n \n @lru_cache()\n def _get_hubble_base_url() -> str:\n-    \"\"\"Get base Hubble Url from api.jina.ai or os.environ\n+    \"\"\"Get base Hubble Url from os.environ or constants\n \n     :return: base Hubble Url\n     \"\"\"\n-    if 'JINA_HUBBLE_REGISTRY' in os.environ:\n-        u = os.environ['JINA_HUBBLE_REGISTRY']\n-    else:\n-        try:\n-            req = Request(\n-                'https://api.jina.ai/hub/hubble.json',\n-                headers={'User-Agent': 'Mozilla/5.0'},\n-            )\n-            with urlopen(req) as resp:\n-                u = json.load(resp)['url']\n-        except:\n-            default_logger.critical(\n-                'Can not fetch the Url of Hubble from `api.jina.ai`'\n-            )\n-            raise\n-\n-    return u\n+    return os.environ.get('JINA_HUBBLE_REGISTRY', 'https://api.hubble.jina.ai')\n \n \n @lru_cache()\n\n\n###\n\n", "completion": "feat(hubble): use fixed domain for hubble api (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -182,6 +182,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13666,3 +13667,29 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```95c1519d```](https://github.com/jina-ai/jina/commit/95c1519d60a9c53274b3d4daad0181c6353cd337)] __-__ fix readme (*Han Xiao*)\n  - [[```6194244f```](https://github.com/jina-ai/jina/commit/6194244fd2886ff2e05e7df27d0d9fdc5dfe75a2)] __-__ __version__: the next version will be 3.4.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-4></a>\n+## Release Note (`3.4.4`)\n+\n+> Release time: 2022-05-18 12:54:06\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Delgermurun,  Sha Zhou,  Jina Dev Bot,  Roshan Jossy,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```0372f10f```](https://github.com/jina-ai/jina/commit/0372f10f381af1b5be1efdcec3ee062f98d5fe30)] __-__ unsetenv not existing on Windows (#4800) (*Joan Fontanals*)\n+ - [[```99ccff1f```](https://github.com/jina-ai/jina/commit/99ccff1fefbf8a6064b685598abe48ad45044234)] __-__ remove executor secret from flow mermaid chart (#4801) (*Delgermurun*)\n+ - [[```d66e98c1```](https://github.com/jina-ai/jina/commit/d66e98c145785e7cb11f496bb061c5da6f537be4)] __-__ __qabot__: hide the slot elements on the docs page (#4799) (*Sha Zhou*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```f0f5948e```](https://github.com/jina-ai/jina/commit/f0f5948ea6a50074b1b74fe9698a83b1413bba30)] __-__ __tracking__: remove adding utm_source to links (#4798) (*Roshan Jossy*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```32d85a50```](https://github.com/jina-ai/jina/commit/32d85a502438a6a99c886e2d4e974db213a025ef)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```2b5efac1```](https://github.com/jina-ai/jina/commit/2b5efac1478f33134d481e8cf9fcc7b405c58515)] __-__ __version__: the next version will be 3.4.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.4'\n+__version__ = '3.4.5'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.5"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -131,6 +131,8 @@ def _try_plugin_command():\n def main():\n     \"\"\"The main entrypoint of the CLI\"\"\"\n \n+    from jina import __windows__\n+\n     class EnvVariableSet:\n         def __init__(self, key, value):\n             self.key = key\n@@ -143,8 +145,10 @@ def main():\n                 os.environ[self.key] = self.value\n \n         def __exit__(self, exc_type, exc_val, exc_tb):\n-            if self.unset:\n+            if self.unset and not __windows__:\n                 os.unsetenv(self.key)\n+            elif self.unset and __windows__:\n+                del os.environ[self.key]\n \n     with EnvVariableSet('JINA_CHECK_VERSION', 'True'):\n         found_plugin = _try_plugin_command()\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1014,7 +1014,8 @@ def _close_loop():\n # workaround for asyncio loop and fork issue: https://github.com/python/cpython/issues/66197\n # we close the loop after forking to avoid reusing the parents process loop\n # a new loop should be created in the child process\n-os.register_at_fork(after_in_child=_close_loop)\n+if not __windows__:\n+    os.register_at_fork(after_in_child=_close_loop)\n \n \n def get_or_reuse_loop():\n\n\n###\n\n", "completion": "fix: unsetenv not existing on Windows (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -189,6 +189,23 @@ def parse_hub_uri(uri_path: str) -> Tuple[str, str, str, str]:\n     return scheme, name, tag, secret\n \n \n+def replace_secret_of_hub_uri(uri_path: str, txt: str = '<secret>') -> str:\n+    \"\"\"Replace the secret of the Jina Hub URI.\n+\n+    :param uri_path: the uri of Jina Hub URI\n+    :param txt: text to replace\n+    :return: the new URI\n+    \"\"\"\n+\n+    try:\n+        secret = parse_hub_uri(uri_path)[-1]\n+        if secret:\n+            return uri_path.replace(secret, txt)\n+    except ValueError:\n+        pass  # ignore if the URI is not a valid Jina Hub URI\n+    return uri_path\n+\n+\n def is_valid_huburi(uri: str) -> bool:\n     \"\"\"Return True if it is a valid Hubble URI\n \n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -11,6 +11,7 @@ from typing import Dict, List, Optional, Set, Union\n from jina import __default_executor__, __default_host__, __docker_host__, helper\n from jina.enums import DeploymentRoleType, PodRoleType, PollingType\n from jina.helper import CatchAllCleanupContextManager\n+from jina.hubble.helper import replace_secret_of_hub_uri\n from jina.hubble.hubio import HubIO\n from jina.jaml.helper import complete_path\n from jina.orchestrate.pods.container import ContainerPod\n@@ -781,6 +782,7 @@ class Deployment(BaseDeployment):\n         .. # noqa: DAR201\n         \"\"\"\n         mermaid_graph = []\n+        secret = '&ltsecret&gt'\n         if self.role != DeploymentRoleType.GATEWAY and not self.external:\n             mermaid_graph = [f'subgraph {self.name};', f'\\ndirection LR;\\n']\n \n@@ -790,7 +792,7 @@ class Deployment(BaseDeployment):\n                 else None\n             )\n             uses_before_uses = (\n-                self.uses_before_args.uses\n+                replace_secret_of_hub_uri(self.uses_before_args.uses, secret)\n                 if self.uses_before_args is not None\n                 else None\n             )\n@@ -798,7 +800,9 @@ class Deployment(BaseDeployment):\n                 self.uses_after_args.name if self.uses_after_args is not None else None\n             )\n             uses_after_uses = (\n-                self.uses_after_args.uses if self.uses_after_args is not None else None\n+                replace_secret_of_hub_uri(self.uses_after_args.uses, secret)\n+                if self.uses_after_args is not None\n+                else None\n             )\n             shard_names = []\n             if len(self.pod_args['pods']) > 1:\n@@ -818,7 +822,7 @@ class Deployment(BaseDeployment):\n                     ]  # all the uses should be the same but let's keep it this\n                     # way\n                     for rep_i, (name, use) in enumerate(zip(names, uses)):\n-                        escaped_uses = f'\"{use}\"'\n+                        escaped_uses = f'\"{replace_secret_of_hub_uri(use, secret)}\"'\n                         shard_mermaid_graph.append(f'{name}[{escaped_uses}]:::pod;')\n                     shard_mermaid_graph.append('end;')\n                     shard_mermaid_graph = [\n@@ -828,7 +832,9 @@ class Deployment(BaseDeployment):\n                     mermaid_graph.append('\\n')\n                 if uses_before_name is not None:\n                     for shard_name in shard_names:\n-                        escaped_uses_before_uses = f'\"{uses_before_uses}\"'\n+                        escaped_uses_before_uses = (\n+                            f'\"{replace_secret_of_hub_uri(uses_before_uses, secret)}\"'\n+                        )\n                         mermaid_graph.append(\n                             f'{self.args.name}-head[{escaped_uses_before_uses}]:::HEADTAIL --> {shard_name};'\n                         )\n@@ -840,16 +846,17 @@ class Deployment(BaseDeployment):\n                         )\n             else:\n                 # single shard case, no uses_before or uses_after_considered\n-                name = list(self.pod_args['pods'].values())[0][0].name\n-                uses = f'\"{list(self.pod_args[\"pods\"].values())[0][0].uses}\"'\n-                num_replicas = list(self.pod_args['pods'].values())[0][0].replicas\n+                pod_args = list(self.pod_args['pods'].values())[0][0]\n+                uses = f'\"{replace_secret_of_hub_uri(pod_args.uses, secret)}\"'\n \n                 # just put the replicas in parallel\n-                if num_replicas > 1:\n-                    for rep_i in range(num_replicas):\n-                        mermaid_graph.append(f'{name}/rep-{rep_i}[{uses}]:::pod;')\n+                if pod_args.replicas > 1:\n+                    for rep_i in range(pod_args.replicas):\n+                        mermaid_graph.append(\n+                            f'{pod_args.name}/rep-{rep_i}[\"{uses}\"]:::pod;'\n+                        )\n                 else:\n-                    mermaid_graph.append(f'{name}[{uses}]:::pod;')\n+                    mermaid_graph.append(f'{pod_args.name}[\"{uses}\"]:::pod;')\n \n             mermaid_graph.append('end;')\n         return mermaid_graph\n\n---\n file path A: tests/unit/hubble/test_helper.py | file path B: tests/unit/hubble/test_helper.py\n\n@@ -5,7 +5,6 @@ import pytest\n \n from jina.hubble import helper\n from jina.hubble.helper import disk_cache_offline\n-from jina.parsers.hubble import set_hub_pull_parser\n \n \n @pytest.fixture\n@@ -44,6 +43,19 @@ def test_parse_wrong_hub_uri(uri_path):\n     assert f'{uri_path} is not a valid Hub URI.' == str(info.value)\n \n \n+def test_replace_secret_of_hub_uri():\n+    result = helper.replace_secret_of_hub_uri('jinahub://hello', '_secret_')\n+    assert result == 'jinahub://hello'\n+\n+    result = helper.replace_secret_of_hub_uri(\n+        'jinahub://hello:dummy@secret/path', '*secret*'\n+    )\n+    assert result == 'jinahub://hello:*secret*/path'\n+\n+    result = helper.replace_secret_of_hub_uri('hello:magic/world')\n+    assert result == 'hello:magic/world'\n+\n+\n def test_md5file(dummy_zip_file):\n     md5sum = helper.md5file(dummy_zip_file)\n     assert md5sum == '7ffd1501f24fe5a66dc45883550c2005'\n\n---\n file path A: tests/unit/orchestrate/deployments/test_deployments.py | file path B: tests/unit/orchestrate/deployments/test_deployments.py\n\n@@ -1,6 +1,5 @@\n import json\n import os\n-from multiprocessing import Process\n \n import pytest\n \n@@ -116,13 +115,14 @@ def test_uses_before_after(pod_args, shards):\n         assert pod.num_pods == 5 if shards == 2 else 1\n \n \n-def test_mermaid_str_no_error(pod_args):\n+def test_mermaid_str_no_secret(pod_args):\n     pod_args.replicas = 3\n-    pod_args.uses_before = 'MyDummyExecutor'\n+    pod_args.shards = 3\n+    pod_args.uses_before = 'jinahub+docker://MyDummyExecutor:Dummy@Secret'\n     pod_args.uses_after = 'ChildDummyExecutor2'\n-    pod_args.uses = 'ChildDummyExecutor'\n+    pod_args.uses = 'jinahub://ChildDummyExecutor:Dummy@Secret'\n     pod = Deployment(pod_args)\n-    print(pod._mermaid_str)\n+    assert 'Dummy@Secret' not in ''.join(pod._mermaid_str)\n \n \n @pytest.mark.slow\n\n\n###\n\n", "completion": "fix: remove executor secret from flow mermaid chart (#<issue-num>)"}
{"prompt": " file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -191,13 +191,15 @@\n     <qa-bot\n         title=\"Jina Bot\"\n         description=\"The cloud-native neural search framework\"\n-        >\n-        <dl>\n-            <dt>You can ask questions about our docs. Try:</dt>\n-            <dd>Does Jina support Kubernetes?</dd>\n-            <dd>What are the basic concepts in Jina?</dd>\n-            <dd>How to share my Executor?</dd>\n-        </dl>\n+    >\n+        <template>\n+            <dl>\n+                <dt>You can ask questions about our docs. Try:</dt>\n+                <dd>Does Jina support Kubernetes?</dd>\n+                <dd>What are the basic concepts in Jina?</dd>\n+                <dd>How to share my Executor?</dd>\n+            </dl>\n+        </template>\n     </qa-bot>\n \n </div>\n\n\n###\n\n", "completion": "fix(qabot): hide the slot elements on the docs page (#<issue-num>)"}
{"prompt": " file path A: docs/_static/source-in-links.js | file path B: None\n\n@@ -1,22 +0,0 @@\n-function addUTMSourceToLink(href) {\n-    try {\n-        var url = new URL(href);\n-        url.searchParams.set(\"utm_source\", \"jina\");\n-        return url.href\n-    }\n-    catch{\n-        return href\n-    }\n-}\n-\n-function addUTMSourceToLinks() {\n-    var anchors = document.getElementsByTagName(\"a\");\n-\n-    for (var i = 0; i < anchors.length; i++) {\n-        anchors[i].href = addUTMSourceToLink(anchors[i].href)\n-    }\n-}\n-\n-window.onload = function () {\n-    addUTMSourceToLinks()\n-}\n\\ No newline at end of file\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -78,8 +78,7 @@ html_css_files = [\n     'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css',\n ]\n html_js_files = [\n-    'https://cdn.jsdelivr.net/npm/qabot@0.4',\n-    'source-in-links.js'\n+    'https://cdn.jsdelivr.net/npm/qabot@0.4'\n ]\n htmlhelp_basename = slug\n html_show_sourcelink = False\n\n\n###\n\n", "completion": "docs(tracking): remove adding utm_source to links (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -181,6 +181,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13642,3 +13643,25 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```8c4d1761```](https://github.com/jina-ai/jina/commit/8c4d17614de841ff1f0e8d7cf24d139225a8504a)] __-__ remove unnecessary steps on chore commit (*Han Xiao*)\n  - [[```01503bcd```](https://github.com/jina-ai/jina/commit/01503bcd66e27021bd41fd1a02888637394ffcf4)] __-__ __version__: the next version will be 3.4.2 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-3></a>\n+## Release Note (`3.4.3`)\n+\n+> Release time: 2022-05-17 10:52:53\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Johannes Messner,  Jina Dev Bot,  Han Xiao,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```a32bfe21```](https://github.com/jina-ai/jina/commit/a32bfe211534fb72fac52f30aa614683e1219f33)] __-__ pop the init time instead of normal access (#4791) (*samsja*)\n+ - [[```c663e291```](https://github.com/jina-ai/jina/commit/c663e2915716fe63af9edad5290b803226823d7a)] __-__ add check that jaml parses to correct class (#4790) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```ec923d02```](https://github.com/jina-ai/jina/commit/ec923d028282d7994069447fe509fafc235c3268)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```95c1519d```](https://github.com/jina-ai/jina/commit/95c1519d60a9c53274b3d4daad0181c6353cd337)] __-__ fix readme (*Han Xiao*)\n+ - [[```6194244f```](https://github.com/jina-ai/jina/commit/6194244fd2886ff2e05e7df27d0d9fdc5dfe75a2)] __-__ __version__: the next version will be 3.4.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.3'\n+__version__ = '3.4.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.4"}
{"prompt": " file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -195,9 +195,10 @@ class RequestHandler:\n                     route.end_time.GetCurrentTime()\n \n             if self._summary:\n-                self._summary.observe(\n-                    time.time() - self.request_init_time[result.request_id]\n-                )\n+                init_time = self.request_init_time.pop(\n+                    result.request_id\n+                )  # need to pop otherwise it stay in memory for ever\n+                self._summary.observe(time.time() - init_time)\n \n             return result\n \n\n\n###\n\n", "completion": "fix: pop the init time instead of normal access (#<issue-num>)"}
{"prompt": " file path A: jina/jaml/__init__.py | file path B: jina/jaml/__init__.py\n\n@@ -749,7 +749,12 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n                 # revert yaml's tag and load again, this time with substitution\n                 tag_yml = JAML.unescape(JAML.dump(no_tag_yml))\n             # load into object, no more substitute\n-            return JAML.load(tag_yml, substitute=False, runtime_args=runtime_args)\n+            obj = JAML.load(tag_yml, substitute=False, runtime_args=runtime_args)\n+            if not isinstance(obj, cls):\n+                raise BadConfigSource(\n+                    f'Can not construct {cls} object from {source}. Source might be an invalid configuration.'\n+                )\n+            return obj\n \n     @classmethod\n     def _override_yml_params(cls, raw_yaml, field_name, override_field):\n\n---\n file path A: None | file path B: tests/unit/jaml/invalid.yml\n\n@@ -0,0 +1 @@\n+invalidkey: hello\n\\ No newline at end of file\n\n---\n file path A: tests/unit/jaml/test_type_parse.py | file path B: tests/unit/jaml/test_type_parse.py\n\n@@ -2,9 +2,10 @@ import os\n \n import pytest\n \n-from jina.serve.executors import BaseExecutor\n+from jina import Flow, __default_executor__, requests\n+from jina.excepts import BadConfigSource\n from jina.jaml import JAML, JAMLCompatible\n-from jina import __default_executor__, requests, Flow\n+from jina.serve.executors import BaseExecutor\n \n \n class MyExecutor(BaseExecutor):\n@@ -179,3 +180,13 @@ def test_parsing_brackets_in_envvar():\n         assert b['executors'][0]['env']['var2'] == 'a'\n         assert b['executors'][0]['env']['var3'] == '{\"1\": \"2\"}-a'\n         assert b['executors'][0]['env']['var4'] == '-{\"1\": \"2\"}'\n+\n+\n+def test_exception_invalid_yaml():\n+    cur_dir = os.path.dirname(os.path.abspath(__file__))\n+    yaml = os.path.join(cur_dir, 'invalid.yml')\n+    with pytest.raises(BadConfigSource):\n+        BaseExecutor.load_config(yaml)\n+\n+    with pytest.raises(BadConfigSource):\n+        Flow.load_config(yaml)\n\n\n###\n\n", "completion": "fix: add check that jaml parses to correct class (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -180,6 +180,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13619,3 +13620,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```13a954be```](https://github.com/jina-ai/jina/commit/13a954bec4b42ce6c6b3540270eae34497c17b71)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```36ca89d3```](https://github.com/jina-ai/jina/commit/36ca89d31876b5eae38d83c28bfb8168e35fe690)] __-__ __version__: the next version will be 3.4.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-2></a>\n+## Release Note (`3.4.2`)\n+\n+> Release time: 2022-05-13 20:09:02\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```1dd09184```](https://github.com/jina-ai/jina/commit/1dd09184b8a0e1d0ce11a57214eb14cb400d86d7)] __-__ __deployment__: add roundrobin cuda device assignment (#4786) (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```8c4d1761```](https://github.com/jina-ai/jina/commit/8c4d17614de841ff1f0e8d7cf24d139225a8504a)] __-__ remove unnecessary steps on chore commit (*Han Xiao*)\n+ - [[```01503bcd```](https://github.com/jina-ai/jina/commit/01503bcd66e27021bd41fd1a02888637394ffcf4)] __-__ __version__: the next version will be 3.4.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.2'\n+__version__ = '3.4.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.3"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -1,7 +1,11 @@\n import copy\n+import os\n+import re\n+import subprocess\n from abc import abstractmethod\n from argparse import Namespace\n from contextlib import ExitStack\n+from itertools import cycle\n from typing import Dict, List, Optional, Set, Union\n \n from jina import __default_executor__, __default_host__, __docker_host__, helper\n@@ -13,6 +17,8 @@ from jina.orchestrate.pods.container import ContainerPod\n from jina.orchestrate.pods.factory import PodFactory\n from jina.serve.networking import GrpcConnectionPool, host_is_local, in_docker\n \n+WRAPPED_SLICE_BASE = r'\\[[-\\d:]+\\]'\n+\n \n class BaseDeployment(ExitStack):\n     \"\"\"A BaseDeployment is an immutable set of pods.\n@@ -603,10 +609,63 @@ class Deployment(BaseDeployment):\n             is_ready = self.uses_after_pod.is_ready.is_set()\n         return is_ready\n \n+    @staticmethod\n+    def _parse_slice(value: str):\n+        \"\"\"Parses a `slice()` from string, like `start:stop:step`.\n+\n+        :param value: a string like\n+        :return: slice\n+        \"\"\"\n+        if re.match(WRAPPED_SLICE_BASE, value):\n+            value = value[1:-1]\n+\n+        if value:\n+            parts = value.split(':')\n+            if len(parts) == 1:\n+                # slice(stop)\n+                parts = [parts[0], str(int(parts[0]) + 1)]\n+            # else: slice(start, stop[, step])\n+        else:\n+            # slice()\n+            parts = []\n+        return slice(*[int(p) if p else None for p in parts])\n+\n+    @staticmethod\n+    def _roundrobin_cuda_device(device_str: str, replicas: int):\n+        \"\"\"Parse cuda device string with RR prefix\n+\n+        :param device_str: `RRm:n`, where `RR` is the prefix, m:n is python slice format\n+        :param replicas: the number of replicas\n+        :return: a map from replica id to device id\n+        \"\"\"\n+        if device_str and device_str.startswith('RR') and replicas >= 1:\n+            try:\n+                num_devices = str(subprocess.check_output(['nvidia-smi', '-L'])).count(\n+                    'UUID'\n+                )\n+            except:\n+                num_devices = int(os.environ.get('CUDA_TOTAL_DEVICES', 0))\n+                if num_devices == 0:\n+                    return\n+\n+            all_devices = list(range(num_devices))\n+            if device_str[2:]:\n+                all_devices = all_devices[Deployment._parse_slice(device_str[2:])]\n+\n+            _c = cycle(all_devices)\n+            return {j: next(_c) for j in range(replicas)}\n+\n     @staticmethod\n     def _set_pod_args(args: Namespace) -> Dict[int, List[Namespace]]:\n         result = {}\n         sharding_enabled = args.shards and args.shards > 1\n+\n+        cuda_device_map = None\n+        if args.env:\n+            cuda_device_map = Deployment._roundrobin_cuda_device(\n+                args.env.get('CUDA_VISIBLE_DEVICES'), args.replicas\n+            )\n+\n         for shard_id in range(args.shards):\n             replica_args = []\n             for replica_id in range(args.replicas):\n@@ -614,6 +673,9 @@ class Deployment(BaseDeployment):\n                 _args.shard_id = shard_id\n                 _args.pod_role = PodRoleType.WORKER\n \n+                if cuda_device_map:\n+                    _args.env['CUDA_VISIBLE_DEVICES'] = str(cuda_device_map[replica_id])\n+\n                 _args.host = args.host\n                 if _args.name:\n                     _args.name += (\n\n---\n file path A: None | file path B: tests/unit/orchestrate/deployments/test_cuda_assignment.py\n\n@@ -0,0 +1,25 @@\n+import os\n+\n+import pytest\n+\n+from jina.orchestrate.deployments import Deployment\n+\n+\n+@pytest.mark.parametrize(\n+    'device_str, replicas, expected',\n+    [\n+        ['1', 1, None],  # wont trigger device RB\n+        ['1', 2, None],  # wont trigger device RB\n+        ['1,2', 2, None],  # wont trigger device RB\n+        ['RR', 2, {0: 0, 1: 1}],\n+        ['RR', 5, {0: 0, 1: 1, 2: 2, 3: 0, 4: 1}],\n+        ['RR1:', 5, {0: 1, 1: 2, 2: 1, 3: 2, 4: 1}],\n+        ['RR0:2', 5, {0: 0, 1: 1, 2: 0, 3: 1, 4: 0}],\n+        ['RR1:2', 2, {0: 1, 1: 1}],\n+        ['RR1:2', 1, {0: 1}],\n+    ],\n+)\n+def test_cuda_assignment(device_str, replicas, expected):\n+    os.environ['CUDA_TOTAL_DEVICES'] = str(3)\n+    actual = Deployment._roundrobin_cuda_device(device_str, replicas)\n+    assert actual == expected\n\n\n###\n\n", "completion": "feat(deployment): add roundrobin cuda device assignment (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -159,6 +159,7 @@ jobs:\n \n   import-test:\n     runs-on: ubuntu-latest\n+    needs: update-schema\n     strategy:\n       fail-fast: false\n       matrix:\n@@ -286,6 +287,7 @@ jobs:\n \n   k8s-failures-test:\n     runs-on: ubuntu-latest\n+    needs: update-schema\n     steps:\n       - uses: actions/checkout@v2\n       - name: Set up Python 3.7\n\n\n###\n\n", "completion": "chore: remove unnecessary steps on chore commit"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -179,6 +179,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13577,3 +13578,44 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```dc18154a```](https://github.com/jina-ai/jina/commit/dc18154ae9cae32fc649b796830864763bae39cb)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```2292e935```](https://github.com/jina-ai/jina/commit/2292e935811c24af8f51017f309486f45b361942)] __-__ __version__: the next version will be 3.3.26 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-1></a>\n+## Release Note (`3.4.1`)\n+\n+> Release time: 2022-05-13 11:55:54\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Johannes Messner,  Delgermurun,  Han Xiao,  Roshan Jossy,  Florian H\u00f6nicke,  Jina Dev Bot,  samsja,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```072a47a4```](https://github.com/jina-ai/jina/commit/072a47a4fa97aca68203882e1ef809681a523097)] __-__ better error messages when gateway can&#39;t connect to other deployment (#4677) (*Johannes Messner*)\n+ - [[```6514ca95```](https://github.com/jina-ai/jina/commit/6514ca95318b6d6262b4e7ec54bcf77a0d2098ac)] __-__ __hubble__: executor push/pull user integration (#4770) (*Delgermurun*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```fb529399```](https://github.com/jina-ai/jina/commit/fb5293993c3468a21f7611e0e833f3a28356da77)] __-__ __sandbox__: send secret in the request (#4781) (*Delgermurun*)\n+ - [[```2e9484ef```](https://github.com/jina-ai/jina/commit/2e9484efa14743a438ea30983a5ef64b6700ce33)] __-__ yaml jtype flow (#4776) (*samsja*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```934ecd8f```](https://github.com/jina-ai/jina/commit/934ecd8fa5c98a8f54a6aeed753698a691bb77d7)] __-__ __flow__: improve success box (#4782) (*Han Xiao*)\n+ - [[```b0df40ae```](https://github.com/jina-ai/jina/commit/b0df40aefc5327fa97becbc14e9b8e16c125a30a)] __-__ logging no print (#4777) (*Florian H\u00f6nicke*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```ad5ed0dc```](https://github.com/jina-ai/jina/commit/ad5ed0dc81b7d853a9c67d6329edc944e87d64bf)] __-__ __tracking__: fix utm source (#4780) (*Roshan Jossy*)\n+ - [[```7de44506```](https://github.com/jina-ai/jina/commit/7de4450658293b9e7c0ca1248c778d9aeb79ae5a)] __-__ add jina now logo (#4775) (*Florian H\u00f6nicke*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```d7c48d5f```](https://github.com/jina-ai/jina/commit/d7c48d5f4e07240811421336a022810209463afe)] __-__ __hubble__: fix failing test (#4783) (*Delgermurun*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```ec136dd8```](https://github.com/jina-ai/jina/commit/ec136dd82c218bc3676cacb3ed8276c46b5d823f)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```13a954be```](https://github.com/jina-ai/jina/commit/13a954bec4b42ce6c6b3540270eae34497c17b71)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```36ca89d3```](https://github.com/jina-ai/jina/commit/36ca89d31876b5eae38d83c28bfb8168e35fe690)] __-__ __version__: the next version will be 3.4.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.1'\n+__version__ = '3.4.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.2"}
{"prompt": " file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -726,8 +726,8 @@ def test_deploy_public_sandbox_existing(mocker, monkeypatch):\n         'uses_with': {'foo': 'bar'},\n         'test_number': 1,\n         'test_string': 'text',\n-        'secret': 'dummy_secret',\n     }\n+    assert kwargs['json']['secret'] == 'dummy_secret'\n \n \n def test_deploy_public_sandbox_create_new(mocker, monkeypatch):\n\n\n###\n\n", "completion": "test(hubble): fix failing test (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -52,7 +52,6 @@ from jina.excepts import (\n from jina.helper import (\n     ArgNamespace,\n     CatchAllCleanupContextManager,\n-    colored_rich,\n     download_mermaid_url,\n     get_internal_ip,\n     get_public_ip,\n@@ -1594,51 +1593,101 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         return table\n \n     def _get_address_table(self, address_table):\n-        address_table.add_row(':link:', 'Protocol', f'{self.protocol}')\n+        _protocol = str(self.protocol)\n+        if self.gateway_args.ssl_certfile and self.gateway_args.ssl_keyfile:\n+            _protocol = f'{self.protocol}S'\n+            address_table.add_row(\n+                ':link:', 'Protocol', f':closed_lock_with_key: {_protocol}'\n+            )\n+\n+        else:\n+            address_table.add_row(':link:', 'Protocol', _protocol)\n+\n+        _protocol = _protocol.lower()\n         address_table.add_row(\n             ':house:',\n-            'Local access',\n-            f'[link={self.protocol}://{self.host}:{self.port}]{self.host}:{self.port}[/]',\n+            'Local',\n+            f'[link={_protocol}://{self.host}:{self.port}]{self.host}:{self.port}[/]',\n         )\n         address_table.add_row(\n             ':lock:',\n-            'Private network',\n-            f'[link={self.protocol}://{self.address_private}:{self.port}]{self.address_private}:{self.port}[/]',\n+            'Private',\n+            f'[link={_protocol}://{self.address_private}:{self.port}]{self.address_private}:{self.port}[/]',\n         )\n \n         if self.address_public:\n             address_table.add_row(\n                 ':earth_africa:',\n-                'Public address',\n-                f'[link={self.protocol}://{self.address_public}:{self.port}]{self.address_public}:{self.port}[/]',\n+                'Public',\n+                f'[link={_protocol}://{self.address_public}:{self.port}]{self.address_public}:{self.port}[/]',\n             )\n \n         if self.protocol == GatewayProtocolType.HTTP:\n+\n+            _address = [\n+                f'[link={_protocol}://localhost:{self.port}/docs]Local[/]',\n+                f'[link={_protocol}://{self.address_private}:{self.port}/docs]Private[/]',\n+            ]\n+            if self.address_public:\n+                _address.append(\n+                    f'[link={_protocol}://{self.address_public}:{self.port}/docs]Public[/]'\n+                )\n             address_table.add_row(\n                 ':speech_balloon:',\n                 'Swagger UI',\n-                f'[link=http://localhost:{self.port}/docs]http://localhost:{self.port}/docs[/]',\n+                '\u00b7'.join(_address),\n             )\n \n+            _address = [\n+                f'[link={_protocol}://localhost:{self.port}/redoc]Local[/]',\n+                f'[link={_protocol}://{self.address_private}:{self.port}/redoc]Private[/]',\n+            ]\n+\n+            if self.address_public:\n+                _address.append(\n+                    f'[link={_protocol}://{self.address_public}:{self.port}/redoc]Public[/]'\n+                )\n+\n             address_table.add_row(\n                 ':books:',\n                 'Redoc',\n-                f'[link=http://localhost:{self.port}/redoc]http://localhost:{self.port}/redoc[/]',\n+                '\u00b7'.join(_address),\n             )\n+\n             if self.gateway_args.expose_graphql_endpoint:\n+                _address = [\n+                    f'[link={_protocol}://localhost:{self.port}/graphql]Local[/]',\n+                    f'[link={_protocol}://{self.address_private}:{self.port}/graphql]Private[/]',\n+                ]\n+\n+                if self.address_public:\n+                    _address.append(\n+                        f'[link={_protocol}://{self.address_public}:{self.port}/graphql]Public[/]'\n+                    )\n+\n                 address_table.add_row(\n                     ':strawberry:',\n                     'GraphQL UI',\n-                    f'[link=http://localhost:{self.port}/graphql]http://localhost:{self.port}/graphql[/]',\n+                    '\u00b7'.join(_address),\n                 )\n-        if self.monitoring:\n \n+        if self.monitoring:\n             for name, deployment in self:\n+                _address = [\n+                    f'[link=http://localhost:{deployment.args.port_monitoring}]Local[/]',\n+                    f'[link=http://{self.address_private}:{deployment.args.port_monitoring}]Private[/]',\n+                ]\n+\n+                if self.address_public:\n+                    _address.append(\n+                        f'[link=http://{self.address_public}:{deployment.args.port_monitoring}]Public[/]'\n+                    )\n+\n                 if deployment.args.monitoring:\n                     address_table.add_row(\n                         ':bar_chart:',\n-                        f'Monitor {name}',\n-                        f'[link=http://localhost:{deployment.args.port_monitoring}]http://localhost:{deployment.args.port_monitoring}[/]',\n+                        f'Monitor [b]{name}[/]',\n+                        '\u00b7'.join(_address),\n                     )\n \n             return self[GATEWAY_NAME].args.port_monitoring\n\n\n###\n\n", "completion": "refactor(flow): improve success box (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -654,6 +654,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n             'tag': tag if tag else 'latest',\n             'jina': __version__,\n             'args': args_copy,\n+            'secret': secret,\n         }\n \n         import requests\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -712,7 +712,7 @@ def test_deploy_public_sandbox_existing(mocker, monkeypatch):\n     monkeypatch.setattr(requests, \"post\", _mock_post)\n \n     args = Namespace(\n-        uses='jinahub+sandbox://dummy_mwu_encoder',\n+        uses='jinahub+sandbox://dummy_mwu_encoder:dummy_secret',\n         uses_with={'foo': 'bar'},\n         test_string='text',\n         test_number=1,\n@@ -726,6 +726,7 @@ def test_deploy_public_sandbox_existing(mocker, monkeypatch):\n         'uses_with': {'foo': 'bar'},\n         'test_number': 1,\n         'test_string': 'text',\n+        'secret': 'dummy_secret',\n     }\n \n \n\n\n###\n\n", "completion": "fix(sandbox): send secret in the request (#<issue-num>)"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -83,6 +83,7 @@ __uptime__ = _datetime.datetime.now().isoformat()\n # 2. grep -rohEI --exclude-dir=jina/hub --exclude-dir=tests --include \\*.py \"\\'JINA_.*?\\'\" jina  | sort -u | sed \"s/$/,/g\"\n # 3. copy all lines EXCEPT the first (which is the grep command in the last line)\n __jina_env__ = (\n+    'JINA_AUTH_TOKEN',\n     'JINA_DEFAULT_HOST',\n     'JINA_DEFAULT_TIMEOUT_CTRL',\n     'JINA_DEFAULT_WORKSPACE_BASE',\n\n---\n file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -20,6 +20,7 @@ from urllib.request import Request, urlopen\n \n from jina import __resources_path__\n from jina.enums import BetterEnum\n+from jina.helper import get_request_header as _get_request_header_main\n from jina.importer import ImportExtensions\n from jina.logging.predefined import default_logger\n \n@@ -34,6 +35,16 @@ def _get_hub_root() -> Path:\n     return hub_root\n \n \n+@lru_cache()\n+def _get_hub_config() -> Optional[Dict]:\n+    hub_root = _get_hub_root()\n+\n+    config_file = hub_root.joinpath('config.json')\n+    if config_file.exists():\n+        with open(config_file) as f:\n+            return json.load(f)\n+\n+\n @lru_cache()\n def get_hub_packages_dir() -> Path:\n     \"\"\"Get the path of folder where the hub packages are stored\n@@ -106,6 +117,37 @@ def _get_hubble_base_url() -> str:\n     return u\n \n \n+@lru_cache()\n+def _get_auth_token() -> Optional[str]:\n+    \"\"\"Get user auth token.\n+    .. note:: We first check `JINA_AUTH_TOKEN` environment variable.\n+        if token is not None, use env token. Otherwise, we get token from config.\n+\n+    :return: user auth token\n+    \"\"\"\n+    token_from_env = os.environ.get('JINA_AUTH_TOKEN')\n+    if token_from_env:\n+        return token_from_env\n+\n+    config = _get_hub_config()\n+    if config:\n+        return config.get('auth_token')\n+\n+\n+def get_request_header() -> Dict:\n+    \"\"\"Return the header of request with an authorization token.\n+\n+    :return: request header\n+    \"\"\"\n+    headers = _get_request_header_main()\n+\n+    auth_token = _get_auth_token()\n+    if auth_token:\n+        headers['Authorization'] = f'token {auth_token}'\n+\n+    return headers\n+\n+\n def get_hubble_url_v1() -> str:\n     \"\"\"Get v1 Hubble Url\n \n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -10,13 +10,7 @@ from pathlib import Path\n from typing import Dict, Optional, Union\n \n from jina import __resources_path__, __version__\n-from jina.helper import (\n-    ArgNamespace,\n-    colored,\n-    get_request_header,\n-    get_rich_console,\n-    retry,\n-)\n+from jina.helper import ArgNamespace, get_rich_console, retry\n from jina.hubble import HubExecutor\n from jina.hubble.helper import (\n     archive_package,\n@@ -26,6 +20,7 @@ from jina.hubble.helper import (\n     get_download_cache_dir,\n     get_hubble_error_message,\n     get_hubble_url_v2,\n+    get_request_header,\n     parse_hub_uri,\n     upload_file,\n )\n@@ -393,7 +388,7 @@ metas:\n                     form_data['secret'] = self.args.secret or secret\n \n                 st.update(f'Connecting to Jina Hub ...')\n-                if form_data.get('id') and form_data.get('secret'):\n+                if form_data.get('id'):\n                     hubble_url = get_hubble_url_v2() + '/rpc/executor.update'\n                 else:\n                     hubble_url = get_hubble_url_v2() + '/rpc/executor.create'\n@@ -461,7 +456,7 @@ metas:\n                 if image:\n                     new_uuid8, new_secret = self._prettyprint_result(console, image)\n                     if new_uuid8 != uuid8 or new_secret != secret:\n-                        dump_secret(work_path, new_uuid8, new_secret)\n+                        dump_secret(work_path, new_uuid8, new_secret or '')\n                 else:\n                     raise Exception(f'Unknown Error, session_id: {session_id}')\n \n@@ -481,7 +476,7 @@ metas:\n         from rich.table import Table\n \n         uuid8 = image['id']\n-        secret = image['secret']\n+        secret = image.get('secret')\n         visibility = image['visibility']\n         tag = self.args.tag[0] if self.args.tag else None\n \n@@ -494,11 +489,14 @@ metas:\n         )\n         if 'name' in image:\n             table.add_row(':name_badge: Name', image['name'])\n-        table.add_row(':lock: Secret', secret)\n-        table.add_row(\n-            '',\n-            ':point_up:\ufe0f [bold red]Please keep this token in a safe place!',\n-        )\n+\n+        if secret:\n+            table.add_row(':lock: Secret', secret)\n+            table.add_row(\n+                '',\n+                ':point_up:\ufe0f [bold red]Please keep this token in a safe place!',\n+            )\n+\n         table.add_row(':eyes: Visibility', visibility)\n \n         p1 = Panel(\n@@ -511,7 +509,9 @@ metas:\n \n         presented_id = image.get('name', uuid8)\n         usage = (\n-            f'{presented_id}' if visibility == 'public' else f'{presented_id}:{secret}'\n+            f'{presented_id}'\n+            if visibility == 'public' or not secret\n+            else f'{presented_id}:{secret}'\n         ) + (f'/{tag}' if tag else '')\n \n         if not self.args.no_usage:\n@@ -789,7 +789,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n                 presented_id = getattr(executor, 'name', executor.uuid)\n                 executor_name = (\n                     f'{presented_id}'\n-                    if executor.visibility == 'public'\n+                    if executor.visibility == 'public' or not secret\n                     else f'{presented_id}:{secret}'\n                 ) + (f'/{tag}' if tag else '')\n \n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -13,7 +13,12 @@ import pytest\n import requests\n import yaml\n \n-from jina.hubble.helper import disk_cache_offline\n+from jina.hubble.helper import (\n+    _get_auth_token,\n+    _get_hub_config,\n+    _get_hub_root,\n+    disk_cache_offline,\n+)\n from jina.hubble.hubio import HubExecutor, HubIO\n from jina.parsers.hubble import (\n     set_hub_new_parser,\n@@ -24,6 +29,27 @@ from jina.parsers.hubble import (\n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n \n+def clear_function_caches():\n+    _get_auth_token.cache_clear()\n+    _get_hub_root.cache_clear()\n+    _get_hub_config.cache_clear()\n+\n+\n+@pytest.fixture(scope='function')\n+def auth_token(tmpdir):\n+    clear_function_caches()\n+    os.environ['JINA_HUB_ROOT'] = str(tmpdir)\n+\n+    token = 'test-auth-token'\n+    with open(tmpdir / 'config.json', 'w') as f:\n+        json.dump({'auth_token': token}, f)\n+\n+    yield token\n+\n+    clear_function_caches()\n+    del os.environ['JINA_HUB_ROOT']\n+\n+\n class PostMockResponse:\n     def __init__(self, response_code: int = 201):\n         self.response_code = response_code\n@@ -212,6 +238,31 @@ def test_push_wrong_dockerfile(\n     )\n \n \n+def test_push_with_authorization(mocker, monkeypatch, auth_token):\n+    mock = mocker.Mock()\n+\n+    def _mock_post(url, data, headers, stream):\n+        mock(url=url, headers=headers)\n+        return PostMockResponse(response_code=200)\n+\n+    monkeypatch.setattr(requests, 'post', _mock_post)\n+\n+    exec_path = os.path.join(cur_dir, 'dummy_executor')\n+    args = set_hub_push_parser().parse_args([exec_path])\n+\n+    HubIO(args).push()\n+\n+    # remove .jina\n+    exec_config_path = os.path.join(exec_path, '.jina')\n+    shutil.rmtree(exec_config_path)\n+\n+    assert mock.call_count == 1\n+\n+    _, kwargs = mock.call_args_list[0]\n+\n+    assert kwargs['headers'].get('Authorization') == f'token {auth_token}'\n+\n+\n @pytest.mark.parametrize('rebuild_image', [True, False])\n def test_fetch(mocker, monkeypatch, rebuild_image):\n     mock = mocker.Mock()\n@@ -293,6 +344,24 @@ def test_fetch_with_retry(mocker, monkeypatch):\n     assert mock.call_count == 6  # mock must be called 3+3\n \n \n+def test_fetch_with_authorization(mocker, monkeypatch, auth_token):\n+    mock = mocker.Mock()\n+\n+    def _mock_post(url, json, headers):\n+        mock(url=url, json=json, headers=headers)\n+        return FetchMetaMockResponse(response_code=200)\n+\n+    monkeypatch.setattr(requests, 'post', _mock_post)\n+\n+    HubIO.fetch_meta('dummy_mwu_encoder', tag=None, force=True)\n+\n+    assert mock.call_count == 1\n+\n+    _, kwargs = mock.call_args_list[0]\n+\n+    assert kwargs['headers'].get('Authorization') == f'token {auth_token}'\n+\n+\n class DownloadMockResponse:\n     def __init__(self, response_code: int = 200):\n         self.response_code = response_code\n\n\n###\n\n", "completion": "feat(hubble): executor push/pull user integration (#<issue-num>)"}
{"prompt": " file path A: docs/_static/source-in-links.js | file path B: docs/_static/source-in-links.js\n\n@@ -1,7 +1,7 @@\n function addUTMSourceToLink(href) {\n     try {\n         var url = new URL(href);\n-        url.searchParams.set(\"utm_source\", \"docarray\");\n+        url.searchParams.set(\"utm_source\", \"jina\");\n         return url.href\n     }\n     catch{\n\n\n###\n\n", "completion": "docs(tracking): fix utm source (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1900,7 +1900,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                         if i < len(k8s_objects) - 1:\n                             fp.write('---\\n')\n \n-        print(\n+        self.logger.info(\n             f'K8s yaml files have been created under [b]{output_base_path}[/]. You can use it by running [b]kubectl apply -R -f {output_base_path}[/]'\n         )\n \n@@ -1958,7 +1958,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n             else f'docker-compose -f {output_path} up'\n         )\n \n-        print(\n+        self.logger.info(\n             f'Docker compose file has been created under [b]{output_path}[/b]. You can use it by running [b]{command}[/b]'\n         )\n \n\n\n###\n\n", "completion": "refactor: logging no print (#<issue-num>)"}
{"prompt": " file path A: docs/_templates/sidebar/navigation.html | file path B: docs/_templates/sidebar/navigation.html\n\n@@ -27,6 +27,10 @@\n             <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/JCloud-light.svg', 1) }}\">\n             <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/JCloud-dark.svg', 1) }}\">\n             JCloud</a></li>\n+        <li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://now.jina.ai\">\n+            <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/now-light.svg', 1) }}\">\n+            <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/now-dark.svg', 1) }}\">\n+            NOW</a></li>\n     </ul>\n </div>\n \n\n\n###\n\n", "completion": "docs: add jina now logo (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/monitoring-flow.md | file path B: docs/fundamentals/flow/monitoring-flow.md\n\n@@ -37,7 +37,7 @@ This example shows how to start a Flow with monitoring enabled via yaml:\n \n In a `flow.yaml` file\n ```yaml\n-!Flow\n+jtype: Flow\n with:\n   monitoring: true\n   port_monitoring: 9090\n\n\n###\n\n", "completion": "fix: yaml jtype flow (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -178,6 +178,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13534,3 +13535,44 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```913d1f31```](https://github.com/jina-ai/jina/commit/913d1f319afcc279fdd80ed18fba5a67768dcc59)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d5c9967c```](https://github.com/jina-ai/jina/commit/d5c9967c0e0cd96f067afeee8aa0adae9cd3f4ef)] __-__ __version__: the next version will be 3.3.25 (*Jina Dev Bot*)\n \n+<a name=release-note-3-4-0></a>\n+## Release Note (`3.4.0`)\n+\n+> Release time: 2022-05-10 14:33:13\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  samsja,  Deepankar Mahapatro,  Roshan Jossy,  Tobias Jacobowitz,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```913312c0```](https://github.com/jina-ai/jina/commit/913312c0b4827de7f81a69ead87fb0e921facd8c)] __-__ rename the endpoint label in monitroing to jina endpoint (#4768) (*samsja*)\n+ - [[```db638330```](https://github.com/jina-ai/jina/commit/db63833046c2f0c8a5ab562b8becdf0221c37f2f)] __-__ add runtime name as label for monitoring (#4752) (*samsja*)\n+ - [[```65d6d6da```](https://github.com/jina-ai/jina/commit/65d6d6da50cb795499ea5e361bf14908f62a3168)] __-__ gateway endpoint discovery (#4756) (*Joan Fontanals*)\n+ - [[```a2cbd8ec```](https://github.com/jina-ai/jina/commit/a2cbd8ecdb320cddb689df46e1585f50c234bb51)] __-__ now display all of the monitoring adress (#4758) (*samsja*)\n+ - [[```c1e03950```](https://github.com/jina-ai/jina/commit/c1e03950670e338c40754b80ce2b6f2128858867)] __-__ add a decoratator for monitoring method (#4737) (*samsja*)\n+ - [[```01dc9da6```](https://github.com/jina-ai/jina/commit/01dc9da6bc7c11bbfa996ffd941d96e4ec8c97df)] __-__ k8s failure testing (#4743) (*Tobias Jacobowitz*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```2fe34c7f```](https://github.com/jina-ai/jina/commit/2fe34c7fc0f65eb66f5fb2bbc5f924ec2447bff8)] __-__ import all from jina (#4772) (*Deepankar Mahapatro*)\n+ - [[```92b0229c```](https://github.com/jina-ai/jina/commit/92b0229c268afe71115eba45e57c80b105e32665)] __-__ fix cd (#4762) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```32e2cd33```](https://github.com/jina-ai/jina/commit/32e2cd332b0305d0126cdfdb22d0329c08f2de75)] __-__ document the monitoring feature (#4710) (*samsja*)\n+ - [[```6975ccb2```](https://github.com/jina-ai/jina/commit/6975ccb25856381360209d8f11ece1a396ad0fec)] __-__ change target executor to be a regex pattern (#4769) (*Joan Fontanals*)\n+ - [[```5c8f8099```](https://github.com/jina-ai/jina/commit/5c8f8099b024208e5c30c3e2158fc2616ffa20b6)] __-__ __tracking__: update refer links to other docs with utm_source (#4750) (*Roshan Jossy*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```b2bc5493```](https://github.com/jina-ai/jina/commit/b2bc5493b08071efcff842c95de5b2b92c10404c)] __-__ fix k8s test in cd (#4765) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```d1ce7e95```](https://github.com/jina-ai/jina/commit/d1ce7e95f76a365ee2f7c667f6b0332eb575375a)] __-__ bump version (#4774) (*Joan Fontanals*)\n+ - [[```dc18154a```](https://github.com/jina-ai/jina/commit/dc18154ae9cae32fc649b796830864763bae39cb)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```2292e935```](https://github.com/jina-ai/jina/commit/2292e935811c24af8f51017f309486f45b361942)] __-__ __version__: the next version will be 3.3.26 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.4.0'\n+__version__ = '3.4.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.4.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.26'\n+__version__ = '3.4.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: bump version (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -372,6 +372,8 @@ jobs:\n           JINA_PIP_INSTALL_PERF: ${{ matrix.perf }}\n       - name: Test basic import\n         run: python -c 'from jina import Executor,requests'\n+      - name: Test import all\n+        run: python -c 'from jina import *'\n \n \n   # just for blocking the merge until all parallel core-test are successful\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -139,7 +139,6 @@ _names_with_underscore = [\n     '__root_dir__',\n     '__default_endpoint__',\n     '__default_executor__',\n-    '__num_args_executor_func__',\n     '__unset_msg__',\n     '__windows__',\n ]\n\n\n###\n\n", "completion": "fix: import all from jina (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -166,7 +166,7 @@ with Flow() as f:\n ```\n \n ### Targeting a specific Executor\n-Usually a `Flow` will send each request to all Executors with matching endpoints as configured. But the `Client` also allows you to only target a specific Executor in a `Flow` using the `target_executor` keyword. The request will then only be processed by the Executor with the provided name. Its usage is shown in the listing below.\n+Usually a `Flow` will send each request to all Executors with matching endpoints as configured. But the `Client` also allows you to only target specific Executors in a `Flow` using the `target_executor` keyword. The request will then only be processed by the Executors which match the provided target_executor regex. Its usage is shown in the listing below.\n \n ```python\n from docarray import Document, DocumentArray\n@@ -193,10 +193,11 @@ f = (\n \n with f:  # Using it as a Context Manager will start the Flow\n     client = Client(port=f.port)\n-    docs = client.post(on='/', target_executor='barExecutor')\n+    docs = client.post(on='/', target_executor='bar*')\n     print(docs.texts)\n ```\n-\n+This will send the request to all Executors whose names start with 'bar', such as 'barExecutor'.\n+In the simplest case, you can specify a precise Executor name, and the request will be sent only to that single Executor.\n ### Request parameters\n \n The Client can also send parameters to the Executors as shown below:\n\n\n###\n\n", "completion": "docs: change target executor to be a regex pattern (#<issue-num>)"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -130,7 +130,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                 'Time spent when calling the executor request method',\n                 registry=self.runtime_args.metrics_registry,\n                 namespace='jina',\n-                labelnames=('executor', 'endpoint', 'runtime_name'),\n+                labelnames=('executor', 'executor_endpoint', 'runtime_name'),\n             )\n             self._metrics_buffer = {'process_request_seconds': self._summary_method}\n \n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -55,7 +55,7 @@ class DataRequestHandler:\n                     'document_processed',\n                     'Number of Documents that have been processed by the executor',\n                     namespace='jina',\n-                    labelnames=('endpoint', 'executor', 'runtime_name'),\n+                    labelnames=('executor_endpoint', 'executor', 'runtime_name'),\n                     registry=metrics_registry,\n                 )\n         else:\n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -36,7 +36,7 @@ def test_enable_monitoring_deployment(port_generator, executor):\n             f.post(f'/{meth}', inputs=DocumentArray())\n             resp = req.get(f'http://localhost:{port2}/')\n             assert (\n-                f'process_request_seconds_created{{endpoint=\"/{meth}\",executor=\"DummyExecutor\",runtime_name=\"executor1/rep-0\"}}'\n+                f'process_request_seconds_created{{executor=\"DummyExecutor\",executor_endpoint=\"/{meth}\",runtime_name=\"executor1/rep-0\"}}'\n                 in str(resp.content)\n             )\n \n@@ -98,12 +98,12 @@ def test_document_processed_total(port_generator, executor):\n \n         resp = req.get(f'http://localhost:{port1}/')\n         assert (\n-            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}} 4.0'  # check that we count 4 documents on foo\n+            f'jina_document_processed_total{{executor=\"DummyExecutor\",executor_endpoint=\"/foo\",runtime_name=\"executor0/rep-0\"}} 4.0'  # check that we count 4 documents on foo\n             in str(resp.content)\n         )\n \n         assert not (\n-            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}}'  # check that we does not start counting documents on bar as it has not been called yet\n+            f'jina_document_processed_total{{executor=\"DummyExecutor\",executor_endpoint=\"/bar\",runtime_name=\"executor0/rep-0\"}}'  # check that we does not start counting documents on bar as it has not been called yet\n             in str(resp.content)\n         )\n \n@@ -112,12 +112,12 @@ def test_document_processed_total(port_generator, executor):\n         )  # process 5 documents on bar\n \n         assert not (\n-            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}} 5.0'  # check that we count 5 documents on foo\n+            f'jina_document_processed_total{{executor=\"DummyExecutor\",executor_endpoint=\"/bar\",runtime_name=\"executor0/rep-0\"}} 5.0'  # check that we count 5 documents on foo\n             in str(resp.content)\n         )\n \n         assert (\n-            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}} 4.0'  # check that we nothing change on bar count\n+            f'jina_document_processed_total{{executor=\"DummyExecutor\",executor_endpoint=\"/foo\",runtime_name=\"executor0/rep-0\"}} 4.0'  # check that we nothing change on bar count\n             in str(resp.content)\n         )\n \n\n\n###\n\n", "completion": "feat: rename the endpoint label in monitroing to jina endpoint (#<issue-num>)"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -15,9 +15,8 @@ from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n from jina.serve.executors.decorators import requests, store_init_kwargs, wrap_func\n \n if TYPE_CHECKING:\n-    from prometheus_client import Summary\n-\n     from docarray import DocumentArray\n+    from prometheus_client import Summary\n \n __all__ = ['BaseExecutor', 'ReducerExecutor']\n \n@@ -131,7 +130,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                 'Time spent when calling the executor request method',\n                 registry=self.runtime_args.metrics_registry,\n                 namespace='jina',\n-                labelnames=('executor', 'endpoint'),\n+                labelnames=('executor', 'endpoint', 'runtime_name'),\n             )\n             self._metrics_buffer = {'process_request_seconds': self._summary_method}\n \n@@ -256,8 +255,14 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n     async def __acall_endpoint__(self, req_endpoint, **kwargs):\n         func = self.requests[req_endpoint]\n \n+        runtime_name = (\n+            self.runtime_args.name if hasattr(self.runtime_args, 'name') else None\n+        )\n+\n         _summary = (\n-            self._summary_method.labels(self.__class__.__name__, req_endpoint).time()\n+            self._summary_method.labels(\n+                self.__class__.__name__, req_endpoint, runtime_name\n+            ).time()\n             if self._summary_method\n             else contextlib.nullcontext()\n         )\n@@ -497,7 +502,8 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                     documentation,\n                     registry=self.runtime_args.metrics_registry,\n                     namespace='jina',\n-                )\n+                    labelnames=('runtime_name',),\n+                ).labels(self.runtime_args.name)\n             return self._metrics_buffer[name]\n         else:\n             return None\n\n---\n file path A: jina/serve/runtimes/gateway/grpc/__init__.py | file path B: jina/serve/runtimes/gateway/grpc/__init__.py\n\n@@ -46,7 +46,7 @@ class GRPCGatewayRuntime(GatewayRuntime):\n \n     async def _async_setup_server(self):\n \n-        request_handler = RequestHandler(self.metrics_registry)\n+        request_handler = RequestHandler(self.metrics_registry, self.name)\n \n         self.streamer = RequestStreamer(\n             args=self.args,\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -72,7 +72,7 @@ def get_fastapi_app(\n     from jina.serve.runtimes.gateway.request_handling import RequestHandler\n     from jina.serve.stream import RequestStreamer\n \n-    request_handler = RequestHandler(metrics_registry)\n+    request_handler = RequestHandler(metrics_registry, args.name)\n \n     streamer = RequestStreamer(\n         args=args,\n@@ -252,6 +252,7 @@ def get_fastapi_app(\n             from dataclasses import asdict\n \n             import strawberry\n+            from docarray import DocumentArray\n             from docarray.document.strawberry_type import (\n                 JSONScalar,\n                 StrawberryDocument,\n@@ -259,8 +260,6 @@ def get_fastapi_app(\n             )\n             from strawberry.fastapi import GraphQLRouter\n \n-            from docarray import DocumentArray\n-\n             async def get_docs_from_endpoint(\n                 data, target_executor, parameters, exec_endpoint\n             ):\n\n---\n file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -19,9 +19,14 @@ class RequestHandler:\n     Class that handles the requests arriving to the gateway and the result extracted from the requests future.\n \n     :param metrics_registry: optional metrics registry for prometheus used if we need to expose metrics from the executor or from the data request handler\n+    :param runtime_name: optional runtime_name that will be registered during monitoring\n     \"\"\"\n \n-    def __init__(self, metrics_registry: Optional['CollectorRegistry'] = None):\n+    def __init__(\n+        self,\n+        metrics_registry: Optional['CollectorRegistry'] = None,\n+        runtime_name: Optional[str] = None,\n+    ):\n         self.request_init_time = {} if metrics_registry else None\n         self._executor_endpoint_mapping = None\n \n@@ -37,7 +42,9 @@ class RequestHandler:\n                 'Time spent processing request',\n                 registry=metrics_registry,\n                 namespace='jina',\n-            )\n+                labelnames=('runtime_name',),\n+            ).labels(runtime_name)\n+\n         else:\n             self._summary = None\n \n\n---\n file path A: jina/serve/runtimes/gateway/websocket/app.py | file path B: jina/serve/runtimes/gateway/websocket/app.py\n\n@@ -109,7 +109,7 @@ def get_fastapi_app(\n     from jina.serve.runtimes.gateway.request_handling import RequestHandler\n     from jina.serve.stream import RequestStreamer\n \n-    request_handler = RequestHandler(metrics_registry)\n+    request_handler = RequestHandler(metrics_registry, args.name)\n \n     streamer = RequestStreamer(\n         args=args,\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -54,12 +54,17 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n             ):\n                 from prometheus_client import Summary\n \n-            self._summary = Summary(\n-                'receiving_request_seconds',\n-                'Time spent processing request',\n-                registry=self.metrics_registry,\n-                namespace='jina',\n-            ).time()\n+            self._summary = (\n+                Summary(\n+                    'receiving_request_seconds',\n+                    'Time spent processing request',\n+                    registry=self.metrics_registry,\n+                    namespace='jina',\n+                    labelnames=('runtime_name',),\n+                )\n+                .labels(self.args.name)\n+                .time()\n+            )\n         else:\n             self._summary = contextlib.nullcontext()\n \n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -55,7 +55,7 @@ class DataRequestHandler:\n                     'document_processed',\n                     'Number of Documents that have been processed by the executor',\n                     namespace='jina',\n-                    labelnames=('endpoint', 'executor'),\n+                    labelnames=('endpoint', 'executor', 'runtime_name'),\n                     registry=metrics_registry,\n                 )\n         else:\n@@ -159,7 +159,9 @@ class DataRequestHandler:\n \n         if self._counter:\n             self._counter.labels(\n-                requests[0].header.exec_endpoint, self._executor.__class__.__name__\n+                requests[0].header.exec_endpoint,\n+                self._executor.__class__.__name__,\n+                self.args.name,\n             ).inc(len(docs))\n \n         DataRequestHandler.replace_docs(requests[0], docs, self.args.output_array_type)\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -41,12 +41,17 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n             ):\n                 from prometheus_client import Summary\n \n-            self._summary_time = Summary(\n-                'receiving_request_seconds',\n-                'Time spent processing request',\n-                registry=self.metrics_registry,\n-                namespace='jina',\n-            ).time()\n+            self._summary_time = (\n+                Summary(\n+                    'receiving_request_seconds',\n+                    'Time spent processing request',\n+                    registry=self.metrics_registry,\n+                    namespace='jina',\n+                    labelnames=('runtime_name',),\n+                )\n+                .labels(self.args.name)\n+                .time()\n+            )\n         else:\n             self._summary_time = contextlib.nullcontext()\n \n\n---\n file path A: tests/integration/monitoring/test_executor.py | file path B: tests/integration/monitoring/test_executor.py\n\n@@ -52,5 +52,10 @@ def test_decorator_interface(port_generator):\n         f.post('/foo', inputs=DocumentArray.empty(4))\n \n         resp = req.get(f'http://localhost:{port}/')\n-        assert f'jina_metrics_name_count 1.0' in str(resp.content)\n-        assert f'jina_proces_2_seconds_count 1.0' in str(resp.content)\n+        assert f'jina_metrics_name_count{{runtime_name=\"executor0/rep-0\"}} 1.0' in str(\n+            resp.content\n+        )\n+        assert (\n+            f'jina_proces_2_seconds_count{{runtime_name=\"executor0/rep-0\"}} 1.0'\n+            in str(resp.content)\n+        )\n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -36,7 +36,7 @@ def test_enable_monitoring_deployment(port_generator, executor):\n             f.post(f'/{meth}', inputs=DocumentArray())\n             resp = req.get(f'http://localhost:{port2}/')\n             assert (\n-                f'process_request_seconds_created{{endpoint=\"/{meth}\",executor=\"DummyExecutor\"}}'\n+                f'process_request_seconds_created{{endpoint=\"/{meth}\",executor=\"DummyExecutor\",runtime_name=\"executor1/rep-0\"}}'\n                 in str(resp.content)\n             )\n \n@@ -67,6 +67,7 @@ def test_monitoring_head(port_generator, executor):\n     with Flow(monitoring=True, port_monitoring=port_generator()).add(\n         uses=executor, port_monitoring=port1\n     ).add(uses=executor, port_monitoring=port2, shards=2) as f:\n+\n         port3 = f._deployment_nodes['executor0'].pod_args['pods'][0][0].port_monitoring\n         port4 = f._deployment_nodes['executor1'].pod_args['pods'][0][0].port_monitoring\n \n@@ -97,12 +98,12 @@ def test_document_processed_total(port_generator, executor):\n \n         resp = req.get(f'http://localhost:{port1}/')\n         assert (\n-            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\"}} 4.0'  # check that we count 4 documents on foo\n+            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}} 4.0'  # check that we count 4 documents on foo\n             in str(resp.content)\n         )\n \n         assert not (\n-            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\"}}'  # check that we does not start counting documents on bar as it has not been called yet\n+            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}}'  # check that we does not start counting documents on bar as it has not been called yet\n             in str(resp.content)\n         )\n \n@@ -111,12 +112,12 @@ def test_document_processed_total(port_generator, executor):\n         )  # process 5 documents on bar\n \n         assert not (\n-            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\"}} 5.0'  # check that we count 5 documents on foo\n+            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}} 5.0'  # check that we count 5 documents on foo\n             in str(resp.content)\n         )\n \n         assert (\n-            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\"}} 4.0'  # check that we nothing change on bar count\n+            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\",runtime_name=\"executor0/rep-0\"}} 4.0'  # check that we nothing change on bar count\n             in str(resp.content)\n         )\n \n\n---\n file path A: tests/unit/serve/runtimes/worker/test_worker_runtime.py | file path B: tests/unit/serve/runtimes/worker/test_worker_runtime.py\n\n@@ -433,12 +433,12 @@ async def test_decorator_monitoring(port_generator):\n         ready_or_shutdown_event=Event(),\n     )\n \n-    result = await GrpcConnectionPool.send_request_async(\n+    await GrpcConnectionPool.send_request_async(\n         _create_test_data_message(), f'{args.host}:{args.port}', timeout=1.0\n     )\n \n     resp = req.get(f'http://localhost:{port}/')\n-    assert f'jina_metrics_name_count 1.0' in str(resp.content)\n+    assert f'jina_metrics_name_count{{runtime_name=\"None\"}} 1.0' in str(resp.content)\n \n     cancel_event.set()\n     runtime_thread.join()\n\n\n###\n\n", "completion": "feat: add runtime name as label for monitoring (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -266,15 +266,17 @@ jobs:\n       - name: Test k8s\n         run: |\n           curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh\n-          pytest -v -s --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml ./tests/k8s/\n+          pytest -v -s --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml ./tests/k8s/test_k8s.py ./tests/k8s/test_graceful_request_handling.py\n         timeout-minutes: 30\n+        env:\n+          JINA_K8S_USE_TEST_PIP: 1\n       - name: Check codecov file\n         id: check_files\n         uses: andstor/file-existence-action@v1\n         with:\n           files: \"coverage.xml\"\n       - name: Upload coverage from test to Codecov\n-        uses: codecov/codecov-action@v1\n+        uses: codecov/codecov-action@v2\n         if: steps.check_files.outputs.files_exists == 'true' && ${{ matrix.python-version }} == '3.7'\n         with:\n           file: coverage.xml\n\n\n###\n\n", "completion": "ci: fix k8s test in cd (#<issue-num>)"}
{"prompt": " file path A: docs/_static/source-in-links.js | file path B: docs/_static/source-in-links.js\n\n@@ -1,20 +1,22 @@\n function addUTMSourceToLink(href) {\n     try {\n         var url = new URL(href);\n-        url.searchParams.set(\"utm_source\", \"core\");\n+        url.searchParams.set(\"utm_source\", \"docarray\");\n         return url.href\n     }\n-    catch{}\n+    catch{\n+        return href\n+    }\n }\n \n-function addSourceToAllLinks() {\n+function addUTMSourceToLinks() {\n     var anchors = document.getElementsByTagName(\"a\");\n \n     for (var i = 0; i < anchors.length; i++) {\n-        anchors[i].href = addUTMSourceToLinks(anchors[i].href)\n+        anchors[i].href = addUTMSourceToLink(anchors[i].href)\n     }\n }\n \n window.onload = function () {\n-    addSourceToAllLinks()\n+    addUTMSourceToLinks()\n }\n\\ No newline at end of file\n\n\n###\n\n", "completion": "docs(tracking): update refer links to other docs with utm_source (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1632,10 +1632,19 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                     f'[link=http://localhost:{self.port}/graphql]http://localhost:{self.port}/graphql[/]',\n                 )\n         if self.monitoring:\n-            address_table.add_row(\n-                ':bar_chart:',\n-                'Prometheus',\n-                f'[link=http://localhost:{self.port_monitoring}]http://localhost:{self.port_monitoring}[/]',\n+\n+            for name, deployment in self:\n+                if deployment.args.monitoring:\n+                    address_table.add_row(\n+                        ':bar_chart:',\n+                        f'Monitor {name}',\n+                        f'[link=http://localhost:{deployment.args.port_monitoring}]http://localhost:{deployment.args.port_monitoring}[/]',\n+                    )\n+\n+            return self[GATEWAY_NAME].args.port_monitoring\n+        else:\n+            return self._common_kwargs.get(\n+                'port_monitoring', __default_port_monitoring__\n             )\n \n         return address_table\n\n\n###\n\n", "completion": "feat: now display all of the monitoring adress (#<issue-num>)"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -206,7 +206,7 @@ from jina.orchestrate.flow.base import Flow\n \n # Executor\n from jina.serve.executors import BaseExecutor as Executor\n-from jina.serve.executors.decorators import requests\n+from jina.serve.executors.decorators import monitor, requests\n \n __all__ = [_s for _s in dir() if not _s.startswith('_')]\n __all__.extend(_names_with_underscore)\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -15,8 +15,9 @@ from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n from jina.serve.executors.decorators import requests, store_init_kwargs, wrap_func\n \n if TYPE_CHECKING:\n-    from jina import DocumentArray\n+    from prometheus_client import Summary\n \n+    from docarray import DocumentArray\n \n __all__ = ['BaseExecutor', 'ReducerExecutor']\n \n@@ -132,8 +133,11 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                 namespace='jina',\n                 labelnames=('executor', 'endpoint'),\n             )\n+            self._metrics_buffer = {'process_request_seconds': self._summary_method}\n+\n         else:\n             self._summary_method = None\n+            self._metrics_buffer = None\n \n     def _add_requests(self, _requests: Optional[Dict]):\n         if not hasattr(self, 'requests'):\n@@ -473,6 +477,31 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n         )\n \n+    def get_metrics(\n+        self, name: Optional[str] = None, documentation: Optional[str] = None\n+    ) -> Optional['Summary']:\n+        \"\"\"\n+        Get a given prometheus metric, if it does not exist yet, it will create it and store it in a buffer.\n+        :param name: the name of the metrics\n+        :param documentation:  the description of the metrics\n+\n+        :return: the given prometheus metrics or None if monitoring is not enable.\n+        \"\"\"\n+\n+        if self._metrics_buffer:\n+            if name not in self._metrics_buffer:\n+                from prometheus_client import Summary\n+\n+                self._metrics_buffer[name] = Summary(\n+                    name,\n+                    documentation,\n+                    registry=self.runtime_args.metrics_registry,\n+                    namespace='jina',\n+                )\n+            return self._metrics_buffer[name]\n+        else:\n+            return None\n+\n \n class ReducerExecutor(BaseExecutor):\n     \"\"\"\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -136,3 +136,45 @@ def requests(\n         return FunctionMapper(func)\n     else:\n         return FunctionMapper\n+\n+\n+def monitor(\n+    *,\n+    name: Optional[str] = None,\n+    documentation: Optional[str] = None,\n+):\n+    \"\"\"\n+    `@monitor()` allow to monitor internal method of your executor. You can access these metrics by enabling the\n+    monitoring on your Executor. It will track the time spend calling the function and the number of times it has been\n+    called. Under the hood it will create a prometheus Summary : https://prometheus.io/docs/practices/histograms/.\n+\n+    :warning: Don't use this decorator with the @request decorator as it already handle monitoring under the hood\n+\n+    :param name: the name of the metrics, by default it is based on the name of the method it decorates\n+    :param documentation:  the description of the metrics, by default it is based on the name of the method it decorates\n+\n+    :return: decorator which takes as an input a single callable\n+    \"\"\"\n+\n+    def _decorator(func: Callable):\n+\n+        name_ = name if name else f'{func.__name__}_seconds'\n+        documentation_ = (\n+            documentation\n+            if documentation\n+            else f'Time spent calling method {func.__name__}'\n+        )\n+\n+        @functools.wraps(func)\n+        def _f(self, *args, **kwargs):\n+            metric = self.get_metrics(name_, documentation_)\n+\n+            if metric:\n+                with metric.time():\n+                    return func(self, *args, **kwargs)\n+            else:\n+                return func(self, *args, **kwargs)\n+\n+        return _f\n+\n+    return _decorator\n\n---\n file path A: None | file path B: tests/integration/monitoring/test_executor.py\n\n@@ -0,0 +1,56 @@\n+import requests as req\n+from docarray import DocumentArray\n+from prometheus_client import Summary\n+\n+from jina import Executor, Flow, monitor, requests\n+\n+\n+def test_prometheus_interface(port_generator):\n+    class DummyExecutor(Executor):\n+        def __init__(self, *args, **kwargs):\n+            super().__init__(*args, **kwargs)\n+            self.summary = Summary(\n+                'a', 'A', registry=self.runtime_args.metrics_registry\n+            )\n+\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+            with self.summary.time():\n+                ...\n+\n+    port = port_generator()\n+    with Flow(monitoring=True, port_monitoring=port_generator()).add(\n+        uses=DummyExecutor, monitoring=True, port_monitoring=port\n+    ) as f:\n+        f.post('/foo', inputs=DocumentArray.empty(4))\n+\n+        resp = req.get(f'http://localhost:{port}/')\n+        assert f'a_count 1.0' in str(  # check that we count 4 documents on foo\n+            resp.content\n+        )\n+\n+\n+def test_decorator_interface(port_generator):\n+    class DummyExecutor(Executor):\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+            self._proces(docs)\n+            self.proces_2(docs)\n+\n+        @monitor(name='metrics_name', documentation='metrics description')\n+        def _proces(self, docs):\n+            ...\n+\n+        @monitor()\n+        def proces_2(self, docs):\n+            ...\n+\n+    port = port_generator()\n+    with Flow(monitoring=True, port_monitoring=port_generator()).add(\n+        uses=DummyExecutor, monitoring=True, port_monitoring=port\n+    ) as f:\n+        f.post('/foo', inputs=DocumentArray.empty(4))\n+\n+        resp = req.get(f'http://localhost:{port}/')\n+        assert f'jina_metrics_name_count 1.0' in str(resp.content)\n+        assert f'jina_proces_2_seconds_count 1.0' in str(resp.content)\n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -7,22 +7,26 @@ from docarray import DocumentArray\n from jina import Executor, Flow, requests\n \n \n-class DummyExecutor(Executor):\n-    @requests(on='/foo')\n-    def foo(self, docs, **kwargs):\n-        ...\n+@pytest.fixture()\n+def executor():\n+    class DummyExecutor(Executor):\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+            ...\n \n-    @requests(on='/bar')\n-    def bar(self, docs, **kwargs):\n-        ...\n+        @requests(on='/bar')\n+        def bar(self, docs, **kwargs):\n+            ...\n \n+    return DummyExecutor\n \n-def test_enable_monitoring_deployment(port_generator):\n+\n+def test_enable_monitoring_deployment(port_generator, executor):\n     port1 = port_generator()\n     port2 = port_generator()\n \n-    with Flow().add(uses=DummyExecutor, port_monitoring=port1, monitoring=True).add(\n-        uses=DummyExecutor, port_monitoring=port2, monitoring=True\n+    with Flow().add(uses=executor, port_monitoring=port1, monitoring=True).add(\n+        uses=executor, port_monitoring=port2, monitoring=True\n     ) as f:\n         for port in [port1, port2]:\n             resp = req.get(f'http://localhost:{port}/')\n@@ -38,14 +42,14 @@ def test_enable_monitoring_deployment(port_generator):\n \n \n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n-def test_enable_monitoring_gateway(protocol, port_generator):\n+def test_enable_monitoring_gateway(protocol, port_generator, executor):\n     port0 = port_generator()\n     port1 = port_generator()\n     port2 = port_generator()\n \n     with Flow(protocol=protocol, monitoring=True, port_monitoring=port0).add(\n-        uses=DummyExecutor, port_monitoring=port1\n-    ).add(uses=DummyExecutor, port_monitoring=port2) as f:\n+        uses=executor, port_monitoring=port1\n+    ).add(uses=executor, port_monitoring=port2) as f:\n         for port in [port0, port1, port2]:\n             resp = req.get(f'http://localhost:{port}/')\n             assert resp.status_code == 200\n@@ -56,13 +60,13 @@ def test_enable_monitoring_gateway(protocol, port_generator):\n         assert f'jina_sending_request_seconds' in str(resp.content)\n \n \n-def test_monitoring_head(port_generator):\n+def test_monitoring_head(port_generator, executor):\n     port1 = port_generator()\n     port2 = port_generator()\n \n-    with Flow(monitoring=True).add(uses=DummyExecutor, port_monitoring=port1).add(\n-        uses=DummyExecutor, port_monitoring=port2, shards=2\n-    ) as f:\n+    with Flow(monitoring=True, port_monitoring=port_generator()).add(\n+        uses=executor, port_monitoring=port1\n+    ).add(uses=executor, port_monitoring=port2, shards=2) as f:\n         port3 = f._deployment_nodes['executor0'].pod_args['pods'][0][0].port_monitoring\n         port4 = f._deployment_nodes['executor1'].pod_args['pods'][0][0].port_monitoring\n \n@@ -76,12 +80,12 @@ def test_monitoring_head(port_generator):\n         assert f'jina_sending_request_seconds' in str(resp.content)\n \n \n-def test_document_processed_total(port_generator):\n+def test_document_processed_total(port_generator, executor):\n     port0 = port_generator()\n     port1 = port_generator()\n \n     with Flow(monitoring=True, port_monitoring=port0).add(\n-        uses=DummyExecutor, port_monitoring=port1\n+        uses=executor, port_monitoring=port1\n     ) as f:\n \n         resp = req.get(f'http://localhost:{port1}/')\n@@ -117,12 +121,12 @@ def test_document_processed_total(port_generator):\n         )\n \n \n-def test_disable_monitoring_on_pods(port_generator):\n+def test_disable_monitoring_on_pods(port_generator, executor):\n     port0 = port_generator()\n     port1 = port_generator()\n \n     with Flow(monitoring=True, port_monitoring=port0).add(\n-        uses=DummyExecutor,\n+        uses=executor,\n         port_monitoring=port1,\n         monitoring=False,\n     ):\n@@ -133,12 +137,12 @@ def test_disable_monitoring_on_pods(port_generator):\n         assert resp.status_code == 200\n \n \n-def test_disable_monitoring_on_gatway_only(port_generator):\n+def test_disable_monitoring_on_gatway_only(port_generator, executor):\n     port0 = port_generator()\n     port1 = port_generator()\n \n     with Flow(monitoring=False, port_monitoring=port0).add(\n-        uses=DummyExecutor,\n+        uses=executor,\n         port_monitoring=port1,\n         monitoring=True,\n     ):\n\n---\n file path A: tests/unit/serve/runtimes/worker/test_worker_runtime.py | file path B: tests/unit/serve/runtimes/worker/test_worker_runtime.py\n\n@@ -8,8 +8,9 @@ from threading import Event\n \n import grpc\n import pytest\n-\n+import requests as req\n from docarray import Document\n+\n from jina import DocumentArray, Executor, requests\n from jina.clients.request import request_generator\n from jina.parsers import set_pod_parser\n@@ -380,3 +381,66 @@ async def test_worker_runtime_reflection():\n \n def _create_test_data_message(counter=0):\n     return list(request_generator('/', DocumentArray([Document(text=str(counter))])))[0]\n+\n+\n+@pytest.mark.asyncio\n+@pytest.mark.slow\n+@pytest.mark.timeout(5)\n+async def test_decorator_monitoring(port_generator):\n+    from jina import monitor\n+\n+    class DummyExecutor(Executor):\n+        @requests\n+        def foo(self, docs, **kwargs):\n+            self._proces(docs)\n+            self.proces_2(docs)\n+\n+        @monitor(name='metrics_name', documentation='metrics description')\n+        def _proces(self, docs):\n+            ...\n+\n+        @monitor()\n+        def proces_2(self, docs):\n+            ...\n+\n+    port = port_generator()\n+    args = set_pod_parser().parse_args(\n+        ['--monitoring', '--port-monitoring', str(port), '--uses', 'DummyExecutor']\n+    )\n+\n+    cancel_event = multiprocessing.Event()\n+\n+    def start_runtime(args, cancel_event):\n+        with WorkerRuntime(args, cancel_event=cancel_event) as runtime:\n+            runtime.run_forever()\n+\n+    runtime_thread = Process(\n+        target=start_runtime,\n+        args=(args, cancel_event),\n+        daemon=True,\n+    )\n+    runtime_thread.start()\n+\n+    assert AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'{args.host}:{args.port}',\n+        ready_or_shutdown_event=Event(),\n+    )\n+\n+    assert AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'{args.host}:{args.port}',\n+        ready_or_shutdown_event=Event(),\n+    )\n+\n+    result = await GrpcConnectionPool.send_request_async(\n+        _create_test_data_message(), f'{args.host}:{args.port}', timeout=1.0\n+    )\n+\n+    resp = req.get(f'http://localhost:{port}/')\n+    assert f'jina_metrics_name_count 1.0' in str(resp.content)\n+\n+    cancel_event.set()\n+    runtime_thread.join()\n+\n+    assert not AsyncNewLoopRuntime.is_ready(f'{args.host}:{args.port}')\n\n\n###\n\n", "completion": "feat: add a decoratator for monitoring method (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -283,7 +283,6 @@ jobs:\n           fail_ci_if_error: false\n \n   k8s-failures-test:\n-    needs: [ commit-lint, lint-flake-8, code-injection ]\n     runs-on: ubuntu-latest\n     steps:\n       - uses: actions/checkout@v2\n\n\n###\n\n", "completion": "fix: fix cd (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -177,6 +177,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13508,3 +13509,27 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```e3c45bf5```](https://github.com/jina-ai/jina/commit/e3c45bf5a3cf4e97c44f3e0463950f9c24d41a0a)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```c4175f95```](https://github.com/jina-ai/jina/commit/c4175f9518fe394fc0812d10728e3f578634e830)] __-__ __version__: the next version will be 3.3.24 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-25></a>\n+## Release Note (`3.3.25`)\n+\n+> Release time: 2022-05-05 17:39:33\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Tobias Jacobowitz,  Roshan Jossy,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```c1f0ae51```](https://github.com/jina-ai/jina/commit/c1f0ae51ed4ef76ff9aaa976d234670a296eac07)] __-__ close loop from run_async (#4734) (*Tobias Jacobowitz*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```36ce8359```](https://github.com/jina-ai/jina/commit/36ce83597befa9c25668489b80548a864c1decb3)] __-__ __tracking__: update refer links to other docs with utm_source (#4744) (*Roshan Jossy*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```913d1f31```](https://github.com/jina-ai/jina/commit/913d1f319afcc279fdd80ed18fba5a67768dcc59)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d5c9967c```](https://github.com/jina-ai/jina/commit/d5c9967c0e0cd96f067afeee8aa0adae9cd3f4ef)] __-__ __version__: the next version will be 3.3.25 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.25'\n+__version__ = '3.3.26'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.26"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -76,3 +76,4 @@ pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n prometheus_client:          perf\n+psutil:                     test\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -993,26 +993,43 @@ def _update_policy():\n         try:\n             import uvloop\n \n-            asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n+            if not isinstance(asyncio.get_event_loop_policy(), uvloop.EventLoopPolicy):\n+                asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n         except ModuleNotFoundError:\n             warnings.warn(\n                 'Install `uvloop` via `pip install \"jina[uvloop]\"` for better performance.'\n             )\n \n \n+def _close_loop():\n+    try:\n+        loop = asyncio.get_event_loop()\n+        if not loop.is_closed():\n+            loop.close()\n+    except RuntimeError:\n+        # there is no loop, so nothing to do here\n+        pass\n+\n+\n+# workaround for asyncio loop and fork issue: https://github.com/python/cpython/issues/66197\n+# we close the loop after forking to avoid reusing the parents process loop\n+# a new loop should be created in the child process\n+os.register_at_fork(after_in_child=_close_loop)\n+\n+\n def get_or_reuse_loop():\n     \"\"\"\n     Get a new eventloop or reuse the current opened eventloop.\n \n     :return: A new eventloop or reuse the current opened eventloop.\n     \"\"\"\n+    _update_policy()\n     try:\n-        loop = asyncio.get_running_loop()\n+        loop = asyncio.get_event_loop()\n         if loop.is_closed():\n             raise RuntimeError\n     except RuntimeError:\n-        _update_policy()\n-        # no running event loop\n+        # no event loop\n         # create a new loop\n         loop = asyncio.new_event_loop()\n         asyncio.set_event_loop(loop)\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -76,3 +76,4 @@ pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n prometheus_client:          perf\n+psutil:                     test\n\n---\n file path A: tests/unit/test_helper.py | file path B: tests/unit/test_helper.py\n\n@@ -2,6 +2,7 @@ import os\n from types import SimpleNamespace\n \n import numpy as np\n+import psutil\n import pytest\n \n from jina import Executor, Flow, __default_endpoint__\n@@ -19,6 +20,7 @@ from jina.helper import (\n     random_port,\n     reset_ports,\n     retry,\n+    run_async,\n )\n from jina.hubble.helper import _get_hubble_base_url\n from jina.jaml.helper import complete_path\n@@ -352,3 +354,19 @@ def test_port_free(port_generator):\n     port = port_generator()\n     is_free = is_port_free('localhost', port)\n     assert is_free\n+\n+\n+def test_run_async():\n+    async def dummy():\n+        pass\n+\n+    p = psutil.Process()\n+\n+    run_async(dummy)\n+    first_fd_count = p.num_fds()\n+\n+    for i in range(10):\n+        run_async(dummy)\n+\n+    end_fd_count = p.num_fds()\n+    assert first_fd_count == end_fd_count\n\n\n###\n\n", "completion": "fix: close loop from run_async (#<issue-num>)"}
{"prompt": " file path A: None | file path B: docs/_static/source-in-links.js\n\n@@ -0,0 +1,20 @@\n+function addUTMSourceToLink(href) {\n+    try {\n+        var url = new URL(href);\n+        url.searchParams.set(\"utm_source\", \"core\");\n+        return url.href\n+    }\n+    catch{}\n+}\n+\n+function addSourceToAllLinks() {\n+    var anchors = document.getElementsByTagName(\"a\");\n+\n+    for (var i = 0; i < anchors.length; i++) {\n+        anchors[i].href = addUTMSourceToLinks(anchors[i].href)\n+    }\n+}\n+\n+window.onload = function () {\n+    addSourceToAllLinks()\n+}\n\\ No newline at end of file\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -82,7 +82,8 @@ html_css_files = [\n     'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css',\n ]\n html_js_files = [\n-    'https://cdn.jsdelivr.net/npm/qabot@0.4'\n+    'https://cdn.jsdelivr.net/npm/qabot@0.4',\n+    'source-in-links.js'\n ]\n htmlhelp_basename = slug\n html_show_sourcelink = False\n\n\n###\n\n", "completion": "docs(tracking): update refer links to other docs with utm_source (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -176,6 +176,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13485,3 +13486,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```f8b994dc```](https://github.com/jina-ai/jina/commit/f8b994dce3914dfd596c487103237e3b713657a4)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```2f08c1b6```](https://github.com/jina-ai/jina/commit/2f08c1b652f399f251e4da09e7d633c90cbd23ff)] __-__ __version__: the next version will be 3.3.23 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-24></a>\n+## Release Note (`3.3.24`)\n+\n+> Release time: 2022-05-04 14:52:39\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Deepankar Mahapatro,  samsja,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```f9f86004```](https://github.com/jina-ai/jina/commit/f9f860043063cc5517a50c2a23bf327120c86f4f)] __-__ inherit monitoring arg from Flow (#4738) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```58847187```](https://github.com/jina-ai/jina/commit/588471873a48e1e58fe3830a599a20baecd578fc)] __-__ grpc version&gt;=1.46.0 (#4746) (*Deepankar Mahapatro*)\n+ - [[```e3c45bf5```](https://github.com/jina-ai/jina/commit/e3c45bf5a3cf4e97c44f3e0463950f9c24d41a0a)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```c4175f95```](https://github.com/jina-ai/jina/commit/c4175f9518fe394fc0812d10728e3f578634e830)] __-__ __version__: the next version will be 3.3.24 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.24'\n+__version__ = '3.3.25'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.25"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -44,8 +44,8 @@ lz4<3.1.2:                  perf, standard,devel\n uvloop:                     perf, standard,devel\n numpy:                      core\n protobuf>=3.19.1:           core\n-grpcio>=1.33.1,<1.44.0:     core\n-grpcio-reflection>=1.33.1,<1.44.0:  core\n+grpcio>=1.46.0:             core\n+grpcio-reflection>=1.46.0:  core\n pyyaml>=5.3.1:              core\n docarray>=0.9.10:           core\n packaging>=20.0:            core\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -44,8 +44,8 @@ lz4<3.1.2:                  perf, standard,devel\n uvloop:                     perf, standard,devel\n numpy:                      core\n protobuf>=3.19.1:           core\n-grpcio>=1.33.1,<1.44.0:     core\n-grpcio-reflection>=1.33.1,<1.44.0:  core\n+grpcio>=1.46.0:             core\n+grpcio-reflection>=1.46.0:  core\n pyyaml>=5.3.1:              core\n docarray>=0.9.10:           core\n packaging>=20.0:            core\n\n\n###\n\n", "completion": "build: grpc version>=1.46.0 (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -832,11 +832,11 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n         # set the kwargs inherit from `Flow(kwargs1=..., kwargs2=)`\n         for key, value in op_flow._common_kwargs.items():\n+\n             # do not inherit from all the argument from the flow\n             if key not in kwargs and key not in [\n                 'port',\n                 'port_monitoring',\n-                'monitoring',\n             ]:\n                 kwargs[key] = value\n \n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -21,8 +21,8 @@ def test_enable_monitoring_deployment(port_generator):\n     port1 = port_generator()\n     port2 = port_generator()\n \n-    with Flow().add(uses=DummyExecutor, monitoring=True, port_monitoring=port1).add(\n-        uses=DummyExecutor, monitoring=True, port_monitoring=port2\n+    with Flow().add(uses=DummyExecutor, port_monitoring=port1, monitoring=True).add(\n+        uses=DummyExecutor, port_monitoring=port2, monitoring=True\n     ) as f:\n         for port in [port1, port2]:\n             resp = req.get(f'http://localhost:{port}/')\n@@ -44,8 +44,8 @@ def test_enable_monitoring_gateway(protocol, port_generator):\n     port2 = port_generator()\n \n     with Flow(protocol=protocol, monitoring=True, port_monitoring=port0).add(\n-        uses=DummyExecutor, monitoring=True, port_monitoring=port1\n-    ).add(uses=DummyExecutor, monitoring=True, port_monitoring=port2) as f:\n+        uses=DummyExecutor, port_monitoring=port1\n+    ).add(uses=DummyExecutor, port_monitoring=port2) as f:\n         for port in [port0, port1, port2]:\n             resp = req.get(f'http://localhost:{port}/')\n             assert resp.status_code == 200\n@@ -60,8 +60,8 @@ def test_monitoring_head(port_generator):\n     port1 = port_generator()\n     port2 = port_generator()\n \n-    with Flow().add(uses=DummyExecutor, monitoring=True, port_monitoring=port1).add(\n-        uses=DummyExecutor, port_monitoring=port2, monitoring=True, shards=2\n+    with Flow(monitoring=True).add(uses=DummyExecutor, port_monitoring=port1).add(\n+        uses=DummyExecutor, port_monitoring=port2, shards=2\n     ) as f:\n         port3 = f._deployment_nodes['executor0'].pod_args['pods'][0][0].port_monitoring\n         port4 = f._deployment_nodes['executor1'].pod_args['pods'][0][0].port_monitoring\n@@ -81,7 +81,7 @@ def test_document_processed_total(port_generator):\n     port1 = port_generator()\n \n     with Flow(monitoring=True, port_monitoring=port0).add(\n-        uses=DummyExecutor, monitoring=True, port_monitoring=port1\n+        uses=DummyExecutor, port_monitoring=port1\n     ) as f:\n \n         resp = req.get(f'http://localhost:{port1}/')\n@@ -115,3 +115,35 @@ def test_document_processed_total(port_generator):\n             f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\"}} 4.0'  # check that we nothing change on bar count\n             in str(resp.content)\n         )\n+\n+\n+def test_disable_monitoring_on_pods(port_generator):\n+    port0 = port_generator()\n+    port1 = port_generator()\n+\n+    with Flow(monitoring=True, port_monitoring=port0).add(\n+        uses=DummyExecutor,\n+        port_monitoring=port1,\n+        monitoring=False,\n+    ):\n+        with pytest.raises(req.exceptions.ConnectionError):  # disable on port1\n+            resp = req.get(f'http://localhost:{port1}/')\n+\n+        resp = req.get(f'http://localhost:{port0}/')  # enable on port0\n+        assert resp.status_code == 200\n+\n+\n+def test_disable_monitoring_on_gatway_only(port_generator):\n+    port0 = port_generator()\n+    port1 = port_generator()\n+\n+    with Flow(monitoring=False, port_monitoring=port0).add(\n+        uses=DummyExecutor,\n+        port_monitoring=port1,\n+        monitoring=True,\n+    ):\n+        with pytest.raises(req.exceptions.ConnectionError):  # disable on port1\n+            resp = req.get(f'http://localhost:{port0}/')\n+\n+        resp = req.get(f'http://localhost:{port1}/')  # enable on port0\n+        assert resp.status_code == 200\n\n---\n file path A: None | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_monitoring.py\n\n@@ -0,0 +1,45 @@\n+import pytest\n+\n+from jina import Executor, Flow, requests\n+\n+\n+@pytest.fixture()\n+def get_executor():\n+    class DummyExecutor(Executor):\n+        @requests(on='/foo')\n+        def foo(self, docs, **kwargs):\n+            ...\n+\n+    return DummyExecutor\n+\n+\n+def test_disable_monitoring_on_pods(port_generator, get_executor):\n+    port0 = port_generator()\n+    port1 = port_generator()\n+\n+    f = Flow(monitoring=True, port_monitoring=port0).add(\n+        uses=get_executor(),\n+        port_monitoring=port1,\n+        monitoring=False,\n+    )\n+\n+    f = f.build()\n+\n+    assert f._deployment_nodes['gateway'].pod_args['pods'][0][0].monitoring\n+    assert not f._deployment_nodes['executor0'].pod_args['pods'][0][0].monitoring\n+\n+\n+def test_disable_monitoring_on_gatway_only(port_generator, get_executor):\n+    port0 = port_generator()\n+    port1 = port_generator()\n+\n+    f = Flow(monitoring=False, port_monitoring=port0).add(\n+        uses=get_executor(),\n+        port_monitoring=port1,\n+        monitoring=True,\n+    )\n+\n+    f = f.build()\n+\n+    assert not f._deployment_nodes['gateway'].pod_args['pods'][0][0].monitoring\n+    assert f._deployment_nodes['executor0'].pod_args['pods'][0][0].monitoring\n\n\n###\n\n", "completion": "feat: inherit monitoring arg from Flow (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -175,6 +175,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13459,3 +13460,27 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```5152c983```](https://github.com/jina-ai/jina/commit/5152c98347ba8f10d2c8d46992a0427f31a2eecb)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```bca843ad```](https://github.com/jina-ai/jina/commit/bca843ad42ec6473a4a84270c943eb1da116894f)] __-__ __version__: the next version will be 3.3.22 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-23></a>\n+## Release Note (`3.3.23`)\n+\n+> Release time: 2022-05-02 20:10:11\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```de381ba0```](https://github.com/jina-ai/jina/commit/de381ba012372907c85a862d181d28671b59566d)] __-__ __logger__: make log format more compact (#4739) (*Han Xiao*)\n+ - [[```944afbc5```](https://github.com/jina-ai/jina/commit/944afbc5797c6c888dc5e9a085f646e157ed31eb)] __-__ move prometheus depedency to perf (#4735) (*samsja*)\n+ - [[```3a1a8f64```](https://github.com/jina-ai/jina/commit/3a1a8f649f409f7a33b231c9d03b80b6c88b3d3a)] __-__ rich console logs (#4724) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```4d1e4685```](https://github.com/jina-ai/jina/commit/4d1e468508facdfefe803568e9612a17a7a8ba26)] __-__ fix rich log format string (#4736) (*Han Xiao*)\n+ - [[```1ddc3953```](https://github.com/jina-ai/jina/commit/1ddc3953f9500475a362005692ded31d2e2ed87d)] __-__ fix rich log format string (*Han Xiao*)\n+ - [[```f8b994dc```](https://github.com/jina-ai/jina/commit/f8b994dce3914dfd596c487103237e3b713657a4)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```2f08c1b6```](https://github.com/jina-ai/jina/commit/2f08c1b652f399f251e4da09e7d633c90cbd23ff)] __-__ __version__: the next version will be 3.3.23 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.23'\n+__version__ = '3.3.24'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.24"}
{"prompt": " file path A: jina/logging/logger.py | file path B: jina/logging/logger.py\n\n@@ -6,6 +6,7 @@ import platform\n import sys\n from typing import Optional\n \n+from rich.logging import LogRender as _LogRender\n from rich.logging import RichHandler as _RichHandler\n \n from jina import __resources_path__, __uptime__, __windows__\n@@ -14,12 +15,69 @@ from jina.jaml import JAML\n from jina.logging import formatter\n \n \n+class _MyLogRender(_LogRender):\n+    \"\"\"Override the original rich log record for more compact layout.\"\"\"\n+\n+    def __call__(\n+        self,\n+        console,\n+        renderables,\n+        log_time=None,\n+        time_format=None,\n+        level=None,\n+        path=None,\n+        line_no=None,\n+        link_path=None,\n+    ):\n+        from rich.containers import Renderables\n+        from rich.table import Table\n+        from rich.text import Text\n+\n+        output = Table.grid(padding=(0, 1))\n+        output.expand = True\n+        if self.show_level:\n+            output.add_column(style=\"log.level\", width=5)\n+\n+        output.add_column(ratio=1, style='log.message', overflow='ellipsis')\n+\n+        if self.show_time:\n+            output.add_column(style=\"log.path\")\n+        row = []\n+\n+        if self.show_level:\n+            row.append(level)\n+\n+        row.append(Renderables(renderables))\n+\n+        if self.show_time:\n+            log_time = log_time or console.get_datetime()\n+            time_format = time_format or self.time_format\n+            if callable(time_format):\n+                log_time_display = time_format(log_time)\n+            else:\n+                log_time_display = Text(log_time.strftime(time_format))\n+            if log_time_display == self._last_time and self.omit_repeated_times:\n+                row.append(Text(\" \" * len(log_time_display)))\n+            else:\n+                row.append(log_time_display)\n+                self._last_time = log_time_display\n+        output.add_row(*row)\n+        return output\n+\n+\n class RichHandler(_RichHandler):\n     \"\"\"Override the original rich handler for more compact layout.\"\"\"\n \n     def __init__(self, *args, **kwargs):\n         super().__init__(*args, **kwargs)\n-        self._log_render.level_width = 5\n+        self._log_render = _MyLogRender(\n+            show_time=self._log_render.show_time,\n+            show_level=self._log_render.show_level,\n+            show_path=self._log_render.show_path,\n+            time_format=self._log_render.time_format,\n+            omit_repeated_times=self._log_render.omit_repeated_times,\n+            level_width=None,\n+        )\n \n \n class SysLogHandlerWrapper(logging.handlers.SysLogHandler):\n\n---\n file path A: jina/resources/logging.default.yml | file path B: jina/resources/logging.default.yml\n\n@@ -20,4 +20,4 @@ configs:\n     markup: true\n     rich_tracebacks: true\n     show_path: false\n-    log_time_format: '%x %X'\n\\ No newline at end of file\n+    log_time_format: '[%x %X]'\n\\ No newline at end of file\n\n\n###\n\n", "completion": "fix(logger): make log format more compact (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -75,4 +75,4 @@ kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n-prometheus_client:          core\n+prometheus_client:          perf\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -75,4 +75,4 @@ kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n-prometheus_client:          core\n+prometheus_client:          perf\n\n\n###\n\n", "completion": "fix: move prometheus depedency to perf (#<issue-num>)"}
{"prompt": " file path A: jina/logging/logger.py | file path B: jina/logging/logger.py\n\n@@ -6,7 +6,7 @@ import platform\n import sys\n from typing import Optional\n \n-from rich.logging import RichHandler\n+from rich.logging import RichHandler as _RichHandler\n \n from jina import __resources_path__, __uptime__, __windows__\n from jina.enums import LogVerbosity\n@@ -14,6 +14,14 @@ from jina.jaml import JAML\n from jina.logging import formatter\n \n \n+class RichHandler(_RichHandler):\n+    \"\"\"Override the original rich handler for more compact layout.\"\"\"\n+\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        self._log_render.level_width = 5\n+\n+\n class SysLogHandlerWrapper(logging.handlers.SysLogHandler):\n     \"\"\"\n     Override the priority_map :class:`SysLogHandler`.\n\n---\n file path A: jina/resources/logging.default.yml | file path B: jina/resources/logging.default.yml\n\n@@ -18,4 +18,6 @@ configs:\n   RichHandler:\n     format: '[dim]{name}@%(process)2d[/dim] %(message)s'\n     markup: true\n-    rich_tracebacks: true\n\\ No newline at end of file\n+    rich_tracebacks: true\n+    show_path: false\n+    log_time_format: '%x %X'\n\\ No newline at end of file\n\n\n###\n\n", "completion": "chore: fix rich log format string (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1523,9 +1523,9 @@ def get_rich_console():\n     :return: rich console\n     \"\"\"\n     return Console(\n-        force_terminal=True,\n+        force_terminal=True if 'PYCHARM_HOSTED' in os.environ else None,\n         color_system=None if 'JINA_LOG_NO_COLOR' in os.environ else 'auto',\n-    )  # It forces render in any terminal, especially in PyCharm\n+    )\n \n \n from jina.parsers import set_client_cli_parser\n\n\n###\n\n", "completion": "fix: rich console logs (#<issue-num>)"}
{"prompt": " file path A: jina/resources/logging.default.yml | file path B: jina/resources/logging.default.yml\n\n@@ -16,6 +16,6 @@ configs:\n     port: # when not given then record it locally,  /dev/log on linux /var/run/syslog on mac\n     formatter: PlainFormatter\n   RichHandler:\n-    format: '[dim]{name:>15}@%(process)2d[/dim] %(message)s'\n+    format: '[dim]{name}@%(process)2d[/dim] %(message)s'\n     markup: true\n     rich_tracebacks: true\n\\ No newline at end of file\n\n\n###\n\n", "completion": "chore: fix rich log format string"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -174,6 +174,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13436,3 +13437,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```2b2b2e61```](https://github.com/jina-ai/jina/commit/2b2b2e612be7cea7c959992f9be3d3a4cfccf043)] __-__ remove redundant code (*Han Xiao*)\n  - [[```5ad319ef```](https://github.com/jina-ai/jina/commit/5ad319efc1b688346bc39a22511a81fd8804bbec)] __-__ __version__: the next version will be 3.3.21 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-22></a>\n+## Release Note (`3.3.22`)\n+\n+> Release time: 2022-04-30 18:43:18\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```1516c276```](https://github.com/jina-ai/jina/commit/1516c276d4554d5fd620f0b804714303e466c3db)] __-__ __flow__: early stop (#4726) (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```930d4bab```](https://github.com/jina-ai/jina/commit/930d4babc61a58d4593de9725594eb8604ef22e7)] __-__ remove redundant colored (*Han Xiao*)\n+ - [[```5152c983```](https://github.com/jina-ai/jina/commit/5152c98347ba8f10d2c8d46992a0427f31a2eecb)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```bca843ad```](https://github.com/jina-ai/jina/commit/bca843ad42ec6473a4a84270c943eb1da116894f)] __-__ __version__: the next version will be 3.3.22 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.22'\n+__version__ = '3.3.23'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.23"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -24,6 +24,14 @@ from typing import (\n \n from rich import print\n from rich.panel import Panel\n+from rich.progress import (\n+    BarColumn,\n+    MofNCompleteColumn,\n+    Progress,\n+    SpinnerColumn,\n+    TextColumn,\n+    TimeElapsedColumn,\n+)\n from rich.table import Table\n \n from jina import __default_host__, __default_port_monitoring__, __docker_host__, helper\n@@ -48,7 +56,6 @@ from jina.helper import (\n     download_mermaid_url,\n     get_internal_ip,\n     get_public_ip,\n-    get_rich_console,\n     is_port_free,\n     typename,\n )\n@@ -1171,45 +1178,63 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n             except Exception as ex:\n                 results[_deployment_name] = repr(ex)\n \n-        def _polling_status(status):\n+        def _polling_status(progress, task):\n+\n+            progress.update(task, total=len(results))\n+            progress.start_task(task)\n \n             while True:\n-                num_all = len(results)\n                 num_done = 0\n                 pendings = []\n                 for _k, _v in results.items():\n                     sys.stdout.flush()\n                     if _v == 'pending':\n                         pendings.append(_k)\n-                    else:\n+                    elif _v == 'done':\n                         num_done += 1\n-                pending_str = colored_rich(' '.join(pendings)[:50], 'yellow')\n+                    else:\n+                        if 'JINA_EARLY_STOP' in os.environ:\n+                            self.logger.error(f'Flow is aborted due to {_k} {_v}.')\n+                            os._exit(1)\n \n-                status.update(\n-                    f'{num_done}/{num_all} waiting {pending_str} to be ready...'\n-                )\n+                pending_str = ' '.join(pendings)\n+\n+                progress.update(task, completed=num_done, pending_str=pending_str)\n \n                 if not pendings:\n                     break\n                 time.sleep(0.1)\n \n-        # kick off all deployments wait-ready threads\n-        for k, v in self:\n-            t = threading.Thread(\n-                target=_wait_ready,\n-                args=(\n-                    k,\n-                    v,\n-                ),\n-                daemon=True,\n+        progress = Progress(\n+            SpinnerColumn(),\n+            TextColumn('Waiting [b]{task.fields[pending_str]}[/]', justify='right'),\n+            BarColumn(),\n+            MofNCompleteColumn(),\n+            TimeElapsedColumn(),\n+            transient=True,\n+        )\n+        with progress:\n+            task = progress.add_task(\n+                'wait', total=len(threads), pending_str='', start=False\n             )\n-            threads.append(t)\n-            t.start()\n \n-        console = get_rich_console()\n-        with console.status('Working...') as status:\n+            # kick off all deployments wait-ready threads\n+            for k, v in self:\n+                t = threading.Thread(\n+                    target=_wait_ready,\n+                    args=(\n+                        k,\n+                        v,\n+                    ),\n+                    daemon=True,\n+                )\n+                threads.append(t)\n+                t.start()\n+\n             # kick off spinner thread\n-            t_m = threading.Thread(target=_polling_status, args=[status], daemon=True)\n+            t_m = threading.Thread(\n+                target=_polling_status, args=(progress, task), daemon=True\n+            )\n             t_m.start()\n \n             # kick off ip getter thread\n\n\n###\n\n", "completion": "fix(flow): early stop (#<issue-num>)"}
{"prompt": " file path A: jina/helloworld/fashion/helper.py | file path B: jina/helloworld/fashion/helper.py\n\n@@ -6,9 +6,8 @@ import webbrowser\n from collections import defaultdict\n \n import numpy as np\n-from docarray import Document\n \n-from jina.helper import colored\n+from docarray import Document\n from jina.logging.predefined import default_logger\n from jina.logging.profile import ProgressBar\n \n@@ -164,11 +163,8 @@ def write_html(html_path):\n             f'if not you may open {url_html_path} manually'\n         )\n \n-    colored_url = colored(\n-        'https://github.com/jina-ai/jina', color='cyan', attrs='underline'\n-    )\n     default_logger.info(\n-        f'\ud83e\udd29 Intrigued? Play with `jina hello fashion --help` and learn more about Jina at {colored_url}'\n+        f'\ud83e\udd29 Intrigued? Play with `jina hello fashion --help` and [link=https://github.com/jina-ai/jina]learn more about Jina[/]'\n     )\n \n \n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -470,7 +470,7 @@ metas:\n \n             except Exception as e:  # IO related errors\n                 self.logger.error(\n-                    f'''Please report this session_id: {colored(req_header[\"jinameta-session-id\"], color=\"yellow\", attrs=\"bold\")} to https://github.com/jina-ai/jina/issues'''\n+                    f'''Please report this session_id: [yellow bold]{req_header[\"jinameta-session-id\"]}[/] to https://github.com/jina-ai/jina/issues'''\n                 )\n                 raise e\n \n\n\n###\n\n", "completion": "chore: remove redundant colored"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -173,6 +173,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13417,3 +13418,19 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```16b6f154```](https://github.com/jina-ai/jina/commit/16b6f154e8b4873babf32fc2121f61bec1104434)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```2ff693f3```](https://github.com/jina-ai/jina/commit/2ff693f3964ebcb400379e4bcaae9a981a1f7304)] __-__ __version__: the next version will be 3.3.20 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-21></a>\n+## Release Note (`3.3.21`)\n+\n+> Release time: 2022-04-29 19:17:10\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```2b2b2e61```](https://github.com/jina-ai/jina/commit/2b2b2e612be7cea7c959992f9be3d3a4cfccf043)] __-__ remove redundant code (*Han Xiao*)\n+ - [[```5ad319ef```](https://github.com/jina-ai/jina/commit/5ad319efc1b688346bc39a22511a81fd8804bbec)] __-__ __version__: the next version will be 3.3.21 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.21'\n+__version__ = '3.3.22'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.22"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -128,11 +128,6 @@ __resources_path__ = _os.path.join(\n     _os.path.dirname(_sys.modules['jina'].__file__), 'resources'\n )\n \n-if _os.getenv('JINA_CHECK_VERSION', None) != 'False':\n-    _warnings.warn(\n-        f'Your version of jina is {__version__}. You may want to check if there are newer versions released in https://pypi.org/project/jina/#history'\n-    )\n-\n _names_with_underscore = [\n     '__version__',\n     '__proto_version__',\n\n---\n file path A: jina/excepts.py | file path B: jina/excepts.py\n\n@@ -1,20 +1,10 @@\n \"\"\"This modules defines all kinds of exceptions raised in Jina.\"\"\"\n-from jina.helper import deprecated_method\n \n \n class BaseJinaException(BaseException):\n     \"\"\"A base class for all exceptions raised by Jina\"\"\"\n \n \n-@deprecated_method('BaseJinaException')\n-class BaseJinaExeception(BaseException):\n-    \"\"\"A base class for all exceptions raised by Jina\"\"\"\n-\n-\n-class ExecutorFailToLoad(SystemError, BaseJinaException):\n-    \"\"\"When the executor can not be loaded in pod/deployment.\"\"\"\n-\n-\n class RuntimeFailToStart(SystemError, BaseJinaException):\n     \"\"\"When pod/deployment is failed to started.\"\"\"\n \n@@ -55,10 +45,6 @@ class BadRequestType(TypeError, BaseJinaException):\n     \"\"\"Exception when can not construct a request object from given data.\"\"\"\n \n \n-class BadClientResponse(Exception, BaseJinaException):\n-    \"\"\"Exception when can not construct a request object from given data.\"\"\"\n-\n-\n class BadImageNameError(Exception, BaseJinaException):\n     \"\"\"Exception when an image name can not be found either local & remote\"\"\"\n \n\n\n###\n\n", "completion": "chore: remove redundant code"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -172,6 +172,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13390,3 +13391,29 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```a884f616```](https://github.com/jina-ai/jina/commit/a884f616bfc79a40b87a5b80fbd66c4d148a88a8)] __-__ __version__: the next version will be 3.3.19 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-20></a>\n+## Release Note (`3.3.20`)\n+\n+> Release time: 2022-04-29 13:48:42\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  samsja,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```55d1f44e```](https://github.com/jina-ai/jina/commit/55d1f44ef160654daeb1efc3814e851b6d410caf)] __-__ allow jina now to unset jina_check_version (#4722) (*Joan Fontanals*)\n+ - [[```615e3efe```](https://github.com/jina-ai/jina/commit/615e3efe52fa87ebebae30431089d1c44047f766)] __-__ monitoring support for k8s (#4687) (*samsja*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```976792e9```](https://github.com/jina-ai/jina/commit/976792e9c08e1902bd9265c73d872cd3a024554c)] __-__ edit conda recipe generator (#4723) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```f5dacb1c```](https://github.com/jina-ai/jina/commit/f5dacb1cd5a31d5a09f53e14318a7eab55c0540b)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```16b6f154```](https://github.com/jina-ai/jina/commit/16b6f154e8b4873babf32fc2121f61bec1104434)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```2ff693f3```](https://github.com/jina-ai/jina/commit/2ff693f3964ebcb400379e4bcaae9a981a1f7304)] __-__ __version__: the next version will be 3.3.20 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.20'\n+__version__ = '3.3.21'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.21"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -128,7 +128,7 @@ __resources_path__ = _os.path.join(\n     _os.path.dirname(_sys.modules['jina'].__file__), 'resources'\n )\n \n-if 'JINA_CHECK_VERSION' in _os.environ:\n+if _os.getenv('JINA_CHECK_VERSION', None) != 'False':\n     _warnings.warn(\n         f'Your version of jina is {__version__}. You may want to check if there are newer versions released in https://pypi.org/project/jina/#history'\n     )\n\n\n###\n\n", "completion": "feat: allow jina now to unset jina_check_version (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -91,6 +91,8 @@ class K8sDeploymentConfig:\n                 pod_type=self.pod_type,\n                 port=self.common_args.port,\n                 env=cargs.env,\n+                monitoring=self.common_args.monitoring,\n+                port_monitoring=self.common_args.port_monitoring,\n             )\n \n         def _get_image_name(self, uses: Optional[str]):\n@@ -192,6 +194,8 @@ class K8sDeploymentConfig:\n                 shard_id=self.shard_id,\n                 env=cargs.env,\n                 gpus=cargs.gpus if hasattr(cargs, 'gpus') else None,\n+                monitoring=cargs.monitoring,\n+                port_monitoring=cargs.port_monitoring,\n             )\n \n     def __init__(\n\n---\n file path A: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py | file path B: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py\n\n@@ -26,6 +26,8 @@ def get_deployment_yamls(\n     container_cmd_uses_after: Optional[str] = None,\n     container_args_uses_before: Optional[str] = None,\n     container_args_uses_after: Optional[str] = None,\n+    monitoring: bool = False,\n+    port_monitoring: Optional[int] = None,\n ) -> List[Dict]:\n     \"\"\"Get the yaml description of a service on Kubernetes\n \n@@ -48,6 +50,8 @@ def get_deployment_yamls(\n     :param container_cmd_uses_after: command executed in the uses_after container on the k8s pods\n     :param container_args_uses_before: arguments used for uses_before container on the k8s pod\n     :param container_args_uses_after: arguments used for uses_after container on the k8s pod\n+    :param monitoring: enable monitoring on the deployment\n+    :param port_monitoring: port which will be exposed, for the prometheus server, by the deployed containers\n     :return: Return a dictionary with all the yaml configuration needed for a deployment\n     \"\"\"\n     # we can always assume the ports are the same for all executors since they run on different k8s pods\n@@ -89,16 +93,29 @@ def get_deployment_yamls(\n     elif image_name_uses_after:\n         template_name = 'deployment-uses-after'\n \n-    yamls = [\n-        kubernetes_tools.get_yaml(\n-            'configmap',\n+    if monitoring:\n+        service_yaml = kubernetes_tools.get_yaml(\n+            'service_monitoring',\n             {\n                 'name': name,\n+                'target': name,\n                 'namespace': namespace,\n-                'data': env,\n+                'port': port,\n+                'type': 'ClusterIP',\n+                'port_monitoring': port_monitoring,\n             },\n-        ),\n-        kubernetes_tools.get_yaml(\n+        )\n+\n+        service_monitor_yaml = kubernetes_tools.get_yaml(\n+            'service_monitor',\n+            {\n+                'name': name,\n+                'target': name,\n+                'namespace': namespace,\n+            },\n+        )\n+    else:\n+        service_yaml = kubernetes_tools.get_yaml(\n             'service',\n             {\n                 'name': name,\n@@ -107,10 +124,25 @@ def get_deployment_yamls(\n                 'port': port,\n                 'type': 'ClusterIP',\n             },\n+        )\n+        service_monitor_yaml = None\n+\n+    yamls = [\n+        kubernetes_tools.get_yaml(\n+            'configmap',\n+            {\n+                'name': name,\n+                'namespace': namespace,\n+                'data': env,\n+            },\n         ),\n+        service_yaml,\n         kubernetes_tools.get_yaml(template_name, deployment_params),\n     ]\n \n+    if service_monitor_yaml:\n+        yamls.append(service_monitor_yaml)\n+\n     return yamls\n \n \n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -825,8 +825,12 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n         # set the kwargs inherit from `Flow(kwargs1=..., kwargs2=)`\n         for key, value in op_flow._common_kwargs.items():\n-            # do not inherit the port argument from the flow\n-            if key not in kwargs and key != 'port':\n+            # do not inherit from all the argument from the flow\n+            if key not in kwargs and key not in [\n+                'port',\n+                'port_monitoring',\n+                'monitoring',\n+            ]:\n                 kwargs[key] = value\n \n         # update kwargs of this Deployment\n\n---\n file path A: None | file path B: jina/resources/k8s/template/service_monitor.yml\n\n@@ -0,0 +1,16 @@\n+apiVersion: monitoring.coreos.com/v1\n+kind: ServiceMonitor\n+metadata:\n+  name: {name}\n+  namespace: {namespace}\n+  labels:\n+    app: {target}\n+spec:\n+  endpoints:\n+    - port: monitoring\n+  namespaceSelector:\n+    matchNames:\n+    - {namespace}\n+  selector:\n+    matchLabels:\n+      app: {target}\n\\ No newline at end of file\n\n---\n file path A: None | file path B: jina/resources/k8s/template/service_monitoring.yml\n\n@@ -0,0 +1,20 @@\n+apiVersion: v1\n+kind: Service\n+metadata:\n+  name: {name}\n+  namespace: {namespace}\n+  labels:\n+    app: {target}\n+spec:\n+  type: {type}\n+  ports:\n+    - port: {port}\n+      targetPort: {port}\n+      name: port\n+      protocol: TCP\n+    - port: {port_monitoring}\n+      targetPort: {port_monitoring}\n+      name: monitoring\n+      protocol: TCP\n+  selector:\n+    app: {target}\n\\ No newline at end of file\n\n---\n file path A: tests/k8s/test_k8s.py | file path B: tests/k8s/test_k8s.py\n\n@@ -236,10 +236,8 @@ def k8s_flow_with_needs(docker_images):\n     [['test-executor', 'executor-merger', 'jinaai/jina']],\n     indirect=True,\n )\n-async def test_flow_with_needs(\n-    logger, k8s_flow_with_needs, tmpdir, docker_images, port_generator\n-):\n-    dump_path = os.path.join(str(tmpdir), 'test-flow-with-needs')\n+async def test_flow_with_monitoring(logger, tmpdir, docker_images, port_generator):\n+    dump_path = os.path.join(str(tmpdir), 'test-flow-with-monitoring')\n     namespace = f'test-flow-monitoring'.lower()\n \n     port1 = port_generator()\n@@ -272,9 +270,24 @@ async def test_flow_with_needs(\n         },\n         logger=logger,\n     )\n-    for port in [port1, port2]:\n-        resp = req.get(f'http://localhost:{port}/')\n-        assert resp.status_code == 200\n+    import portforward\n+\n+    config_path = os.environ['KUBECONFIG']\n+    gateway_pod_name = (\n+        core_client.list_namespaced_pod(\n+            namespace=namespace, label_selector='app=gateway'\n+        )\n+        .items[0]\n+        .metadata.name\n+    )\n+\n+    pod_port_ref = [(gateway_pod_name, port1)]\n+\n+    for (pod_name, port) in pod_port_ref:\n+        with portforward.forward(namespace, pod_name, port, port, config_path):\n+            resp = req.get(f'http://localhost:{port}/')\n+            assert resp.status_code == 200\n+\n     core_client.delete_namespace(namespace)\n \n \n\n\n###\n\n", "completion": "feat: monitoring support for k8s (#<issue-num>)"}
{"prompt": " file path A: scripts/create-conda-recipe.py | file path B: scripts/create-conda-recipe.py\n\n@@ -170,7 +170,7 @@ recipe_object = {\n         'doc_url': 'https://docs.jina.ai',\n     },\n     'extra': {\n-        'recipe-maintainers': ['tadejsv', 'JoanFM', 'nan-wang', 'hanxiao'],\n+        'recipe-maintainers': ['JoanFM', 'nan-wang', 'hanxiao'],\n         'feedstock-name': 'jina',\n     },\n }\n\n\n###\n\n", "completion": "fix: edit conda recipe generator (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -171,6 +171,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13363,3 +13364,27 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```e75efaef```](https://github.com/jina-ai/jina/commit/e75efaefb426d0e952a55cc9b84c5920cd91e6fe)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```87b4b035```](https://github.com/jina-ai/jina/commit/87b4b035f56b54954eb3f791b0678578ee906245)] __-__ __version__: the next version will be 3.3.18 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-19></a>\n+## Release Note (`3.3.19`)\n+\n+> Release time: 2022-04-28 16:14:00\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Yanlong Wang,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```93bda042```](https://github.com/jina-ai/jina/commit/93bda042aae15732bacec6f89427b6df49b9533f)] __-__ allow user not to print version check print (#4720) (*Joan Fontanals*)\n+ - [[```19e5cd7e```](https://github.com/jina-ai/jina/commit/19e5cd7e5be84f755c418c2c7c57a4e0f9f49f6c)] __-__ immutable tags for executors (#4676) (*Yanlong Wang*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```ac204dcb```](https://github.com/jina-ai/jina/commit/ac204dcbce0a3fa2a32d4fd02b8ae377f4804b5a)] __-__ rename immutable-tag to protected-tag (#4721) (*Yanlong Wang*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```a884f616```](https://github.com/jina-ai/jina/commit/a884f616bfc79a40b87a5b80fbd66c4d148a88a8)] __-__ __version__: the next version will be 3.3.19 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.19'\n+__version__ = '3.3.20'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.20"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -135,12 +135,16 @@ def main():\n         def __init__(self, key, value):\n             self.key = key\n             self.value = value\n+            self.unset = False\n \n         def __enter__(self):\n-            os.environ[self.key] = self.value\n+            if self.key not in os.environ:\n+                self.unset = True\n+                os.environ[self.key] = self.value\n \n         def __exit__(self, exc_type, exc_val, exc_tb):\n-            os.unsetenv(self.key)\n+            if self.unset:\n+                os.unsetenv(self.key)\n \n     with EnvVariableSet('JINA_CHECK_VERSION', 'True'):\n         found_plugin = _try_plugin_command()\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -128,7 +128,7 @@ __resources_path__ = _os.path.join(\n     _os.path.dirname(_sys.modules['jina'].__file__), 'resources'\n )\n \n-if _os.environ.get('JINA_CHECK_VERSION', None):\n+if 'JINA_CHECK_VERSION' in _os.environ:\n     _warnings.warn(\n         f'Your version of jina is {__version__}. You may want to check if there are newer versions released in https://pypi.org/project/jina/#history'\n     )\n\n\n###\n\n", "completion": "feat: allow user not to print version check print (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -183,7 +183,7 @@ ac_table = {\n             '--verbose',\n             '--dockerfile',\n             '--tag',\n-            '--immutable-tag',\n+            '--protected-tag',\n             '--force-update',\n             '--force',\n             '--secret',\n\n---\n file path A: docs/fundamentals/executor/hub/push-executor.md | file path B: docs/fundamentals/executor/hub/push-executor.md\n\n@@ -68,14 +68,14 @@ If you want to create a new tag for an existing Executor, you can also add the `\n jina hub push [--public/--private] --force-update <NAME> --secret <SECRET> -t TAG <path_to_executor_folder>\n ```\n \n-### Immutable tags\n+### Protected tags\n \n If you don\u2019t want some tags to be later overwritten to keep a stable, consistent behavior, \n-immutable tags are the exact thing you are looking for.\n+protected tags are the exact thing you are looking for.\n \n-You can leverage the `--immutable-tag` option to create immutable tags. \n-After being pushed for the first time, the immutable tags can not be pushed again.\n+You can leverage the `--protected-tag` option to create protected tags. \n+After being pushed for the first time, the protected tags can not be pushed again.\n \n ```bash\n-jina hub push [--public/--private] --force-update <NAME> --secret <SECRET> --immutable-tag <IMMUTABLE_TAG_1> --immutable-tag <IMMUTABLE_TAG_2> <path_to_executor_folder>\n+jina hub push [--public/--private] --force-update <NAME> --secret <SECRET> --protected-tag <PROTECTED_TAG_1> --protected-tag <PROTECTED_TAG_2> <path_to_executor_folder>\n ```\n\\ No newline at end of file\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -336,8 +336,8 @@ metas:\n         exec_immutable_tags = None\n         if self.args.tag:\n             exec_tags = ','.join(self.args.tag)\n-        if self.args.immutable_tag:\n-            exec_immutable_tags = ','.join(self.args.immutable_tag)\n+        if self.args.protected_tag:\n+            exec_immutable_tags = ','.join(self.args.protected_tag)\n \n         dockerfile = None\n         if self.args.dockerfile:\n\n---\n file path A: jina/parsers/hubble/push.py | file path B: jina/parsers/hubble/push.py\n\n@@ -50,9 +50,9 @@ One can later fetch a tagged Executor via `jinahub[+docker]://MyExecutor/gpu`\n     )\n \n     gp.add_argument(\n-        '--immutable-tag',\n+        '--protected-tag',\n         action='append',\n-        help='A list of immutable tags. Like tag but immutable after first push.',\n+        help='A list of protected tags. Like tag but protected against updates after first push.',\n     )\n \n     gp.add_argument(\n\n\n###\n\n", "completion": "fix: rename immutable-tag to protected-tag (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -183,6 +183,7 @@ ac_table = {\n             '--verbose',\n             '--dockerfile',\n             '--tag',\n+            '--immutable-tag',\n             '--force-update',\n             '--force',\n             '--secret',\n\n---\n file path A: docs/fundamentals/executor/hub/push-executor.md | file path B: docs/fundamentals/executor/hub/push-executor.md\n\n@@ -67,3 +67,15 @@ If you want to create a new tag for an existing Executor, you can also add the `\n ```bash\n jina hub push [--public/--private] --force-update <NAME> --secret <SECRET> -t TAG <path_to_executor_folder>\n ```\n+\n+### Immutable tags\n+\n+If you don\u2019t want some tags to be later overwritten to keep a stable, consistent behavior, \n+immutable tags are the exact thing you are looking for.\n+\n+You can leverage the `--immutable-tag` option to create immutable tags. \n+After being pushed for the first time, the immutable tags can not be pushed again.\n+\n+```bash\n+jina hub push [--public/--private] --force-update <NAME> --secret <SECRET> --immutable-tag <IMMUTABLE_TAG_1> --immutable-tag <IMMUTABLE_TAG_2> <path_to_executor_folder>\n+```\n\\ No newline at end of file\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -333,8 +333,11 @@ metas:\n         work_path = Path(self.args.path)\n \n         exec_tags = None\n+        exec_immutable_tags = None\n         if self.args.tag:\n             exec_tags = ','.join(self.args.tag)\n+        if self.args.immutable_tag:\n+            exec_immutable_tags = ','.join(self.args.immutable_tag)\n \n         dockerfile = None\n         if self.args.dockerfile:\n@@ -377,6 +380,9 @@ metas:\n                 if exec_tags:\n                     form_data['tags'] = exec_tags\n \n+                if exec_immutable_tags:\n+                    form_data['immutableTags'] = exec_immutable_tags\n+\n                 if dockerfile:\n                     form_data['dockerfile'] = str(dockerfile)\n \n\n---\n file path A: jina/parsers/hubble/push.py | file path B: jina/parsers/hubble/push.py\n\n@@ -49,6 +49,12 @@ One can later fetch a tagged Executor via `jinahub[+docker]://MyExecutor/gpu`\n ''',\n     )\n \n+    gp.add_argument(\n+        '--immutable-tag',\n+        action='append',\n+        help='A list of immutable tags. Like tag but immutable after first push.',\n+    )\n+\n     gp.add_argument(\n         '--force-update',\n         '--force',\n\n\n###\n\n", "completion": "feat: immutable tags for executors (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -170,6 +170,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13338,3 +13339,27 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```22d5ce67```](https://github.com/jina-ai/jina/commit/22d5ce67b2ba7959cdd2706b8f508b2a9b56a15c)] __-__ update readme (*Han Xiao*)\n  - [[```d2423b27```](https://github.com/jina-ai/jina/commit/d2423b27265fca2d0aa440c160f87ab16af2beb6)] __-__ __version__: the next version will be 3.3.17 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-18></a>\n+## Release Note (`3.3.18`)\n+\n+> Release time: 2022-04-28 13:17:43\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  samsja,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```0def13df```](https://github.com/jina-ai/jina/commit/0def13dfa83fab625516ee8045f49a960b87ffe1)] __-__ add resource layer in docker compose gpu (#4718) (*Joan Fontanals*)\n+ - [[```e57f9524```](https://github.com/jina-ai/jina/commit/e57f9524499db19cb1d78312a5c07b523cf759a6)] __-__ remove version check from cli (#4716) (*Joan Fontanals*)\n+ - [[```07ae316d```](https://github.com/jina-ai/jina/commit/07ae316d75d6bb85d80f2feffd4a684672ccae31)] __-__ fix grpcio-reflection version (#4715) (*Joan Fontanals*)\n+ - [[```917604de```](https://github.com/jina-ai/jina/commit/917604dead545fd810022785628e9aeaee1f649b)] __-__ update failing test (#4711) (*samsja*)\n+ - [[```59340e05```](https://github.com/jina-ai/jina/commit/59340e05b185b0354e0bd2297a597d2cb5328871)] __-__ the cd (#4714) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```e75efaef```](https://github.com/jina-ai/jina/commit/e75efaefb426d0e952a55cc9b84c5920cd91e6fe)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```87b4b035```](https://github.com/jina-ai/jina/commit/87b4b035f56b54954eb3f791b0678578ee906245)] __-__ __version__: the next version will be 3.3.18 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.18'\n+__version__ = '3.3.19'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.19"}
{"prompt": " file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -180,14 +180,16 @@ class DockerComposeConfig:\n                         count = cargs.gpus\n \n                     config['deploy'] = {\n-                        'reservations': {\n-                            'devices': [\n-                                {\n-                                    'driver': 'nvidia',\n-                                    'count': count,\n-                                    'capabilities': ['gpu'],\n-                                }\n-                            ]\n+                        'resources': {\n+                            'reservations': {\n+                                'devices': [\n+                                    {\n+                                        'driver': 'nvidia',\n+                                        'count': count,\n+                                        'capabilities': ['gpu'],\n+                                    }\n+                                ]\n+                            }\n                         }\n                     }\n \n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py\n\n@@ -397,7 +397,6 @@ def test_disable_auto_volume(tmpdir):\n \n \n def test_flow_to_docker_compose_sandbox(tmpdir):\n-\n     flow = Flow(name='test-flow', port=8080).add(\n         uses=f'jinahub+sandbox://DummyHubExecutor'\n     )\n@@ -438,7 +437,11 @@ def test_flow_to_docker_compose_gpus(tmpdir, count):\n     services = configuration['services']\n     encoder_service = services['encoder']\n     assert encoder_service['deploy'] == {\n-        'reservations': {\n-            'devices': [{'driver': 'nvidia', 'count': count, 'capabilities': ['gpu']}]\n+        'resources': {\n+            'reservations': {\n+                'devices': [\n+                    {'driver': 'nvidia', 'count': count, 'capabilities': ['gpu']}\n+                ]\n+            }\n         }\n     }\n\n\n###\n\n", "completion": "fix: add resource layer in docker compose gpu (#<issue-num>)"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -3,9 +3,6 @@ import shutil\n import subprocess\n import sys\n \n-import pkg_resources\n-from packaging.version import Version, parse\n-\n \n def _get_run_args(print_args: bool = True):\n     from jina.helper import get_rich_console\n@@ -91,56 +88,6 @@ def _quick_ac_lookup():\n             exit()\n \n \n-def _parse_latest_release_version(resp):\n-    # credit: https://stackoverflow.com/a/34366589\n-    import json\n-\n-    latest_release_ver = parse('0')\n-    j = json.load(resp)\n-    releases = j.get('releases', [])\n-    for release in releases:\n-        latest_ver = parse(release)\n-        if not latest_ver.is_prerelease:\n-            latest_release_ver = max(latest_release_ver, latest_ver)\n-    return latest_release_ver\n-\n-\n-def _is_latest_version(package='jina', suppress_on_error=True):\n-    try:\n-        import warnings\n-        from urllib.request import Request, urlopen\n-\n-        cur_ver = Version(pkg_resources.get_distribution(package).version)\n-\n-        req = Request(\n-            f'https://pypi.python.org/pypi/{package}/json',\n-            headers={'User-Agent': 'Mozilla/5.0'},\n-        )\n-        with urlopen(\n-            req, timeout=5\n-        ) as resp:  # 'with' is important to close the resource after use\n-            latest_release_ver = _parse_latest_release_version(resp)\n-            if cur_ver < latest_release_ver:\n-\n-                warnings.warn(\n-                    f'You are using {package} version {cur_ver}, however version {latest_release_ver} is available. '\n-                    f'You should consider upgrading via the \"pip install --upgrade {package}\" command.'\n-                )\n-                return False\n-        return True\n-    except:\n-        # no network, too slow, PyPi is down\n-        if not suppress_on_error:\n-            raise\n-\n-\n-def _is_latest_version_plugin(subcommand):\n-    from cli.known_plugins import plugin_info\n-\n-    if subcommand in plugin_info:\n-        _is_latest_version(package=plugin_info[subcommand]['pip-package'])\n-\n-\n def _try_plugin_command():\n     \"\"\"Tries to call the CLI of an external Jina project.\n \n@@ -150,7 +97,7 @@ def _try_plugin_command():\n     if len(argv) < 2:  # no command given\n         return False\n \n-    from .autocomplete import ac_table\n+    from cli.autocomplete import ac_table\n \n     if argv[1] in ac_table['commands']:  # native command can't be plugin command\n         return False\n@@ -161,17 +108,10 @@ def _try_plugin_command():\n     subcommand = argv[1]\n     cmd = 'jina-' + subcommand\n     if _cmd_exists(cmd):\n-        import threading\n-\n-        threading.Thread(\n-            target=_is_latest_version_plugin,\n-            daemon=True,\n-            args=(subcommand,),\n-        ).start()\n         subprocess.run([cmd] + argv[2:])\n         return True\n \n-    from .known_plugins import plugin_info\n+    from cli.known_plugins import plugin_info\n \n     if subcommand in plugin_info:\n         from jina.helper import get_rich_console\n@@ -191,17 +131,25 @@ def _try_plugin_command():\n def main():\n     \"\"\"The main entrypoint of the CLI\"\"\"\n \n-    # checking version info in another thread\n-    import threading\n+    class EnvVariableSet:\n+        def __init__(self, key, value):\n+            self.key = key\n+            self.value = value\n+\n+        def __enter__(self):\n+            os.environ[self.key] = self.value\n+\n+        def __exit__(self, exc_type, exc_val, exc_tb):\n+            os.unsetenv(self.key)\n \n-    threading.Thread(target=_is_latest_version, daemon=True, args=('jina',)).start()\n-    found_plugin = _try_plugin_command()\n+    with EnvVariableSet('JINA_CHECK_VERSION', 'True'):\n+        found_plugin = _try_plugin_command()\n \n-    if not found_plugin:\n-        _quick_ac_lookup()\n+        if not found_plugin:\n+            _quick_ac_lookup()\n \n-        from cli import api\n+            from cli import api\n \n-        args = _get_run_args()\n+            args = _get_run_args()\n \n-        getattr(api, args.cli.replace('-', '_'))(args)\n+            getattr(api, args.cli.replace('-', '_'))(args)\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -103,6 +103,7 @@ __jina_env__ = (\n     'JINA_RANDOM_PORT_MAX',\n     'JINA_RANDOM_PORT_MIN',\n     'JINA_VCS_VERSION',\n+    'JINA_CHECK_VERSION',\n )\n \n __default_host__ = _os.environ.get(\n@@ -127,6 +128,11 @@ __resources_path__ = _os.path.join(\n     _os.path.dirname(_sys.modules['jina'].__file__), 'resources'\n )\n \n+if _os.environ.get('JINA_CHECK_VERSION', None):\n+    _warnings.warn(\n+        f'Your version of jina is {__version__}. You may want to check if there are newer versions released in https://pypi.org/project/jina/#history'\n+    )\n+\n _names_with_underscore = [\n     '__version__',\n     '__proto_version__',\n\n\n###\n\n", "completion": "fix: remove version check from cli (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -45,7 +45,7 @@ uvloop:                     perf, standard,devel\n numpy:                      core\n protobuf>=3.19.1:           core\n grpcio>=1.33.1,<1.44.0:     core\n-grpcio-reflection>=1.33.1:  core\n+grpcio-reflection>=1.33.1,<1.44.0:  core\n pyyaml>=5.3.1:              core\n docarray>=0.9.10:           core\n packaging>=20.0:            core\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -45,7 +45,7 @@ uvloop:                     perf, standard,devel\n numpy:                      core\n protobuf>=3.19.1:           core\n grpcio>=1.33.1,<1.44.0:     core\n-grpcio-reflection>=1.33.1:  core\n+grpcio-reflection>=1.33.1,<1.44.0:  core\n pyyaml>=5.3.1:              core\n docarray>=0.9.10:           core\n packaging>=20.0:            core\n\n\n###\n\n", "completion": "fix: fix grpcio-reflection version (#<issue-num>)"}
{"prompt": " file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py\n\n@@ -308,7 +308,7 @@ def test_flow_head_runtime_failure(monkeypatch, capfd):\n \n     out, err = capfd.readouterr()\n     assert 'NotImplementedError' in out\n-    assert 'Intentional error' in out\n+    assert 'Intentional' in out and 'error' in out\n \n \n class TimeoutSlowExecutor(Executor):\n\n\n###\n\n", "completion": "fix: update failing test (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -159,7 +159,6 @@ jobs:\n \n   import-test:\n     runs-on: ubuntu-latest\n-    needs: [ commit-lint, lint-flake-8, code-injection ]\n     strategy:\n       fail-fast: false\n       matrix:\n\n\n###\n\n", "completion": "fix: the cd (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -169,6 +169,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13313,3 +13314,21 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```955adb40```](https://github.com/jina-ai/jina/commit/955adb405990bb64dd97d0b81b467028c8937142)] __-__ __version__: the next version will be 3.3.16 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-17></a>\n+## Release Note (`3.3.17`)\n+\n+> Release time: 2022-04-27 21:10:33\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```9f83ab6b```](https://github.com/jina-ai/jina/commit/9f83ab6b881dcc2f7adb17c0108d074316a121f4)] __-__ readme badge (*Han Xiao*)\n+ - [[```b2e11974```](https://github.com/jina-ai/jina/commit/b2e11974685b706e8a46ea61b648850df3c47c43)] __-__ sort and optimize imports (#4713) (*Han Xiao*)\n+ - [[```22d5ce67```](https://github.com/jina-ai/jina/commit/22d5ce67b2ba7959cdd2706b8f508b2a9b56a15c)] __-__ update readme (*Han Xiao*)\n+ - [[```d2423b27```](https://github.com/jina-ai/jina/commit/d2423b27265fca2d0aa440c160f87ab16af2beb6)] __-__ __version__: the next version will be 3.3.17 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.17'\n+__version__ = '3.3.18'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.18"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -10,6 +10,7 @@\n \n \n <p align=center>\n+<a href=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml\"><img alt=\"Github CD status\" src=\"https://github.com/jina-ai/jina/actions/workflows/cd.yml/badge.svg\"></a>\n <a href=\"https://pypi.org/project/jina/\"><img alt=\"PyPI\" src=\"https://img.shields.io/pypi/v/jina?label=PyPI&logo=pypi&logoColor=white&style=flat-square\"></a>\n <a href=\"https://codecov.io/gh/jina-ai/jina\"><img alt=\"Codecov branch\" src=\"https://img.shields.io/codecov/c/github/jina-ai/jina/master?logo=Codecov&logoColor=white&style=flat-square\"></a>\n <a href=\"https://slack.jina.ai\"><img src=\"https://img.shields.io/badge/Slack-2.8k-blueviolet?logo=slack&amp;logoColor=white&style=flat-square\"></a>\n\n\n###\n\n", "completion": "chore: readme badge"}
{"prompt": " file path A: jina/clients/base/http.py | file path B: jina/clients/base/http.py\n\n@@ -1,5 +1,5 @@\n import asyncio\n-from contextlib import AsyncExitStack, nullcontext\n+from contextlib import AsyncExitStack\n from typing import TYPE_CHECKING, Optional\n \n from jina.clients.base import BaseClient\n\n---\n file path A: jina/clients/base/websocket.py | file path B: jina/clients/base/websocket.py\n\n@@ -1,12 +1,11 @@\n \"\"\"A module for the websockets-based Client for Jina.\"\"\"\n import asyncio\n-from contextlib import AsyncExitStack, nullcontext\n+from contextlib import AsyncExitStack\n from typing import TYPE_CHECKING, Dict, Optional\n \n from jina.clients.base import BaseClient\n from jina.clients.base.helper import WebsocketClientlet\n from jina.clients.helper import callback_exec, callback_exec_on_error\n-from jina.excepts import BadClient\n from jina.helper import get_or_reuse_loop\n from jina.importer import ImportExtensions\n from jina.logging.profile import ProgressBar\n\n---\n file path A: jina/helloworld/fashion/app.py | file path B: jina/helloworld/fashion/app.py\n\n@@ -1,28 +1,28 @@\n import os\n-from pathlib import Path\n from functools import partial\n+from pathlib import Path\n \n from jina import Flow\n from jina.parsers.helloworld import set_hw_parser\n \n if __name__ == '__main__':\n     from helper import (\n-        print_result,\n-        write_html,\n         download_data,\n+        get_groundtruths,\n         index_generator,\n+        print_result,\n         query_generator,\n-        get_groundtruths,\n+        write_html,\n     )\n     from my_executors import MyEncoder, MyIndexer\n else:\n     from .helper import (\n-        print_result,\n-        write_html,\n         download_data,\n+        get_groundtruths,\n         index_generator,\n+        print_result,\n         query_generator,\n-        get_groundtruths,\n+        write_html,\n     )\n     from .my_executors import MyEncoder, MyIndexer\n \n\n---\n file path A: jina/helloworld/fashion/my_executors.py | file path B: jina/helloworld/fashion/my_executors.py\n\n@@ -2,8 +2,9 @@ import os\n from typing import Dict\n \n import numpy as np\n-from jina import Executor, requests\n+\n from docarray import DocumentArray\n+from jina import Executor, requests\n \n \n class MyIndexer(Executor):\n\n---\n file path A: jina/hubble/hubapi.py | file path B: jina/hubble/hubapi.py\n\n@@ -1,7 +1,6 @@\n \"\"\"Module wrapping interactions with the local executor packages.\"\"\"\n \n import json\n-import os\n import shutil\n from pathlib import Path\n from typing import Tuple\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -735,7 +735,6 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n \n     def _load_docker_client(self):\n         with ImportExtensions(required=True):\n-            import docker\n             import docker.errors\n             from docker import APIClient\n \n\n---\n file path A: jina/jaml/__init__.py | file path B: jina/jaml/__init__.py\n\n@@ -21,7 +21,6 @@ from jina.jaml.helper import (\n __all__ = ['JAML', 'JAMLCompatible']\n \n from jina.excepts import BadConfigSource\n-from jina.helper import expand_env_var\n \n internal_var_regex = re.compile(\n     r'{.+}|\\$[a-zA-Z0-9_]*\\b'\n\n---\n file path A: jina/jaml/parsers/__init__.py | file path B: jina/jaml/parsers/__init__.py\n\n@@ -1,9 +1,9 @@\n import warnings\n from typing import List, Optional, Type\n \n-from jina.jaml.parsers.base import VersionedYAMLParser\n-from jina.jaml import JAMLCompatible\n from jina.excepts import BadYAMLVersion\n+from jina.jaml import JAMLCompatible\n+from jina.jaml.parsers.base import VersionedYAMLParser\n \n \n def _get_all_parser(cls: Type['JAMLCompatible']):\n@@ -12,8 +12,8 @@ def _get_all_parser(cls: Type['JAMLCompatible']):\n     :param cls: target class\n     :return: a tuple of two elements; first is a list of all parsers, second is the legacy parser for default fallback\n     \"\"\"\n-    from jina.serve.executors import BaseExecutor\n     from jina.orchestrate.flow.base import Flow\n+    from jina.serve.executors import BaseExecutor\n \n     if issubclass(cls, Flow):\n         return _get_flow_parser()\n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -1,5 +1,4 @@\n import copy\n-import os\n from abc import abstractmethod\n from argparse import Namespace\n from contextlib import ExitStack\n\n---\n file path A: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py | file path B: jina/orchestrate/deployments/config/k8slib/kubernetes_deployment.py\n\n@@ -1,9 +1,9 @@\n import json\n from argparse import Namespace\n-from typing import Dict, Optional, Tuple, Union, List\n+from typing import Dict, List, Optional, Tuple, Union\n \n-from jina.serve.networking import GrpcConnectionPool\n from jina.orchestrate.deployments.config.k8slib import kubernetes_tools\n+from jina.serve.networking import GrpcConnectionPool\n \n \n def get_deployment_yamls(\n\n---\n file path A: jina/orchestrate/flow/asyncio.py | file path B: jina/orchestrate/flow/asyncio.py\n\n@@ -1,5 +1,5 @@\n-from jina.orchestrate.flow.base import Flow\n from jina.clients.mixin import AsyncPostMixin\n+from jina.orchestrate.flow.base import Flow\n \n \n class AsyncFlow(AsyncPostMixin, Flow):\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -4,12 +4,10 @@ import copy\n import json\n import multiprocessing\n import os\n-import re\n import sys\n import threading\n import time\n import uuid\n-import warnings\n from collections import OrderedDict\n from contextlib import ExitStack\n from typing import (\n\n---\n file path A: jina/orchestrate/pods/helper.py | file path B: jina/orchestrate/pods/helper.py\n\n@@ -1,8 +1,7 @@\n import multiprocessing\n-import threading\n from copy import deepcopy\n from functools import partial\n-from typing import TYPE_CHECKING, Callable, Dict, Optional, Union\n+from typing import TYPE_CHECKING\n \n from grpc import RpcError\n \n\n---\n file path A: jina/parsers/flow.py | file path B: jina/parsers/flow.py\n\n@@ -2,7 +2,6 @@\n from jina.parsers.base import set_base_parser\n from jina.parsers.helper import KVAppendAction, add_arg_group\n from jina.parsers.orchestrate.base import mixin_essential_parser\n-from jina.parsers.orchestrate.runtimes.remote import mixin_graphql_parser\n \n \n def mixin_flow_features_parser(parser):\n@@ -42,7 +41,6 @@ def set_flow_parser(parser=None):\n     :param parser: an (optional) initial parser to build upon\n     :return: the parser\n     \"\"\"\n-    from jina.parsers.orchestrate.base import mixin_base_ppr_parser\n \n     if not parser:\n         parser = set_base_parser()\n\n---\n file path A: jina/parsers/helloworld.py | file path B: jina/parsers/helloworld.py\n\n@@ -1,9 +1,9 @@\n \"\"\"Module for hello world argparser\"\"\"\n import argparse\n \n-from jina.parsers.base import set_base_parser\n-from jina.parsers.helper import add_arg_group, _SHOW_ALL_ARGS, _chf\n from jina.helper import random_identity\n+from jina.parsers.base import set_base_parser\n+from jina.parsers.helper import _SHOW_ALL_ARGS, _chf, add_arg_group\n \n \n def mixin_hw_base_parser(parser):\n\n---\n file path A: jina/parsers/orchestrate/base.py | file path B: jina/parsers/orchestrate/base.py\n\n@@ -36,8 +36,6 @@ def mixin_essential_parser(parser):\n         'If not set, then derive from its parent `workspace`.',\n     )\n \n-    from jina import __resources_path__\n-\n     gp.add_argument(\n         '--log-config',\n         type=str,\n\n---\n file path A: jina/parsers/orchestrate/runtimes/distributed.py | file path B: jina/parsers/orchestrate/runtimes/distributed.py\n\n@@ -1,7 +1,6 @@\n \"\"\"Argparser module for distributed runtimes\"\"\"\n-import argparse\n \n-from jina.parsers.helper import _SHOW_ALL_ARGS, add_arg_group\n+from jina.parsers.helper import add_arg_group\n \n \n def mixin_distributed_feature_parser(parser):\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -2,16 +2,7 @@\n import functools\n import inspect\n from functools import wraps\n-from typing import (\n-    TYPE_CHECKING,\n-    Callable,\n-    ContextManager,\n-    Dict,\n-    List,\n-    Optional,\n-    Sequence,\n-    Union,\n-)\n+from typing import TYPE_CHECKING, Callable, Dict, List, Optional, Sequence, Union\n \n from jina.helper import convert_tuple_to_list, iscoroutinefunction\n from jina.serve.executors.metas import get_default_metas\n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -2,7 +2,6 @@ import asyncio\n import contextlib\n import ipaddress\n import os\n-import time\n from collections import defaultdict\n from typing import Dict, List, Optional, Tuple\n from urllib.parse import urlparse\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -2,12 +2,10 @@ import argparse\n import asyncio\n import contextlib\n import json\n-import multiprocessing\n import os\n-import threading\n from abc import ABC\n from collections import defaultdict\n-from typing import Dict, List, Optional, Tuple, Union\n+from typing import Dict, List, Optional, Tuple\n \n import grpc\n from grpc_reflection.v1alpha import reflection\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -1,10 +1,7 @@\n import argparse\n-import asyncio\n import contextlib\n-import multiprocessing\n-import threading\n from abc import ABC\n-from typing import List, Optional, Union\n+from typing import List\n \n import grpc\n from grpc_reflection.v1alpha import reflection\n\n---\n file path A: jina/serve/stream/__init__.py | file path B: jina/serve/stream/__init__.py\n\n@@ -1,6 +1,5 @@\n import argparse\n import asyncio\n-import contextlib\n from typing import (\n     TYPE_CHECKING,\n     AsyncIterator,\n@@ -18,8 +17,6 @@ from jina.serve.stream.helper import AsyncRequestsIterator\n __all__ = ['RequestStreamer']\n \n if TYPE_CHECKING:\n-    from prometheus_client import CollectorRegistry\n-\n     from jina.types.request import Request\n \n \n\n---\n file path A: jina/types/request/__init__.py | file path B: jina/types/request/__init__.py\n\n@@ -1,8 +1,8 @@\n import traceback\n from typing import Optional\n \n-from jina.serve.executors import BaseExecutor\n from jina.proto import jina_pb2\n+from jina.serve.executors import BaseExecutor\n from jina.types.mixin import ProtoTypeMixin\n \n \n\n---\n file path A: jina/types/request/control.py | file path B: jina/types/request/control.py\n\n@@ -1,8 +1,8 @@\n from typing import Optional\n \n-from jina.types.request import Request\n-from jina.helper import typename, random_identity\n+from jina.helper import random_identity, typename\n from jina.proto import jina_pb2\n+from jina.types.request import Request\n \n _available_commands = dict(jina_pb2.ControlRequestProto.DESCRIPTOR.enum_values_by_name)\n \n\n\n###\n\n", "completion": "style: sort and optimize imports (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -168,6 +168,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13292,3 +13293,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```b1bff161```](https://github.com/jina-ai/jina/commit/b1bff161b022c02b6b6215130f46a8def807541e)] __-__ __version__: the next version will be 3.3.15 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-16></a>\n+## Release Note (`3.3.16`)\n+\n+> Release time: 2022-04-27 19:38:37\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```4bafca88```](https://github.com/jina-ai/jina/commit/4bafca88a5d8348c46460e7e37f2991def8c57d4)] __-__ __logger__: use docker log handler for container (#4712) (*Han Xiao*)\n+ - [[```bb227615```](https://github.com/jina-ai/jina/commit/bb227615b9f7bee32115d6f00e7ed56e27d0f968)] __-__ fix add deploy resources when gpus detected (#4706) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```955adb40```](https://github.com/jina-ai/jina/commit/955adb405990bb64dd97d0b81b467028c8937142)] __-__ __version__: the next version will be 3.3.16 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.16'\n+__version__ = '3.3.17'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.17"}
{"prompt": " file path A: cli/api.py | file path B: cli/api.py\n\n@@ -1,6 +1,5 @@\n from typing import TYPE_CHECKING\n \n-\n if TYPE_CHECKING:\n     from argparse import Namespace\n \n@@ -61,7 +60,7 @@ def executor_native(args: 'Namespace'):\n             if hasattr(rt, '_data_request_handler')\n             else rt.name\n         )\n-        rt.logger.success(f' Executor {name} started')\n+        rt.logger.info(f'Executor {name} started')\n         rt.run_forever()\n \n \n@@ -88,8 +87,8 @@ def worker_runtime(args: 'Namespace'):\n     from jina.serve.runtimes.worker import WorkerRuntime\n \n     with WorkerRuntime(args) as runtime:\n-        runtime.logger.success(\n-            f' Executor {runtime._data_request_handler._executor.metas.name} started'\n+        runtime.logger.info(\n+            f'Executor {runtime._data_request_handler._executor.metas.name} started'\n         )\n         runtime.run_forever()\n \n@@ -111,8 +110,8 @@ def gateway(args: 'Namespace'):\n     runtime_cls = get_runtime(gateway_runtime_dict[args.protocol])\n \n     with runtime_cls(args) as runtime:\n-        runtime.logger.success(\n-            f' Gateway with protocol {gateway_runtime_dict[args.protocol]} started'\n+        runtime.logger.info(\n+            f'Gateway with protocol {gateway_runtime_dict[args.protocol]} started'\n         )\n         runtime.run_forever()\n \n@@ -146,9 +145,10 @@ def export_api(args: 'Namespace'):\n     :param args: arguments coming from the CLI.\n     \"\"\"\n     import json\n+\n     from cli.export import api_to_dict\n-    from jina.jaml import JAML\n     from jina import __version__\n+    from jina.jaml import JAML\n     from jina.logging.predefined import default_logger\n     from jina.schemas import get_full_schema\n \n@@ -234,7 +234,9 @@ def new(args: 'Namespace'):\n     Create a new jina project\n     :param args:  arguments coming from the CLI.\n     \"\"\"\n-    import shutil, os\n+    import os\n+    import shutil\n+\n     from jina import __resources_path__\n \n     shutil.copytree(\n\n---\n file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -70,7 +70,6 @@ ac_table = {\n             '--output-array-type',\n             '--entrypoint',\n             '--docker-kwargs',\n-            '--pull-latest',\n             '--volumes',\n             '--gpus',\n             '--disable-auto-volume',\n@@ -223,7 +222,6 @@ ac_table = {\n             '--output-array-type',\n             '--entrypoint',\n             '--docker-kwargs',\n-            '--pull-latest',\n             '--volumes',\n             '--gpus',\n             '--disable-auto-volume',\n@@ -274,7 +272,6 @@ ac_table = {\n             '--output-array-type',\n             '--entrypoint',\n             '--docker-kwargs',\n-            '--pull-latest',\n             '--volumes',\n             '--gpus',\n             '--disable-auto-volume',\n\n---\n file path A: jina/checker.py | file path B: jina/checker.py\n\n@@ -13,9 +13,10 @@ class NetworkChecker:\n         :param args: args provided by the CLI.\n         \"\"\"\n \n+        import time\n+\n         from jina.logging.profile import TimeContext\n         from jina.serve.runtimes.worker import WorkerRuntime\n-        import time\n \n         ctrl_addr = f'{args.host}:{args.port}'\n         try:\n@@ -45,7 +46,7 @@ class NetworkChecker:\n                     )\n                 )\n             if total_success > 0:\n-                default_logger.success(\n+                default_logger.info(\n                     'avg. latency: %.0f ms' % (total_time / total_success * 1000)\n                 )\n                 exit(0)\n\n---\n file path A: jina/clients/helper.py | file path B: jina/clients/helper.py\n\n@@ -1,15 +1,13 @@\n \"\"\"Helper functions for clients in Jina.\"\"\"\n \n from functools import wraps\n-from inspect import signature\n from typing import Callable, Optional\n-import warnings\n \n from jina.excepts import BadClientCallback\n+from jina.helper import get_rich_console\n from jina.logging.logger import JinaLogger\n from jina.proto import jina_pb2\n from jina.types.request.data import Response\n-from jina.helper import get_rich_console\n \n \n def pprint_routes(resp: 'Response', stack_limit: int = 3):\n@@ -20,8 +18,8 @@ def pprint_routes(resp: 'Response', stack_limit: int = 3):\n     \"\"\"\n     routes = resp.routes\n \n-    from rich.table import Table\n     from rich import box\n+    from rich.table import Table\n \n     table = Table(box=box.SIMPLE)\n     for v in ('Executor', 'Time', 'Exception'):\n\n---\n file path A: jina/helloworld/fork.py | file path B: jina/helloworld/fork.py\n\n@@ -13,7 +13,7 @@ def fork_hello(args) -> None:\n     from_path = os.path.join(os.path.dirname(__file__), args.project)\n     shutil.copytree(from_path, args.destination)\n     full_path = os.path.abspath(args.destination)\n-    default_logger.success(f'{args.project} project is forked to {full_path}')\n+    default_logger.info(f'{args.project} project is forked to {full_path}')\n     default_logger.info(\n         f'''\n     To run the project:\n\n---\n file path A: jina/logging/logger.py | file path B: jina/logging/logger.py\n\n@@ -8,6 +8,7 @@ from typing import Optional\n \n from rich.logging import RichHandler\n \n+from jina import __resources_path__, __uptime__, __windows__\n from jina.enums import LogVerbosity\n from jina.jaml import JAML\n from jina.logging import formatter\n@@ -52,16 +53,15 @@ class JinaLogger:\n         quiet: bool = False,\n         **kwargs,\n     ):\n-        from jina import __resources_path__, __uptime__, __windows__\n \n         if not log_config:\n             log_config = os.getenv(\n                 'JINA_LOG_CONFIG',\n-                os.path.join(__resources_path__, 'logging.default.yml'),\n+                'default',\n             )\n \n         if quiet or os.getenv('JINA_LOG_CONFIG', None) == 'QUIET':\n-            log_config = os.path.join(__resources_path__, 'logging.quiet.yml')\n+            log_config = 'quiet'\n \n         if not name:\n             name = os.getenv('JINA_DEPLOYMENT_NAME', context)\n@@ -118,10 +118,20 @@ class JinaLogger:\n         :param config_path: Path of config file.\n         :param kwargs: Extra parameters.\n         \"\"\"\n-        from jina import __windows__\n \n         self.logger.handlers = []\n \n+        if not os.path.exists(config_path):\n+            old_config_path = config_path\n+            if 'logging.' in config_path and '.yml' in config_path:\n+                config_path = os.path.join(__resources_path__, config_path)\n+            else:\n+                config_path = os.path.join(\n+                    __resources_path__, f'logging.{config_path}.yml'\n+                )\n+            if not os.path.exists(config_path):\n+                config_path = old_config_path\n+\n         with open(config_path) as fp:\n             config = JAML.load(fp)\n \n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -645,7 +645,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n         port_monitoring: Optional[int] = 9090,\n-        pull_latest: Optional[bool] = False,\n         py_modules: Optional[List[str]] = None,\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n@@ -722,7 +721,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n               {'/custom': 'ALL', '/search': 'ANY', '*': 'ANY'}\n         :param port: The port for input data to bind to, default is a random port between [49152, 65535]\n         :param port_monitoring: The port on which the prometheus server is exposed, default port is 9090\n-        :param pull_latest: Pull the latest image before running\n         :param py_modules: The customized python modules need to be imported before loading the executor\n \n           Note that the recommended way is to only import a single module - a simple python file, if your\n\n---\n file path A: jina/orchestrate/pods/container.py | file path B: jina/orchestrate/pods/container.py\n\n@@ -1,13 +1,16 @@\n import argparse\n import asyncio\n+import copy\n import multiprocessing\n import os\n+import re\n import signal\n import threading\n import time\n from typing import TYPE_CHECKING, Dict, Optional, Union\n \n from jina import __docker_host__, __windows__\n+from jina.excepts import BadImageNameError, DockerVersionError\n from jina.helper import random_name, slugify\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n@@ -37,8 +40,6 @@ def _docker_run(\n \n     import docker\n \n-    from jina.excepts import BadImageNameError, DockerVersionError\n-\n     docker_version = client.version().get('Version')\n     if not docker_version:\n         raise DockerVersionError('docker version can not be resolved')\n@@ -91,19 +92,6 @@ def _docker_run(\n         logger.error(f'can not find local image: {uses_img}')\n         img_not_found = True\n \n-    if args.pull_latest or img_not_found:\n-        logger.warning(\n-            f'pulling {uses_img}, this could take a while. if you encounter '\n-            f'timeout error due to pulling takes to long, then please set '\n-            f'\"timeout-ready\" to a larger value.'\n-        )\n-        try:\n-            client.images.pull(uses_img)\n-            img_not_found = False\n-        except docker.errors.NotFound:\n-            img_not_found = True\n-            logger.error(f'can not find remote image: {uses_img}')\n-\n     if img_not_found:\n         raise BadImageNameError(f'image: {uses_img} can not be found local & remote.')\n \n@@ -195,7 +183,9 @@ def run(\n     \"\"\"\n     import docker\n \n-    logger = JinaLogger(name, **vars(args))\n+    log_kwargs = copy.deepcopy(vars(args))\n+    log_kwargs['log_config'] = 'docker'\n+    logger = JinaLogger(name, **log_kwargs)\n \n     cancel = threading.Event()\n     fail_to_start = threading.Event()\n@@ -266,7 +256,8 @@ def run(\n                     and not cancel.is_set()\n                 ):\n                     await asyncio.sleep(0.01)\n-                logger.info(line.strip().decode())\n+                msg = line.decode().rstrip()  # type: str\n+                logger.debug(re.sub(r'\\u001b\\[.*?[@-~]', '', msg))\n \n         async def _run_async(container):\n             await asyncio.gather(\n\n---\n file path A: jina/parsers/orchestrate/base.py | file path B: jina/parsers/orchestrate/base.py\n\n@@ -41,7 +41,7 @@ def mixin_essential_parser(parser):\n     gp.add_argument(\n         '--log-config',\n         type=str,\n-        default=os.path.join(__resources_path__, 'logging.default.yml'),\n+        default='default',\n         help='The YAML config of the logger used in this object.',\n     )\n \n\n---\n file path A: jina/parsers/orchestrate/runtimes/container.py | file path B: jina/parsers/orchestrate/runtimes/container.py\n\n@@ -27,12 +27,7 @@ More details can be found in the Docker SDK docs:  https://docker-py.readthedocs\n \n ''',\n     )\n-    gp.add_argument(\n-        '--pull-latest',\n-        action='store_true',\n-        default=False,\n-        help='Pull the latest image before running',\n-    )\n+\n     gp.add_argument(\n         '--volumes',\n         type=str,\n\n---\n file path A: jina/resources/logging.default.yml | file path B: jina/resources/logging.default.yml\n\n@@ -18,4 +18,4 @@ configs:\n   RichHandler:\n     format: '[dim]{name:>15}@%(process)2d[/dim] %(message)s'\n     markup: true\n-    rich_tracebacks: True\n+    rich_tracebacks: true\n\\ No newline at end of file\n\n---\n file path A: jina/resources/logging.docker.yml | file path B: jina/resources/logging.docker.yml\n\n@@ -1,5 +1,5 @@\n handlers:\n-  - StreamHandler\n+  - RichHandler\n   - SysLogHandler\n level: INFO\n configs:\n@@ -8,10 +8,16 @@ configs:\n     output: 'jina-%(uptime)s.log'\n     formatter: JsonFormatter\n   StreamHandler:\n-    format: '\ud83d\udc33 %(message)s'\n+    format: '\ud83d\udc33 %(asctime)s: %(message)s'\n     formatter: PlainFormatter\n   SysLogHandler:\n     format: '{name:>15}@%(process)2d[%(levelname).1s]:%(message)s'\n     host: # when not given then record it locally\n     port: # when not given then record it locally\n     formatter: PlainFormatter\n+  RichHandler:\n+    format: '\ud83d\udc33 %(message)s'\n+    markup: true\n+    show_path: false\n+    show_level: false\n+    show_time: false\n\\ No newline at end of file\n\n\n###\n\n", "completion": "fix(logger): use docker log handler for container (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -1,7 +1,6 @@\n import copy\n import os\n from argparse import Namespace\n-from pathlib import Path\n from typing import Dict, List, Optional, Tuple, Union\n \n from jina import __default_executor__\n@@ -174,6 +173,24 @@ class DockerComposeConfig:\n                     ],\n                 }\n \n+                if cargs.gpus:\n+                    try:\n+                        count = int(cargs.gpus)\n+                    except ValueError:\n+                        count = cargs.gpus\n+\n+                    config['deploy'] = {\n+                        'reservations': {\n+                            'devices': [\n+                                {\n+                                    'driver': 'nvidia',\n+                                    'count': count,\n+                                    'capabilities': ['gpu'],\n+                                }\n+                            ]\n+                        }\n+                    }\n+\n                 if cargs.monitoring:\n                     config['expose'] = [cargs.port_monitoring]\n                     config['ports'] = [\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py\n\n@@ -420,3 +420,25 @@ def test_flow_to_docker_compose_sandbox(tmpdir):\n         gateway_args[gateway_args.index('--deployments-addresses') + 1]\n     )\n     assert deployment_addresses['executor0'][0].startswith('grpcs://')\n+\n+\n+@pytest.mark.parametrize('count', [1, 'all'])\n+def test_flow_to_docker_compose_gpus(tmpdir, count):\n+    flow = Flow().add(name='encoder', gpus=count)\n+    dump_path = os.path.join(str(tmpdir), 'test_flow_docker_compose_gpus.yml')\n+\n+    flow.to_docker_compose_yaml(\n+        output_path=dump_path,\n+    )\n+\n+    configuration = None\n+    with open(dump_path) as f:\n+        configuration = yaml.safe_load(f)\n+\n+    services = configuration['services']\n+    encoder_service = services['encoder']\n+    assert encoder_service['deploy'] == {\n+        'reservations': {\n+            'devices': [{'driver': 'nvidia', 'count': count, 'capabilities': ['gpu']}]\n+        }\n+    }\n\n\n###\n\n", "completion": "fix: fix add deploy resources when gpus detected (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -167,6 +167,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13271,3 +13272,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```06fc848c```](https://github.com/jina-ai/jina/commit/06fc848ca0a2d729c35db0768f2fe55ed02268c3)] __-__ __version__: the next version will be 3.3.14 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-15></a>\n+## Release Note (`3.3.15`)\n+\n+> Release time: 2022-04-27 15:42:23\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```a8f50dd0```](https://github.com/jina-ai/jina/commit/a8f50dd0ca5a161b8633bec530ce28204cd89d58)] __-__ change way of importing in cli (#4709) (*Joan Fontanals*)\n+ - [[```734edbc2```](https://github.com/jina-ai/jina/commit/734edbc20e74ab0a2e9e1d9a00ee1b73b86ee35a)] __-__ some UI improvement (#4705) (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```b1bff161```](https://github.com/jina-ai/jina/commit/b1bff161b022c02b6b6215130f46a8def807541e)] __-__ __version__: the next version will be 3.3.15 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -64,7 +64,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.15'\n+__version__ = '3.3.16'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.16"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -3,6 +3,7 @@ import shutil\n import subprocess\n import sys\n \n+import pkg_resources\n from packaging.version import Version, parse\n \n \n@@ -109,8 +110,6 @@ def _is_latest_version(package='jina', suppress_on_error=True):\n         import warnings\n         from urllib.request import Request, urlopen\n \n-        import pkg_resources\n-\n         cur_ver = Version(pkg_resources.get_distribution(package).version)\n \n         req = Request(\n@@ -136,7 +135,7 @@ def _is_latest_version(package='jina', suppress_on_error=True):\n \n \n def _is_latest_version_plugin(subcommand):\n-    from .known_plugins import plugin_info\n+    from cli.known_plugins import plugin_info\n \n     if subcommand in plugin_info:\n         _is_latest_version(package=plugin_info[subcommand]['pip-package'])\n\n\n###\n\n", "completion": "refactor: change way of importing in cli (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -166,6 +166,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13251,3 +13252,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```d1c44920```](https://github.com/jina-ai/jina/commit/d1c449206381a28765b966648c6db3d2e52e34f4)] __-__ __version__: the next version will be 3.3.13 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-14></a>\n+## Release Note (`3.3.14`)\n+\n+> Release time: 2022-04-27 10:50:31\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```9a579cd6```](https://github.com/jina-ai/jina/commit/9a579cd6f5e5df08c771fa38ee354e88968bab02)] __-__ use warnings and threading (#4703) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```06fc848c```](https://github.com/jina-ai/jina/commit/06fc848ca0a2d729c35db0768f2fe55ed02268c3)] __-__ __version__: the next version will be 3.3.14 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.14'\n+__version__ = '3.3.15'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.15"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -118,9 +118,8 @@ def _is_latest_version(package='jina', suppress_on_error=True):\n         ) as resp:  # 'with' is important to close the resource after use\n             latest_release_ver = _parse_latest_release_version(resp)\n             if cur_ver < latest_release_ver:\n-                from jina.logging.predefined import default_logger\n \n-                default_logger.warning(\n+                warnings.warn(\n                     f'You are using {package} version {cur_ver}, however version {latest_release_ver} is available. '\n                     f'You should consider upgrading via the \"pip install --upgrade {package}\" command.'\n                 )\n@@ -159,9 +158,9 @@ def _try_plugin_command():\n     subcommand = argv[1]\n     cmd = 'jina-' + subcommand\n     if _cmd_exists(cmd):\n-        import multiprocessing\n+        import threading\n \n-        multiprocessing.Process(\n+        threading.Thread(\n             target=_is_latest_version_plugin,\n             daemon=True,\n             args=(subcommand,),\n\n\n###\n\n", "completion": "fix: use warnings and threading (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -165,6 +165,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13231,3 +13232,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```524bedd5```](https://github.com/jina-ai/jina/commit/524bedd564b85bfd5dd6018514098bb2816b77e6)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```7649d5d9```](https://github.com/jina-ai/jina/commit/7649d5d9ff451154be08d319bb7450ce49eb9f49)] __-__ __version__: the next version will be 3.3.12 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-13></a>\n+## Release Note (`3.3.13`)\n+\n+> Release time: 2022-04-27 09:08:20\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ felix-wang,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```e56d787c```](https://github.com/jina-ai/jina/commit/e56d787cc0d7ce4314099ef33f7af58bf18f7328)] __-__ parsing requirements of executor (#4698) (*felix-wang*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```d1c44920```](https://github.com/jina-ai/jina/commit/d1c449206381a28765b966648c6db3d2e52e34f4)] __-__ __version__: the next version will be 3.3.13 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.13'\n+__version__ = '3.3.14'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.14"}
{"prompt": " file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -444,7 +444,7 @@ def is_requirements_installed(\n \n \n def _get_install_options(requirements_file: 'Path', excludes: Tuple[str] = ('jina',)):\n-    import pkg_resources\n+    from .requirements import parse_requirement\n \n     with requirements_file.open() as requirements:\n         install_options = []\n@@ -456,12 +456,10 @@ def _get_install_options(requirements_file: 'Path', excludes: Tuple[str] = ('jin\n             elif req.startswith('-'):\n                 install_options.extend(req.split(' '))\n             else:\n-                for req_spec in pkg_resources.parse_requirements(req):\n-                    if (\n-                        req_spec.project_name not in excludes\n-                        or len(req_spec.extras) > 0\n-                    ):\n-                        install_reqs.append(req)\n+                req_spec = parse_requirement(req)\n+\n+                if req_spec.project_name not in excludes or len(req_spec.extras) > 0:\n+                    install_reqs.append(req)\n \n     return install_reqs, install_options\n \n\n---\n file path A: None | file path B: jina/hubble/requirements.py\n\n@@ -0,0 +1,101 @@\n+\"\"\"Module for helper functions for parsing requirements file.\"\"\"\n+\n+import os\n+import re\n+from typing import Dict, Tuple, cast\n+\n+from pkg_resources import Requirement\n+\n+# Adopted from requirements-parser:\n+# https://github.com/madpah/requirements-parser\n+\n+VCS = [\n+    'git',\n+    'hg',\n+    'svn',\n+    'bzr',\n+]\n+\n+VCS_SCHEMES = [\n+    'git',\n+    'git+https',\n+    'git+ssh',\n+    'git+git',\n+    'hg+http',\n+    'hg+https',\n+    'hg+static-http',\n+    'hg+ssh',\n+    'svn',\n+    'svn+svn',\n+    'svn+http',\n+    'svn+https',\n+    'svn+ssh',\n+    'bzr+http',\n+    'bzr+https',\n+    'bzr+ssh',\n+    'bzr+sftp',\n+    'bzr+ftp',\n+    'bzr+lp',\n+]\n+\n+URI_REGEX = re.compile(\n+    r'^(?P<scheme>https?|file|ftps?)://(?P<path>[^#]+)' r'(#(?P<fragment>\\S+))?'\n+)\n+\n+VCS_SCHEMES_REGEX = r'|'.join([scheme.replace('+', r'\\+') for scheme in VCS_SCHEMES])\n+VCS_REGEX = re.compile(\n+    rf'^(?P<scheme>{VCS_SCHEMES_REGEX})://((?P<login>[^/@]+)@)?'\n+    r'(?P<path>[^#@]+)(@(?P<revision>[^#]+))?(#(?P<fragment>\\S+))?'\n+)\n+\n+\n+extras_require_search = re.compile(r'(?P<name>.+)\\[(?P<extras>[^\\]]+)\\]')\n+\n+\n+def _parse_fragment(fragment_string: str) -> Dict[str, str]:\n+    \"\"\"Takes a fragment string nd returns a dict of the components\n+\n+    :param fragment_string: a fragment string\n+    :return: a dict of components\n+    \"\"\"\n+    fragment_string = fragment_string.lstrip('#')\n+\n+    try:\n+        return dict(\n+            cast(Tuple[str, str], tuple(key_value_string.split('=')))\n+            for key_value_string in fragment_string.split('&')\n+        )\n+    except ValueError:\n+        raise ValueError(f'Invalid fragment string {fragment_string}')\n+\n+\n+def parse_requirement(line: str) -> 'Requirement':\n+    \"\"\"Parses a Requirement from a line of a requirement file.\n+\n+    :param line: a line of a requirement file\n+    :returns: a Requirement instance for the given line\n+    \"\"\"\n+\n+    vcs_match = VCS_REGEX.match(line)\n+    uri_match = URI_REGEX.match(line)\n+\n+    if vcs_match is not None:\n+        groups = vcs_match.groupdict()\n+        name = os.path.basename(groups['path']).split('.')[0]\n+        egg = None\n+        if groups['fragment']:\n+            fragment = _parse_fragment(groups['fragment'])\n+            egg = fragment.get('egg')\n+\n+        line = f'{egg or name} @ {line}'\n+    elif uri_match is not None:\n+        groups = uri_match.groupdict()\n+        name = os.path.basename(groups['path']).split('.')[0]\n+        egg = None\n+        if groups['fragment']:\n+            fragment = _parse_fragment(groups['fragment'])\n+            egg = fragment.get('egg')\n+\n+        line = f'{egg or name} @ {line}'\n+\n+    return Requirement.parse(line)\n\n---\n file path A: tests/unit/hubble/test_helper.py | file path B: tests/unit/hubble/test_helper.py\n\n@@ -1,8 +1,8 @@\n import urllib\n+from pathlib import Path\n \n import pytest\n \n-from pathlib import Path\n from jina.hubble import helper\n from jina.hubble.helper import disk_cache_offline\n from jina.parsers.hubble import set_hub_pull_parser\n@@ -83,6 +83,33 @@ def test_install_requirements():\n     )\n \n \n+@pytest.mark.parametrize(\n+    'requirement, name, specs, extras',\n+    [\n+        ('docarray', 'docarray', [], []),\n+        ('jina[dev]', 'jina', [], ['dev']),\n+        ('clip-server==0.3.0', 'clip-server', [('==', '0.3.0')], []),\n+        ('git+https://github.com/jina-ai/jina.git', 'jina', [], []),\n+        ('git+https://github.com/jina-ai/jina.git@v0.1', 'jina', [], []),\n+        (\n+            'git+https://github.com/jina-ai/jina.git@0.1#egg=jina[dev]',\n+            'jina',\n+            [],\n+            ['dev'],\n+        ),\n+        ('http://pypi.python.org/packages/source/p/jina/jina.tar.gz', 'jina', [], []),\n+    ],\n+)\n+def test_parse_requirements(requirement, name, specs, extras):\n+    from jina.hubble.requirements import parse_requirement\n+\n+    req_spec = parse_requirement(requirement)\n+\n+    assert req_spec.project_name == name\n+    assert list(req_spec.extras) == extras\n+    assert req_spec.specs == specs\n+\n+\n def test_is_requirement_installed(tmpfile):\n     with open(tmpfile, 'w') as f:\n         f.write('jina==0.0.1\\npydatest==0.0.1\\nfinefinetuner==0.0.1')\n\n\n###\n\n", "completion": "fix: parsing requirements of executor (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -164,6 +164,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13209,3 +13210,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```655213d0```](https://github.com/jina-ai/jina/commit/655213d07258490d4a12b29adcfb5dab0e21fe3d)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d9b5b718```](https://github.com/jina-ai/jina/commit/d9b5b7187d0e1e912cae69b1862aa7759b7c4ab5)] __-__ __version__: the next version will be 3.3.11 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-12></a>\n+## Release Note (`3.3.12`)\n+\n+> Release time: 2022-04-27 08:57:34\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Yanlong Wang,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```a3b71c72```](https://github.com/jina-ai/jina/commit/a3b71c7208b3cd48aa7bc978c3343a074947e3d9)] __-__ __parsers__: clearify flow args (#4701) (*Han Xiao*)\n+ - [[```babd97d0```](https://github.com/jina-ai/jina/commit/babd97d041063f5193b1478c35acc8579b78aae2)] __-__ __hubio__: improve error message from hubble (#4674) (*Yanlong Wang*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```524bedd5```](https://github.com/jina-ai/jina/commit/524bedd564b85bfd5dd6018514098bb2816b77e6)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```7649d5d9```](https://github.com/jina-ai/jina/commit/7649d5d9ff451154be08d319bb7450ce49eb9f49)] __-__ __version__: the next version will be 3.3.12 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.12'\n+__version__ = '3.3.13'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.13"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -106,11 +106,6 @@ ac_table = {\n             '--quiet',\n             '--quiet-error',\n             '--workspace-id',\n-            '--extra-search-paths',\n-            '--timeout-ctrl',\n-            '--k8s-namespace',\n-            '--polling',\n-            '--expose-graphql-endpoint',\n             '--uses',\n             '--env',\n             '--inspect',\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -199,13 +199,13 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         :param monitoring: If set, spawn an http server with a prometheus endpoint to expose metrics\n         :param name: The name of this object.\n \n-          This will be used in the following places:\n-          - how you refer to this object in Python/YAML/CLI\n-          - visualization\n-          - log message header\n-          - ...\n+              This will be used in the following places:\n+              - how you refer to this object in Python/YAML/CLI\n+              - visualization\n+              - log message header\n+              - ...\n \n-          When not given, then the default naming strategy will apply.\n+              When not given, then the default naming strategy will apply.\n         :param native: If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime.\n         :param no_crud_endpoints: If set, /index, /search, /update, /delete endpoints are removed from HTTP interface.\n \n@@ -278,14 +278,11 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         self,\n         *,\n         env: Optional[dict] = None,\n-        expose_graphql_endpoint: Optional[bool] = False,\n         inspect: Optional[str] = 'COLLECT',\n         log_config: Optional[str] = None,\n         name: Optional[str] = None,\n-        polling: Optional[str] = 'ANY',\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n-        timeout_ctrl: Optional[int] = 60,\n         uses: Optional[str] = None,\n         workspace: Optional[str] = None,\n         **kwargs,\n@@ -293,31 +290,21 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         \"\"\"Create a Flow. Flow is how Jina streamlines and scales Executors. This overloaded method provides arguments from `jina flow` CLI.\n \n         :param env: The map of environment variables that are available inside runtime\n-        :param expose_graphql_endpoint: If set, /graphql endpoint is added to HTTP interface.\n         :param inspect: The strategy on those inspect deployments in the flow.\n \n               If `REMOVE` is given then all inspect deployments are removed when building the flow.\n         :param log_config: The YAML config of the logger used in this object.\n         :param name: The name of this object.\n \n-          This will be used in the following places:\n-          - how you refer to this object in Python/YAML/CLI\n-          - visualization\n-          - log message header\n-          - ...\n+              This will be used in the following places:\n+              - how you refer to this object in Python/YAML/CLI\n+              - visualization\n+              - log message header\n+              - ...\n \n-          When not given, then the default naming strategy will apply.\n-        :param polling: The polling strategy of the Deployment and its endpoints (when `shards>1`).\n-              Can be defined for all endpoints of a Deployment or by endpoint.\n-              Define per Deployment:\n-              - ANY: only one (whoever is idle) Pod polls the message\n-              - ALL: all Pods poll the message (like a broadcast)\n-              Define per Endpoint:\n-              JSON dict, {endpoint: PollingType}\n-              {'/custom': 'ALL', '/search': 'ANY', '*': 'ANY'}\n+              When not given, then the default naming strategy will apply.\n         :param quiet: If set, then no log will be emitted from this object.\n         :param quiet_error: If set, then exception stack information will not be added to the log\n-        :param timeout_ctrl: The timeout in milliseconds of the control request, -1 for waiting forever\n         :param uses: The YAML file represents a flow\n         :param workspace: The working directory for any IO operations in this object. If not set, then derive from its parent `workspace`.\n \n@@ -342,17 +329,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n             GATEWAY_NAME\n         ]  #: default first deployment is gateway, will add when build()\n         self._update_args(args, **kwargs)\n-        if (\n-            self.protocol == GatewayProtocolType.HTTP\n-            and self.args.expose_graphql_endpoint\n-            and not docarray_graphql_compatible()\n-        ):\n-            self.args.expose_graphql_endpoint = False\n-            warnings.warn(\n-                'DocArray version is incompatible with GraphQL features. '\n-                'Automatically setting expose_graphql_endpoint=False. '\n-                f'To use GraphQL features, install docarray>={GRAPHQL_MIN_DOCARRAY_VERSION}'\n-            )\n \n         if isinstance(self.args, argparse.Namespace):\n             self.logger = JinaLogger(\n@@ -476,9 +452,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n             kwargs.get('port', None) is None and kwargs.get('port_expose', None) is None\n         )\n         args.noblock_on_start = True\n-        args.expose_graphql_endpoint = (\n-            self.args.expose_graphql_endpoint\n-        )  # also used in Flow, thus not in kwargs\n         args.graph_description = json.dumps(graph_description)\n         args.graph_conditions = json.dumps(graph_conditions)\n         args.deployments_addresses = json.dumps(deployments_addresses)\n@@ -727,13 +700,13 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         :param monitoring: If set, spawn an http server with a prometheus endpoint to expose metrics\n         :param name: The name of this object.\n \n-          This will be used in the following places:\n-          - how you refer to this object in Python/YAML/CLI\n-          - visualization\n-          - log message header\n-          - ...\n+              This will be used in the following places:\n+              - how you refer to this object in Python/YAML/CLI\n+              - visualization\n+              - log message header\n+              - ...\n \n-          When not given, then the default naming strategy will apply.\n+              When not given, then the default naming strategy will apply.\n         :param native: If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime.\n         :param output_array_type: The type of array `tensor` and `embedding` will be serialized to.\n \n@@ -884,7 +857,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n             args.workspace = self.workspace\n \n         args.noblock_on_start = True\n-        args.extra_search_paths = self.args.extra_search_paths\n \n         port = kwargs.get('port', None)\n         if not port:\n@@ -1625,7 +1597,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                 'Redoc',\n                 f'[underline]http://localhost:{self.port}/redoc[/underline]',\n             )\n-            if self.args.expose_graphql_endpoint:\n+            if self.gateway_args.expose_graphql_endpoint:\n                 address_table.add_row(\n                     '\ud83d\udcac',\n                     'GraphQL UI',\n\n---\n file path A: jina/parsers/flow.py | file path B: jina/parsers/flow.py\n\n@@ -1,7 +1,8 @@\n \"\"\"Argparser module for Flow\"\"\"\n from jina.parsers.base import set_base_parser\n+from jina.parsers.helper import KVAppendAction, add_arg_group\n+from jina.parsers.orchestrate.base import mixin_essential_parser\n from jina.parsers.orchestrate.runtimes.remote import mixin_graphql_parser\n-from jina.parsers.helper import add_arg_group, KVAppendAction\n \n \n def mixin_flow_features_parser(parser):\n@@ -46,8 +47,7 @@ def set_flow_parser(parser=None):\n     if not parser:\n         parser = set_base_parser()\n \n-    mixin_base_ppr_parser(parser)\n-    mixin_graphql_parser(parser)\n+    mixin_essential_parser(parser)\n     mixin_flow_features_parser(parser)\n \n     return parser\n\n---\n file path A: jina/parsers/orchestrate/base.py | file path B: jina/parsers/orchestrate/base.py\n\n@@ -2,31 +2,30 @@\n import argparse\n import os\n \n-from jina.parsers.helper import add_arg_group, _SHOW_ALL_ARGS\n from jina.enums import PollingType\n from jina.helper import random_identity\n+from jina.parsers.helper import _SHOW_ALL_ARGS, add_arg_group\n \n \n-def mixin_base_ppr_parser(parser):\n-    \"\"\"Mixing in arguments required by pod/deployment/runtime module into the given parser.\n+def mixin_essential_parser(parser):\n+    \"\"\"Mixing in arguments required by every module into the given parser.\n     :param parser: the parser instance to which we add arguments\n     \"\"\"\n-\n     gp = add_arg_group(parser, title='Essential')\n     gp.add_argument(\n         '--name',\n         type=str,\n         help='''\n-The name of this object.\n+    The name of this object.\n \n-This will be used in the following places:\n-- how you refer to this object in Python/YAML/CLI\n-- visualization\n-- log message header\n-- ...\n+    This will be used in the following places:\n+    - how you refer to this object in Python/YAML/CLI\n+    - visualization\n+    - log message header\n+    - ...\n \n-When not given, then the default naming strategy will apply.\n-                    ''',\n+    When not given, then the default naming strategy will apply.\n+                        ''',\n     )\n \n     gp.add_argument(\n@@ -71,7 +70,17 @@ When not given, then the default naming strategy will apply.\n         else argparse.SUPPRESS,\n     )\n \n-    parser.add_argument(\n+\n+def mixin_base_ppr_parser(parser):\n+    \"\"\"Mixing in arguments required by pod/deployment/runtime module into the given parser.\n+    :param parser: the parser instance to which we add arguments\n+    \"\"\"\n+\n+    mixin_essential_parser(parser)\n+\n+    gp = add_arg_group(parser, title='Base Deployment')\n+\n+    gp.add_argument(\n         '--extra-search-paths',\n         type=str,\n         default=[],\n\n\n###\n\n", "completion": "fix(parsers): clearify flow args (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/helper.py | file path B: jina/hubble/helper.py\n\n@@ -11,14 +11,15 @@ import tarfile\n import urllib\n import warnings\n import zipfile\n+from contextlib import nullcontext\n from functools import lru_cache, wraps\n from pathlib import Path\n-from typing import Tuple, Optional, Dict\n-from urllib.parse import urlparse, urljoin\n+from typing import Dict, Optional, Tuple\n+from urllib.parse import urljoin, urlparse\n from urllib.request import Request, urlopen\n-from contextlib import nullcontext\n \n from jina import __resources_path__\n+from jina.enums import BetterEnum\n from jina.importer import ImportExtensions\n from jina.logging.predefined import default_logger\n \n@@ -421,12 +422,12 @@ def is_requirements_installed(\n     :param show_warning: if to show a warning when a dependency is not satisfied\n     :return: True or False if not satisfied\n     \"\"\"\n+    import pkg_resources\n     from pkg_resources import (\n         DistributionNotFound,\n-        VersionConflict,\n         RequirementParseError,\n+        VersionConflict,\n     )\n-    import pkg_resources\n \n     install_reqs, install_options = _get_install_options(requirements_file)\n \n@@ -488,3 +489,103 @@ def install_requirements(requirements_file: 'Path', timeout: int = 1000):\n         + install_reqs\n         + install_options\n     )\n+\n+\n+class HubbleReturnStatus(BetterEnum):\n+    \"\"\"\n+    Type of hubble return status enum\n+    \"\"\"\n+\n+    UNKNOWN_ERROR = -1\n+    OK = 20000\n+    PARAM_VALIDATION_ERROR = 40001\n+    SQL_CREATION_ERROR = 40002\n+    DATA_STREAM_BROKEN_ERROR = 40003\n+    UNEXPECTED_MIME_TYPE_ERROR = 40004\n+    SSO_LOGIN_REQUIRED = 40101\n+    AUTHENTICATION_FAILED = 40102\n+    AUTHENTICATION_REQUIRED = 40103\n+    OPERATION_NOT_ALLOWED = 40301\n+    INTERNAL_RESOURCE_NOT_FOUND = 40401\n+    RPC_METHOD_NOT_FOUND = 40402\n+    REQUESTED_ENTITY_NOT_FOUND = 40403\n+    INTERNAL_RESOURCE_METHOD_NOT_ALLOWED = 40501\n+    INCOMPATIBLE_METHOD_ERROR = 40502\n+    INTERNAL_RESOURCE_ID_CONFLICT = 40901\n+    RESOURCE_POLICY_DENY = 40902\n+    TOO_LARGE_FILE = 41301\n+    INTERNAL_DATA_CORRUPTION = 42201\n+    IDENTIFIER_NAMESPACE_OCCUPIED = 42202\n+    SUBMITTED_DATA_MALFORMED = 42203\n+    EXTERNAL_SERVICE_FAILURE = 42204\n+    DOWNSTREAM_SERVICE_FAILURE = 42205\n+    SERVER_INTERNAL_ERROR = 50001\n+    DOWNSTREAM_SERVICE_ERROR = 50002\n+    SERVER_SUBPROCESS_ERROR = 50003\n+    SANDBOX_BUILD_NOT_FOUND = 50004\n+    NOT_IMPLEMENTED_ERROR = 50005\n+    RESPONSE_STREAM_CLOSED = 50006\n+\n+\n+class NormalizerErrorCode(BetterEnum):\n+    \"\"\"\n+    Type of executor-normalizer error code enum\n+    \"\"\"\n+\n+    ExecutorNotFound = 4000\n+    ExecutorExists = 4001\n+    IllegalExecutor = 4002\n+    BrokenDependency = 4003\n+\n+    Others = 5000\n+\n+\n+def get_hubble_error_message(hubble_structured_error: dict) -> Tuple[str, str]:\n+    \"\"\"Override some of the hubble error messages to provide better user experience\n+    :param hubble_structured_error: the hubble structured error response\n+    :returns: Tuple of overridden_msg and original_msg\n+    \"\"\"\n+    msg = hubble_structured_error.get(\n+        'readableMessage', ''\n+    ) or hubble_structured_error.get('message', '')\n+    status = hubble_structured_error.get('status', None)\n+    original_msg = msg\n+\n+    if not status:\n+        return (msg, msg)\n+\n+    if (\n+        status == HubbleReturnStatus.SERVER_SUBPROCESS_ERROR\n+        and hubble_structured_error.get('cmd', '') == 'docker'\n+    ):\n+\n+        msg = '''\n+Failed on building Docker image. Potential solutions:\n+  - If you haven't provide a Dockerfile in the executor bundle, you may want to provide one,\n+    as the auto-generated one on the cloud did not work.\n+  - If you have provided a Dockerfile, you may want to check the validity of this Dockerfile.\n+'''\n+    elif (\n+        status == HubbleReturnStatus.DOWNSTREAM_SERVICE_FAILURE\n+        and hubble_structured_error.get('service', '') == 'normalizer'\n+    ):\n+\n+        normalizer_error = hubble_structured_error.get('err', '')\n+        if (\n+            isinstance(normalizer_error, dict)\n+            and normalizer_error.get('code', None)\n+            == NormalizerErrorCode.ExecutorNotFound\n+        ):\n+            msg = '''\n+We can not discover any Executor in your uploaded bundle. This is often due to one of the following errors:\n+  - The bundle did not contain any valid executor.\n+  - The config.yml's `jtype` is mismatched with the actual Executor class name.\n+    For more information about the expected bundle structure, please refer to the documentation.\n+    https://docs.jina.ai/fundamentals/executor/repository-structure/\n+'''\n+        msg += '''\n+For more detailed information, you can try the `executor-normalizer` locally to see the root cause.\n+    https://github.com/jina-ai/executor-normalizer\n+'''\n+\n+    return (msg, original_msg)\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -24,6 +24,7 @@ from jina.hubble.helper import (\n     download_with_resume,\n     get_cache_db,\n     get_download_cache_dir,\n+    get_hubble_error_message,\n     get_hubble_url_v2,\n     parse_hub_uri,\n     upload_file,\n@@ -413,23 +414,21 @@ metas:\n                     payload = stream_msg.get('payload', '')\n                     if t == 'error':\n                         msg = stream_msg.get('message')\n-                        if not msg and payload and isinstance(payload, dict):\n-                            msg = payload.get('readableMessage') or payload.get(\n-                                'message'\n+                        hubble_err = payload\n+                        overridden_msg = ''\n+                        detail_msg = ''\n+                        if isinstance(hubble_err, dict):\n+                            (overridden_msg, detail_msg) = get_hubble_error_message(\n+                                hubble_err\n                             )\n+                            if not msg:\n+                                msg = detail_msg\n \n-                        if 'Process(docker) exited on non-zero code' in msg:\n-                            self.logger.error(\n-                                '''\n-                            Failed on building Docker image. Potential solutions:\n-                            - If you haven't provide a Dockerfile in the executor bundle, you may want to provide one,\n-                              as the auto-generated one on the cloud did not work.\n-                            - If you have provided a Dockerfile, you may want to check the validity of this Dockerfile.\n-                            '''\n-                            )\n+                        if overridden_msg and overridden_msg != detail_msg:\n+                            self.logger.warning(overridden_msg)\n \n                         raise Exception(\n-                            f'{msg or \"Unknown Error\"} session_id: {session_id}'\n+                            f'{overridden_msg or msg or \"Unknown Error\"} session_id: {session_id}'\n                         )\n                     if t == 'progress' and subject == 'buildWorkspace':\n                         legacy_message = stream_msg.get('legacyMessage', {})\n@@ -465,8 +464,7 @@ metas:\n \n             except Exception as e:  # IO related errors\n                 self.logger.error(\n-                    f'''Please report this session_id: {colored(req_header[\"jinameta-session-id\"], color=\"yellow\", attrs=\"bold\")} to https://github.com/jina-ai/jina/issues'\n-                {e!r}'''\n+                    f'''Please report this session_id: {colored(req_header[\"jinameta-session-id\"], color=\"yellow\", attrs=\"bold\")} to https://github.com/jina-ai/jina/issues'''\n                 )\n                 raise e\n \n\n\n###\n\n", "completion": "fix(hubio): improve error message from hubble (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -163,6 +163,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13182,3 +13183,28 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```a8329d66```](https://github.com/jina-ai/jina/commit/a8329d66a7aabf67efc7e488b6c94e3317d488e2)] __-__ __version__: the next version will be 3.3.10 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-11></a>\n+## Release Note (`3.3.11`)\n+\n+> Release time: 2022-04-26 14:47:52\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Deepankar Mahapatro,  Tobias Jacobowitz,  Jina Dev Bot,  Joan Fontanals,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```25b8df17```](https://github.com/jina-ai/jina/commit/25b8df17389ac3674cfc10767d5e348974422ec1)] __-__ graceful shutdown (#4682) (*Tobias Jacobowitz*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```e23ff11a```](https://github.com/jina-ai/jina/commit/e23ff11a2f5826af4a4bb5ff40af4bebd3acf3a1)] __-__ pod does not start runtime process as daemon (#4692) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```05222069```](https://github.com/jina-ai/jina/commit/0522206909c3b743684c1aecf490e47564b860d9)] __-__ disable console color with envvar (#4697) (*Deepankar Mahapatro*)\n+ - [[```655213d0```](https://github.com/jina-ai/jina/commit/655213d07258490d4a12b29adcfb5dab0e21fe3d)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d9b5b718```](https://github.com/jina-ai/jina/commit/d9b5b7187d0e1e912cae69b1862aa7759b7c4ab5)] __-__ __version__: the next version will be 3.3.11 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.11'\n+__version__ = '3.3.12'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.12"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -56,7 +56,8 @@ def _get_run_args(print_args: bool = True):\n \n                 param_str.add_row(sign, param, value, style=style)\n \n-            print(f'\\n{logo_str}\\n')\n+            if 'JINA_LOG_NO_COLOR' not in os.environ:\n+                print(f'\\n{logo_str}\\n')\n             console.print(f'\u25b6\ufe0f  {\" \".join(sys.argv)}', param_str)\n         return args\n     else:\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1529,6 +1529,7 @@ def get_rich_console():\n     \"\"\"\n     return Console(\n         force_terminal=True,\n+        color_system=None if 'JINA_LOG_NO_COLOR' in os.environ else 'auto',\n     )  # It forces render in any terminal, especially in PyCharm\n \n \n\n\n###\n\n", "completion": "chore: disable console color with envvar (#<issue-num>)"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -636,14 +636,23 @@ class GrpcConnectionPool:\n                         timeout=timeout,\n                     )\n                 except AioRpcError as e:\n-                    if e.code() != grpc.StatusCode.UNAVAILABLE:\n+                    # connection failures and cancelled requests should be retried\n+                    # all other cases should not be retried and will be raised immediately\n+                    # connection failures have the code grpc.StatusCode.UNAVAILABLE\n+                    # cancelled requests have the code grpc.StatusCode.CANCELLED\n+                    # requests usually gets cancelled when the server shuts down\n+                    # retries for cancelled requests will hit another replica in K8s\n+                    if (\n+                        e.code() != grpc.StatusCode.UNAVAILABLE\n+                        and e.code() != grpc.StatusCode.CANCELLED\n+                    ):\n                         raise\n                     elif e.code() == grpc.StatusCode.UNAVAILABLE and i == 2:\n                         self._logger.debug(f'GRPC call failed, retries exhausted')\n                         raise\n                     else:\n                         self._logger.debug(\n-                            f'GRPC call failed with StatusCode.UNAVAILABLE, retry attempt {i+1}/3'\n+                            f'GRPC call failed with code {e.code()}, retry attempt {i+1}/3'\n                         )\n \n         return asyncio.create_task(task_wrapper(requests, connection, endpoint))\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -100,8 +100,8 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         self.logger.debug('Cancel WorkerRuntime')\n \n         # 0.5 gives the runtime some time to complete outstanding responses\n-        # this should be handled better, 0.5 is a rather random number\n-        await self._grpc_server.stop(0.5)\n+        # this should be handled better, 1.0 is a rather random number\n+        await self._grpc_server.stop(1.0)\n         self.logger.debug('Stopped GRPC Server')\n \n     async def async_teardown(self):\n\n---\n file path A: tests/k8s/test_graceful_request_handling.py | file path B: tests/k8s/test_graceful_request_handling.py\n\n@@ -130,10 +130,6 @@ def send_requests(\n \n \n @pytest.mark.asyncio\n-@pytest.mark.skipif(\n-    'GITHUB_WORKFLOW' in os.environ,\n-    reason='this actually does not work, there are messages lost when shutting down k8s pods',\n-)\n @pytest.mark.parametrize(\n     'docker_images', [['slow-process-executor', 'jinaai/jina']], indirect=True\n )\n@@ -238,10 +234,6 @@ async def test_no_message_lost_during_scaling(logger, docker_images, tmpdir):\n \n \n @pytest.mark.asyncio\n-@pytest.mark.skipif(\n-    'GITHUB_WORKFLOW' in os.environ,\n-    reason='this actually does not work, there are messages lost when shutting down k8s pods',\n-)\n @pytest.mark.parametrize(\n     'docker_images', [['slow-process-executor', 'jinaai/jina']], indirect=True\n )\n\n\n###\n\n", "completion": "feat: graceful shutdown (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/pods/__init__.py | file path B: jina/orchestrate/pods/__init__.py\n\n@@ -316,7 +316,7 @@ class Pod(BasePod):\n                 'jaml_classes': JAML.registered_classes(),\n             },\n             name=self.name,\n-            daemon=True,\n+            daemon=False,\n         )\n \n     def start(self):\n\n---\n file path A: tests/integration/runtimes/test_runtimes.py | file path B: tests/integration/runtimes/test_runtimes.py\n\n@@ -450,9 +450,6 @@ async def test_runtimes_with_executor(port_generator):\n     for i in range(10):\n         assert doc_texts.count(f'pod0/shards/{i}') == 1\n \n-    for process in runtime_processes:\n-        assert process.exitcode == 0\n-\n \n @pytest.mark.asyncio\n async def test_runtimes_gateway_worker_direct_connection(port_generator):\n\n\n###\n\n", "completion": "fix: pod does not start runtime process as daemon (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -162,6 +162,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13158,3 +13159,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```278a6992```](https://github.com/jina-ai/jina/commit/278a6992379764f273c614dc5b37bde3857f3075)] __-__ __version__: the next version will be 3.3.9 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-10></a>\n+## Release Note (`3.3.10`)\n+\n+> Release time: 2022-04-25 21:00:48\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```5af4efe3```](https://github.com/jina-ai/jina/commit/5af4efe38b64248629f531b7837aa3cbad64d7a7)] __-__ fix deadlock on import (#4693) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```a8329d66```](https://github.com/jina-ai/jina/commit/a8329d66a7aabf67efc7e488b6c94e3317d488e2)] __-__ __version__: the next version will be 3.3.10 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.10'\n+__version__ = '3.3.11'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.11"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -158,9 +158,9 @@ def _try_plugin_command():\n     subcommand = argv[1]\n     cmd = 'jina-' + subcommand\n     if _cmd_exists(cmd):\n-        import threading\n+        import multiprocessing\n \n-        threading.Thread(\n+        multiprocessing.Process(\n             target=_is_latest_version_plugin,\n             daemon=True,\n             args=(subcommand,),\n\n\n###\n\n", "completion": "fix: fix deadlock on import (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -161,6 +161,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13138,3 +13139,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```e9a4d79c```](https://github.com/jina-ai/jina/commit/e9a4d79c5f4bd95a582cdb1a41e47fb4689cf836)] __-__ __version__: the next version will be 3.3.8 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-9></a>\n+## Release Note (`3.3.9`)\n+\n+> Release time: 2022-04-25 19:59:19\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```162a59b6```](https://github.com/jina-ai/jina/commit/162a59b6057b5ff91c3f0ca871ed87575a3f76ee)] __-__ fix target executor in http (#4690) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```278a6992```](https://github.com/jina-ai/jina/commit/278a6992379764f273c614dc5b37bde3857f3075)] __-__ __version__: the next version will be 3.3.9 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.9'\n+__version__ = '3.3.10'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.10"}
{"prompt": " file path A: jina/clients/base/helper.py | file path B: jina/clients/base/helper.py\n\n@@ -77,7 +77,8 @@ class HTTPClientlet(AioHttpClientlet):\n         \"\"\"\n         req_dict = request.to_dict()\n         req_dict['exec_endpoint'] = req_dict['header']['exec_endpoint']\n-\n+        if 'target_executor' in req_dict['header']:\n+            req_dict['target_executor'] = req_dict['header']['target_executor']\n         return await self.session.post(url=self.url, json=req_dict).__aenter__()\n \n     async def recv_message(self):\n\n---\n file path A: None | file path B: tests/integration/issues/github_4683/test_target_executor_http.py\n\n@@ -0,0 +1,24 @@\n+import pytest\n+\n+from docarray import Document\n+from jina import Executor, Flow, requests\n+\n+\n+@pytest.mark.parametrize('protocol', ['http', 'websocket'])\n+def test_good_entrypoint(protocol):\n+    class E1(Executor):\n+        @requests\n+        def foo(self, docs, **kwargs):\n+            docs.texts = ['hello']\n+\n+    class E2(Executor):\n+        @requests\n+        def foo(self, docs, **kwargs):\n+            docs.texts = ['goodbye']\n+\n+    f = Flow(protocol=protocol).add(name='m1', uses=E1).add(name='m2', uses=E2)\n+\n+    with f:\n+        returned_texts = f.post('/', Document(), target_executor='m1').texts\n+\n+    assert returned_texts == ['hello']\n\n\n###\n\n", "completion": "fix: fix target executor in http (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -160,6 +160,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13118,3 +13119,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```b086f0d9```](https://github.com/jina-ai/jina/commit/b086f0d9016cef3c925a832c33c44e779351d879)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```e7bd24ab```](https://github.com/jina-ai/jina/commit/e7bd24abce90cf1ea3973f542b25b4c632cbc2fc)] __-__ __version__: the next version will be 3.3.7 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-8></a>\n+## Release Note (`3.3.8`)\n+\n+> Release time: 2022-04-25 17:42:17\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```81a0b8d5```](https://github.com/jina-ai/jina/commit/81a0b8d59abddeabf352379bef653445d7f320de)] __-__ fix configuration of addresses in docker compose (#4684) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```e9a4d79c```](https://github.com/jina-ai/jina/commit/e9a4d79c5f4bd95a582cdb1a41e47fb4689cf836)] __-__ __version__: the next version will be 3.3.8 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.8'\n+__version__ = '3.3.9'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.9"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -541,16 +541,26 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                 continue\n \n             if v.external:\n-                deployment_docker_compose_address = f'{v.protocol}://{v.host}:{v.port}'\n+                deployment_docker_compose_address = [\n+                    f'{v.protocol}://{v.host}:{v.port}'\n+                ]\n             elif v.head_args:\n-                deployment_docker_compose_address = (\n+                deployment_docker_compose_address = [\n                     f'{to_compatible_name(v.head_args.name)}:{port}'\n-                )\n+                ]\n             else:\n-                deployment_docker_compose_address = (\n-                    f'{to_compatible_name(v.name)}:{port}'\n-                )\n-            graph_dict[node] = [deployment_docker_compose_address]\n+                if v.args.replicas == 1:\n+                    deployment_docker_compose_address = [\n+                        f'{to_compatible_name(v.name)}:{port}'\n+                    ]\n+                else:\n+                    deployment_docker_compose_address = []\n+                    for rep_id in range(v.args.replicas):\n+                        node_name = f'{v.name}/rep-{rep_id}'\n+                        deployment_docker_compose_address.append(\n+                            f'{to_compatible_name(node_name)}:{port}'\n+                        )\n+            graph_dict[node] = deployment_docker_compose_address\n \n         return graph_dict\n \n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -282,10 +282,10 @@ class GrpcConnectionPool:\n             self, deployment: str, head: bool, entity_id: Optional[int] = None\n         ) -> ReplicaList:\n             if deployment in self._deployments:\n-                type = 'heads' if head else 'shards'\n+                type_ = 'heads' if head else 'shards'\n                 if entity_id is None and head:\n                     entity_id = 0\n-                return self._get_connection_list(deployment, type, entity_id)\n+                return self._get_connection_list(deployment, type_, entity_id)\n             else:\n                 self._logger.debug(\n                     f'Unknown deployment {deployment}, no replicas available'\n@@ -312,27 +312,27 @@ class GrpcConnectionPool:\n             self._deployments.clear()\n \n         def _get_connection_list(\n-            self, deployment: str, type: str, entity_id: Optional[int] = None\n+            self, deployment: str, type_: str, entity_id: Optional[int] = None\n         ) -> ReplicaList:\n             try:\n-                if entity_id is None and len(self._deployments[deployment][type]) > 0:\n+                if entity_id is None and len(self._deployments[deployment][type_]) > 0:\n                     # select a random entity\n                     self._access_count[deployment] += 1\n-                    return self._deployments[deployment][type][\n+                    return self._deployments[deployment][type_][\n                         self._access_count[deployment]\n-                        % len(self._deployments[deployment][type])\n+                        % len(self._deployments[deployment][type_])\n                     ]\n                 else:\n-                    return self._deployments[deployment][type][entity_id]\n+                    return self._deployments[deployment][type_][entity_id]\n             except KeyError:\n                 if (\n                     entity_id is None\n                     and deployment in self._deployments\n-                    and len(self._deployments[deployment][type])\n+                    and len(self._deployments[deployment][type_])\n                 ):\n                     # This can happen as a race condition when removing connections while accessing it\n                     # In this case we don't care for the concrete entity, so retry with the first one\n-                    return self._get_connection_list(deployment, type, 0)\n+                    return self._get_connection_list(deployment, type_, 0)\n                 self._logger.debug(\n                     f'Did not find a connection for deployment {deployment}, type {type} and entity_id {entity_id}. There are {len(self._deployments[deployment][type]) if deployment in self._deployments else 0} available connections for this deployment and type. '\n                 )\n\n---\n file path A: tests/docker_compose/test_docker_compose.py | file path B: tests/docker_compose/test_docker_compose.py\n\n@@ -79,7 +79,6 @@ async def run_test(flow, endpoint, num_docs=10, request_size=10):\n     client_kwargs = dict(\n         host='localhost',\n         port=flow.port,\n-        return_responses=True,\n         asyncio=True,\n     )\n     client_kwargs.update(flow._common_kwargs)\n@@ -91,6 +90,7 @@ async def run_test(flow, endpoint, num_docs=10, request_size=10):\n         endpoint,\n         inputs=[Document() for _ in range(num_docs)],\n         request_size=request_size,\n+        return_responses=True,\n     ):\n         responses.append(resp)\n \n@@ -131,6 +131,7 @@ def flow_with_needs(docker_images):\n         .add(\n             name='segmenter',\n             uses=f'docker://{docker_images[0]}',\n+            replicas=2,\n         )\n         .add(\n             name='textencoder',\n@@ -167,8 +168,13 @@ async def test_flow_with_needs(logger, flow_with_needs, tmpdir, docker_images):\n             flow=flow_with_needs,\n             endpoint='/debug',\n         )\n-        expected_traversed_executors = {\n-            'segmenter',\n+        expected_traversed_executors_0 = {\n+            'segmenter/rep-0',\n+            'imageencoder',\n+            'textencoder',\n+        }\n+        expected_traversed_executors_1 = {\n+            'segmenter/rep-1',\n             'imageencoder',\n             'textencoder',\n         }\n@@ -176,7 +182,13 @@ async def test_flow_with_needs(logger, flow_with_needs, tmpdir, docker_images):\n         docs = resp[0].docs\n         assert len(docs) == 10\n         for doc in docs:\n-            assert set(doc.tags['traversed-executors']) == expected_traversed_executors\n+            path_1 = (\n+                set(doc.tags['traversed-executors']) == expected_traversed_executors_0\n+            )\n+            path_2 = (\n+                set(doc.tags['traversed-executors']) == expected_traversed_executors_1\n+            )\n+            assert path_1 or path_2\n \n \n @pytest.mark.asyncio\n\n\n###\n\n", "completion": "fix: fix configuration of addresses in docker compose (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -159,6 +159,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13082,3 +13083,38 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```0c8d6371```](https://github.com/jina-ai/jina/commit/0c8d6371cc64e51f5bf1a2af66120b8d99bfca26)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d1add5a6```](https://github.com/jina-ai/jina/commit/d1add5a624e1cc474a77d4ae70cf1c82c68e5005)] __-__ __version__: the next version will be 3.3.6 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-7></a>\n+## Release Note (`3.3.7`)\n+\n+> Release time: 2022-04-25 14:16:33\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Tobias Jacobowitz,  Johannes Messner,  joschkabraun,  Joan Fontanals,  Jina Dev Bot,  cristian,  felix-wang,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```6ac879e4```](https://github.com/jina-ai/jina/commit/6ac879e4e59fffa014111abd815971dde63f900c)] __-__ add linkerd details in contributing (#4686) (*samsja*)\n+ - [[```59b76269```](https://github.com/jina-ai/jina/commit/59b7626903b5e9a303eba0817191c8d6ec5b6e77)] __-__ add timeout_send (#4660) (*Tobias Jacobowitz*)\n+ - [[```4c4fc9e2```](https://github.com/jina-ai/jina/commit/4c4fc9e2c1fa23a9bc39ab79906e7cb40dffc9d8)] __-__ __monitoring__: count the number of processed documents (#4672) (*samsja*)\n+ - [[```b3b139be```](https://github.com/jina-ai/jina/commit/b3b139beb3df8a50ebaae1b6eee25eb9b0407d30)] __-__ pass environment to head and gateway (#4646) (*Joan Fontanals*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```9b8deaa2```](https://github.com/jina-ai/jina/commit/9b8deaa2a098be35bebaaa9bb523aed51c64bc4d)] __-__ __dependency__: prometheus client should be a core dependency (#4689) (*samsja*)\n+ - [[```96a83469```](https://github.com/jina-ai/jina/commit/96a8346973ac732d5e74cf5b3ec894a0c5944d43)] __-__ better error messages when flow fails to start (#4652) (*Johannes Messner*)\n+ - [[```4168d44d```](https://github.com/jina-ai/jina/commit/4168d44dfaba0fa43709eea2a3ef859f686ddeb6)] __-__ set the multiprocessing start_method spawn (#4650) (*felix-wang*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```85b597ab```](https://github.com/jina-ai/jina/commit/85b597ab1f92c2f5596edb779d8d79196f3aa3fc)] __-__ fixed typos in limiting outstanding requests (#4611) (*joschkabraun*)\n+ - [[```b6aaa3ef```](https://github.com/jina-ai/jina/commit/b6aaa3ef074713c0f74402627a121f090e28d938)] __-__ add docs guide (#4659) (*cristian*)\n+ - [[```0c1468a7```](https://github.com/jina-ai/jina/commit/0c1468a7d08795b358dada91e5a81986fb16d23e)] __-__ normalize usage of admonition boxes (#4662) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```b086f0d9```](https://github.com/jina-ai/jina/commit/b086f0d9016cef3c925a832c33c44e779351d879)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```e7bd24ab```](https://github.com/jina-ai/jina/commit/e7bd24abce90cf1ea3973f542b25b4c632cbc2fc)] __-__ __version__: the next version will be 3.3.7 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -65,7 +65,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.7'\n+__version__ = '3.3.8'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.8"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -75,4 +75,4 @@ kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n-prometheus_client:          standard\n+prometheus_client:          core\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -75,4 +75,4 @@ kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n-prometheus_client:          standard\n+prometheus_client:          core\n\n\n###\n\n", "completion": "fix(dependency): prometheus client should be a core dependency (#<issue-num>)"}
{"prompt": " file path A: CONTRIBUTING.md | file path B: CONTRIBUTING.md\n\n@@ -217,6 +217,8 @@ pip install \".[test]\"\n pytest -v -s --ignore-glob='tests/integration/hub_usage/dummyhub*' tests\n ```\n \n+Tips: If you want to run the k8s tests then you should install [linkerd cli](https://linkerd.io/2.11/getting-started/#step-1-install-the-cli) before.\n+\n When you add an executor or a driver, you may introduce new dependencies to Jina. You can verify the dependencies via:\n \n ```bash\n\n---\n file path A: tests/k8s/test_k8s.py | file path B: tests/k8s/test_k8s.py\n\n@@ -1,4 +1,5 @@\n # kind version has to be bumped to v0.11.1 since pytest-kind is just using v0.10.0 which does not work on ubuntu in ci\n+# You need to install linkerd cli on your local machine if you want to run the k8s tests https://linkerd.io/2.11/getting-started/#step-1-install-the-cli\n import asyncio\n import os\n \n\n\n###\n\n", "completion": "feat: add linkerd details in contributing (#<issue-num>)"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -1,3 +1,4 @@\n+import contextlib\n import inspect\n import multiprocessing\n import os\n@@ -129,7 +130,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n                 'Time spent when calling the executor request method',\n                 registry=self.runtime_args.metrics_registry,\n                 namespace='jina',\n-                labelnames=('method', 'executor'),\n+                labelnames=('executor', 'endpoint'),\n             )\n         else:\n             self._summary_method = None\n@@ -250,10 +251,18 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n \n     async def __acall_endpoint__(self, req_endpoint, **kwargs):\n         func = self.requests[req_endpoint]\n-        if iscoroutinefunction(func):\n-            return await func(self, **kwargs)\n-        else:\n-            return func(self, **kwargs)\n+\n+        _summary = (\n+            self._summary_method.labels(self.__class__.__name__, req_endpoint).time()\n+            if self._summary_method\n+            else contextlib.nullcontext()\n+        )\n+\n+        with _summary:\n+            if iscoroutinefunction(func):\n+                return await func(self, **kwargs)\n+            else:\n+                return func(self, **kwargs)\n \n     @property\n     def workspace(self) -> Optional[str]:\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -1,5 +1,4 @@\n \"\"\"Decorators and wrappers designed for wrapping :class:`BaseExecutor` functions. \"\"\"\n-import contextlib\n import functools\n import inspect\n from functools import wraps\n@@ -18,8 +17,6 @@ from jina.helper import convert_tuple_to_list, iscoroutinefunction\n from jina.serve.executors.metas import get_default_metas\n \n if TYPE_CHECKING:\n-    from prometheus_client import Summary\n-\n     from jina import DocumentArray\n \n \n@@ -118,12 +115,7 @@ def requests(\n                 async def arg_wrapper(\n                     executor_instance, *args, **kwargs\n                 ):  # we need to get the summary from the executor, so we need to access the self\n-                    with self._get_summary(\n-                        executor_instance._summary_method,\n-                        executor_instance.__class__.__name__,\n-                        fn.__name__,\n-                    ):\n-                        return await fn(executor_instance, *args, **kwargs)\n+                    return await fn(executor_instance, *args, **kwargs)\n \n                 self.fn = arg_wrapper\n             else:\n@@ -132,12 +124,7 @@ def requests(\n                 def arg_wrapper(\n                     executor_instance, *args, **kwargs\n                 ):  # we need to get the summary from the executor, so we need to access the self\n-                    with self._get_summary(\n-                        executor_instance._summary_method,\n-                        executor_instance.__class__.__name__,\n-                        fn.__name__,\n-                    ):\n-                        return fn(executor_instance, *args, **kwargs)\n+                    return fn(executor_instance, *args, **kwargs)\n \n                 self.fn = arg_wrapper\n \n@@ -154,15 +141,6 @@ def requests(\n \n             setattr(owner, name, self.fn)\n \n-        def _get_summary(\n-            self, summary: Optional['Summary'], executor_name: str, method_name: str\n-        ) -> ContextManager:\n-            return (\n-                summary.labels(method_name, executor_name).time()\n-                if summary\n-                else contextlib.nullcontext()\n-            )\n-\n     if func:\n         return FunctionMapper(func)\n     else:\n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -4,6 +4,7 @@ from docarray import DocumentArray\n \n from jina import __default_endpoint__\n from jina.excepts import BadConfigSource\n+from jina.importer import ImportExtensions\n from jina.serve.executors import BaseExecutor\n from jina.types.request.data import DataRequest\n \n@@ -38,6 +39,27 @@ class DataRequestHandler:\n         self.logger = logger\n         self._is_closed = False\n         self._load_executor(metrics_registry)\n+        self._init_monitoring(metrics_registry)\n+\n+    def _init_monitoring(self, metrics_registry: Optional['CollectorRegistry'] = None):\n+\n+        if metrics_registry:\n+\n+            with ImportExtensions(\n+                required=True,\n+                help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n+            ):\n+                from prometheus_client import Counter\n+\n+                self._counter = Counter(\n+                    'document_processed',\n+                    'Number of Documents that have been processed by the executor',\n+                    namespace='jina',\n+                    labelnames=('endpoint', 'executor'),\n+                    registry=metrics_registry,\n+                )\n+        else:\n+            self._counter = None\n \n     def _load_executor(self, metrics_registry: Optional['CollectorRegistry'] = None):\n         \"\"\"\n@@ -135,6 +157,11 @@ class DataRequestHandler:\n                     f'but getting {return_data!r}'\n                 )\n \n+        if self._counter:\n+            self._counter.labels(\n+                requests[0].header.exec_endpoint, self._executor.__class__.__name__\n+            ).inc(len(docs))\n+\n         DataRequestHandler.replace_docs(requests[0], docs, self.args.output_array_type)\n \n         return requests[0]\n\n---\n file path A: tests/integration/monitoring/test_monitoring.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -32,7 +32,7 @@ def test_enable_monitoring_deployment(port_generator):\n             f.post(f'/{meth}', inputs=DocumentArray())\n             resp = req.get(f'http://localhost:{port2}/')\n             assert (\n-                f'process_request_seconds_created{{executor=\"DummyExecutor\",method=\"{meth}\"}}'\n+                f'process_request_seconds_created{{endpoint=\"/{meth}\",executor=\"DummyExecutor\"}}'\n                 in str(resp.content)\n             )\n \n@@ -74,3 +74,44 @@ def test_monitoring_head(port_generator):\n         resp = req.get(f'http://localhost:{port2}/')\n         assert f'jina_receiving_request_seconds' in str(resp.content)\n         assert f'jina_sending_request_seconds' in str(resp.content)\n+\n+\n+def test_document_processed_total(port_generator):\n+    port0 = port_generator()\n+    port1 = port_generator()\n+\n+    with Flow(monitoring=True, port_monitoring=port0).add(\n+        uses=DummyExecutor, monitoring=True, port_monitoring=port1\n+    ) as f:\n+\n+        resp = req.get(f'http://localhost:{port1}/')\n+        assert resp.status_code == 200\n+\n+        f.post(\n+            f'/foo', inputs=DocumentArray.empty(size=4)\n+        )  # process 4 documents on foo\n+\n+        resp = req.get(f'http://localhost:{port1}/')\n+        assert (\n+            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\"}} 4.0'  # check that we count 4 documents on foo\n+            in str(resp.content)\n+        )\n+\n+        assert not (\n+            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\"}}'  # check that we does not start counting documents on bar as it has not been called yet\n+            in str(resp.content)\n+        )\n+\n+        f.post(\n+            f'/bar', inputs=DocumentArray.empty(size=5)\n+        )  # process 5 documents on bar\n+\n+        assert not (\n+            f'jina_document_processed_total{{endpoint=\"/bar\",executor=\"DummyExecutor\"}} 5.0'  # check that we count 5 documents on foo\n+            in str(resp.content)\n+        )\n+\n+        assert (\n+            f'jina_document_processed_total{{endpoint=\"/foo\",executor=\"DummyExecutor\"}} 4.0'  # check that we nothing change on bar count\n+            in str(resp.content)\n+        )\n\n\n###\n\n", "completion": "feat(monitoring): count the number of processed documents (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -3,7 +3,7 @@ from typing import TYPE_CHECKING, Dict, List, Optional\n from docarray import DocumentArray\n \n from jina import __default_endpoint__\n-from jina.excepts import BadConfigSource, ExecutorFailToLoad\n+from jina.excepts import BadConfigSource\n from jina.serve.executors import BaseExecutor\n from jina.types.request.data import DataRequest\n \n@@ -62,18 +62,18 @@ class DataRequestHandler:\n                 extra_search_paths=self.args.extra_search_paths,\n             )\n \n-        except BadConfigSource as ex:\n+        except BadConfigSource:\n             self.logger.error(\n                 f'fail to load config from {self.args.uses}, if you are using docker image for --uses, '\n                 f'please use \"docker://YOUR_IMAGE_NAME\"'\n             )\n-            raise ExecutorFailToLoad from ex\n-        except FileNotFoundError as ex:\n+            raise\n+        except FileNotFoundError:\n             self.logger.error(f'fail to load file dependency')\n-            raise ExecutorFailToLoad from ex\n-        except Exception as ex:\n+            raise\n+        except Exception:\n             self.logger.critical(f'can not load the executor from {self.args.uses}')\n-            raise ExecutorFailToLoad from ex\n+            raise\n \n     @staticmethod\n     def _parse_params(parameters: Dict, executor_name: str):\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py\n\n@@ -253,6 +253,31 @@ def test_flow_startup_exception_not_hanging2(protocol):\n             pass\n \n \n+@pytest.mark.timeout(10)\n+@pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n+def test_flow_startup_exception_not_hanging_filenotfound(protocol):\n+    f = Flow(protocol=protocol).add(uses='doesntexist.yml')\n+    from jina.excepts import RuntimeFailToStart\n+\n+    with pytest.raises(RuntimeFailToStart):\n+        with f:\n+            pass\n+\n+\n+@pytest.mark.timeout(10)\n+@pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n+def test_flow_startup_exception_not_hanging_invalid_config(protocol):\n+    this_file = os.path.dirname(os.path.abspath(__file__))\n+    f = Flow(protocol=protocol).add(\n+        name='importErrorExecutor',\n+        uses=this_file,\n+    )\n+\n+    with pytest.raises(RuntimeFailToStart):\n+        with f:\n+            pass\n+\n+\n def test_flow_does_not_import_exec_depencies():\n     cur_dir = os.path.dirname(os.path.abspath(__file__))\n     f = Flow().add(\n\n\n###\n\n", "completion": "fix: better error messages when flow fails to start (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/flow-api.md | file path B: docs/fundamentals/flow/flow-api.md\n\n@@ -342,11 +342,9 @@ If both of these are provided, the Flow will automatically configure itself to u\n \n ## Limit outstanding requests\n \n-By default, Jina's Client sens requests to the Flow as fast as possible, without any throttling.\n-If a client sends his request faster than the Flow can process them, this can put a lot of loan on the Flow.\n-Typically, this is most likely to happen for expensive index Flows. \n+By default, Jina\u2019s Client sends requests to the Flow as fast as possible without any delay. If a client sends their request faster than the Flow can process them, this can put a high load on the Flow. Typically, this is most likely to happen for Flows with expensive indexing.\n \n-You can control the number of in flight requests per Client with the `prefetch` argument, e.g. setting `prefetch=2` lets the API accept only 2 requests per client in parallel, hence limiting the load. By default, prefetch is disabled (set to 0).\n+You can control the number of in flight requests per Client with the `prefetch` argument. E.g. setting `prefetch=2` lets the API accept only 2 requests per client in parallel, hence limiting the load. By default, prefetch is disabled (set to 0).\n \n ```{code-block} python\n ---\n\n\n###\n\n", "completion": "docs: fixed typos in limiting outstanding requests (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -58,7 +58,6 @@ class DockerComposeConfig:\n             )\n             cargs = copy.copy(self.service_args)\n             cargs.deployments_addresses = self.deployments_addresses\n-            cargs.env = None\n             from jina.helper import ArgNamespace\n             from jina.parsers import set_gateway_parser\n \n@@ -72,6 +71,7 @@ class DockerComposeConfig:\n                 'workspace_id',\n                 'upload_files',\n                 'noblock_on_start',\n+                'env',\n             }\n \n             non_defaults = ArgNamespace.get_non_defaults_args(\n@@ -86,6 +86,10 @@ class DockerComposeConfig:\n                 [f'{cargs.port_monitoring}'] if cargs.monitoring else []\n             )\n \n+            envs = [f'JINA_LOG_LEVEL={os.getenv(\"JINA_LOG_LEVEL\", \"INFO\")}']\n+            if cargs.env:\n+                for k, v in cargs.env.items():\n+                    envs.append(f'{k}={v}')\n             return {\n                 'image': image_name,\n                 'entrypoint': ['jina'],\n@@ -96,9 +100,7 @@ class DockerComposeConfig:\n                     'test': f'python -m jina.resources.health_check.gateway localhost:{cargs.port} {protocol}',\n                     'interval': '2s',\n                 },\n-                'environment': [\n-                    f'JINA_LOG_LEVEL={os.getenv(\"JINA_LOG_LEVEL\", \"INFO\")}'\n-                ],\n+                'environment': envs,\n             }\n \n         def _get_image_name(self, uses: Optional[str]):\n@@ -285,7 +287,6 @@ class DockerComposeConfig:\n             parsed_args['head_service'].uses_with = None\n             parsed_args['head_service'].uses_before = None\n             parsed_args['head_service'].uses_after = None\n-            parsed_args['head_service'].env = None\n \n             # if the k8s connection pool is disabled, the connection pool is managed manually\n             import json\n\n---\n file path A: jina/orchestrate/deployments/config/helper.py | file path B: jina/orchestrate/deployments/config/helper.py\n\n@@ -84,6 +84,7 @@ def construct_runtime_container_args(cargs, uses_metas, uses_with, pod_type):\n         'workspace_id',\n         'upload_files',\n         'noblock_on_start',\n+        'env',\n     }\n \n     if pod_type == PodRoleType.HEAD:\n\n---\n file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -57,7 +57,6 @@ class K8sDeploymentConfig:\n             )\n \n             cargs = copy.copy(self.deployment_args)\n-            cargs.env = None\n             cargs.deployments_addresses = self.k8s_deployments_addresses\n             from jina.helper import ArgNamespace\n             from jina.parsers import set_gateway_parser\n@@ -72,6 +71,7 @@ class K8sDeploymentConfig:\n                 'workspace_id',\n                 'upload_files',\n                 'noblock_on_start',\n+                'env',\n             }\n \n             non_defaults = ArgNamespace.get_non_defaults_args(\n@@ -143,11 +143,11 @@ class K8sDeploymentConfig:\n                 uses_before_cargs.uses_after = None\n                 uses_before_cargs.uses_with = None\n                 uses_before_cargs.uses_metas = None\n-                uses_before_cargs.env = None\n                 uses_before_cargs.connection_list = None\n                 uses_before_cargs.runtime_cls = 'WorkerRuntime'\n                 uses_before_cargs.pod_role = PodRoleType.WORKER\n                 uses_before_cargs.polling = None\n+                uses_before_cargs.env = None\n                 container_args_uses_before = self._get_container_args(\n                     uses_before_cargs, PodRoleType.WORKER\n                 )\n@@ -164,11 +164,11 @@ class K8sDeploymentConfig:\n                 uses_after_cargs.uses_after = None\n                 uses_after_cargs.uses_with = None\n                 uses_after_cargs.uses_metas = None\n-                uses_after_cargs.env = None\n                 uses_after_cargs.connection_list = None\n                 uses_after_cargs.runtime_cls = 'WorkerRuntime'\n                 uses_after_cargs.pod_role = PodRoleType.WORKER\n                 uses_after_cargs.polling = None\n+                uses_after_cargs.env = None\n                 container_args_uses_after = self._get_container_args(\n                     uses_after_cargs, PodRoleType.WORKER\n                 )\n@@ -273,7 +273,6 @@ class K8sDeploymentConfig:\n                 parsed_args['head_deployment'].uses = None\n                 parsed_args['head_deployment'].uses_metas = None\n                 parsed_args['head_deployment'].uses_with = None\n-                parsed_args['head_deployment'].env = None\n \n                 import json\n \n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -470,6 +470,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                 port=self.port,\n                 deployment_role=DeploymentRoleType.GATEWAY,\n                 expose_endpoints=json.dumps(self._endpoints_mapping),\n+                env=self.env,\n             )\n         )\n \n@@ -1768,6 +1769,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         self.args.env = value\n         for k, v in self:\n             v.args.env = value\n+            v.update_pod_args()\n \n     @overload\n     def expose_endpoint(self, exec_endpoint: str, path: Optional[str] = None):\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -39,7 +39,6 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n         :param kwargs: keyword args\n         \"\"\"\n         super().__init__(args, **kwargs)\n-\n         if args.name is None:\n             args.name = ''\n         self.name = args.name\n\n---\n file path A: tests/unit/orchestrate/deploymens/__init__.py | file path B: tests/unit/orchestrate/deployments/__init__.py\n\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/__init__.py | file path B: tests/unit/orchestrate/deployments/config/__init__.py\n\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/k8slib/__init__.py | file path B: tests/unit/orchestrate/deployments/config/k8slib/__init__.py\n\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/k8slib/test_kubernetes_tools.py | file path B: tests/unit/orchestrate/deployments/config/k8slib/test_kubernetes_tools.py\n\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_docker_compose_pod_config.py | file path B: tests/unit/orchestrate/deployments/config/test_docker_compose_pod_config.py\n\n@@ -597,11 +597,7 @@ def test_docker_compose_yaml_regular_deployment(\n             assert replica_args[replica_args.index('--name') + 1] == expected_arg_name\n             assert '--port' in replica_args\n             assert replica_args[replica_args.index('--port') + 1] == '8081'\n-            assert '--env' in replica_args\n-            assert (\n-                replica_args[replica_args.index('--env') + 1]\n-                == '{\"ENV_VAR\": \"ENV_VALUE\"}'\n-            )\n+            assert '--env' not in replica_args\n             assert '--connection-list' not in replica_args\n             if uses_with is not None:\n                 assert '--uses-with' in replica_args\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_helper.py | file path B: tests/unit/orchestrate/deployments/config/test_helper.py\n\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_k8s_deployment_config.py | file path B: tests/unit/orchestrate/deployments/config/test_k8s_deployment_config.py\n\n@@ -286,6 +286,7 @@ def test_k8s_yaml_gateway(deployments_addresses, custom_gateway):\n         config_map,\n         'gateway',\n         {\n+            'ENV_VAR': 'ENV_VALUE',\n             'JINA_LOG_LEVEL': 'INFO',\n             'pythonunbuffered': '1',\n             'worker_class': 'uvicorn.workers.UvicornH11Worker',\n@@ -452,6 +453,7 @@ def test_k8s_yaml_regular_deployment(\n             config_map,\n             'executor-head',\n             {\n+                'ENV_VAR': 'ENV_VALUE',\n                 'JINA_LOG_LEVEL': 'INFO',\n                 'pythonunbuffered': '1',\n                 'worker_class': 'uvicorn.workers.UvicornH11Worker',\n@@ -728,13 +730,7 @@ def test_k8s_yaml_regular_deployment(\n             ]\n             == '8080'\n         )\n-        assert '--env' in shard_container_runtime_container_args\n-        assert (\n-            shard_container_runtime_container_args[\n-                shard_container_runtime_container_args.index('--env') + 1\n-            ]\n-            == '{\"ENV_VAR\": \"ENV_VALUE\"}'\n-        )\n+        assert '--env' not in shard_container_runtime_container_args\n         assert '--connection-list' not in shard_container_runtime_container_args\n \n         if uses_with is not None:\n\n---\n file path A: tests/unit/orchestrate/deploymens/test_deployments.py | file path B: tests/unit/orchestrate/deployments/test_deployments.py\n\n\n\n###\n\n", "completion": "feat: pass environment to head and gateway (#<issue-num>)"}
{"prompt": " file path A: .github/pull_request_template.md | file path B: .github/pull_request_template.md\n\n@@ -1,9 +1,5 @@\n-# Pull Request Title\n+Goals:\n \n-## Description\n-\n-Please describe what your PR is doing and why. Are there any parts which need extra attention during review? Are there any dependencies from other PRs or projcts? Is this a breaking change?\n-\n-Is this PR ready or work in progress (WIP)? Ready means it can be reviewed and merged from the author's perspective. If the PR is WIP: Make it a draft PR and state open questions and TODO items.\n-\n-Closes # (issue)\n\\ No newline at end of file\n+- ...\n+- ...\n+- [ ] check and update documentation. See [guide](https://github.com/jina-ai/jina/CONTRIBUTING.md#documentation-guidelines) and ask the team.\n\n---\n file path A: CONTRIBUTING.md | file path B: CONTRIBUTING.md\n\n@@ -241,6 +241,32 @@ Good docs make developers happy, and we love happy developers! We've got a few d\n * Tutorials/examples\n * Docstrings in Python functions in RST format - generated by Sphinx\n \n+### Documentation guidelines\n+\n+1. Decide if your page is a **guide or a tutorial**. Make sure it fits its section.\n+2. Use \u201c**you**\u201d instead of \u201cwe\u201d or \u201cI\u201d. It **engages** the reader more.\n+3. **Sentence case** for headers. (Use [https://convertcase.net/](https://convertcase.net/) to check)\n+4. Keep sentences short. If possible, **fewer than 13 words**.\n+5. Only use `backticks` for direct references to code elements.\n+6. Jina product names should be capitalized and not backticked (Flow, Executor, Hub etc.).\n+7. All **acronyms** should be UPPERCASE (Ex. YAML, JSON, HTTP, SSL).\n+8. Think about the **structure** of the page beforehand. Split it into headers before writing the content.\n+9. If relevant, include a \u201c**See also**\u201d section at the end.\n+10. Link to any existing explanations of the concepts you are using.\n+\n+Bonus: **Know when to break the rules**. Documentation writing is as much art as it is science. Sometimes you will have to deviate from these rules in order to write good documentation.\n+Refer to these pages as standardized examples:\n+\n+* https://docs.jina.ai/fundamentals/flow/access-flow-api/ \n+* https://docs.jina.ai/fundamentals/flow/flow-api/\n+* https://docs.jina.ai/how-to/flow-switch/ \n+\n+[MyST](https://myst-parser.readthedocs.io/en/latest/) Elements Usage\n+\n+1. Use the `{tab}` element to show multiple ways of doing one thing. [Example](https://docs.jina.ai/fundamentals/flow/create-flow/#instantiate-a-flow) \n+2. Use the `{admonition}` boxes with care. We recommend restricting yourself to [Hint](https://docs.jina.ai/fundamentals/flow/create-flow/#create-a-flow), [Caution](https://docs.jina.ai/fundamentals/flow/flow-api/#add-graphql-endpoint) and [See Also](https://docs.jina.ai/fundamentals/flow/flow-api/#add-graphql-endpoint).\n+3. Use `{dropdown}` to hide optional content, such as long code snippets or console output. [Example](https://docs.jina.ai/fundamentals/flow/access-flow-api/#use-http-client-to-send-request)\n+\n ### Building documentation on your local machine\n \n #### Requirements\n\n\n###\n\n", "completion": "docs: add docs guide (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -44,7 +44,7 @@ lz4<3.1.2:                  perf, standard,devel\n uvloop:                     perf, standard,devel\n numpy:                      core\n protobuf>=3.19.1:           core\n-grpcio>=1.33.1:             core\n+grpcio>=1.33.1,<1.44.0:     core\n grpcio-reflection>=1.33.1:  core\n pyyaml>=5.3.1:              core\n docarray>=0.9.10:           core\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -39,13 +39,18 @@ _os.environ['OBJC_DISABLE_INITIALIZE_FORK_SAFETY'] = 'YES'\n \n # JINA_MP_START_METHOD has higher priority than os-patch\n _start_method = _os.environ.get('JINA_MP_START_METHOD', None)\n-\n if _start_method and _start_method.lower() in {'fork', 'spawn', 'forkserver'}:\n     from multiprocessing import set_start_method as _set_start_method\n \n-    _set_start_method(_start_method.lower())\n-    _warnings.warn(f'multiprocessing start method is set to `{_start_method.lower()}`')\n-    _os.environ.pop('JINA_MP_START_METHOD')\n+    try:\n+        _set_start_method(_start_method.lower())\n+        _warnings.warn(\n+            f'multiprocessing start method is set to `{_start_method.lower()}`'\n+        )\n+    except Exception as e:\n+        _warnings.warn(\n+            f'failed to set multiprocessing start_method to `{_start_method.lower()}`: {e!r}'\n+        )\n elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n     # DO SOME OS-WISE PATCHES\n \n@@ -55,6 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n \n     _set_start_method('fork')\n \n+\n # do not change this line manually\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -44,7 +44,7 @@ lz4<3.1.2:                  perf, standard,devel\n uvloop:                     perf, standard,devel\n numpy:                      core\n protobuf>=3.19.1:           core\n-grpcio>=1.33.1:             core\n+grpcio>=1.33.1,<1.44.0:     core\n grpcio-reflection>=1.33.1:  core\n pyyaml>=5.3.1:              core\n docarray>=0.9.10:           core\n\n\n###\n\n", "completion": "fix: set the multiprocessing start_method spawn (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -38,7 +38,7 @@ class MyExecutor(Executor):\n \n \n ````{admonition} What is inside kwargs? \n-:class: tip\n+:class: hint\n Here, `kwargs` are reserved for Jina to inject `metas` and `requests` (representing the request-to-function mapping) values when the Executor is used inside a Flow.\n \n You can access the values of these arguments in the `__init__` body via `self.metas`/`self.requests`/`self.runtime_args`, \n@@ -390,9 +390,9 @@ kubectl apply -R -f /tmp/config_out_folder\n ```\n The above example will deploy the `DummyHubExecutor` from Jina Hub into your Kubernetes cluster.\n \n-````{admonition} Note\n-:class: note\n-The Executor you are using, needs to be already containerized and stored in a registry accessible from your Kubernetes cluster. We recommend Jina Hub for this.\n+````{admonition} Hint\n+:class: hint\n+The Executor you are using needs to be already containerized and stored in a registry accessible from your Kubernetes cluster. We recommend Jina Hub for this.\n ````\n \n (external-shared-executor)=\n@@ -419,9 +419,9 @@ Executor.to_docker_compose_yaml(\n ```\n The above example will run the `DummyHubExecutor` from Jina Hub locally on your computer using Docker Compose.\n \n-````{admonition} Note\n-:class: note\n-The Executor you are using, needs to be already containerized and stored in an accessible registry. We recommend Jina Hub for this.\n+````{admonition} Hint\n+:class: hint\n+The Executor you are using needs to be already containerized and stored in an accessible registry. We recommend Jina Hub for this.\n ````\n \n ### Use async Executors\n\n---\n file path A: docs/fundamentals/flow/access-flow-api.md | file path B: docs/fundamentals/flow/access-flow-api.md\n\n@@ -315,7 +315,7 @@ We use [subprotocols](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket\n The Flow defaults to `json` when a subprotocol is not passed during connection establishment (Our Python client uses `bytes` streaming by using [jina.proto](../../proto/docs.md) definition).\n \n \n-````{admonition} Hint\n+````{Hint}\n \n - Choose Websocket over HTTP if you want to stream requests. \n - Choose Websocket over gRPC if\n\n---\n file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -221,7 +221,7 @@ with f:\n     client.post('/', Document(), parameters={'hello': 'world'})\n ```\n \n-````{admonition} Note\n+````{hint} \n :class: note\n You can send a parameters-only data request via:\n \n@@ -245,8 +245,7 @@ For this purpose, Jina implements a promise-like interface, letting you specify\n - `on_error` is executed whenever an error occurs in `client.post()`\n - `on_always` is always performed, no matter the success or failure of `client.post()`\n \n-```{admonition} Tip\n-:class: tip\n+```{hint} \n Both `on_done`and `on_always` callback won't be trigger if the failure is due to an error happening outside of \n networking or internal jina issues. For example, if a `SIGKILL` is triggered by the OS during the handling of the request\n none of the callback will be executed.   \n@@ -258,8 +257,7 @@ Callback functions in Jina expect a `Response` of the type `jina.types.request.d\n parameters, and other information.\n \n \n-````{admonition} Understanding DataRequest\n-:class: note\n+````{hint} Understanding DataRequest\n \n `DataRequest`s are objects that are sent by Jina internally. Callback functions process DataRequests, and `client.post()`\n can return DataRequests.\n@@ -346,8 +344,7 @@ By setting `return_responses=True` as an argument to `client.post(return_respons\n \n If a callback is provided, no results will be returned.\n \n-```{admonition} Danger\n-:class: danger\n+```{caution}\n Not using a callback function and instead returning results can come with a **serious performance penalty**.\n \n Callbacks operate on each individual Request, which represents a batch of the data.\n\n---\n file path A: docs/how-to/async-executors.md | file path B: docs/how-to/async-executors.md\n\n@@ -7,7 +7,7 @@ Python to write concurrent code.\n \n \n ````{admonition} Example code\n-:class: tip\n+:class: hint\n \n Functions decorated by `requests`  can be directly implemented as async `coroutines. \n \n\n---\n file path A: docs/how-to/debug-executor.md | file path B: docs/how-to/debug-executor.md\n\n@@ -7,7 +7,7 @@ To debug an Executor, you need to look under the hood of Jina. This means things\n ````\n \n ````{admonition} Containerized Executor\n-:class: danger\n+:class: caution\n This How-To does not work for containerized Executors.\n ````\n \n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -38,7 +38,7 @@ After that, the external Executor will behave just like an internal one. And you\n Flows!\n \n ````{admonition} Note\n-:class: note\n+:class: hint\n If an external Executor needs multiple predecessors, reducing needs to be enabled. So setting disable_reduce=True is not allowed for these cases. \n ````\n \n\n---\n file path A: docs/how-to/flow-switch.md | file path B: docs/how-to/flow-switch.md\n\n@@ -2,7 +2,7 @@\n # How to build switches in a Flow\n \n ````{admonition} Requirements\n-:class: note\n+:class: hint\n To follow along with this How-To, you need Jina 3.2.2 or higher.\n ````\n \n\n---\n file path A: docs/how-to/gpu-executor.md | file path B: docs/how-to/gpu-executor.md\n\n@@ -8,7 +8,7 @@ Using a GPU allows you to significantly speed up encoding for most deep learning\n reducing response latency by anything from 5 to 100 times, depending on the model and inputs used.\n \n ```{admonition} Important\n-:class: important\n+:class: caution\n \n This tutorial assumes you are already familiar with basic Jina concepts, such as Document, Executor, and Flow. Some knowledge of the [Hub](../fundamentals/executor/hub/index) is also needed for the last part of the tutorial.\n \n@@ -135,7 +135,7 @@ pip install jina\n \n \n ```{admonition} Jina Hub\n-:class: info\n+:class: hint\n \n In this section we create an executor using [Jina Hub](https://hub.jina.ai/). This still creates your executor locally\n and privately, but makes it quick and easy to run your\n@@ -226,7 +226,7 @@ pip install -r requirements.txt\n ```\n \n ```{admonition} Do I need to install CUDA?\n-:class: info\n+:class: hint\n \n All machine learning frameworks rely on CUDA for running on GPU. However, whether you\n need CUDA installed on your system or not depends on the framework that you are using.\n@@ -237,7 +237,7 @@ you to install CUDA yourself.\n ```\n \n ```{admonition} Install only what you need\n-:class: tip\n+:class: hint\n \n In this example we are installing the GPU-enabled version of PyTorch, which is the default\n version when installing from PyPI. However, if you know that you only need to use your\n@@ -368,7 +368,7 @@ time can be decreased from 20s to 3s by running on GPU.\n That is more than a **6x speedup!** And that's not even the best we can do - if we increase the batch size to max out the GPU's memory we would get even larger speedups. But such optimizations are beyond the scope of this tutorial.\n \n ```{admonition} Note\n-:class: note\n+:class: hint\n \n You have probably noticed that there was a delay (about 3 seconds) when creating the Flow.\n This occured because the weights of our model needed to be transfered from CPU to GPU when we\n@@ -379,7 +379,7 @@ so for most use cases this is not something we would worry about.\n ## Using GPU in a container\n \n ```{admonition} Using your GPU inside a container\n-:class: tip\n+:class: caution\n \n For this part of the tutorial, you need `nvidia-container-toolkit` installed on your machine.\n If you haven't installed that already, you can find an installation guide [here](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).\n@@ -390,6 +390,7 @@ When you'll be using your Executor in production you will most likely want to pu\n Using GPU-enabled Executors in this case is no harder than using them locally. In this case we don't even need to modify the default `Dockerfile`.\n \n ```{admonition} Choosing the right base image\n+:class: hint\n \n In our case we are using the default `jinaai/jina:latest` base image. However, parallel to the comments about having to install CUDA locally, you might need to use a different base image, depending on the framework you are using.\n \n@@ -474,7 +475,7 @@ f = Flow().add(\n You'll see that the first time you run the script, downloading the Docker image will take some time - GPU images are large! But after that, everything will work just as it did with your local Docker image, out of the box.\n \n ```{admonition} Important\n-:class: important\n+:class: caution\n \n When using GPU encoders from Jina Hub, always use `jinahub+docker://`, and not `jinahub://`. As discussed above, these encoders might need CUDA installed (or other system dependencies), and installing that properly can be tricky. For that reason, you should prefer using Docker images, which already come with all these dependencies pre-installed.\n ```\n\n---\n file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -20,8 +20,8 @@ Linkerd will automatically load balance traffic between all replicas of an Execu\n \n It is also generally possible to use other service mesh providers (like [Istio](https://istio.io/)) with Jina. You need to manually change Jina's deployment configurations in the generated YAML files for this.\n \n-````{admonition} Attention\n-:class: attention\n+````{admonition} Caution\n+:class: caution\n \n If you don't install a third party service mesh (like Linkerd), you will not be able to scale the number of replicas per Executor to more than one. A single replica will always handle all the traffic. No matter how many replicas will be running.\n ````\n\n\n###\n\n", "completion": "docs: normalize usage of admonition boxes (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -158,6 +158,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13055,3 +13056,28 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```bf4c2be2```](https://github.com/jina-ai/jina/commit/bf4c2be225bfa8abed3aa6da768c9fdc558d5df9)] __-__ __version__: the next version will be 3.3.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-6></a>\n+## Release Note (`3.3.6`)\n+\n+> Release time: 2022-04-22 07:01:51\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  samsja,  Jina Dev Bot,  Johannes Messner,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```955a08d8```](https://github.com/jina-ai/jina/commit/955a08d8216eaa31f58251eb5b404a8687a82d8f)] __-__ fix circular import (#4649) (*Joan Fontanals*)\n+ - [[```af81dfe9```](https://github.com/jina-ai/jina/commit/af81dfe97e6de2fa96247cc225ef96fda416d823)] __-__ reorder correctly the remark page (#4665) (*samsja*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```4a0a878e```](https://github.com/jina-ai/jina/commit/4a0a878e130e0a52667c085c1cec8bb0911822f1)] __-__ make all how-to titles sentence case (#4663) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```0c8d6371```](https://github.com/jina-ai/jina/commit/0c8d6371cc64e51f5bf1a2af66120b8d99bfca26)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d1add5a6```](https://github.com/jina-ai/jina/commit/d1add5a624e1cc474a77d4ae70cf1c82c68e5005)] __-__ __version__: the next version will be 3.3.6 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -59,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.6'\n+__version__ = '3.3.7'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.7"}
{"prompt": " file path A: jina/logging/logger.py | file path B: jina/logging/logger.py\n\n@@ -8,10 +8,9 @@ from typing import Optional\n \n from rich.logging import RichHandler\n \n-from jina.logging import formatter\n-from jina import __uptime__, __resources_path__, __windows__\n from jina.enums import LogVerbosity\n from jina.jaml import JAML\n+from jina.logging import formatter\n \n \n class SysLogHandlerWrapper(logging.handlers.SysLogHandler):\n@@ -53,6 +52,7 @@ class JinaLogger:\n         quiet: bool = False,\n         **kwargs,\n     ):\n+        from jina import __resources_path__, __uptime__, __windows__\n \n         if not log_config:\n             log_config = os.getenv(\n@@ -118,6 +118,8 @@ class JinaLogger:\n         :param config_path: Path of config file.\n         :param kwargs: Extra parameters.\n         \"\"\"\n+        from jina import __windows__\n+\n         self.logger.handlers = []\n \n         with open(config_path) as fp:\n\n\n###\n\n", "completion": "fix: fix circular import (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/remarks.md | file path B: docs/fundamentals/flow/remarks.md\n\n@@ -1,17 +1,5 @@\n # Remarks\n \n-\n-## multiprocessing Spawn\n-\n-Few cases require to use `spawn` start method for multiprocessing. \n-(e.g.- Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method)\n-\n-- Please set `JINA_MP_START_METHOD=spawn` before starting the Python script to enable this.\n-\n-    ````{hint}\n-    There's no need to set this for Windows, as it only supports spawn method for multiprocessing. \n-    ````\n-\n - Define & start the Flow via an explicit function call inside `if __name__ == '__main__'`. For example\n \n     ````{tab} \u2705 Do\n@@ -111,7 +99,22 @@ Few cases require to use `spawn` start method for multiprocessing.\n     ```\n     ````\n \n+- **Always provide absolute path**\n+\n+    While passing filepaths to different jina arguments (e.g.- `uses`, `py_modules`), always pass the absolute path.\n+\n+\n \n+## multiprocessing Spawn\n+\n+Few cases require to use `spawn` start method for multiprocessing. \n+(e.g.- Cannot re-initialize CUDA in forked subprocess. To use CUDA with multiprocessing, you must use the 'spawn' start method)\n+\n+- Please set `JINA_MP_START_METHOD=spawn` before starting the Python script to enable this.\n+\n+    ````{hint}\n+    There's no need to set this for Windows, as it only supports spawn method for multiprocessing. \n+    ````\n - **Avoid un-picklable objects**\n \n     [Here's a list of types that can be pickled in Python](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled). Since `spawn` relies on pickling, we should avoid using code that cannot be pickled.\n@@ -128,12 +131,6 @@ Few cases require to use `spawn` start method for multiprocessing.\n \n     Inline functions, such as nested or lambda functions are not picklable. Use `functools.partial` instead.\n \n-- **Always provide absolute path**\n-\n-    While passing filepaths to different jina arguments (e.g.- `uses`, `py_modules`), always pass the absolute path.\n-\n-\n-\n \n \n ## Debugging Executor in a Flow\n\n\n###\n\n", "completion": "fix: reorder correctly the remark page (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/debug-executor.md | file path B: docs/how-to/debug-executor.md\n\n@@ -1,5 +1,5 @@\n (debug-executor)=\n-# How to Debug Executor\n+# How to debug an Executor\n \n ````{admonition} Caution\n :class: caution\n\n---\n file path A: docs/how-to/scale-out.md | file path B: docs/how-to/scale-out.md\n\n@@ -1,5 +1,5 @@\n (scale-out)=\n-# How to Scale Out Your Executor\n+# How to scale out your Executor\n \n ## Overview\n \n\n\n###\n\n", "completion": "docs: make all how-to titles sentence case (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -157,6 +157,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13032,3 +13033,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```9140b134```](https://github.com/jina-ai/jina/commit/9140b134034812a3ee3bd717c059634f89f43896)] __-__ __version__: the next version will be 3.3.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-5></a>\n+## Release Note (`3.3.5`)\n+\n+> Release time: 2022-04-21 14:49:03\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Tobias Jacobowitz,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```8c53323e```](https://github.com/jina-ai/jina/commit/8c53323edf2aa7d743265299e02cc20f5641cdfa)] __-__ sandbox usage from k8s/docker-compose (#4671) (*Tobias Jacobowitz*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```bf4c2be2```](https://github.com/jina-ai/jina/commit/bf4c2be225bfa8abed3aa6da768c9fdc558d5df9)] __-__ __version__: the next version will be 3.3.5 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -59,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.5'\n+__version__ = '3.3.6'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.6"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -531,7 +531,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n             external_port = v.head_port if v.head_port else v.port\n             graph_dict[node] = [\n-                f'{deployment_k8s_address}:{external_port if v.external else GrpcConnectionPool.K8S_PORT}'\n+                f'{v.protocol}://{deployment_k8s_address}:{external_port if v.external else GrpcConnectionPool.K8S_PORT}'\n             ]\n \n         return graph_dict if graph_dict else None\n@@ -544,6 +544,9 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         for node, v in self._deployment_nodes.items():\n             if node == 'gateway':\n                 continue\n+\n+            if v.external:\n+                deployment_docker_compose_address = f'{v.protocol}://{v.host}:{v.port}'\n             elif v.head_args:\n                 deployment_docker_compose_address = (\n                     f'{to_compatible_name(v.head_args.name)}:{port}'\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_docker_compose_yaml.py\n\n@@ -1,3 +1,4 @@\n+import json\n import os\n from pathlib import Path\n from unittest import mock\n@@ -393,3 +394,29 @@ def test_disable_auto_volume(tmpdir):\n         'executor0',\n     }\n     assert 'volumes' not in services['executor0']\n+\n+\n+def test_flow_to_docker_compose_sandbox(tmpdir):\n+\n+    flow = Flow(name='test-flow', port=8080).add(\n+        uses=f'jinahub+sandbox://DummyHubExecutor'\n+    )\n+\n+    dump_path = os.path.join(str(tmpdir), 'test_flow_docker_compose.yml')\n+\n+    flow.to_docker_compose_yaml(\n+        output_path=dump_path,\n+    )\n+\n+    configuration = None\n+    with open(dump_path) as f:\n+        configuration = yaml.safe_load(f)\n+\n+    services = configuration['services']\n+    gateway_service = services['gateway']\n+    gateway_args = gateway_service['command']\n+\n+    deployment_addresses = json.loads(\n+        gateway_args[gateway_args.index('--deployments-addresses') + 1]\n+    )\n+    assert deployment_addresses['executor0'][0].startswith('grpcs://')\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py\n\n@@ -1,3 +1,4 @@\n+import json\n import os\n \n import pytest\n@@ -104,7 +105,7 @@ def test_flow_to_k8s_yaml(tmpdir, protocol, flow_port):\n     assert '--deployments-addresses' in gateway_args\n     assert (\n         gateway_args[gateway_args.index('--deployments-addresses') + 1]\n-        == '{\"executor0\": [\"executor0.test-flow-ns.svc:8080\"], \"executor1\": [\"executor1-head.test-flow-ns.svc:8080\"], \"executor2\": [\"executor2-head.test-flow-ns.svc:8080\"]}'\n+        == '{\"executor0\": [\"grpc://executor0.test-flow-ns.svc:8080\"], \"executor1\": [\"grpc://executor1-head.test-flow-ns.svc:8080\"], \"executor2\": [\"grpc://executor2-head.test-flow-ns.svc:8080\"]}'\n     )\n     assert '--pod-role' in gateway_args\n     assert gateway_args[gateway_args.index('--pod-role') + 1] == 'GATEWAY'\n@@ -449,13 +450,13 @@ def test_flow_to_k8s_yaml_external_pod(tmpdir, has_external):\n         assert '--deployments-addresses' in gateway_args\n         assert (\n             gateway_args[gateway_args.index('--deployments-addresses') + 1]\n-            == '{\"executor0\": [\"executor0.test-flow-ns.svc:8080\"], \"external_executor\": [\"1.2.3.4:9090\"]}'\n+            == '{\"executor0\": [\"grpc://executor0.test-flow-ns.svc:8080\"], \"external_executor\": [\"grpc://1.2.3.4:9090\"]}'\n         )\n     else:\n         assert '--deployments-addresses' in gateway_args\n         assert (\n             gateway_args[gateway_args.index('--deployments-addresses') + 1]\n-            == '{\"executor0\": [\"executor0.test-flow-ns.svc:8080\"], \"external_executor\": [\"external-executor.test-flow-ns.svc:8080\"]}'\n+            == '{\"executor0\": [\"grpc://executor0.test-flow-ns.svc:8080\"], \"external_executor\": [\"grpc://external-executor.test-flow-ns.svc:8080\"]}'\n         )\n \n \n@@ -465,3 +466,43 @@ def test_raise_exception_invalid_executor(tmpdir):\n     with pytest.raises(NoContainerizedError):\n         f = Flow().add(uses='A')\n         f.to_k8s_yaml(str(tmpdir))\n+\n+\n+def test_flow_to_k8s_yaml_sandbox(tmpdir):\n+\n+    flow = Flow(name='test-flow', port=8080).add(\n+        uses=f'jinahub+sandbox://DummyHubExecutor'\n+    )\n+\n+    dump_path = os.path.join(str(tmpdir), 'test_flow_k8s')\n+\n+    namespace = 'test-flow-ns'\n+    flow.to_k8s_yaml(\n+        output_base_path=dump_path,\n+        k8s_namespace=namespace,\n+    )\n+\n+    yaml_dicts_per_deployment = {\n+        'gateway': [],\n+    }\n+    for pod_name in set(os.listdir(dump_path)):\n+        file_set = set(os.listdir(os.path.join(dump_path, pod_name)))\n+        for file in file_set:\n+            with open(os.path.join(dump_path, pod_name, file)) as f:\n+                yml_document_all = list(yaml.safe_load_all(f))\n+            yaml_dicts_per_deployment[file[:-4]] = yml_document_all\n+\n+    gateway_objects = yaml_dicts_per_deployment['gateway']\n+    gateway_args = gateway_objects[2]['spec']['template']['spec']['containers'][0][\n+        'args'\n+    ]\n+    assert (\n+        gateway_args[gateway_args.index('--graph-description') + 1]\n+        == '{\"executor0\": [\"end-gateway\"], \"start-gateway\": [\"executor0\"]}'\n+    )\n+\n+    assert '--deployments-addresses' in gateway_args\n+    deployment_addresses = json.loads(\n+        gateway_args[gateway_args.index('--deployments-addresses') + 1]\n+    )\n+    assert deployment_addresses['executor0'][0].startswith('grpcs://')\n\n\n###\n\n", "completion": "fix: sandbox usage from k8s/docker-compose (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -156,6 +156,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -13002,3 +13003,32 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```abbd95a3```](https://github.com/jina-ai/jina/commit/abbd95a389eeb5e3ccc2c972e909c241baf9ed1c)] __-__ fix readme (*Han Xiao*)\n  - [[```3497abf5```](https://github.com/jina-ai/jina/commit/3497abf525914b19834342b9a5ebd2f04b75bc48)] __-__ __version__: the next version will be 3.3.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-4></a>\n+## Release Note (`3.3.4`)\n+\n+> Release time: 2022-04-21 12:56:57\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ cristian,  Joan Fontanals,  felix-wang,  Tobias Jacobowitz,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```2c72e770```](https://github.com/jina-ai/jina/commit/2c72e77077d1ff9915bce5097de09b02ca05a92a)] __-__ pass extra search paths given from args (#4651) (*felix-wang*)\n+ - [[```8a3083f8```](https://github.com/jina-ai/jina/commit/8a3083f89a7b6d5a846e72c24555c76e3299f089)] __-__ relax time constraint in block exec test (#4653) (*Tobias Jacobowitz*)\n+ - [[```e92e26cc```](https://github.com/jina-ai/jina/commit/e92e26cc7af3e494cbbd82721d787a1f34e10f09)] __-__ better reporting of errors in the head (#4640) (*Johannes Messner*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```b76d4774```](https://github.com/jina-ai/jina/commit/b76d47746753310b3e8601df1c12ed0a70792f32)] __-__ remove runtime backend cli arg (#4644) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```d2161e66```](https://github.com/jina-ai/jina/commit/d2161e66e80c4a816f48ac3adc0140f011d52d29)] __-__ fix admonition in access flow page (#4655) (*cristian*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```9140b134```](https://github.com/jina-ai/jina/commit/9140b134034812a3ee3bd717c059634f89f43896)] __-__ __version__: the next version will be 3.3.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -59,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.4'\n+__version__ = '3.3.5'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.5"}
{"prompt": " file path A: docs/fundamentals/flow/access-flow-api.md | file path B: docs/fundamentals/flow/access-flow-api.md\n\n@@ -315,10 +315,10 @@ We use [subprotocols](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket\n The Flow defaults to `json` when a subprotocol is not passed during connection establishment (Our Python client uses `bytes` streaming by using [jina.proto](../../proto/docs.md) definition).\n \n \n-````{admonition} Note\n+````{admonition} Hint\n \n-- Choose Websocket over HTTP, if you want to stream requests. \n-- Choose Websocket over gRPC, if\n+- Choose Websocket over HTTP if you want to stream requests. \n+- Choose Websocket over gRPC if\n   - you want to stream using JSON, not bytes\n   - your client language doesn't support gRPC\n   - you don't want to compile the [Protobuf definitions](../../proto/docs.md) for your gRPC client\n\n\n###\n\n", "completion": "docs: fix admonition in access flow page (#<issue-num>)"}
{"prompt": " file path A: jina/jaml/__init__.py | file path B: jina/jaml/__init__.py\n\n@@ -724,7 +724,7 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n                     no_tag_yml,\n                     extra_search_paths=(_extra_search_paths + [os.path.dirname(s_path)])\n                     if s_path\n-                    else None,\n+                    else _extra_search_paths,\n                 )\n \n             from jina.orchestrate.flow.base import Flow\n\n\n###\n\n", "completion": "fix: pass extra search paths given from args (#<issue-num>)"}
{"prompt": " file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -501,7 +501,7 @@ async def test_blocking_sync_exec():\n     end_time = time.time()\n \n     assert all(result.docs.texts == ['BlockingExecutor'] for result in results)\n-    assert end_time - start_time < (REQUEST_COUNT * SLEEP_TIME) + 0.2\n+    assert end_time - start_time < (REQUEST_COUNT * SLEEP_TIME) * 2.0\n \n     cancel_event.set()\n     runtime_thread.join()\n\n\n###\n\n", "completion": "fix: relax time constraint in block exec test (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -209,7 +209,9 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n                 else '',\n                 exc_info=not self.args.quiet_error,\n             )\n-            raise\n+            requests[0].add_exception(ex, executor=None)\n+            context.set_trailing_metadata((('is-error', 'true'),))\n+            return requests[0]\n \n     async def process_control(self, request: ControlRequest, *args) -> ControlRequest:\n         \"\"\"\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_except.py\n\n@@ -2,11 +2,11 @@ import os\n \n import numpy as np\n import pytest\n+from docarray.document.generators import from_ndarray\n \n-from jina import Flow, Executor, requests, Document\n+from jina import Document, Executor, Flow, requests\n from jina.excepts import RuntimeFailToStart\n from jina.proto import jina_pb2\n-from docarray.document.generators import from_ndarray\n from tests import validate_callback\n \n \n@@ -263,3 +263,23 @@ def test_flow_does_not_import_exec_depencies():\n     with pytest.raises(RuntimeFailToStart):\n         with f:\n             pass\n+\n+\n+def test_flow_head_runtime_failure(monkeypatch, capfd):\n+    from jina.serve.runtimes.request_handlers.data_request_handler import (\n+        DataRequestHandler,\n+    )\n+\n+    def fail(*args, **kwargs):\n+        raise NotImplementedError('Intentional error')\n+\n+    monkeypatch.setattr(DataRequestHandler, 'merge_routes', fail)\n+\n+    with Flow().add(shards=2) as f:\n+        f.index(\n+            [Document(text='abbcs')],\n+        )\n+\n+    out, err = capfd.readouterr()\n+    assert 'NotImplementedError' in out\n+    assert 'Intentional error' in out\n\n---\n file path A: tests/unit/serve/runtimes/head/test_head_runtime.py | file path B: tests/unit/serve/runtimes/head/test_head_runtime.py\n\n@@ -49,10 +49,10 @@ def test_control_message_processing():\n     cancel_event, handle_queue, runtime_thread = _create_runtime(args)\n \n     # no connection registered yet\n-    with pytest.raises(RpcError):\n-        GrpcConnectionPool.send_request_sync(\n-            _create_test_data_message(), f'{args.host}:{args.port}'\n-        )\n+    resp = GrpcConnectionPool.send_request_sync(\n+        _create_test_data_message(), f'{args.host}:{args.port}'\n+    )\n+    assert resp.status.code == resp.status.ERROR\n \n     _add_worker(args, 'ip1')\n     # after adding a connection, sending should work\n@@ -63,10 +63,10 @@ def test_control_message_processing():\n \n     _remove_worker(args, 'ip1')\n     # after removing the connection again, sending does not work anymore\n-    with pytest.raises(RpcError):\n-        GrpcConnectionPool.send_request_sync(\n-            _create_test_data_message(), f'{args.host}:{args.port}'\n-        )\n+    resp = GrpcConnectionPool.send_request_sync(\n+        _create_test_data_message(), f'{args.host}:{args.port}'\n+    )\n+    assert resp.status.code == resp.status.ERROR\n \n     _destroy_runtime(args, cancel_event, runtime_thread)\n \n\n\n###\n\n", "completion": "fix: better reporting of errors in the head (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -155,6 +155,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12980,3 +12981,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```e0367473```](https://github.com/jina-ai/jina/commit/e03674731a7032035cdf6019b0492a58badffeab)] __-__ remove legacy codebooks and figures (#4530) (*Wang Bo*)\n  - [[```17172d5f```](https://github.com/jina-ai/jina/commit/17172d5f8a193480ded73babd0dc4ba5cc3a51c5)] __-__ __version__: the next version will be 3.2.9 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-3></a>\n+## Release Note (`3.3.3`)\n+\n+> Release time: 2022-04-21 09:43:24\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Jina Dev Bot,  Han Xiao,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```0f38f711```](https://github.com/jina-ai/jina/commit/0f38f711fa471abdc6e3e662b44e6e09eff6587b)] __-__ remove prometheus import from the top of the files (#4641) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```712cccb8```](https://github.com/jina-ai/jina/commit/712cccb86b1e07bec6b8b51598c1400333c5de99)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```abbd95a3```](https://github.com/jina-ai/jina/commit/abbd95a389eeb5e3ccc2c972e909c241baf9ed1c)] __-__ fix readme (*Han Xiao*)\n+ - [[```3497abf5```](https://github.com/jina-ai/jina/commit/3497abf525914b19834342b9a5ebd2f04b75bc48)] __-__ __version__: the next version will be 3.3.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -59,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.3'\n+__version__ = '3.3.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.4"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -157,6 +157,33 @@ jobs:\n           flags: ${{ steps.test.outputs.codecov_flag }}\n           fail_ci_if_error: false\n \n+  import-test:\n+    runs-on: ubuntu-latest\n+    needs: [ commit-lint, lint-flake-8, code-injection ]\n+    strategy:\n+      fail-fast: false\n+      matrix:\n+        core: ['', 'true']\n+        perf: ['', 'true']\n+        exclude: \n+          - core: 'true'\n+            perf: 'true'\n+    steps:\n+      - uses: actions/checkout@v2\n+      - name: Set up Python 3.7\n+        uses: actions/setup-python@v2\n+        with:\n+          python-version: 3.7\n+      - name: Prepare enviroment\n+        run: |\n+          python -m pip install --upgrade pip\n+          python -m pip install wheel\n+          pip install --no-cache-dir .\n+        env:\n+          JINA_PIP_INSTALL_CORE: ${{ matrix.core }}\n+          JINA_PIP_INSTALL_PERF: ${{ matrix.perf }}\n+      - name: Test basic import\n+        run: python -c 'from jina import Executor,requests'\n   docker-image-test:\n     needs: update-schema\n     runs-on: ubuntu-latest\n@@ -317,7 +344,7 @@ jobs:\n   # just for blocking the merge until all parallel core-test are successful\n   success-all-steps:\n     runs-on: ubuntu-latest\n-    needs: [core-test, hub-test, k8s-test, docker-compose-test, docker-image-test, benchmark-pre-release, update-schema, update-docker]\n+    needs: [core-test, import-test, hub-test, k8s-test, docker-compose-test, docker-image-test, benchmark-pre-release, update-schema, update-docker]\n     if: always()\n     steps:\n       - uses: technote-space/workflow-conclusion-action@v2\n\n---\n file path A: .github/workflows/ci.yml | file path B: .github/workflows/ci.yml\n\n@@ -304,10 +304,39 @@ jobs:\n           flags: ${{ steps.test.outputs.codecov_flag }}\n           fail_ci_if_error: false\n \n+  import-test:\n+    runs-on: ubuntu-latest\n+    needs: [ commit-lint, lint-flake-8, code-injection ]\n+    strategy:\n+      fail-fast: false\n+      matrix:\n+        core: ['', 'true']\n+        perf: ['', 'true']\n+        exclude: \n+          - core: 'true'\n+            perf: 'true'\n+    steps:\n+      - uses: actions/checkout@v2\n+      - name: Set up Python 3.7\n+        uses: actions/setup-python@v2\n+        with:\n+          python-version: 3.7\n+      - name: Prepare enviroment\n+        run: |\n+          python -m pip install --upgrade pip\n+          python -m pip install wheel\n+          pip install --no-cache-dir .\n+        env:\n+          JINA_PIP_INSTALL_CORE: ${{ matrix.core }}\n+          JINA_PIP_INSTALL_PERF: ${{ matrix.perf }}\n+      - name: Test basic import\n+        run: python -c 'from jina import Executor,requests'\n+\n+\n   # just for blocking the merge until all parallel core-test are successful\n   success-all-test:\n     runs-on: ubuntu-latest\n-    needs: [core-test, hub-test, k8s-test, docker-compose-test, docker-image-test, check-docstring, check-black, code-injection]\n+    needs: [core-test, import-test, hub-test, k8s-test, docker-compose-test, docker-image-test, check-docstring, check-black, code-injection]\n     if: always()\n     steps:\n       - uses: technote-space/workflow-conclusion-action@v2\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -6,11 +6,10 @@ import warnings\n from types import SimpleNamespace\n from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union\n \n-from prometheus_client import Summary\n-\n from jina import __args_executor_init__, __default_endpoint__\n from jina.enums import BetterEnum\n from jina.helper import ArgNamespace, T, iscoroutinefunction, typename\n+from jina.importer import ImportExtensions\n from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n from jina.serve.executors.decorators import requests, store_init_kwargs, wrap_func\n \n@@ -115,7 +114,16 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             self.runtime_args = SimpleNamespace()\n \n     def _init_monitoring(self):\n-        if hasattr(self.runtime_args, 'metrics_registry'):\n+        if (\n+            hasattr(self.runtime_args, 'metrics_registry')\n+            and self.runtime_args.metrics_registry\n+        ):\n+            with ImportExtensions(\n+                required=True,\n+                help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n+            ):\n+                from prometheus_client import Summary\n+\n             self._summary_method = Summary(\n                 'process_request_seconds',\n                 'Time spent when calling the executor request method',\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -14,12 +14,12 @@ from typing import (\n     Union,\n )\n \n-from prometheus_client import Summary\n-\n from jina.helper import convert_tuple_to_list, iscoroutinefunction\n from jina.serve.executors.metas import get_default_metas\n \n if TYPE_CHECKING:\n+    from prometheus_client import Summary\n+\n     from jina import DocumentArray\n \n \n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -12,6 +12,7 @@ from grpc_reflection.v1alpha.reflection_pb2 import ServerReflectionRequest\n from grpc_reflection.v1alpha.reflection_pb2_grpc import ServerReflectionStub\n \n from jina.enums import PollingType\n+from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n from jina.proto import jina_pb2_grpc\n from jina.types.request import Request\n@@ -408,7 +409,11 @@ class GrpcConnectionPool:\n         )\n \n         if metrics_registry:\n-            from prometheus_client import Summary\n+            with ImportExtensions(\n+                required=True,\n+                help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n+            ):\n+                from prometheus_client import Summary\n \n             self._summary_time = Summary(\n                 'sending_request_seconds',\n\n---\n file path A: jina/serve/runtimes/gateway/request_handling.py | file path B: jina/serve/runtimes/gateway/request_handling.py\n\n@@ -5,6 +5,7 @@ from typing import TYPE_CHECKING, Callable, List, Optional\n \n from docarray import DocumentArray\n \n+from jina.importer import ImportExtensions\n from jina.serve.networking import GrpcConnectionPool\n from jina.serve.runtimes.gateway.graph.topology_graph import TopologyGraph\n \n@@ -25,7 +26,11 @@ class RequestHandler:\n         self.request_init_time = {} if metrics_registry else None\n \n         if metrics_registry:\n-            from prometheus_client import Summary\n+            with ImportExtensions(\n+                required=True,\n+                help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n+            ):\n+                from prometheus_client import Summary\n \n             self._summary = Summary(\n                 'receiving_request_seconds',\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -13,6 +13,7 @@ import grpc\n from grpc_reflection.v1alpha import reflection\n \n from jina.enums import PollingType\n+from jina.importer import ImportExtensions\n from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.networking import GrpcConnectionPool\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n@@ -54,7 +55,11 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n         )\n \n         if self.metrics_registry:\n-            from prometheus_client import Summary\n+            with ImportExtensions(\n+                required=True,\n+                help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n+            ):\n+                from prometheus_client import Summary\n \n             self._summary = Summary(\n                 'receiving_request_seconds',\n\n---\n file path A: jina/serve/runtimes/monitoring.py | file path B: jina/serve/runtimes/monitoring.py\n\n@@ -1,11 +1,6 @@\n-from prometheus_client import CollectorRegistry\n-\n-\n class MonitoringMixin:\n     \"\"\"The Monitoring Mixin for pods\"\"\"\n \n-    metrics_registry: CollectorRegistry\n-\n     def _setup_monitoring(self):\n         \"\"\"\n         Wait for the monitoring server to start\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -9,6 +9,7 @@ from typing import List, Optional, Union\n import grpc\n from grpc_reflection.v1alpha import reflection\n \n+from jina.importer import ImportExtensions\n from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n from jina.serve.runtimes.request_handlers.data_request_handler import DataRequestHandler\n@@ -41,7 +42,11 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         await self._async_setup_grpc_server()\n \n         if self.metrics_registry:\n-            from prometheus_client import Summary\n+            with ImportExtensions(\n+                required=True,\n+                help_text='You need to install the `prometheus_client` to use the montitoring functionality of jina',\n+            ):\n+                from prometheus_client import Summary\n \n             self._summary_time = Summary(\n                 'receiving_request_seconds',\n\n\n###\n\n", "completion": "fix: remove prometheus import from the top of the files (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -154,6 +154,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12916,3 +12917,65 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```e122d894```](https://github.com/jina-ai/jina/commit/e122d89420ac3f87e8c0cce06ee50fa79e036636)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n  - [[```dac21509```](https://github.com/jina-ai/jina/commit/dac2150965ce2585dabd5e86283273f616c5fa73)] __-__ __version__: the next version will be 3.3.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-2></a>\n+## Release Note (`3.3.2`)\n+\n+> Release time: 2022-04-20 14:23:02\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  samsja,  Zhaofeng Miao,  Johannes Messner,  Han Xiao,  cristian,  Jina Dev Bot,  joschkabraun,  Tobias Jacobowitz,  Roshan Jossy,  Wang Bo,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```daff8440```](https://github.com/jina-ai/jina/commit/daff84402a5cd8f0f2a3c17c4aa42be89bf4d658)] __-__ add receiving request second to gateway and head (#4638) (*samsja*)\n+ - [[```9136be81```](https://github.com/jina-ai/jina/commit/9136be81557917c9250b77a237da6baf49a6e267)] __-__ add process request seconds for executor (#4635) (*samsja*)\n+ - [[```a0844f72```](https://github.com/jina-ai/jina/commit/a0844f72c467bc07ec661202540f08b79aa1b9e3)] __-__ __client__: add total_docs to client post kwargs (*Han Xiao*)\n+ - [[```dd5f08e9```](https://github.com/jina-ai/jina/commit/dd5f08e9d0c535de2f0e6b106db3b21c597752cd)] __-__ add grpc tls support on gateway (#4522) (*samsja*)\n+ - [[```0ff05200```](https://github.com/jina-ai/jina/commit/0ff0520039d0b3a15ac84afeaf9575dcc52c9c05)] __-__ __client__: add total_docs to client post kwargs (#4528) (*Han Xiao*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```7d9be4e2```](https://github.com/jina-ai/jina/commit/7d9be4e2969d33b251997b7f847d4ba140bea61c)] __-__ fix flow plot with private executor (#4643) (*Joan Fontanals*)\n+ - [[```608670b9```](https://github.com/jina-ai/jina/commit/608670b9efbbc0e711573d2bb7abc4d024e62c32)] __-__ remove force interactive in rich console (#4614) (*samsja*)\n+ - [[```ded90ea0```](https://github.com/jina-ai/jina/commit/ded90ea03ebbcb74f9aa3e65d6b482dbb617abc7)] __-__ prometheus client requirements to match conda package (#4606) (*Joan Fontanals*)\n+ - [[```929054e3```](https://github.com/jina-ai/jina/commit/929054e347011e9ad1f2d39db009965054b1f843)] __-__ 8080 as default gateway port in k8s (#4605) (*Tobias Jacobowitz*)\n+ - [[```59e14986```](https://github.com/jina-ai/jina/commit/59e149862342ffb59c531c0dfee4e094b3007e9d)] __-__ pin black version (#4557) (*Tobias Jacobowitz*)\n+ - [[```d1f08482```](https://github.com/jina-ai/jina/commit/d1f08482f1a2cd9f871faa2b161e48b667388130)] __-__ install linkerd in cd pipeline (#4552) (*Tobias Jacobowitz*)\n+ - [[```0f008bc2```](https://github.com/jina-ai/jina/commit/0f008bc281b681e779cdd2fc1daf2be9ea87271d)] __-__ client args are now parse in the client function (#4549) (*samsja*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```73718c98```](https://github.com/jina-ai/jina/commit/73718c980fb9e1d7bf1337d71cdf8a528209beb5)] __-__ avoid threadpool (#4633) (*Joan Fontanals*)\n+ - [[```94f24dc1```](https://github.com/jina-ai/jina/commit/94f24dc1ba4a471512d19ae49fbc65cca43853ca)] __-__ __monitoring__: add jina namespace to current metrics (#4636) (*samsja*)\n+ - [[```2ce76751```](https://github.com/jina-ai/jina/commit/2ce767517532ebbf85ade4b84cfba0f7bb69c4f9)] __-__ remove jinad (#4550) (*Tobias Jacobowitz*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```218a31c9```](https://github.com/jina-ai/jina/commit/218a31c9cbe2128aaaa24b1f05cf2380e3a5ea1d)] __-__ __sandbox__: sandbox is serverless now (#4639) (*Zhaofeng Miao*)\n+ - [[```8e9714ee```](https://github.com/jina-ai/jina/commit/8e9714ee9e2b73e9f15894a077f84fd4b84ca717)] __-__ restructure flow yaml instructions (#4574) (*Johannes Messner*)\n+ - [[```9892ae11```](https://github.com/jina-ai/jina/commit/9892ae11077c7b5578e7f0c96057bb18b167203c)] __-__ add postman collection (#4623) (*cristian*)\n+ - [[```aa6238b1```](https://github.com/jina-ai/jina/commit/aa6238b13c2c49cfcc98f5ddf30cc5117f78f35b)] __-__ remove needless python api page (#4620) (*cristian*)\n+ - [[```6dbcd806```](https://github.com/jina-ai/jina/commit/6dbcd806e8bcf57fd3b948877bdee121a16fa167)] __-__ renamed function to be named differently from property (#4610) (*joschkabraun*)\n+ - [[```c630b515```](https://github.com/jina-ai/jina/commit/c630b5154cead90952443143ce00191bfbd5104b)] __-__ mention scaling of gateway (#4609) (*Tobias Jacobowitz*)\n+ - [[```e3607334```](https://github.com/jina-ai/jina/commit/e3607334c2afd548cf74664f9e75fbe5b31767aa)] __-__ __tracking__: add scarf tracking (#4553) (*Roshan Jossy*)\n+ - [[```953206fa```](https://github.com/jina-ai/jina/commit/953206fabc3984451c1d9713fce6bda33d22a70e)] __-__ explain https support (#4500) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```e4fba28b```](https://github.com/jina-ai/jina/commit/e4fba28b3a9aec759b7a2170262d78001c4047de)] __-__ add logo (*Han Xiao*)\n+ - [[```1775edfa```](https://github.com/jina-ai/jina/commit/1775edfa3fa7b696de9858630179bcbdf7054925)] __-__ fix workflow (*Han Xiao*)\n+ - [[```7f06a0a7```](https://github.com/jina-ai/jina/commit/7f06a0a773bfb9c4c0487aafec956158c53b7e02)] __-__ fix readme (*Han Xiao*)\n+ - [[```9f53566e```](https://github.com/jina-ai/jina/commit/9f53566e692a73c25c6a21012d8dfa1ba846a03c)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```49774fb2```](https://github.com/jina-ai/jina/commit/49774fb2ac419fd645d203858c9929d23b83c229)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```7363f5bf```](https://github.com/jina-ai/jina/commit/7363f5bf2b6f3e435e1b38f146d6a70215c27fb3)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```913b681a```](https://github.com/jina-ai/jina/commit/913b681a04aeacd2fb8cf3b050469074e6ed1995)] __-__ __version__: the next version will be 3.3.2 (*Jina Dev Bot*)\n+ - [[```dac21509```](https://github.com/jina-ai/jina/commit/dac2150965ce2585dabd5e86283273f616c5fa73)] __-__ __version__: the next version will be 3.3.1 (*Jina Dev Bot*)\n+ - [[```58547ea4```](https://github.com/jina-ai/jina/commit/58547ea43416260c9c92a869c0a1247b0b8f06c0)] __-__ bump version (#4604) (*Joan Fontanals*)\n+ - [[```5b292a3f```](https://github.com/jina-ai/jina/commit/5b292a3f67c75f8fd71d37a9f7cd4922c04a1e99)] __-__ __version__: the next version will be 3.2.10 (*Jina Dev Bot*)\n+ - [[```fbaad7ed```](https://github.com/jina-ai/jina/commit/fbaad7edf276cd3c74cea073cf5d0c7af95ee9af)] __-__ __docs__: add banner (*Han Xiao*)\n+ - [[```e0367473```](https://github.com/jina-ai/jina/commit/e03674731a7032035cdf6019b0492a58badffeab)] __-__ remove legacy codebooks and figures (#4530) (*Wang Bo*)\n+ - [[```17172d5f```](https://github.com/jina-ai/jina/commit/17172d5f8a193480ded73babd0dc4ba5cc3a51c5)] __-__ __version__: the next version will be 3.2.9 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -59,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.2'\n+__version__ = '3.3.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.3"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1271,12 +1271,6 @@ def iscoroutinefunction(func: Callable):\n     return inspect.iscoroutinefunction(func)\n \n \n-async def run_in_threadpool(func: Callable, executor=None, *args, **kwargs):\n-    return await get_or_reuse_loop().run_in_executor(\n-        executor, functools.partial(func, *args, **kwargs)\n-    )\n-\n-\n def run_async(func, *args, **kwargs):\n     \"\"\"Generalized asyncio.run for jupyter notebook.\n \n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -2,9 +2,7 @@ import inspect\n import multiprocessing\n import os\n import threading\n-import uuid\n import warnings\n-from concurrent.futures import ThreadPoolExecutor\n from types import SimpleNamespace\n from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union\n \n@@ -12,13 +10,7 @@ from prometheus_client import Summary\n \n from jina import __args_executor_init__, __default_endpoint__\n from jina.enums import BetterEnum\n-from jina.helper import (\n-    ArgNamespace,\n-    T,\n-    iscoroutinefunction,\n-    run_in_threadpool,\n-    typename,\n-)\n+from jina.helper import ArgNamespace, T, iscoroutinefunction, typename\n from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n from jina.serve.executors.decorators import requests, store_init_kwargs, wrap_func\n \n@@ -111,7 +103,6 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         :param runtime_args: a dict of arguments injected from :class:`Runtime` during runtime\n         :param kwargs: additional extra keyword arguments to avoid failing when extra params ara passed that are not expected\n         \"\"\"\n-        self._thread_pool = ThreadPoolExecutor(max_workers=1)\n         self._add_metas(metas)\n         self._add_requests(requests)\n         self._add_runtime_args(runtime_args)\n@@ -254,7 +245,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         if iscoroutinefunction(func):\n             return await func(self, **kwargs)\n         else:\n-            return await run_in_threadpool(func, self._thread_pool, self, **kwargs)\n+            return func(self, **kwargs)\n \n     @property\n     def workspace(self) -> Optional[str]:\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -1,6 +1,10 @@\n+import asyncio\n+import multiprocessing\n import os\n+import time\n from copy import deepcopy\n-from pathlib import Path\n+from multiprocessing import Process\n+from threading import Event\n from unittest import mock\n \n import pytest\n@@ -8,8 +12,13 @@ import yaml\n from docarray import Document, DocumentArray\n \n from jina import Client, Executor, Flow, requests\n+from jina.clients.request import request_generator\n+from jina.parsers import set_pod_parser\n from jina.serve.executors import ReducerExecutor\n from jina.serve.executors.metas import get_default_metas\n+from jina.serve.networking import GrpcConnectionPool\n+from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n+from jina.serve.runtimes.worker import WorkerRuntime\n \n PORT = 12350\n \n@@ -435,3 +444,64 @@ def test_to_docker_compose_yaml(tmpdir, exec_type):\n             assert services['gateway']['ports'][0] == '2020:2020'\n             gateway_args = services['gateway']['command']\n             assert gateway_args[gateway_args.index('--port') + 1] == '2020'\n+\n+\n+def _create_test_data_message(counter=0):\n+    return list(request_generator('/', DocumentArray([Document(text=str(counter))])))[0]\n+\n+\n+@pytest.mark.asyncio\n+async def test_blocking_sync_exec():\n+    SLEEP_TIME = 0.01\n+    REQUEST_COUNT = 100\n+\n+    class BlockingExecutor(Executor):\n+        @requests\n+        def foo(self, docs: DocumentArray, **kwargs):\n+            time.sleep(SLEEP_TIME)\n+            for doc in docs:\n+                doc.text = 'BlockingExecutor'\n+            return docs\n+\n+    args = set_pod_parser().parse_args(['--uses', 'BlockingExecutor'])\n+\n+    cancel_event = multiprocessing.Event()\n+\n+    def start_runtime(args, cancel_event):\n+        with WorkerRuntime(args, cancel_event) as runtime:\n+            runtime.run_forever()\n+\n+    runtime_thread = Process(\n+        target=start_runtime,\n+        args=(args, cancel_event),\n+        daemon=True,\n+    )\n+    runtime_thread.start()\n+\n+    assert AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=5.0,\n+        ctrl_address=f'{args.host}:{args.port}',\n+        ready_or_shutdown_event=Event(),\n+    )\n+\n+    send_tasks = []\n+    start_time = time.time()\n+    for i in range(REQUEST_COUNT):\n+        send_tasks.append(\n+            asyncio.create_task(\n+                GrpcConnectionPool.send_request_async(\n+                    _create_test_data_message(),\n+                    target=f'{args.host}:{args.port}',\n+                    timeout=3.0,\n+                )\n+            )\n+        )\n+\n+    results = await asyncio.gather(*send_tasks)\n+    end_time = time.time()\n+\n+    assert all(result.docs.texts == ['BlockingExecutor'] for result in results)\n+    assert end_time - start_time < (REQUEST_COUNT * SLEEP_TIME) + 0.2\n+\n+    cancel_event.set()\n+    runtime_thread.join()\n\n\n###\n\n", "completion": "refactor: avoid threadpool (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -757,7 +757,8 @@ class Deployment(BaseDeployment):\n                     ]  # all the uses should be the same but let's keep it this\n                     # way\n                     for rep_i, (name, use) in enumerate(zip(names, uses)):\n-                        shard_mermaid_graph.append(f'{name}[{use}]:::pod;')\n+                        escaped_uses = f'\"{use}\"'\n+                        shard_mermaid_graph.append(f'{name}[{escaped_uses}]:::pod;')\n                     shard_mermaid_graph.append('end;')\n                     shard_mermaid_graph = [\n                         node.replace(';', '\\n') for node in shard_mermaid_graph\n@@ -766,18 +767,20 @@ class Deployment(BaseDeployment):\n                     mermaid_graph.append('\\n')\n                 if uses_before_name is not None:\n                     for shard_name in shard_names:\n+                        escaped_uses_before_uses = f'\"{uses_before_uses}\"'\n                         mermaid_graph.append(\n-                            f'{self.args.name}-head[{uses_before_uses}]:::HEADTAIL --> {shard_name};'\n+                            f'{self.args.name}-head[{escaped_uses_before_uses}]:::HEADTAIL --> {shard_name};'\n                         )\n                 if uses_after_name is not None:\n                     for shard_name in shard_names:\n+                        escaped_uses_after_uses = f'\"{uses_after_uses}\"'\n                         mermaid_graph.append(\n-                            f'{shard_name} --> {self.args.name}-tail[{uses_after_uses}]:::HEADTAIL;'\n+                            f'{shard_name} --> {self.args.name}-tail[{escaped_uses_after_uses}]:::HEADTAIL;'\n                         )\n             else:\n                 # single shard case, no uses_before or uses_after_considered\n                 name = list(self.pod_args['pods'].values())[0][0].name\n-                uses = list(self.pod_args['pods'].values())[0][0].uses\n+                uses = f'\"{list(self.pod_args[\"pods\"].values())[0][0].uses}\"'\n                 num_replicas = list(self.pod_args['pods'].values())[0][0].replicas\n \n                 # just put the replicas in parallel\n@@ -786,5 +789,6 @@ class Deployment(BaseDeployment):\n                         mermaid_graph.append(f'{name}/rep-{rep_i}[{uses}]:::pod;')\n                 else:\n                     mermaid_graph.append(f'{name}[{uses}]:::pod;')\n+\n             mermaid_graph.append('end;')\n         return mermaid_graph\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1345,7 +1345,8 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         # plot subgraphs\n         for node, v in self._deployment_nodes.items():\n             deployment_nodes.append(v.name)\n-            mermaid_graph.extend(v._mermaid_str)\n+            deployment_mermaid = v._mermaid_str\n+            mermaid_graph.extend(deployment_mermaid)\n \n         for node, v in self._deployment_nodes.items():\n             for need in sorted(v.needs):\n\n\n###\n\n", "completion": "fix: fix flow plot with private executor (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/sandbox.md | file path B: docs/how-to/sandbox.md\n\n@@ -31,7 +31,7 @@ This starts a Flow that only has one Executor, and sends a Document to it. The D\n \n ## Sandbox Lifecycle\n \n-The sandbox will not be removed immediately after the Flow is closed. It will be kept alive until there is no traffic during this certain period. The default period is currently 15 minutes.\n+Sandbox is serverless. It will not be removed immediately after the Flow is closed but kept alive for several minutes. If there is no traffic, it will automatically scale down to 0 to save resources, but it will restart again and give the response whenever a new request is sent to the same Sandbox.\n \n **Sandbox will be shared with other users**. Sometimes you will start the sandbox very quickly because the other users already started it.\n \n\n\n###\n\n", "completion": "docs(sandbox): sandbox is serverless now (#<issue-num>)"}
{"prompt": " file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -8,6 +8,8 @@ from concurrent.futures import ThreadPoolExecutor\n from types import SimpleNamespace\n from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union\n \n+from prometheus_client import Summary\n+\n from jina import __args_executor_init__, __default_endpoint__\n from jina.enums import BetterEnum\n from jina.helper import (\n@@ -113,6 +115,7 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         self._add_metas(metas)\n         self._add_requests(requests)\n         self._add_runtime_args(runtime_args)\n+        self._init_monitoring()\n \n     def _add_runtime_args(self, _runtime_args: Optional[Dict]):\n         if _runtime_args:\n@@ -120,6 +123,18 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         else:\n             self.runtime_args = SimpleNamespace()\n \n+    def _init_monitoring(self):\n+        if hasattr(self.runtime_args, 'metrics_registry'):\n+            self._summary_method = Summary(\n+                'process_request_seconds',\n+                'Time spent when calling the executor request method',\n+                registry=self.runtime_args.metrics_registry,\n+                namespace='jina',\n+                labelnames=('method', 'executor'),\n+            )\n+        else:\n+            self._summary_method = None\n+\n     def _add_requests(self, _requests: Optional[Dict]):\n         if not hasattr(self, 'requests'):\n             self.requests = {}\n\n---\n file path A: jina/serve/executors/decorators.py | file path B: jina/serve/executors/decorators.py\n\n@@ -1,12 +1,23 @@\n \"\"\"Decorators and wrappers designed for wrapping :class:`BaseExecutor` functions. \"\"\"\n-\n+import contextlib\n import functools\n import inspect\n from functools import wraps\n-from typing import Callable, Union, List, Optional, Dict, Sequence, TYPE_CHECKING\n+from typing import (\n+    TYPE_CHECKING,\n+    Callable,\n+    ContextManager,\n+    Dict,\n+    List,\n+    Optional,\n+    Sequence,\n+    Union,\n+)\n+\n+from prometheus_client import Summary\n \n-from jina.serve.executors.metas import get_default_metas\n from jina.helper import convert_tuple_to_list, iscoroutinefunction\n+from jina.serve.executors.metas import get_default_metas\n \n if TYPE_CHECKING:\n     from jina import DocumentArray\n@@ -87,7 +98,7 @@ def requests(\n     :param on: the endpoint string, by convention starts with `/`\n     :return: decorated function\n     \"\"\"\n-    from jina import __default_endpoint__, __args_executor_func__\n+    from jina import __args_executor_func__, __default_endpoint__\n \n     class FunctionMapper:\n         def __init__(self, fn):\n@@ -104,15 +115,29 @@ def requests(\n             if iscoroutinefunction(fn):\n \n                 @functools.wraps(fn)\n-                async def arg_wrapper(*args, **kwargs):\n-                    return await fn(*args, **kwargs)\n+                async def arg_wrapper(\n+                    executor_instance, *args, **kwargs\n+                ):  # we need to get the summary from the executor, so we need to access the self\n+                    with self._get_summary(\n+                        executor_instance._summary_method,\n+                        executor_instance.__class__.__name__,\n+                        fn.__name__,\n+                    ):\n+                        return await fn(executor_instance, *args, **kwargs)\n \n                 self.fn = arg_wrapper\n             else:\n \n                 @functools.wraps(fn)\n-                def arg_wrapper(*args, **kwargs):\n-                    return fn(*args, **kwargs)\n+                def arg_wrapper(\n+                    executor_instance, *args, **kwargs\n+                ):  # we need to get the summary from the executor, so we need to access the self\n+                    with self._get_summary(\n+                        executor_instance._summary_method,\n+                        executor_instance.__class__.__name__,\n+                        fn.__name__,\n+                    ):\n+                        return fn(executor_instance, *args, **kwargs)\n \n                 self.fn = arg_wrapper\n \n@@ -129,6 +154,15 @@ def requests(\n \n             setattr(owner, name, self.fn)\n \n+        def _get_summary(\n+            self, summary: Optional['Summary'], executor_name: str, method_name: str\n+        ) -> ContextManager:\n+            return (\n+                summary.labels(method_name, executor_name).time()\n+                if summary\n+                else contextlib.nullcontext()\n+            )\n+\n     if func:\n         return FunctionMapper(func)\n     else:\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -60,7 +60,9 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         # Keep this initialization order\n         # otherwise readiness check is not valid\n         # The DataRequestHandler needs to be started BEFORE the grpc server\n-        self._data_request_handler = DataRequestHandler(self.args, self.logger)\n+        self._data_request_handler = DataRequestHandler(\n+            self.args, self.logger, self.metrics_registry\n+        )\n \n         self._grpc_server = grpc.aio.server(\n             options=[\n\n---\n file path A: tests/integration/monitoring/test_pod.py | file path B: tests/integration/monitoring/test_monitoring.py\n\n@@ -1,13 +1,20 @@\n+import time\n+\n import pytest\n import requests as req\n+from docarray import DocumentArray\n \n from jina import Executor, Flow, requests\n \n \n class DummyExecutor(Executor):\n-    @requests\n+    @requests(on='/foo')\n     def foo(self, docs, **kwargs):\n-        print('here')\n+        ...\n+\n+    @requests(on='/bar')\n+    def bar(self, docs, **kwargs):\n+        ...\n \n \n def test_enable_monitoring_deployment(port_generator):\n@@ -16,11 +23,19 @@ def test_enable_monitoring_deployment(port_generator):\n \n     with Flow().add(uses=DummyExecutor, monitoring=True, port_monitoring=port1).add(\n         uses=DummyExecutor, monitoring=True, port_monitoring=port2\n-    ):\n+    ) as f:\n         for port in [port1, port2]:\n             resp = req.get(f'http://localhost:{port}/')\n             assert resp.status_code == 200\n \n+        for meth in ['bar', 'foo']:\n+            f.post(f'/{meth}', inputs=DocumentArray())\n+            resp = req.get(f'http://localhost:{port2}/')\n+            assert (\n+                f'process_request_seconds_created{{executor=\"DummyExecutor\",method=\"{meth}\"}}'\n+                in str(resp.content)\n+            )\n+\n \n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n def test_enable_monitoring_gateway(protocol, port_generator):\n@@ -43,7 +58,6 @@ def test_monitoring_head(port_generator):\n     with Flow().add(uses=DummyExecutor, monitoring=True, port_monitoring=port1).add(\n         uses=DummyExecutor, port_monitoring=port2, monitoring=True, shards=2\n     ) as f:\n-\n         port3 = f._deployment_nodes['executor0'].pod_args['pods'][0][0].port_monitoring\n         port4 = f._deployment_nodes['executor1'].pod_args['pods'][0][0].port_monitoring\n \n\n\n###\n\n", "completion": "feat: add process request seconds for executor (#<issue-num>)"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -414,6 +414,7 @@ class GrpcConnectionPool:\n                 'sending_request_seconds',\n                 'Time spent between sending a request to the Pod and receiving the response',\n                 registry=metrics_registry,\n+                namespace='jina',\n             ).time()\n         else:\n             self._summary_time = contextlib.nullcontext()\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -47,6 +47,7 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n                 'receiving_request_seconds',\n                 'Time spent processing request',\n                 registry=self.metrics_registry,\n+                namespace='jina',\n             ).time()\n         else:\n             self._summary_time = contextlib.nullcontext()\n\n\n###\n\n", "completion": "refactor(monitoring): add jina namespace to current metrics (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -3,10 +3,28 @@\n \n Creating a Flow, on its face, means instantiating a Python object.\n More importantly, however, creating and configuring a Flow means defining your {ref}`search microservice architecture <architecture-overview>`.\n+It defines how your Executors are connected together and how your data *flows* through them.\n \n-The most trivial `Flow` is the empty `Flow` as shown below:\n+Every Flow can be defined either purely in Python, or be loaded from a YAML file.\n \n-````{tab} Pythonic style\n+````{admonition} Hint\n+:class: hint\n+\n+For production use we recommend YAML files to configure your Flows.\n+This is because YAML files are:\n+\n+- independent of Python source code\n+- easy to edit, maintain and extend\n+- human-readable\n+\n+````\n+\n+## Instantiate a Flow\n+\n+The most trivial Flow is the empty Flow and, like any other Flow, it can be instantiated purely in Python, or from a\n+YAML file:\n+\n+````{tab} Python\n \n ```python\n from jina import Flow\n@@ -17,7 +35,7 @@ with f:  # Using it as a Context Manager will start the Flow\n ```\n ````\n \n-````{tab} Load from YAML\n+`````{tab} YAML\n `flow.yml`:\n \n ```yaml\n@@ -32,14 +50,21 @@ f = Flow.load_config('flow.yml')  # Load the Flow definition from Yaml file\n with f:  # Using it as a Context Manager will start the Flow\n     f.post(on='/search')  # This sends a request to the /search endpoint of the Flow\n ```\n+\n+````{admonition} Hint: Dump Flow configuration\n+:class: hint\n+\n+In addition to loading a Flow from a YAML file, you can also save an existing Flow configuration to YAML. To do so, execute `f.save_config('path/to/flow.yml')`.\n ````\n+`````\n+\n \n ## Start and stop a Flow\n \n Creating a Flow means defining your microservice architecture, and starting a Flow means launching it.\n When a Flow starts, all its {ref}`added Executors <flow-add-executors>` will start as well, making it possible to {ref}`reach the service through its API <access-flow-api>`.\n \n-Jina `Flow`s are context managers and can be started and stopped using Pythons `with` notation:\n+Jina Flows are context managers and can be started and stopped using Pythons `with` notation:\n \n ```python\n from jina import Flow\n@@ -92,7 +117,7 @@ e.set()  # set event and stop (unblock) the Flow\n ## Add Executors\n A `Flow` orchestrates its Executors as a graph and will send requests to all Executors in the desired order. Executors can be added with the `.add()` method of the `Flow` or be listed in the yaml configuration of a Flow. When you start a `Flow`, it will check the configured Executors and starts instances of these Executors accordingly. When adding Executors you have to define its type with the `uses` keyword. Executors can be used from various sources like code, docker images and the Hub:\n \n-````{tab} Pythonic style\n+````{tab} Python\n \n ```python\n from docarray import Document, DocumentArray\n@@ -124,7 +149,7 @@ with f:  # Using it as a Context Manager will start the Flow\n ```\n ````\n \n-````{tab} Load from YAML\n+`````{tab} YAML\n `flow.yml`:\n \n ```yaml\n@@ -157,6 +182,7 @@ class BarExecutor(Executor):\n         docs.append(Document(text='bar was here'))\n ```\n \n+`main.py`\n ```python\n from jina import Flow\n \n@@ -168,13 +194,32 @@ with f:\n     )  # This sends a request to the /search endpoint of the Flow\n     print(response.texts)\n ```\n+\n+````{admonition} Hint: Load multiple Executors from the same module\n+:class: hint\n+\n+You can override the `metas` attribute for all Executors in a Flow. This allows you to specify a single Python module\n+from which you can then load all of your Executors, without having to specify the module individually for each Executor:\n+\n+```yaml\n+jtype: Flow\n+metas:\n+  py_modules:\n+    - executors.py\n+executors:\n+  - uses: FooExecutor\n+  - uses: BarExecutor\n ```\n+\n+In this example, both `FooExecutor` and `BarExecutor` are defined inside of `executors.py`, and both will be located and loaded by the Flow.\n ````\n+`````\n \n \n The response of the `Flow` defined above is `['foo was here', 'bar was here']`, because the request was first sent to FooExecutor and then to BarExecutor.\n \n-### Executor discovery\n+### Add Executors from different sources\n+\n As explained above, the type of Executor is defined by providing the `uses` keyword. The source of an Executor can be code, docker images or Hub images.\n \n ```python\n@@ -204,69 +249,28 @@ f = (\n \n More complex Executors typically are used from Docker images or will be structured into separate Python modules. \n \n-### Executor from configuration\n-You can use Executors from code, being defined outside your current `PATH` environment variable. To do this you need to define your Executor configuration in a separate configuration yaml, which will be used in the `Flow`:\n+\n+````{admonition} Hint: Load multiple Executors from the same directory\n+:class: hint\n+\n+If you want to load multiple Executor YAMLs from the same directory, you don't need to specify the parent directory for\n+each Executor.\n+Instead, you can configure a common search path for all Executors:\n \n ```\n .\n \u251c\u2500\u2500 app\n \u2502   \u2514\u2500\u2500 \u25b6 main.py\n \u2514\u2500\u2500 executor\n-    \u251c\u2500\u2500 config.yml\n+    \u251c\u2500\u2500 config1.yml\n+    \u251c\u2500\u2500 config2.yml\n     \u2514\u2500\u2500 my_executor.py\n ```\n-`executor/my_executor.py`:\n-```python\n-from docarray import DocumentArray\n-from jina import Executor, requests\n-\n-\n-class MyExecutor(Executor):\n-    @requests\n-    def foo(self, docs: DocumentArray, **kwargs):\n-        pass\n-```\n-\n-`executor/config.yml`:\n-```yaml\n-jtype: MyExecutor\n-metas:\n-  py_modules:\n-    - executor.py\n-```\n \n-Now, in `app/main.py`, to correctly load the Executor, you can specify the directory of the Executor in Python or in a `Flow` yaml:\n-````{tab} Load from Python\n ```{code-block} python\n----\n-emphasize-lines: 3\n----\n-from docarray import Document\n-from jina import Flow\n-f = Flow(extra_search_paths=['../executor']).add(uses='config.yml')\n-with f:\n-    r = f.post('/', inputs=Document())\n+f = Flow(extra_search_paths=['../executor']).add(uses='config1.yml').add(uses='config2.yml')\n ```\n-````\n \n-````{tab} Load from YAML\n-`flow.yml`:\n-```yaml\n-jtype: Flow\n-executors:\n-  - name: executor\n-    uses: ../executor/config.yml\n-```\n-\n-`main.py`:\n-```python\n-from docarray import Document\n-from jina import Flow\n-\n-f = Flow.load_config('../flow/flow.yml')\n-with f:\n-    r = f.post('/', inputs=Document())\n-```\n ````\n \n ### Override Executor configuration\n@@ -523,7 +527,7 @@ print(\n \n ````\n \n-````{tab} Load from YAML\n+````{tab} YAML\n `flow.yml`:\n \n ```yaml\n\n---\n file path A: docs/fundamentals/flow/flow-yaml.md | file path B: None\n\n@@ -1,119 +0,0 @@\n-# Configure a Flow from YAML\n-\n-Instead of constructing a Flow in Python source codes, using a YAML file is the recommended way to configure Flows \n-because it is \n-\n-- independent of the Python source codes,\n-- easy to edit, maintain and extend,\n-- human-readable.\n-\n-## Load and Save a Flow configuration\n-`load_config()` is used to load the Flow configuration from a YAML file. Correspondingly, one uses `save_config()`  to \n-save the Flow configuration. In the following example, `jtype: Flow` in the YAML file tells the parser to construct a \n-`Flow` using this YAML file. \n-\n-`flow.yml`:\n-\n-```yaml\n-jtype: Flow\n-```\n-\n-```python\n-from jina import Flow\n-\n-f = Flow.load_config('flow.yml')  # Load the Flow definition from Yaml file\n-...\n-f.save_config('flow.yml')\n-```\n-\n-## Configure Executors\n-`executors` field in the YAML file is for adding Executors to the Flow. It accepts a list of dictionaries, each of \n-which specifies a configuration of one executor. The dictionary accepts all the arguments from the `add()` method of the \n-Flow. \n-`uses` field is used to define the type of the Executor. As for using a local executor with source codes, the grammar \n-for setting `uses` is the same as that for configuring Executors in a YAML file. As for the other sources, one can \n-assign strings directly, for example `jinahub+sandbox://Hello`. \n-\n-`flow.yml`:\n-\n-```yaml\n-jtype: Flow\n-executors:\n-  - name: local_executor_with_source_codes\n-    uses: \n-      jtype: LocalExecutor\n-      metas:\n-        py_modules:\n-          - executors.py\n-      with:\n-        foo: 'Foo'\n-  - name: sandbox_executor\n-    uses: 'jinahub+sandbox://Hello'\n-```\n-\n-`executors.py`:\n-\n-```python\n-from jina import Executor, requests\n-\n-\n-class LocalExecutor(Executor):\n-    def __init__(self, foo, **kwargs):\n-        super().__init__(**kwargs)\n-        self.foo = foo\n-\n-    @requests\n-    def bar(self, **kwargs):\n-        print(f'foo={self.foo}')\n-```\n-\n-## Configure Flow APIs\n-Use `with` field to configure the Flow APIs. It accepts all the arguments in Flow constructor. In the example below, we \n-set the Flow to serve `http` at the port `45678` with CORS being enabled.\n-\n-```yaml\n-jtype: Flow\n-with:\n-  port: 45678\n-  protocol: 'http'\n-  cors: True\n-```\n-\n-## Configure Flow Meta Information\n-In the case that you want to set the same value for the `metas` attributes in **all** the executors, `metas` field can \n-help. This is very helpful when you use the executors with local source codes and have all of them in one Python module.\n-In the following example, the two executors are defined in the same module.\n-\n-````{tab} Use Flow metas\n-\n-```yaml\n-jtype: Flow\n-metas:\n-  py_modules:\n-    - executors.py\n-executors:\n-  - uses: FooExecutor\n-  - uses: BarExecutor\n-```\n-\n-````\n-\n-````{tab} Use Executor metas\n-\n-```yaml\n-jtype: Flow\n-executors:\n-  - uses:\n-      jtype: FooExecutor\n-      metas:\n-        py_modules:\n-          - executors.py\n-  - uses:\n-      jtype: BarExecutor\n-      metas:\n-        py_modules:\n-          - executors.py\n-```\n-\n-````\n-\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -142,7 +142,6 @@ Executor and Flow are the two fundamental concepts in Jina.\n :hidden:\n \n create-flow\n-flow-yaml\n flow-api\n access-flow-api\n client\n\n\n###\n\n", "completion": "docs: restructure flow yaml instructions (#<issue-num>)"}
{"prompt": " file path A: None | file path B: docs/_static/JCloud-dark.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"320px\" height=\"320px\" viewBox=\"0 0 320 320\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>JCloud-dark</title>\n+    <g id=\"JCloud-dark\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4\">\n+            <rect id=\"\u77e9\u5f62\u5907\u4efd-11\" fill-rule=\"nonzero\" x=\"0\" y=\"0\" width=\"320\" height=\"320\"></rect>\n+            <g id=\"\u7f16\u7ec4-4\u5907\u4efd\" transform=\"translate(20.000000, 60.000000)\">\n+                <path d=\"M256,79.8170732 C269.254834,79.8170732 280,90.5622392 280,103.817073 L280,163 C280,176.254834 269.254834,187 256,187 L196.571429,187 C183.316595,187 172.571429,176.254834 172.571429,163 L172.571429,103.817073 C172.571429,90.5622392 183.316595,79.8170732 196.571429,79.8170732 L256,79.8170732 Z M198.169366,110.093818 C195.503074,108.649809 192.149146,109.552333 190.574155,112.183335 L190.574155,112.183335 L190.444918,112.410652 C189.004211,115.083055 189.904672,118.444669 192.529657,120.02327 L192.529657,120.02327 L214.231325,133.073025 L192.421291,146.861608 L192.197604,147.010379 C189.714601,148.74624 189.008986,152.150329 190.640831,154.743329 C192.320671,157.412594 195.841369,158.21156 198.50453,156.52787 L198.50453,156.52787 L228.150872,137.785013 L228.366293,137.64224 C231.740047,135.299571 231.610909,130.197871 228.042505,128.051922 L228.042505,128.051922 L198.396164,110.223351 Z M260.581882,148.231707 L237.703833,148.231707 C235.184875,148.231707 233.142857,150.273726 233.142857,152.792683 C233.142857,155.31164 235.184875,157.353659 237.703833,157.353659 L237.703833,157.353659 L260.581882,157.353659 C263.100839,157.353659 265.142857,155.31164 265.142857,152.792683 C265.142857,150.273726 263.100839,148.231707 260.581882,148.231707 L260.581882,148.231707 Z\" id=\"\u5f62\u72b6\u7ed3\u5408\" fill=\"#FBCB67\"></path>\n+                <path d=\"M141.776,0 C180.100571,0 214.04,23.3154785 227.931429,58.0873691 C229.787429,62.7348563 227.485714,67.9919798 222.789714,69.8288061 C218.094857,71.6667634 212.782857,69.3888274 210.925714,64.7413402 C199.768,36.811175 172.525714,18.0968107 141.776,18.0968107 C112.677714,18.0968107 87.5097143,36.1495104 76.6137143,63.8783485 C75.2468571,67.3563293 71.8628571,69.647838 68.0925714,69.647838 C40.7954286,69.647838 18.2857143,92.4192811 18.2857143,119.401626 C18.2857143,146.475586 40.1474286,168.459817 67.2685714,168.896403 L68.0925714,168.903189 L156.099429,168.903189 C161.148571,168.903189 165.242286,172.954613 165.242286,177.951595 C165.242286,182.854699 161.301714,186.846177 156.384,186.995476 L156.099429,187 L68.0925714,187 C30.4777143,187 0,156.72856 0,119.401626 C0,84.7258744 27.0422857,55.2868877 61.424,51.879032 L61.9257143,51.83379 L62.2068571,51.2365952 C76.8091429,20.4855897 106.501714,0.429799254 140.673143,0.006786304 L141.776,0 Z\" id=\"\u8def\u5f84\u5907\u4efd-5\" fill=\"#FBCB67\"></path>\n+            </g>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/_static/JCloud-light.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"320px\" height=\"320px\" viewBox=\"0 0 320 320\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>JCloud-light</title>\n+    <g id=\"JCloud-light\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4\">\n+            <rect id=\"\u77e9\u5f62\u5907\u4efd-11\" fill-rule=\"nonzero\" x=\"0\" y=\"0\" width=\"320\" height=\"320\"></rect>\n+            <g id=\"\u7f16\u7ec4-4\u5907\u4efd\" transform=\"translate(20.000000, 60.000000)\" fill=\"#009191\">\n+                <path d=\"M256,79.8170732 C269.254834,79.8170732 280,90.5622392 280,103.817073 L280,163 C280,176.254834 269.254834,187 256,187 L196.571429,187 C183.316595,187 172.571429,176.254834 172.571429,163 L172.571429,103.817073 C172.571429,90.5622392 183.316595,79.8170732 196.571429,79.8170732 L256,79.8170732 Z M198.169366,110.093818 C195.503074,108.649809 192.149146,109.552333 190.574155,112.183335 L190.574155,112.183335 L190.444918,112.410652 C189.004211,115.083055 189.904672,118.444669 192.529657,120.02327 L192.529657,120.02327 L214.231325,133.073025 L192.421291,146.861608 L192.197604,147.010379 C189.714601,148.74624 189.008986,152.150329 190.640831,154.743329 C192.320671,157.412594 195.841369,158.21156 198.50453,156.52787 L198.50453,156.52787 L228.150872,137.785013 L228.366293,137.64224 C231.740047,135.299571 231.610909,130.197871 228.042505,128.051922 L228.042505,128.051922 L198.396164,110.223351 Z M260.581882,148.231707 L237.703833,148.231707 C235.184875,148.231707 233.142857,150.273726 233.142857,152.792683 C233.142857,155.31164 235.184875,157.353659 237.703833,157.353659 L237.703833,157.353659 L260.581882,157.353659 C263.100839,157.353659 265.142857,155.31164 265.142857,152.792683 C265.142857,150.273726 263.100839,148.231707 260.581882,148.231707 L260.581882,148.231707 Z\" id=\"\u5f62\u72b6\u7ed3\u5408\"></path>\n+                <path d=\"M141.776,0 C180.100571,0 214.04,23.3154785 227.931429,58.0873691 C229.787429,62.7348563 227.485714,67.9919798 222.789714,69.8288061 C218.094857,71.6667634 212.782857,69.3888274 210.925714,64.7413402 C199.768,36.811175 172.525714,18.0968107 141.776,18.0968107 C112.677714,18.0968107 87.5097143,36.1495104 76.6137143,63.8783485 C75.2468571,67.3563293 71.8628571,69.647838 68.0925714,69.647838 C40.7954286,69.647838 18.2857143,92.4192811 18.2857143,119.401626 C18.2857143,146.475586 40.1474286,168.459817 67.2685714,168.896403 L68.0925714,168.903189 L156.099429,168.903189 C161.148571,168.903189 165.242286,172.954613 165.242286,177.951595 C165.242286,182.854699 161.301714,186.846177 156.384,186.995476 L156.099429,187 L68.0925714,187 C30.4777143,187 0,156.72856 0,119.401626 C0,84.7258744 27.0422857,55.2868877 61.424,51.879032 L61.9257143,51.83379 L62.2068571,51.2365952 C76.8091429,20.4855897 106.501714,0.429799254 140.673143,0.006786304 L141.776,0 Z\" id=\"\u8def\u5f84\u5907\u4efd-5\"></path>\n+            </g>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n---\n file path A: docs/_templates/sidebar/navigation.html | file path B: docs/_templates/sidebar/navigation.html\n\n@@ -23,6 +23,10 @@\n             <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/cas-light.svg', 1) }}\">\n             <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/cas-dark.svg', 1) }}\">\n             CLIP-as-service</a></li>\n+        <li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://github.com/jina-ai/jcloud\">\n+            <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/JCloud-light.svg', 1) }}\">\n+            <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/JCloud-dark.svg', 1) }}\">\n+            JCloud</a></li>\n     </ul>\n </div>\n \n\n\n###\n\n", "completion": "chore: add logo"}
{"prompt": " file path A: .github/workflows/autocommit.yml | file path B: .github/workflows/autocommit.yml\n\n@@ -24,29 +24,6 @@ jobs:\n       - uses: actions/setup-python@v2\n         with:\n           python-version: 3.7\n-      - name: Checkout wall-of-honor\n-        uses: actions/checkout@v2\n-        with:\n-          repository: jina-ai/wall-of-honor\n-          path: wall\n-          token: ${{ secrets.JINA_DEV_BOT }}\n-      - name: Run contributor generation\n-        run: |\n-          cd wall\n-          npm i -D all-contributors-cli@6.17.1\n-          npm list all-contributors-cli\n-          cp patch.js ./node_modules/all-contributors-cli/dist/generate/index.js\n-          cp ../README.md README.md\n-          pip install -r requirements.txt\n-          python app.py config.yml export.yml\n-          cp README.md ../README.md\n-          cd ..\n-          rm -rf wall\n-          git add README.md &> /dev/null || true\n-          git commit -m 'chore(contributor): update contributors' &> /dev/null || true\n-          git status\n-        env:\n-          PRIVATE_TOKEN: ${{ secrets.JINA_DEV_BOT }}\n       - name: Generate TOC\n         uses: technote-space/toc-generator@v3\n         with:\n@@ -57,16 +34,6 @@ jobs:\n           TOC_TITLE: ''\n           TARGET_PATHS: 'CHANGELOG.md,CONTRIBUTING.md,RELEASE.md'\n           CHECK_ONLY_DEFAULT_BRANCH: true\n-      - name: Generate TOC\n-        uses: technote-space/toc-generator@v3\n-        with:\n-          MAX_HEADER_LEVEL: 4\n-          GITHUB_TOKEN: ${{ secrets.JINA_DEV_BOT }}\n-          COMMIT_NAME: Jina Dev Bot\n-          COMMIT_EMAIL: dev-bot@jina.ai\n-          TOC_TITLE: 'Table of Contents'\n-          TARGET_PATHS: '.github/2.0/cookbooks/*.md'\n-          CHECK_ONLY_DEFAULT_BRANCH: true\n       - uses: ad-m/github-push-action@v0.6.0\n         with:\n           github_token: ${{ secrets.JINA_DEV_BOT }}\n\n\n###\n\n", "completion": "chore: fix workflow"}
{"prompt": " file path A: docs/api.md | file path B: docs/api.md\n\n@@ -1,15 +1,9 @@\n # Python API\n \n-There are four packages shipped with Jina:\n-\n-- `jina`: the framework;\n-- `daemon`: a simple orchestrator for Jina;\n-- `cli`: the command line interface for Jina.\n+This section includes the API documentation from the `jina` codebase. These are automatically extracted from the [docstrings](https://peps.python.org/pep-0257/) in the code.\n \n ```{toctree}\n-:hidden:\n \n api/jina\n-api/daemon\n api/cli\n-```\n\\ No newline at end of file\n+```\n\n\n###\n\n", "completion": "docs: remove needless python api page (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/flow-yaml.md | file path B: docs/fundamentals/flow/flow-yaml.md\n\n@@ -63,7 +63,7 @@ class LocalExecutor(Executor):\n         self.foo = foo\n \n     @requests\n-    def foo(self, **kwargs):\n+    def bar(self, **kwargs):\n         print(f'foo={self.foo}')\n ```\n \n\n\n###\n\n", "completion": "docs: renamed function to be named differently from property (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1534,8 +1534,8 @@ def get_rich_console():\n     :return: rich console\n     \"\"\"\n     return Console(\n-        force_terminal=True, force_interactive=True\n-    )  # It forces render in any terminal, especily in PyCharm\n+        force_terminal=True,\n+    )  # It forces render in any terminal, especially in PyCharm\n \n \n GRAPHQL_MIN_DOCARRAY_VERSION = '0.8.8'  # graphql requires this or higher\n\n\n###\n\n", "completion": "fix: remove force interactive in rich console (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -26,6 +26,7 @@ It is also generally possible to use other service mesh providers (like [Istio](\n If you don't install a third party service mesh (like Linkerd), you will not be able to scale the number of replicas per Executor to more than one. A single replica will always handle all the traffic. No matter how many replicas will be running.\n ````\n \n+(kubernetes-deploy)=\n ## Deploy your Flow\n \n To deploy a Flow on `Kubernetes`, first, you have to generate Kubernetes YAML configuration files from a Jina Flow.\n@@ -68,6 +69,11 @@ Once the Flow is deployed on Kubernetes, you can use all the native Kubernetes t\n \n You can use this to [add or remove replicas](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#scaling-a-deployment), to run [rolling update](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment) operations, etc ...\n \n+### Scaling the Gateway\n+The Gateway is responsible for providing the API of the {ref}`Flow <flow>`. If you have a large Flow with many Clients and many replicated Executors, the Gateway can become the bottleneck. In this case you can also scale up the Gateway deployment to be backed by multiple Kubernetes Pods.\n+This is done by the regular means of Kubernetes: Either increase the number of replicas in the  {ref}`generated yaml configuration files <kubernetes-deploy>` or [add replicas while running](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#scaling-a-deployment).\n+To expose your Gateway replicas outside Kubernetes, you can add a load balancer as described {ref}`here <kubernetes-expose>`.\n+\n ## Extra Kubernetes options\n \n One could see that you can't add basic Kubernetes feature like `Secrets`, `ConfigMap` or `Lables` via the pythonic interface. That is intended\n@@ -202,6 +208,7 @@ with portforward.forward('custom-namespace', 'gateway-7df8765bd9-xf5tf', 8080, 8\n     print(f' Indexed documents: {len(docs)}')\n ```\n \n+(kubernetes-expose)=\n ## Exposing your Flow\n The previous examples use port-forwarding to index documents to the Flow. \n Thinking about real world applications, \n\n\n###\n\n", "completion": "docs: mention scaling of gateway (#<issue-num>)"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -75,4 +75,4 @@ kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n-prometheus-client:          standard\n\\ No newline at end of file\n+prometheus_client:          standard\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -75,4 +75,4 @@ kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n sgqlc:                      cicd, graphql\n-prometheus-client:          standard\n\\ No newline at end of file\n+prometheus_client:          standard\n\n\n###\n\n", "completion": "fix: prometheus client requirements to match conda package (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -153,6 +153,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12892,3 +12893,25 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```f6325ee3```](https://github.com/jina-ai/jina/commit/f6325ee33e9bdbc6f05281e2a27492fef4db5e65)] __-__ update setup.py to include py310 (*Han Xiao*)\n  - [[```818e0ffa```](https://github.com/jina-ai/jina/commit/818e0ffaa9735f81aa77651ff154b897d5449f26)] __-__ __version__: the next version will be 3.2.11 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-1></a>\n+## Release Note (`3.3.1`)\n+\n+> Release time: 2022-04-13 10:02:06\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Tobias Jacobowitz,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```b6d96813```](https://github.com/jina-ai/jina/commit/b6d9681380e54fec84529bace3ef5098c8976e54)] __-__ sandbox tls (#4608) (*Tobias Jacobowitz*)\n+ - [[```929054e3```](https://github.com/jina-ai/jina/commit/929054e347011e9ad1f2d39db009965054b1f843)] __-__ 8080 as default gateway port in k8s (#4605) (*Tobias Jacobowitz*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```07db5544```](https://github.com/jina-ai/jina/commit/07db55449aba9fadd9f1b390f9899381094d4c01)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```e122d894```](https://github.com/jina-ai/jina/commit/e122d89420ac3f87e8c0cce06ee50fa79e036636)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```dac21509```](https://github.com/jina-ai/jina/commit/dac2150965ce2585dabd5e86283273f616c5fa73)] __-__ __version__: the next version will be 3.3.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -59,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.1'\n+__version__ = '3.3.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.2"}
{"prompt": " file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -166,8 +166,10 @@ class GrpcConnectionPool:\n \n         # This has to be done lazily, because the target endpoint may not be available\n         # when a connection is added\n-        def _init_stubs(self):\n-            available_services = GrpcConnectionPool.get_available_services(self.address)\n+        async def _init_stubs(self):\n+            available_services = await GrpcConnectionPool.get_available_services(\n+                self.channel\n+            )\n             stubs = defaultdict(lambda: None)\n             for service in available_services:\n                 stubs[service] = self.STUB_MAPPING[service](self.channel)\n@@ -191,7 +193,7 @@ class GrpcConnectionPool:\n             :returns: Tuple of response and metadata about the response\n             \"\"\"\n             if not self._initialized:\n-                self._init_stubs()\n+                await self._init_stubs()\n             request_type = type(requests[0])\n             if request_type == DataRequest and len(requests) == 1:\n                 if self.single_data_stub:\n@@ -888,25 +890,28 @@ class GrpcConnectionPool:\n         )\n \n     @staticmethod\n-    def get_available_services(address: str) -> List[str]:\n+    async def get_available_services(channel) -> List[str]:\n         \"\"\"\n         Lists available services by name, exposed at target address\n \n-        :param address: the address to check for services, like 127.0.0.0.1:8080\n+        :param channel: the channel to use\n \n         :returns: List of services offered\n         \"\"\"\n-        with grpc.insecure_channel(address) as channel:\n-            reflection_stub = ServerReflectionStub(channel)\n-            response = reflection_stub.ServerReflectionInfo(\n-                iter([ServerReflectionRequest(list_services=\"\")])\n+        reflection_stub = ServerReflectionStub(channel)\n+        response = reflection_stub.ServerReflectionInfo(\n+            iter([ServerReflectionRequest(list_services=\"\")])\n+        )\n+        service_names = []\n+        async for res in response:\n+            service_names.append(\n+                [\n+                    service.name\n+                    for service in res.list_services_response.service\n+                    if service.name != 'grpc.reflection.v1alpha.ServerReflection'\n+                ]\n             )\n-            res = next(response)\n-            return [\n-                service.name\n-                for service in res.list_services_response.service\n-                if service.name != 'grpc.reflection.v1alpha.ServerReflection'\n-            ]\n+        return service_names[0]\n \n \n def in_docker():\n\n---\n file path A: tests/integration/sandbox/__init__.py | file path B: tests/integration/sandbox/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/sandbox/test_sandbox.py\n\n@@ -0,0 +1,23 @@\n+import pytest\n+\n+from jina import Document, Flow\n+\n+\n+@pytest.mark.parametrize('endpoint', ['foo', 'bar'])\n+def test_sandbox(endpoint):\n+    with Flow().add(uses='jinahub+sandbox://Hello') as f:\n+        da = f.post(\n+            endpoint,\n+            [\n+                Document(text=\"dog world\"),\n+                Document(text=\"cat world\"),\n+                Document(id=\"a\", text=\"elephant world\"),\n+                Document(id=\"b\", text=\"monkey world\"),\n+            ],\n+        )\n+        assert da.texts == [\n+            'hello dog world',\n+            'hello cat world',\n+            'hello elephant world',\n+            'hello monkey world',\n+        ]\n\n---\n file path A: tests/unit/serve/runtimes/gateway/grpc/test_grpc_gateway_runtime.py | file path B: tests/unit/serve/runtimes/gateway/grpc/test_grpc_gateway_runtime.py\n\n@@ -5,6 +5,7 @@ import multiprocessing\n import time\n from multiprocessing import Process\n \n+import grpc\n import pytest\n \n from jina import Document, DocumentArray\n@@ -430,7 +431,8 @@ def test_grpc_gateway_runtime_handle_empty_graph():\n     assert p.exitcode == 0\n \n \n-def test_grpc_gateway_runtime_reflection():\n+@pytest.mark.asyncio\n+async def test_grpc_gateway_runtime_reflection():\n     deployment0_port = random_port()\n     deployment1_port = random_port()\n     port = random_port()\n@@ -459,7 +461,9 @@ def test_grpc_gateway_runtime_reflection():\n     time.sleep(1.0)\n     assert AsyncNewLoopRuntime.is_ready(ctrl_address=f'127.0.0.1:{port}')\n \n-    service_names = GrpcConnectionPool.get_available_services(f'127.0.0.1:{port}')\n+    async with grpc.aio.insecure_channel(f'127.0.0.1:{port}') as channel:\n+        service_names = await GrpcConnectionPool.get_available_services(channel)\n+\n     assert all(\n         service_name in service_names\n         for service_name in ['jina.JinaControlRequestRPC', 'jina.JinaRPC']\n\n---\n file path A: tests/unit/serve/runtimes/head/test_head_runtime.py | file path B: tests/unit/serve/runtimes/head/test_head_runtime.py\n\n@@ -246,7 +246,8 @@ def test_base_polling(polling):\n     _destroy_runtime(args, cancel_event, runtime_thread)\n \n \n-def test_head_runtime_reflection():\n+@pytest.mark.asyncio\n+async def test_head_runtime_reflection():\n     args = set_pod_parser().parse_args([])\n     cancel_event, handle_queue, runtime_thread = _create_runtime(args)\n \n@@ -256,9 +257,9 @@ def test_head_runtime_reflection():\n         ready_or_shutdown_event=multiprocessing.Event(),\n     )\n \n-    service_names = GrpcConnectionPool.get_available_services(\n-        f'{args.host}:{args.port}'\n-    )\n+    async with grpc.aio.insecure_channel(f'{args.host}:{args.port}') as channel:\n+        service_names = await GrpcConnectionPool.get_available_services(channel)\n+\n     assert all(\n         service_name in service_names\n         for service_name in [\n\n---\n file path A: tests/unit/serve/runtimes/worker/test_worker_runtime.py | file path B: tests/unit/serve/runtimes/worker/test_worker_runtime.py\n\n@@ -338,7 +338,8 @@ async def test_worker_runtime_slow_init_exec():\n     assert not AsyncNewLoopRuntime.is_ready(f'{args.host}:{args.port}')\n \n \n-def test_worker_runtime_reflection():\n+@pytest.mark.asyncio\n+async def test_worker_runtime_reflection():\n     args = set_pod_parser().parse_args([])\n \n     cancel_event = multiprocessing.Event()\n@@ -360,9 +361,8 @@ def test_worker_runtime_reflection():\n         ready_or_shutdown_event=Event(),\n     )\n \n-    service_names = GrpcConnectionPool.get_available_services(\n-        f'{args.host}:{args.port}'\n-    )\n+    async with grpc.aio.insecure_channel(f'{args.host}:{args.port}') as channel:\n+        service_names = await GrpcConnectionPool.get_available_services(channel)\n     assert all(\n         service_name in service_names\n         for service_name in [\n\n\n###\n\n", "completion": "fix: sandbox tls (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -478,6 +478,10 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         kwargs.update(self._common_kwargs)\n         args = ArgNamespace.kwargs2namespace(kwargs, set_gateway_parser())\n \n+        # We need to check later if the port was manually set or randomly\n+        args.default_port = (\n+            kwargs.get('port', None) is None and kwargs.get('port_expose', None) is None\n+        )\n         args.noblock_on_start = True\n         args.expose_graphql_endpoint = (\n             self.args.expose_graphql_endpoint\n@@ -1852,6 +1856,13 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         for node, v in self._deployment_nodes.items():\n             if v.external or (node == 'gateway' and not include_gateway):\n                 continue\n+            if node == 'gateway' and v.args.default_port:\n+                from jina.serve.networking import GrpcConnectionPool\n+\n+                v.args.port = GrpcConnectionPool.K8S_PORT\n+                v.first_pod_args.port = GrpcConnectionPool.K8S_PORT\n+                v.args.default_port = False\n+\n             deployment_base = os.path.join(output_base_path, node)\n             k8s_deployment = K8sDeploymentConfig(\n                 args=v.args,\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_to_k8s_yaml.py\n\n@@ -4,12 +4,17 @@ import pytest\n import yaml\n \n from jina import Flow\n+from jina.serve.networking import GrpcConnectionPool\n \n \n @pytest.mark.parametrize('protocol', ['http', 'grpc'])\n-def test_flow_to_k8s_yaml(tmpdir, protocol):\n+@pytest.mark.parametrize('flow_port', [1234, None])\n+def test_flow_to_k8s_yaml(tmpdir, protocol, flow_port):\n+    flow_kwargs = {'name': 'test-flow', 'protocol': protocol}\n+    if flow_port:\n+        flow_kwargs['port'] = flow_port\n     flow = (\n-        Flow(name='test-flow', port=8080, protocol=protocol)\n+        Flow(**flow_kwargs)\n         .add(name='executor0', uses_with={'param': 0})\n         .add(name='executor1', shards=2, uses_with={'param': 0})\n         .add(\n@@ -85,7 +90,10 @@ def test_flow_to_k8s_yaml(tmpdir, protocol):\n     ]\n     assert gateway_args[0] == 'gateway'\n     assert '--port' in gateway_args\n-    assert gateway_args[gateway_args.index('--port') + 1] == '8080'\n+    assert gateway_args[gateway_args.index('--port') + 1] == (\n+        str(flow_port) if flow_port else str(GrpcConnectionPool.K8S_PORT)\n+    )\n+    assert gateway_args[gateway_args.index('--port') + 1] == str(flow.port)\n     assert '--k8s-namespace' in gateway_args\n     assert gateway_args[gateway_args.index('--k8s-namespace') + 1] == namespace\n     assert '--graph-description' in gateway_args\n\n\n###\n\n", "completion": "fix: 8080 as default gateway port in k8s (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -152,6 +152,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12831,3 +12832,62 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```eb78af6b```](https://github.com/jina-ai/jina/commit/eb78af6b5d8f2cf75a30996e36559673032b4f6f)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```5b292a3f```](https://github.com/jina-ai/jina/commit/5b292a3f67c75f8fd71d37a9f7cd4922c04a1e99)] __-__ __version__: the next version will be 3.2.10 (*Jina Dev Bot*)\n \n+<a name=release-note-3-3-0></a>\n+## Release Note (`3.3.0`)\n+\n+> Release time: 2022-04-12 12:50:25\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Tobias Jacobowitz,  Zhaofeng Miao,  joschkabraun,  Jina Dev Bot,  Delgermurun,  cristian,  samsja,  Johannes Messner,  Saba Sturua,  Han Xiao,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```8a8c293f```](https://github.com/jina-ai/jina/commit/8a8c293f17fba5cd24eed36754894d730997107f)] __-__ Expose Executors as first class citizens (#4597) (*Tobias Jacobowitz*)\n+ - [[```fab9f073```](https://github.com/jina-ai/jina/commit/fab9f0736c8d99558d93020cb3f27108627218f1)] __-__ __hub__: add --no-cache option to &#34;jina hub push&#34; cli (#4594) (*Delgermurun*)\n+ - [[```f45a6e9c```](https://github.com/jina-ai/jina/commit/f45a6e9cda3481851db6a7c37f702e41a9c10a28)] __-__ add grpc reflection support (#4585) (*Tobias Jacobowitz*)\n+ - [[```8dc2999a```](https://github.com/jina-ai/jina/commit/8dc2999a588c46deca60b3f0d5c1b6278a6e165c)] __-__ expose prometheus metrics (#4526) (*samsja*)\n+ - [[```2cce9a72```](https://github.com/jina-ai/jina/commit/2cce9a720b6dfe042fa141f8baa213e2292a77d0)] __-__ add support for cli plugins (#4579) (*Johannes Messner*)\n+ - [[```984e7437```](https://github.com/jina-ai/jina/commit/984e743734b18c1117bbbc2eda49d7eceaa9343f)] __-__ add default volume to dockererized executors (#4554) (*Johannes Messner*)\n+ - [[```12163af0```](https://github.com/jina-ai/jina/commit/12163af01009772035b2e87523663beb890a2549)] __-__ remove head for non sharded deployments (#4517) (*Tobias Jacobowitz*)\n+ - [[```7c48b33c```](https://github.com/jina-ai/jina/commit/7c48b33cb1429b67c41dab5084f3975263f0c5e0)] __-__ __hubble__: add option on fetch_meta for rebuild image or not (#4566) (*Delgermurun*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```c3429154```](https://github.com/jina-ai/jina/commit/c3429154682ccf0a41efac4cfb7ba2be298d5b25)] __-__ do not copy flow if already built (#4603) (*Joan Fontanals*)\n+ - [[```9ca659ed```](https://github.com/jina-ai/jina/commit/9ca659ed05b92c2c9a3c63fce111764747f32f93)] __-__ __executor__: runtime args are now passed directly without any parsing (#4581) (*samsja*)\n+ - [[```1ff6940a```](https://github.com/jina-ai/jina/commit/1ff6940a4105b3ccc32cbd799e9851728c692d8b)] __-__ increase pytest timeout to 30 (#4582) (*Tobias Jacobowitz*)\n+ - [[```542e40e4```](https://github.com/jina-ai/jina/commit/542e40e44cc74129d5bd955ccfba9797c5520ae2)] __-__ start DataRequestHandler before grpc server (#4571) (*Tobias Jacobowitz*)\n+ - [[```d72fe218```](https://github.com/jina-ai/jina/commit/d72fe2181ddf3d10e1d1c05b50e2476a6decedf0)] __-__ check if port is occupied (#4562) (*samsja*)\n+ - [[```662f2845```](https://github.com/jina-ai/jina/commit/662f2845cd969b76302167efc23454c70e6749e7)] __-__ __hubble__: retry fetch meta 3 times (#4540) (*Delgermurun*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```639114fd```](https://github.com/jina-ai/jina/commit/639114fdc89619a2e9a60332b01e3b1667f4fce5)] __-__ __hubble__: remove livetime tip since we have long-live sandbox now (#4602) (*Zhaofeng Miao*)\n+ - [[```eafd4691```](https://github.com/jina-ai/jina/commit/eafd469174dc16c845c0277af530c86df29fd826)] __-__ __docs__: clarifiy kubernetes utilisation (#4572) (*samsja*)\n+ - [[```238dcc18```](https://github.com/jina-ai/jina/commit/238dcc1887dcbd1704b33713313c91fb5ebcd066)] __-__ __docs__:  flow api (#4547) (*samsja*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```ebe43ee8```](https://github.com/jina-ai/jina/commit/ebe43ee8c7e0c5ffa7f8d547640a472b73a2940e)] __-__ __sandbox__: fixed typo in sandbox lifecycle (#4595) (*joschkabraun*)\n+ - [[```5e0ee17b```](https://github.com/jina-ai/jina/commit/5e0ee17bb9d2ce44b2403f86e7b7cf5202f04a19)] __-__ added m1 installation (#4592) (*joschkabraun*)\n+ - [[```bdad931a```](https://github.com/jina-ai/jina/commit/bdad931a265f2f17e5e9a0939ce2ff63dae418db)] __-__ refactor access flow page (#4573) (*cristian*)\n+ - [[```5df29076```](https://github.com/jina-ai/jina/commit/5df29076a6f601d37f22cc7f62f462ca2ec3d894)] __-__ disable reduce in example (#4586) (*Joan Fontanals*)\n+ - [[```ef8eacce```](https://github.com/jina-ai/jina/commit/ef8eacceacb4d223c024f9eca3f5617e4681ee45)] __-__ __executor__: add references to replicas and shards (#4584) (*Saba Sturua*)\n+ - [[```76ad7779```](https://github.com/jina-ai/jina/commit/76ad7779e2d188108384dabde3d162c6e39adf27)] __-__ refactor executor in flow (#4548) (*cristian*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```70c931bf```](https://github.com/jina-ai/jina/commit/70c931bf80f2a150a1e5f8c3cea02cd9263a7cc0)] __-__ add tests for blob over http (#4536) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```58547ea4```](https://github.com/jina-ai/jina/commit/58547ea43416260c9c92a869c0a1247b0b8f06c0)] __-__ bump version (#4604) (*Joan Fontanals*)\n+ - [[```dd8e501f```](https://github.com/jina-ai/jina/commit/dd8e501fb2fce616d7b61e2a819705e2b5713c05)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```b30b1ba6```](https://github.com/jina-ai/jina/commit/b30b1ba621e0eeb089d07ba72ea7cff8702eaacf)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```0a75d9cd```](https://github.com/jina-ai/jina/commit/0a75d9cdfd83b2400d6f1acd1ce31cba8447751b)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```f6325ee3```](https://github.com/jina-ai/jina/commit/f6325ee33e9bdbc6f05281e2a27492fef4db5e65)] __-__ update setup.py to include py310 (*Han Xiao*)\n+ - [[```818e0ffa```](https://github.com/jina-ai/jina/commit/818e0ffaa9735f81aa77651ff154b897d5449f26)] __-__ __version__: the next version will be 3.2.11 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -59,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.3.0'\n+__version__ = '3.3.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.3.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -12,7 +12,6 @@ import os as _os\n import platform as _platform\n import signal as _signal\n import sys as _sys\n-import types as _types\n import warnings as _warnings\n \n import docarray as _docarray\n@@ -60,7 +59,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.11'\n+__version__ = '3.3.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore: bump version (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1421,9 +1421,14 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n         # deepcopy causes the below error while reusing a Flow in Jupyter\n         # 'Pickling an AuthenticationString object is disallowed for security reasons'\n-        op_flow = copy.deepcopy(self) if copy_flow else self\n+        # no need to deep copy if the Graph is built because no change will be made to the Flow\n+        op_flow = (\n+            copy.deepcopy(self)\n+            if (copy_flow and self._build_level.value == FlowBuildLevel.EMPTY)\n+            else self\n+        )\n \n-        if build:\n+        if build and op_flow._build_level.value == FlowBuildLevel.EMPTY:\n             op_flow.build(False)\n \n         mermaid_str = op_flow._mermaid_str\n\n---\n file path A: tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py | file path B: tests/unit/orchestrate/flow/flow-construct/test_flow_visualization.py\n\n@@ -1,11 +1,10 @@\n+import imghdr\n import os\n import struct\n-import imghdr\n \n import pytest\n \n-from jina import Flow\n-from jina import Executor\n+from jina import Executor, Flow\n \n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n@@ -115,3 +114,11 @@ def test_flow_vertical(tmpdir, vertical_layout):\n     assert w_h is not None\n     w, h = w_h\n     assert (w < h) == vertical_layout\n+\n+\n+def test_flow_plot_after_build():\n+    f = Flow().add().add()\n+    with f:\n+        f.plot()\n+\n+    f.plot()\n\n\n###\n\n", "completion": "fix: do not copy flow if already built (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -317,11 +317,17 @@ print(docs.embeddings.shape)\n ```\n ````\n \n+(serve-executor-standalone)=\n ## Serve Executor stand-alone\n \n Executors can be served - and remotely accessed - directly, without the need to instantiate a Flow manually.\n-This is especially useful when debugging an Executor in a remote setting.\n+This is especially useful when debugging an Executor in a remote setting. It can also be used to run external/shared Executors to be used in multiple Flows.\n+There are different options how you can deploy and run a stand-alone Executor:\n+* Run the Executor directly from Python with the `.serve()` class method\n+* Run the static `Executor.to_k8s_yaml()` method to generate K8s deployment configuration files\n+* Run the static `Executor.to_docker_compose_yaml()` method to generate a docker-compose service file\n \n+### Serving Executors\n An Executor can be served using the `.serve()` class method:\n \n ````{tab} Serve Executor\n@@ -366,6 +372,58 @@ the Executor, and `**kwargs` is passed to the internal `Flow()` initialisation c\n For more details on these arguments and the workings of `Flow`, see the {ref}`Flow section <flow-cookbook>`.\n ````\n \n+### Run Executors in Kubernetes\n+You can generate Kubernetes configuration files for your containerized Executor by using the static `Executor.to_k8s_yaml()` method. This works very similar to {ref}`deploying a Flow in Kubernetes <kubernetes>`, because your Executor is wrapped automatically in a Flow and using the very same deployment techniques.\n+\n+```python\n+from jina import Executor\n+\n+Executor.to_k8s_yaml(\n+    output_base_path='/tmp/config_out_folder',\n+    port_expose=8080,\n+    uses='jinahub+docker://DummyHubExecutor',\n+    executor_type=Executor.StandaloneExecutorType.EXTERNAL,\n+)\n+```\n+```shell\n+kubectl apply -R -f /tmp/config_out_folder\n+```\n+The above example will deploy the `DummyHubExecutor` from Jina Hub into your Kubernetes cluster.\n+\n+````{admonition} Note\n+:class: note\n+The Executor you are using, needs to be already containerized and stored in a registry accessible from your Kubernetes cluster. We recommend Jina Hub for this.\n+````\n+\n+(external-shared-executor)=\n+#### External and shared Executors\n+The type of stand-alone Executors can be either *external* or *shared*. By default, it will be external.\n+An external Executor is deployd alongside a {ref}`Gateway <architecture-overview>`. \n+A shared Executor has no Gateway. Both types of Executor {ref}`can be used directly in any Flow <external-executor>`.\n+Having a Gateway may be useful if you want to be able to access your Executor with the {ref}`Client <client>` without an additional Flow. If the Executor will only be used inside other Flows, you should define a shared Executor to save the costs of running the Gateway Pod in Kubernetes.\n+\n+### Run Executors with Docker Compose\n+You can generate a Docker Compose service file for your containerized Executor by using the static `Executor.to_docker_compose_yaml()` method. This works very similar to {ref}`running a Flow with Docker Compose <docker-compose>`, because your Executor is wrapped automatically in a Flow and using the very same deployment techniques.\n+\n+```python\n+from jina import Executor\n+\n+Executor.to_docker_compose_yaml(\n+    output_path='/tmp/docker-compose.yml',\n+    port_expose=8080,\n+    uses='jinahub+docker://DummyHubExecutor',\n+)\n+```\n+```shell\n+ docker-compose -f /tmp/docker-compose.ym up\n+```\n+The above example will run the `DummyHubExecutor` from Jina Hub locally on your computer using Docker Compose.\n+\n+````{admonition} Note\n+:class: note\n+The Executor you are using, needs to be already containerized and stored in an accessible registry. We recommend Jina Hub for this.\n+````\n+\n ### Use async Executors\n \n \n\n---\n file path A: docs/how-to/external-executor.md | file path B: docs/how-to/external-executor.md\n\n@@ -47,14 +47,15 @@ If an external Executor needs multiple predecessors, reducing needs to be enable\n The example above assumes that there already is an Executor running, and you just want to access\n it from your Flow.\n \n-You can, however, also start your own standalone Executors, which can then be accessed from anywhere. There are two\n-ways of doing this: Pulling an Executor from Jina Hub, and using a locally defined Executor. In either case, you will\n-launch the Executor using the Jina command line interface (CLI).\n \n-````{admonition} Advanced CLI options\n+You can, however, also start your own standalone Executors, which can then be accessed from anywhere.\n+In the following sections we will describe how to run standalone Executors via the Jina command line interface (CLI). For more options to run your Executor, including in Kubernetes and Docker Compose, please read the {ref}`Executor API section <serve-executor-standalone>`.\n+\n+\n+````{admonition} Advanced deployment options\n :class: seealso\n This tutorial walks through the basics of spawing a standalone (external) Executor. For more advanced options, refer to the\n-{ref}`CLI <api/cli>`\n+{ref}`CLI <api/cli>` and {ref}`Executor API section <serve-executor-standalone>`\n ````\n \n ## Using Jina Hub\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1819,7 +1819,12 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n     # for backward support\n     join = needs\n \n-    def to_k8s_yaml(self, output_base_path: str, k8s_namespace: Optional[str] = None):\n+    def to_k8s_yaml(\n+        self,\n+        output_base_path: str,\n+        k8s_namespace: Optional[str] = None,\n+        include_gateway: bool = True,\n+    ):\n         \"\"\"\n         Converts the Flow into a set of yaml deployments to deploy in Kubernetes.\n \n@@ -1828,6 +1833,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n         :param output_base_path: The base path where to dump all the yaml files\n         :param k8s_namespace: The name of the k8s namespace to set for the configurations. If None, the name of the Flow will be used.\n+        :param include_gateway: Defines if the gateway deployment should be included, defaults to True\n         \"\"\"\n         import yaml\n \n@@ -1839,7 +1845,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         k8s_namespace = k8s_namespace or self.args.name or 'default'\n \n         for node, v in self._deployment_nodes.items():\n-            if v.external:\n+            if v.external or (node == 'gateway' and not include_gateway):\n                 continue\n             deployment_base = os.path.join(output_base_path, node)\n             k8s_deployment = K8sDeploymentConfig(\n@@ -1869,11 +1875,13 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         self,\n         output_path: Optional[str] = None,\n         network_name: Optional[str] = None,\n+        include_gateway: bool = True,\n     ):\n         \"\"\"\n         Converts the Flow into a yaml file to run with `docker-compose up`\n         :param output_path: The output path for the yaml file\n         :param network_name: The name of the network that will be used by the deployment name\n+        :param include_gateway: Defines if the gateway deployment should be included, defaults to True\n         \"\"\"\n         import yaml\n \n@@ -1895,6 +1903,9 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         services = {}\n \n         for node, v in self._deployment_nodes.items():\n+            if v.external or (node == 'gateway' and not include_gateway):\n+                continue\n+\n             docker_compose_deployment = DockerComposeConfig(\n                 args=v.args,\n                 deployments_addresses=self._get_docker_compose_deployments_addresses(),\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -9,6 +9,7 @@ from types import SimpleNamespace\n from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union\n \n from jina import __args_executor_init__, __default_endpoint__\n+from jina.enums import BetterEnum\n from jina.helper import (\n     ArgNamespace,\n     T,\n@@ -359,6 +360,96 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         with f:\n             f.block(stop_event)\n \n+    class StandaloneExecutorType(BetterEnum):\n+        \"\"\"\n+        Type of standalone Executors\n+        \"\"\"\n+\n+        EXTERNAL = 0  # served by a gateway\n+        SHARED = 1  # not served by a gateway, served by head/worker\n+\n+    @staticmethod\n+    def to_k8s_yaml(\n+        uses: str,\n+        output_base_path: str,\n+        k8s_namespace: Optional[str] = None,\n+        executor_type: Optional[\n+            StandaloneExecutorType\n+        ] = StandaloneExecutorType.EXTERNAL,\n+        uses_with: Optional[Dict] = None,\n+        uses_metas: Optional[Dict] = None,\n+        uses_requests: Optional[Dict] = None,\n+        **kwargs,\n+    ):\n+        \"\"\"\n+        Converts the Executor into a set of yaml deployments to deploy in Kubernetes.\n+\n+        If you don't want to rebuild image on Jina Hub,\n+        you can set `JINA_HUB_NO_IMAGE_REBUILD` environment variable.\n+\n+        :param uses: the Executor to use. Has to be containerized and accessible from K8s\n+        :param output_base_path: The base path where to dump all the yaml files\n+        :param k8s_namespace: The name of the k8s namespace to set for the configurations. If None, the name of the Flow will be used.\n+        :param executor_type: The type of Executor. Can be external or shared. External Executors include the Gateway. Shared Executors don't. Defaults to External\n+        :param uses_with: dictionary of parameters to overwrite from the default config's with field\n+        :param uses_metas: dictionary of parameters to overwrite from the default config's metas field\n+        :param uses_requests: dictionary of parameters to overwrite from the default config's requests field\n+        :param kwargs: other kwargs accepted by the Flow, full list can be found `here <https://docs.jina.ai/api/jina.orchestrate.flow.base/>`\n+        \"\"\"\n+        from jina import Flow\n+\n+        f = Flow(**kwargs).add(\n+            uses=uses,\n+            uses_with=uses_with,\n+            uses_metas=uses_metas,\n+            uses_requests=uses_requests,\n+        )\n+        f.to_k8s_yaml(\n+            output_base_path=output_base_path,\n+            k8s_namespace=k8s_namespace,\n+            include_gateway=executor_type\n+            == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n+        )\n+\n+    @staticmethod\n+    def to_docker_compose_yaml(\n+        uses: str,\n+        output_path: Optional[str] = None,\n+        network_name: Optional[str] = None,\n+        executor_type: Optional[\n+            StandaloneExecutorType\n+        ] = StandaloneExecutorType.EXTERNAL,\n+        uses_with: Optional[Dict] = None,\n+        uses_metas: Optional[Dict] = None,\n+        uses_requests: Optional[Dict] = None,\n+        **kwargs,\n+    ):\n+        \"\"\"\n+        Converts the Executor into a yaml file to run with `docker-compose up`\n+        :param uses: the Executor to use. Has to be containerized\n+        :param output_path: The output path for the yaml file\n+        :param network_name: The name of the network that will be used by the deployment name\n+        :param executor_type: The type of Executor. Can be external or shared. External Executors include the Gateway. Shared Executors don't. Defaults to External\n+        :param uses_with: dictionary of parameters to overwrite from the default config's with field\n+        :param uses_metas: dictionary of parameters to overwrite from the default config's metas field\n+        :param uses_requests: dictionary of parameters to overwrite from the default config's requests field\n+        :param kwargs: other kwargs accepted by the Flow, full list can be found `here <https://docs.jina.ai/api/jina.orchestrate.flow.base/>`\n+        \"\"\"\n+        from jina import Flow\n+\n+        f = Flow(**kwargs).add(\n+            uses=uses,\n+            uses_with=uses_with,\n+            uses_metas=uses_metas,\n+            uses_requests=uses_requests,\n+        )\n+        f.to_docker_compose_yaml(\n+            output_path=output_path,\n+            network_name=network_name,\n+            include_gateway=executor_type\n+            == BaseExecutor.StandaloneExecutorType.EXTERNAL,\n+        )\n+\n \n class ReducerExecutor(BaseExecutor):\n     \"\"\"\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -4,6 +4,7 @@ from pathlib import Path\n from unittest import mock\n \n import pytest\n+import yaml\n from docarray import Document, DocumentArray\n \n from jina import Client, Executor, Flow, requests\n@@ -366,3 +367,71 @@ def test_default_workspace(tmpdir):\n         assert result_workspace == os.path.join(\n             os.environ['JINA_DEFAULT_WORKSPACE_BASE'], 'WorkspaceExec', '0'\n         )\n+\n+\n+@pytest.mark.parametrize(\n+    'exec_type',\n+    [Executor.StandaloneExecutorType.EXTERNAL, Executor.StandaloneExecutorType.SHARED],\n+)\n+def test_to_k8s_yaml(tmpdir, exec_type):\n+    Executor.to_k8s_yaml(\n+        output_base_path=tmpdir,\n+        port_expose=2020,\n+        uses='jinahub+docker://DummyHubExecutor',\n+        executor_type=exec_type,\n+    )\n+\n+    with open(os.path.join(tmpdir, 'executor0', 'executor0.yml')) as f:\n+        exec_yaml = list(yaml.safe_load_all(f))[-1]\n+        assert exec_yaml['spec']['template']['spec']['containers'][0][\n+            'image'\n+        ].startswith('jinahub/')\n+\n+    if exec_type == Executor.StandaloneExecutorType.SHARED:\n+        assert set(os.listdir(tmpdir)) == {\n+            'executor0',\n+        }\n+    else:\n+        assert set(os.listdir(tmpdir)) == {\n+            'executor0',\n+            'gateway',\n+        }\n+\n+        with open(os.path.join(tmpdir, 'gateway', 'gateway.yml')) as f:\n+            gatewayyaml = list(yaml.safe_load_all(f))[-1]\n+            assert (\n+                gatewayyaml['spec']['template']['spec']['containers'][0]['ports'][0][\n+                    'containerPort'\n+                ]\n+                == 2020\n+            )\n+            gateway_args = gatewayyaml['spec']['template']['spec']['containers'][0][\n+                'args'\n+            ]\n+            assert gateway_args[gateway_args.index('--port') + 1] == '2020'\n+\n+\n+@pytest.mark.parametrize(\n+    'exec_type',\n+    [Executor.StandaloneExecutorType.EXTERNAL, Executor.StandaloneExecutorType.SHARED],\n+)\n+def test_to_docker_compose_yaml(tmpdir, exec_type):\n+    compose_file = os.path.join(tmpdir, 'compose.yml')\n+    Executor.to_docker_compose_yaml(\n+        output_path=compose_file,\n+        port_expose=2020,\n+        uses='jinahub+docker://DummyHubExecutor',\n+        executor_type=exec_type,\n+    )\n+\n+    with open(compose_file) as f:\n+        services = list(yaml.safe_load_all(f))[0]['services']\n+        assert services['executor0']['image'].startswith('jinahub/')\n+\n+        if exec_type == Executor.StandaloneExecutorType.SHARED:\n+            assert len(services) == 1\n+        else:\n+            assert len(services) == 2\n+            assert services['gateway']['ports'][0] == '2020:2020'\n+            gateway_args = services['gateway']['command']\n+            assert gateway_args[gateway_args.index('--port') + 1] == '2020'\n\n\n###\n\n", "completion": "feat: Expose Executors as first class citizens (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -667,18 +667,13 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n         if json_response.get('code') == 200:\n             host = json_response.get('data', {}).get('host', None)\n             port = json_response.get('data', {}).get('port', None)\n-            livetime = json_response.get('data', {}).get('livetime', '15 mins')\n \n         if host and port:\n-            console.log(f\"A sandbox already exists, reusing it.\")\n-            console.log(\n-                f\"[bold green]This sandbox will be removed when there has been no traffic for {livetime}\"\n-            )\n-\n+            console.log(f\"\ud83c\udf89 A sandbox already exists, reusing it.\")\n             return host, port\n \n         with console.status(\n-            f\"[bold green]Deploying sandbox for [bold white]{name}[/bold white] since none exists...\"\n+            f\"[bold green]\ud83d\udea7 Deploying sandbox for [bold white]{name}[/bold white] since none exists...\"\n         ):\n             try:\n                 json_response = requests.post(\n@@ -690,16 +685,14 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n                 data = json_response.get('data') or {}\n                 host = data.get('host', None)\n                 port = data.get('port', None)\n-                livetime = data.get('livetime', '15 mins')\n                 if not host or not port:\n                     raise Exception(f'Failed to deploy sandbox: {json_response}')\n \n-                console.log(f\"Deployment completed: {host}:{port}\")\n+                console.log(f\"\ud83c\udf89 Deployment completed, using it.\")\n+            except:\n                 console.log(\n-                    f\"[bold green]This sandbox will be removed when no traffic during [bold white]{livetime}[/bold white]\"\n+                    \"\ud83d\udea8 Deployment failed, feel free to raise an issue. https://github.com/jina-ai/jina/issues/new\"\n                 )\n-            except:\n-                console.log(\"Deployment failed\")\n                 raise\n \n         return host, port\n\n\n###\n\n", "completion": "refactor(hubble): remove livetime tip since we have long-live sandbox now (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/sandbox.md | file path B: docs/how-to/sandbox.md\n\n@@ -44,7 +44,7 @@ If all these three factors match, then it will reuse the existing sandboxes.\n \n ```{admonition} Caution\n :class: caution\n-If the Jina version of Gateway is later than the latest released Jina version (things happens when you are in the master branch of jina repository), then the sandbox will always be created instead of reused.\n+If the Jina version of Gateway is later than the latest released Jina version (this happens when you are in the master branch of jina repository), then the sandbox will always be created instead of reused.\n ```\n \n ## Version consistency\n\n\n###\n\n", "completion": "docs(sandbox): fixed typo in sandbox lifecycle (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -198,6 +198,7 @@ ac_table = {\n             '--force-update',\n             '--force',\n             '--secret',\n+            '--no-cache',\n             '--public',\n             '--private',\n         ],\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -370,6 +370,9 @@ metas:\n                 if self.args.verbose:\n                     form_data['verbose'] = 'True'\n \n+                if self.args.no_cache:\n+                    form_data['buildWithNoCache'] = 'True'\n+\n                 if exec_tags:\n                     form_data['tags'] = exec_tags\n \n\n---\n file path A: jina/parsers/hubble/push.py | file path B: jina/parsers/hubble/push.py\n\n@@ -61,6 +61,13 @@ One can later fetch a tagged Executor via `jinahub[+docker]://MyExecutor/gpu`\n         help='The secret for overwrite a Hub executor',\n     )\n \n+    gp.add_argument(\n+        '--no-cache',\n+        action='store_true',\n+        default=False,\n+        help='If set, \"--no-cache\" option will be added to the Docker build.',\n+    )\n+\n     gp = add_arg_group(parser, title='Visibility')\n \n     mutually_exclusive_group = gp.add_mutually_exclusive_group()\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -1,9 +1,11 @@\n+import cgi\n import itertools\n import json\n import os\n import shutil\n import urllib\n from argparse import Namespace\n+from io import BytesIO\n from pathlib import Path\n \n import docker\n@@ -100,15 +102,16 @@ class FetchMetaMockResponse:\n         return self.response_code\n \n \n+@pytest.mark.parametrize('no_cache', [False, True])\n @pytest.mark.parametrize('tag', [None, '-t v0'])\n @pytest.mark.parametrize('force', [None, 'UUID8'])\n @pytest.mark.parametrize('path', ['dummy_executor'])\n @pytest.mark.parametrize('mode', ['--public', '--private'])\n-def test_push(mocker, monkeypatch, path, mode, tmpdir, force, tag):\n+def test_push(mocker, monkeypatch, path, mode, tmpdir, force, tag, no_cache):\n     mock = mocker.Mock()\n \n     def _mock_post(url, data, headers=None, stream=True):\n-        mock(url=url, data=data)\n+        mock(url=url, data=data, headers=headers)\n         return PostMockResponse(response_code=requests.codes.created)\n \n     monkeypatch.setattr(requests, 'post', _mock_post)\n@@ -124,6 +127,9 @@ def test_push(mocker, monkeypatch, path, mode, tmpdir, force, tag):\n     if tag:\n         _args_list.append(tag)\n \n+    if no_cache:\n+        _args_list.append('--no-cache')\n+\n     args = set_hub_push_parser().parse_args(_args_list)\n     result = HubIO(args).push()\n \n@@ -131,6 +137,40 @@ def test_push(mocker, monkeypatch, path, mode, tmpdir, force, tag):\n     exec_config_path = os.path.join(exec_path, '.jina')\n     shutil.rmtree(exec_config_path)\n \n+    _, mock_kwargs = mock.call_args_list[0]\n+\n+    c_type, c_data = cgi.parse_header(mock_kwargs['headers']['Content-Type'])\n+    assert c_type == 'multipart/form-data'\n+\n+    form_data = cgi.parse_multipart(\n+        BytesIO(mock_kwargs['data']), {'boundary': c_data['boundary'].encode()}\n+    )\n+\n+    assert 'file' in form_data\n+    assert 'md5sum' in form_data\n+\n+    if force:\n+        assert form_data['id'] == ['UUID8']\n+    else:\n+        assert form_data.get('id') is None\n+\n+    if mode == '--private':\n+        assert form_data['private'] == ['True']\n+        assert form_data['public'] == ['False']\n+    else:\n+        assert form_data['private'] == ['False']\n+        assert form_data['public'] == ['True']\n+\n+    if tag:\n+        assert form_data['tags'] == [' v0']\n+    else:\n+        assert form_data.get('tags') is None\n+\n+    if no_cache:\n+        assert form_data['buildWithNoCache'] == ['True']\n+    else:\n+        assert form_data.get('buildWithNoCache') is None\n+\n \n @pytest.mark.parametrize(\n     'dockerfile, expected_error',\n\n---\n file path A: tests/unit/parsers/hubble/test_pushpull.py | file path B: tests/unit/parsers/hubble/test_pushpull.py\n\n@@ -1,7 +1,9 @@\n import argparse\n+\n import pytest\n-from jina.parsers.hubble.push import mixin_hub_push_parser\n+\n from jina.parsers.hubble.pull import mixin_hub_pull_parser\n+from jina.parsers.hubble.push import mixin_hub_push_parser\n \n \n def test_push_parser(tmpdir):\n@@ -17,6 +19,7 @@ def test_push_parser(tmpdir):\n     assert args.force_update is None\n     assert args.secret is None\n     assert args.verbose is False\n+    assert args.no_cache is False\n     assert not hasattr(args, 'public')\n     assert not hasattr(args, 'private')\n \n@@ -56,6 +59,9 @@ def test_push_parser(tmpdir):\n     args = parser.parse_args([tmpdir, '--verbose'])\n     assert args.verbose is True\n \n+    args = parser.parse_args([tmpdir, '--no-cache'])\n+    assert args.no_cache is True\n+\n \n def test_pull_parser():\n     parser = argparse.ArgumentParser(\n\n\n###\n\n", "completion": "feat(hub): add --no-cache option to \"jina hub push\" cli (#<issue-num>)"}
{"prompt": " file path A: docs/get-started/install/troubleshooting.md | file path B: docs/get-started/install/troubleshooting.md\n\n@@ -33,6 +33,8 @@ Then you are likely installing Jina on a less-supported system/architecture. For\n \n ## On Mac M1\n \n+It is generally recommended using a conda environment on a Mac M1 and installing in particular `grpcio`, `protobuf` and `torch`  using `conda install`. See for more [Issue 4422](https://github.com/jina-ai/jina/issues/4422#issuecomment-1057663345).\n+\n Some users may have difficulty to install Protobuf on MacOS from `pip`, you may try `brew install protobuf`.\n \n In general, some upstream dependencies do not yet have pre-built wheels for the M1 chip, so you are likely to encounter some issues during the install. In this case, you need to configure the development environment using [Rosetta2](https://support.apple.com/en-us/HT211861), including your terminal, `brew` and `python`. They must all be running under Rosetta2 instead of natively on M1.\n\n\n###\n\n", "completion": "docs: added m1 installation (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/access-flow-api.md | file path B: docs/fundamentals/flow/access-flow-api.md\n\n@@ -1,134 +1,46 @@\n (access-flow-api)=\n-# Access Flow API\n+# Access Flow\n \n Once you have {ref}`configured your Flow API <flow-api>` you can access it over the network.\n There are multiple ways of doing this.\n \n-## Jina Client\n-\n ```{admonition} See Also\n :class: seealso\n \n-For a more detailed description of the Jina Client, see its dedicated {ref}`documentation page <client>`.\n-```\n-\n-Jina offers a built-in client that supports gRPC, HTTP, and Websocket connections to a Flow.\n-Sending a request to a Flow is as simple as calling the `.post()` method:\n-\n-````{tab} gRPC\n-\n-```{code-block} python\n-from docarray import Document, DocumentArray\n-from jina import Client\n-\n-# Flow exposed on host HOST and port PORT\n-c = Client(host=HOST, port=PORT)\n-response_docs = c.post(on='/search', inputs=DocumentArray())\n-```\n-````\n-\n-````{tab} HTTP\n-```{code-block} python\n-from docarray import Document, DocumentArray\n-from jina import Client\n-\n-# Flow exposed on host HOST and port PORT\n-c = Client(host=HOST, port=PORT, protocol='http')\n-response_docs = c.post(on='/search', inputs=DocumentArray())\n-```\n-````\n-\n-````{tab} WebSocket\n-\n-```{code-block} python\n-from docarray import Document, DocumentArray\n-from jina import Client\n-\n-# Flow exposed on host HOST and port PORT\n-c = Client(host=HOST, port=PORT, protocol='websocket')\n-response_docs = c.post(on='/search', inputs=DocumentArray())\n+This page is about accessing the Flow with external clients.\n+You can also use the Jina Client, provided by us in the `jina` package. \n+It supports all the protocols listed here under a convenient, simple API.\n+Check its dedicated {ref}`documentation page <client>`.\n ```\n-````\n-\n-The Client also supports a number of additional features, such as batching requests, callback functions, asynchronous calls,\n-passing additional parameters, and {ref}`more <client>`.\n \n ## HTTP access\n \n ```{admonition} Available Protocols\n :class: caution\n-Jina Flows can use one of three protocols: gRPC, HTTP, or Websocket. Only Flows that use HTTP can be accessed via the\n-methods described below.\n+Jina Flows can use one of {ref}`three protocols <flow-protocol>`: gRPC, HTTP, or Websocket. \n+Only Flows that use HTTP can be accessed via the methods described below.\n ```\n \n-Outside of using the Jina Client, various forms of sending HTTP requests are the most common way of interacting with a Flow.\n+Apart from using the {ref}`Jina Client <client>`, the most common way of interacting with your deployed Flow is via HTTP.\n \n You can always use `post` to interact with a Flow, using the `/post` HTTP endpoint.\n \n-#### Arguments\n-\n-Your HTTP request can include the following parameters:\n-\n-| Name | Type | Description | Example |\n-| --- | --- | --- | --- | \n-| `execEndpoint` | required | Executor endpoint string to target | `\"execEndpoint\": \"/index\"` |\n-| `data` | optional | List specifying the input Documents | `\"data\": [{\"text\": \"hello\"}, {\"text\": \"world\"}]`. |\n-| `parameters` | optional | Dictionary of parameters to be sent to the Executors | `\"parameters\": {\"param1\": \"hello world\"}` |\n-| `targetExecutor` | optional | String indicating an Executor to target. Default targets all Executors | `\"targetExecutor\": \"MyExec\"`  |\n-\n-\n-Instead of using the generic `/post` endpoint, you can directly use endpoints like `/index` or `/search`.\n-In this case your data request will be sent to the corresponding Executor endpoint, so the parameter `execEndpoint` does not need to be specified.\n-\n-In any case, the response you receive will include `data` (and array of Documents), as well as the fields `routes`, `parameters`, and `header`.\n-\n-```{admonition} See also: Flow REST API\n-:class: seealso\n-For a more detailed descripton of the REST API of a generic Flow, including the complete request body schema and request samples, please check\n-\n-1. [OpenAPI Schema](https://api.jina.ai/rest/latest.json)\n-2. [Redoc UI](https://api.jina.ai/rest/)\n-\n-For a specific deployed Flow, you can get the same overview by accessing the `/redoc` endpoint.\n-```\n \n-(swagger-ui)=\n-### Use Swagger UI to send HTTP request\n+### Use HTTP client to send request\n \n-Flows provide a customized [Swagger UI](https://swagger.io/tools/swagger-ui/) which can be used to interact with the Flow\n-visually, through a web browser.\n+With the help of [OpenAPI schema](https://swagger.io/specification/), one can send data requests to a Flow via `cURL`, JavaScript, [Postman](https://www.postman.com/), or any other HTTP client or programming library. \n \n-```{admonition} Available Protocols\n-:class: caution\n-Only Flows that have {ref}`cors <cors>` enabled expose a Swagger UI interface.\n-```\n+`````{tab} via cURL\n \n-For a Flow that is exposed on port `PORT`, you can navigate to the Swagger UI via `http://localhost:PORT/docs`:\n+Here's an example that uses `cURL`.\n \n-```{figure} ../../../.github/2.0/swagger-ui.png\n-:align: center\n+```bash\n+curl --request POST 'http://localhost:12345/post' --header 'Content-Type: application/json' -d '{\"data\": [{\"text\": \"hello world\"}],\"execEndpoint\": \"/search\"}'\n ```\n-Here you can see all the endpoints that are exposed by the Flow, such as `/search` and `/index`.\n-\n-To send a request, click on the endpoint you want to target, then on `try it out`.\n \n-Now you can enter your HTTP request, and send it by clicking on `Execute`.\n-You can again use the [REST HTTP request schema](https://api.jina.ai/rest/), but do not need to specify `execEndpoint`.\n-\n-You should see the raw response, together with a visual representation of the returned Documents.\n-\n-### Use HTTP client to send request\n-\n-With the help of OpenAPI schema, one can send data requests to a Flow via cURL, Postman, or any other HTTP client. Here's an example that uses cURL.\n+````{dropdown} Sample response\n \n-\n-```bash\n-curl --request POST 'http://localhost:12345/post' --header 'Content-Type: application/json' -d '{\"data\": [{\"text\": \"hello world\"}],\"execEndpoint\": \"/index\"}'\n ```\n-\n-<details>\n-  <summary>Sample response</summary>    \n-    \n     {\n       \"requestId\": \"e2978837-e5cb-45c6-a36d-588cf9b24309\",\n       \"data\": {\n@@ -178,8 +90,149 @@ curl --request POST 'http://localhost:12345/post' --header 'Content-Type: applic\n         \"exception\": null\n       }\n     }\n+```\n+\n+````\n+\n+`````\n+\n+`````{tab} via JavaScript\n+\n+Sending a request from the front-end JavaScript code is a common use case too. Here's how this would look like:\n+\n+```javascript\n+fetch('http://localhost:12345/post', {\n+    method: 'POST',\n+    headers: {\n+        'Content-Type': 'application/json'\n+    },\n+    body: JSON.stringify({\"data\": [{\"text\": \"hello world\"}],\"execEndpoint\": \"/search\"})\n+}).then(response => response.json()).then(data => console.log(data));\n+```\n+\n+````{dropdown} Output\n+\n+```javascript\n+{\n+  \"data\": [\n+    {\n+      \"id\": \"37e6f1bc7ec82fc4ba75691315ae54a6\",\n+      \"text\": \"hello world\"\n+      \"matches\": ...\n+    },\n+  \"header\": {\n+    \"requestId\": \"c725217aa7714de88039866fb5aa93d2\",\n+    \"execEndpoint\": \"/index\",\n+    \"targetExecutor\": \"\"\n+  },\n+  \"routes\": [\n+    {\n+      \"executor\": \"gateway\",\n+      \"startTime\": \"2022-04-01T13:11:57.992497+00:00\",\n+      \"endTime\": \"2022-04-01T13:11:57.997802+00:00\"\n+    },\n+    {\n+      \"executor\": \"executor0\",\n+      \"startTime\": \"2022-04-01T13:11:57.993686+00:00\",\n+      \"endTime\": \"2022-04-01T13:11:57.997274+00:00\"\n+    }\n+  ],\n+  ]\n+}\n+```\n+\n+```` \n+\n+`````\n+\n+### Arguments\n+\n+Your HTTP request can include the following parameters:\n+\n+| Name             | Required     | Description                                                                            | Example                                           |\n+| ---------------- | ------------ | -------------------------------------------------------------------------------------- | ------------------------------------------------- |\n+| `execEndpoint`   | **required** | Executor endpoint to target                                                            | `\"execEndpoint\": \"/index\"`                        |\n+| `data`           | optional     | List specifying the input [Documents](https://docarray.jina.ai/fundamentals/document/) | `\"data\": [{\"text\": \"hello\"}, {\"text\": \"world\"}]`. |\n+| `parameters`     | optional     | Dictionary of parameters to be sent to the Executors                                   | `\"parameters\": {\"param1\": \"hello world\"}`         |\n+| `targetExecutor` | optional     | String indicating an Executor to target. Default targets all Executors                 | `\"targetExecutor\": \"MyExec\"`                      |\n+\n+\n+Instead of using the generic `/post` endpoint, you can directly use endpoints like `/index` or `/search` to perform a specific operation.\n+In this case your data request will be sent to the corresponding Executor endpoint, so the parameter `execEndpoint` does not need to be specified.\n+\n+`````{dropdown} Example\n+\n+````{tab} cURL\n+\n+```{code-block} bash\n+---\n+emphasize-lines: 2\n+---\n+curl --request POST \\\n+'http://localhost:12345/search' \\\n+--header 'Content-Type: application/json' -d '{\"data\": [{\"text\": \"hello world\"}]}'\n+```\n+\n+````\n+\n+````{tab} javascript\n+\n+```{code-block} javascript\n+---\n+emphasize-lines: 2\n+---\n+fetch(\n+    'http://localhost:12345/search', \n+    {\n+        method: 'POST',\n+        headers: {\n+            'Content-Type': 'application/json'\n+    },\n+    body: JSON.stringify({\"data\": [{\"text\": \"hello world\"}]})\n+}).then(response => response.json()).then(data => console.log(data));\n+```\n+\n+````\n+\n+`````\n+\n+\n+The response you receive includes `data` (an array of [Documents](https://docarray.jina.ai/fundamentals/document/)), as well as the fields `routes`, `parameters`, and `header`.\n \n-</details>\n+```{admonition} See also: Flow REST API\n+:class: seealso\n+For a more detailed descripton of the REST API of a generic Flow, including the complete request body schema and request samples, please check\n+\n+1. [OpenAPI Schema](https://api.jina.ai/rest/latest.json)\n+2. [Redoc UI](https://api.jina.ai/rest/)\n+\n+For a specific deployed Flow, you can get the same overview by accessing the `/redoc` endpoint.\n+```\n+\n+(swagger-ui)=\n+### Use Swagger UI to send HTTP request\n+\n+Flows provide a customized [Swagger UI](https://swagger.io/tools/swagger-ui/) which can be used to interact with the Flow\n+visually, through a web browser.\n+\n+```{admonition} Available Protocols\n+:class: caution\n+Only Flows that have enabled {ref}`CORS <cors>` expose the Swagger UI interface.\n+```\n+\n+For a Flow that is exposed on port `PORT`, you can navigate to the Swagger UI via `http://localhost:PORT/docs`:\n+\n+```{figure} ../../../.github/2.0/swagger-ui.png\n+:align: center\n+```\n+Here you can see all the endpoints that are exposed by the Flow, such as `/search` and `/index`.\n+\n+To send a request, click on the endpoint you want to target, then on `Try it out`.\n+\n+Now you can enter your HTTP request, and send it by clicking on `Execute`.\n+You can again use the [REST HTTP request schema](https://api.jina.ai/rest/), but do not need to specify `execEndpoint`.\n+\n+Below, in `Responses`, you can see the reply, together with a visual representation of the returned Documents.\n \n (flow-graphql)=\n ## GraphQL Interface\n@@ -191,7 +244,7 @@ This article does not serve as the introduction to GraphQL.\n If you are not already familiar with GraphQL, we recommend you learn more about GraphQL from the official [GraphQL documentation](https://graphql.org/learn/).\n You may also want to learn about [Strawberry](https://strawberry.rocks/), the library that powers Jina's GraphQL support.\n ````\n-Jina Flows that use the HTTP protocol can also provide a GraphQL API, which is located behind the '/graphql' endpoint.\n+Jina Flows that use the HTTP protocol can also provide a GraphQL API, which is located behind the `/graphql` endpoint.\n GraphQL has the advantage of letting the user define their own response schema, which means that only the fields that are required\n will be sent over the wire.\n This is especially useful when the user does not need potentially large fields, like image tensors.\n@@ -240,21 +293,27 @@ The available fields in the GraphQL API are defined by the [Document Strawberry\n Essentially, you can ask for any property of a Document, including `embedding`, `text`, `tensor`, `id`, `matches`, `tags`,\n and more.\n \n+## gRPC\n+\n+If you want to create a gRPC client in another language, you will need to compile the [Protobuf definitions](../../proto/docs.md). In Python, you can use our {ref}`own client <client>`.\n \n ## Websocket\n \n-Websocket uses persistent connections between the Client & Gateway, hence allowing streaming usecases. While you can always use the Python Client to stream requests like any other protocol, websocket allows streaming jsons from anywhere (CLI / Postman / Any other programming language). The same set of arguments as [HTTP](#arguments) can be used in the json. \n+Websocket uses persistent connections between the client & Flow, hence allowing streaming use cases. \n+While you can always use the Python client to stream requests like any other protocol, websocket allows streaming JSON from anywhere (CLI / Postman / any other programming language). \n+The same set of arguments as [HTTP](#arguments) can be used in the payload.\n \n-We use [subprotocols](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers#subprotocols) to separate streaming json vs bytes. Gateway defaults to `json` when a subprotocol is not passed during connection establishment (Our python Client uses `bytes` streaming by using [jina.proto](../../proto/docs.md) definition)\n+We use [subprotocols](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers#subprotocols) to separate streaming JSON vs bytes. \n+The Flow defaults to `json` when a subprotocol is not passed during connection establishment (Our Python client uses `bytes` streaming by using [jina.proto](../../proto/docs.md) definition).\n \n \n ````{admonition} Note\n \n-- Prefer using Websocket over HTTP, if you want to stream requests. \n-- Prefer using Websocket over gRPC, if\n-  - You want to stream using json, not bytes.\n-  - Your client language doesn't support gRPC .\n-  - You're too lazy to compile [jina.proto](../../proto/docs.md) & generate a Client.\n+- Choose Websocket over HTTP, if you want to stream requests. \n+- Choose Websocket over gRPC, if\n+  - you want to stream using JSON, not bytes\n+  - your client language doesn't support gRPC\n+  - you don't want to compile the [Protobuf definitions](../../proto/docs.md) for your gRPC client\n \n ````\n \n@@ -262,5 +321,5 @@ We use [subprotocols](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket\n ## See further\n \n - {ref}`Access a Flow with the Client <client>`\n-- {ref}`Configure Flow API <flow>`\n+- {ref}`Configure Flow <flow>`\n - [Flow REST API reference](https://api.jina.ai/rest/)\n\\ No newline at end of file\n\n---\n file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -1,5 +1,5 @@\n (client)=\n-# Client API\n+# Python Client\n The most convenient way to work with the `Flow` API is the Python Client.\n It enables you to send `Documents` to a running `Flow` in a number of different ways, as shown below.\n \n\n---\n file path A: docs/fundamentals/flow/flow-api.md | file path B: docs/fundamentals/flow/flow-api.md\n\n@@ -1,6 +1,6 @@\n (flow)=\n \n-# Configure Flow API\n+# Configure Flow\n \n **Flow** ties Executors together into a processing pipeline, provides scalability and facilitates deployments in the cloud.\n Every `Flow` provides an API to receive requests over the network. Supported protocols are gRPC, HTTP and WebSocket.\n@@ -18,6 +18,7 @@ This does not affect how you have to configure your Flow API, so the examples he\n For more proper use of the Client, and more information about the Client itself, see the {ref}`Client documentation <client>`.\n ```\n \n+(flow-protocol)=\n ## Serve Flow with different protocols\n You can use three different protocols to serve the `Flow`: `grpc`,`http` and `websocket`\n \n\n\n###\n\n", "completion": "docs: refactor access flow page (#<issue-num>)"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -1,6 +1,10 @@\n import os\n+import shutil\n+import subprocess\n import sys\n \n+from packaging.version import Version, parse\n+\n \n def _get_run_args(print_args: bool = True):\n     from jina.helper import get_rich_console\n@@ -81,51 +85,120 @@ def _quick_ac_lookup():\n             exit()\n \n \n-def _is_latest_version(suppress_on_error=True):\n+def _parse_latest_release_version(resp):\n+    # credit: https://stackoverflow.com/a/34366589\n+    import json\n+\n+    latest_release_ver = parse('0')\n+    j = json.load(resp)\n+    releases = j.get('releases', [])\n+    for release in releases:\n+        latest_ver = parse(release)\n+        if not latest_ver.is_prerelease:\n+            latest_release_ver = max(latest_release_ver, latest_ver)\n+    return latest_release_ver\n+\n+\n+def _is_latest_version(package='jina', suppress_on_error=True):\n     try:\n-        import json\n         import warnings\n         from urllib.request import Request, urlopen\n \n-        from jina import __version__\n+        import pkg_resources\n+\n+        cur_ver = Version(pkg_resources.get_distribution(package).version)\n \n         req = Request(\n-            'https://api.jina.ai/latest', headers={'User-Agent': 'Mozilla/5.0'}\n+            f'https://pypi.python.org/pypi/{package}/json',\n+            headers={'User-Agent': 'Mozilla/5.0'},\n         )\n         with urlopen(\n             req, timeout=5\n         ) as resp:  # 'with' is important to close the resource after use\n-            latest_ver = json.load(resp)['version']\n-            from packaging.version import Version\n-\n-            latest_ver = Version(latest_ver)\n-            cur_ver = Version(__version__)\n-            if cur_ver < latest_ver:\n+            latest_release_ver = _parse_latest_release_version(resp)\n+            if cur_ver < latest_release_ver:\n                 from jina.logging.predefined import default_logger\n \n                 default_logger.warning(\n-                    f'You are using Jina version {cur_ver}, however version {latest_ver} is available. '\n-                    f'You should consider upgrading via the \"pip install --upgrade jina\" command.'\n+                    f'You are using {package} version {cur_ver}, however version {latest_release_ver} is available. '\n+                    f'You should consider upgrading via the \"pip install --upgrade {package}\" command.'\n                 )\n                 return False\n         return True\n     except:\n-        # no network, two slow, api.jina.ai is down\n+        # no network, too slow, PyPi is down\n         if not suppress_on_error:\n             raise\n \n \n-def main():\n-    \"\"\"The main entrypoint of the CLI \"\"\"\n-    _quick_ac_lookup()\n+def _is_latest_version_plugin(subcommand):\n+    from .known_plugins import plugin_info\n+\n+    if subcommand in plugin_info:\n+        _is_latest_version(package=plugin_info[subcommand]['pip-package'])\n+\n+\n+def _try_plugin_command():\n+    \"\"\"Tries to call the CLI of an external Jina project.\n+\n+    :return: if the plugin has been found (locally or among the known plugins)\n+    \"\"\"\n+    argv = sys.argv\n+    if len(argv) < 2:  # no command given\n+        return False\n+\n+    from .autocomplete import ac_table\n+\n+    if argv[1] in ac_table['commands']:  # native command can't be plugin command\n+        return False\n \n-    from cli import api\n+    def _cmd_exists(cmd):\n+        return shutil.which(cmd) is not None\n \n-    args = _get_run_args()\n+    subcommand = argv[1]\n+    cmd = 'jina-' + subcommand\n+    if _cmd_exists(cmd):\n+        import threading\n+\n+        threading.Thread(\n+            target=_is_latest_version_plugin,\n+            daemon=True,\n+            args=(subcommand,),\n+        ).start()\n+        subprocess.run([cmd] + argv[2:])\n+        return True\n+\n+    from .known_plugins import plugin_info\n+\n+    if subcommand in plugin_info:\n+        from jina.helper import get_rich_console\n+\n+        cmd_info = plugin_info[subcommand]\n+        project, package = cmd_info['display-name'], cmd_info['pip-package']\n+        console = get_rich_console()\n+        console.print(\n+            f\"It seems like [yellow]{project}[/yellow] is not installed in your environment.\"\n+            f\"To use it via the [green]'jina {subcommand}'[/green] command, \"\n+            f\"install it first: [green]'pip install {package}'[/green].\"\n+        )\n+        return True\n+    return False\n+\n+\n+def main():\n+    \"\"\"The main entrypoint of the CLI\"\"\"\n \n     # checking version info in another thread\n     import threading\n \n-    threading.Thread(target=_is_latest_version, daemon=True).start()\n+    threading.Thread(target=_is_latest_version, daemon=True, args=('jina',)).start()\n+    found_plugin = _try_plugin_command()\n+\n+    if not found_plugin:\n+        _quick_ac_lookup()\n+\n+        from cli import api\n+\n+        args = _get_run_args()\n \n-    getattr(api, args.cli.replace('-', '_'))(args)\n+        getattr(api, args.cli.replace('-', '_'))(args)\n\n---\n file path A: None | file path B: cli/known_plugins.py\n\n@@ -0,0 +1,6 @@\n+plugin_info = {\n+    'now': {  # your sub-command\n+        'display-name': 'Jina Now',  # the name of your plugin/project\n+        'pip-package': 'jina-now',  # the pip package to install\n+    }\n+}\n\n\n###\n\n", "completion": "feat: add support for cli plugins (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-in-flow.md | file path B: docs/fundamentals/executor/executor-in-flow.md\n\n@@ -540,7 +540,7 @@ f = (\n     Flow()\n     .add(uses=Exec1, name='exec1')\n     .add(uses=Exec2, name='exec2')\n-    .add(uses=MergeExec, needs=['exec1', 'exec2'])\n+    .add(uses=MergeExec, needs=['exec1', 'exec2'], disable_reduce=True)\n )\n \n with f:\n\n\n###\n\n", "completion": "docs: disable reduce in example (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-in-flow.md | file path B: docs/fundamentals/executor/executor-in-flow.md\n\n@@ -18,6 +18,7 @@ This is a basic Executor, defined in its own file. Notice that there are no {ref\n from jina import Executor\n from docarray import DocumentArray\n \n+\n class MyExecutor(Executor):\n     def __init__(self, parameter_1, parameter_2, **kwargs):\n         super().__init__(**kwargs)\n@@ -46,23 +47,16 @@ This example shows how to start a Flow with an Executor via the Python API:\n ```python\n with Flow().add(\n     uses='MyExecutor',\n-    uses_with={\n-      \"parameter_1\": \"foo\",\n-      \"parameter_2\": \"bar\"\n-    },\n+    uses_with={\"parameter_1\": \"foo\", \"parameter_2\": \"bar\"},\n     uses_metas={\n-      \"name\": \"MyExecutor\",\n-      \"description\": \"MyExecutor does a thing to the stuff in your Documents\",\n-      \"py_modules\": [\"executor.py\"]\n+        \"name\": \"MyExecutor\",\n+        \"description\": \"MyExecutor does a thing to the stuff in your Documents\",\n+        \"py_modules\": [\"executor.py\"],\n     },\n-    uses_requests={\n-      \"/index\": \"my_index\",\n-      \"/search\": \"my_search\",\n-      \"/random\": \"foo\"\n-    },\n-    workspace=\"some_custom_path\"\n+    uses_requests={\"/index\": \"my_index\", \"/search\": \"my_search\", \"/random\": \"foo\"},\n+    workspace=\"some_custom_path\",\n ) as f:\n-  ...\n+    ...\n ```\n \n Python API-specific options:\n@@ -117,12 +111,14 @@ When using an Executor in a Flow, there are two ways of passing arguments.\n ```python\n from jina import Executor, Flow\n \n+\n class MyExecutor(Executor):\n     def __init__(self, foo, bar, **kwargs):\n         super().__init__(**kwargs)\n         print(f'foo = {foo}')\n         print(f'bar = {bar}')\n \n+\n f = Flow().add(uses=MyExecutor, uses_with={'foo': 'hello', 'bar': 1})\n \n with f:\n@@ -177,6 +173,7 @@ The same applies to `uses_metas` and `uses_requests`. You can define them static\n ```python\n from jina import Executor, requests, Flow\n \n+\n class MyExecutor(Executor):\n     def __init__(self, parameter_1, parameter_2, **kwargs):\n         super().__init__(**kwargs)\n@@ -331,8 +328,8 @@ As the name suggests, `runtime_args` are dynamically determined during runtime,\n The list of the `runtime_args` is:\n \n - `name`: Name given to the `Executor`. This is dynamically adapted from the `name` in `metas` and depends on some additional arguments like `shard_id`. \n-- `replicas`: Number of replicas of the same `Executor` deployed with the `Flow`.\n-- `shards`: Number of shards of the same `Executor` deployed with the `Flow`.\n+- `replicas`: Number of {ref}`replicas <replicate-executors>` of the same `Executor` deployed with the `Flow`.\n+- `shards`: Number of {ref}`shards <partition-data-by-using-shards>` of the same `Executor` deployed with the `Flow`.\n - `shard_id`: Identifier of the `shard` corresponding to the given `Executor` instance.\n - `workspace`: Path to be used by the `Executor`. Note that the actual workspace directory used by the Executor is obtained by appending `'/<executor_name>/<shard_id>/'` to this value.\n - `py_modules`: Path to the modules needed to import the `Executor`. This is another way to pass `py-modules` to the `Executor` from the `Flow`\n@@ -355,6 +352,7 @@ It also exposes a `status` endpoint returning internal information in the form o\n ```python\n from jina import requests, Executor\n \n+\n class MyExec(Executor):\n     def __init__(self, parameter=20, **kwargs):\n         super().__init__(**kwargs)\n\n---\n file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -649,7 +649,7 @@ This means that you can not only use this feature to build complex logic, but al\n \n For a hands-on example on how to leverage these filter conditions, see {ref}`this how-to <flow-switch>`.\n ````\n-\n+(replicate-executors)=\n ### Replicate Executors\n \n Replication can be used to create multiple copies of the same Executor. Each request in the Flow is then passed to only one replica (instance) of your Executor. This can be useful for a couple of challenges like performance and availability:\n@@ -671,6 +671,7 @@ Flow with 3 replicas of slow_encoder and 1 replica of fast_indexer\n The above Flow will create a topology with three Replicas of Executor `slow_encoder`. The `Flow` will send every \n request to exactly one of the three instances. Then the replica will send its result to `fast_indexer`.\n \n+(partition-data-by-using-shards)=\n ### Partition data by using Shards\n \n Sharding can be used to partition data (like an Index) into several parts. This enables the distribution of data across multiple machines.\n\n---\n file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -40,7 +40,7 @@ You should see this in your terminal:\n \n ## Adding dependencies\n \n-You can use any third-party Python library in Executor. Let's create `executor1/requirements.txt` and `pytorch` to it.\n+You can use any third-party Python library in Executor. Let's create `executor1/requirements.txt` and add `pytorch` to it.\n \n Then in `executor.py`, let's add another endpoint `/get-tensor` as follows:\n \n\n\n###\n\n", "completion": "docs(executor): add references to replicas and shards (#<issue-num>)"}
{"prompt": " file path A: jina/jaml/__init__.py | file path B: jina/jaml/__init__.py\n\n@@ -5,16 +5,17 @@ import string\n import tempfile\n import warnings\n from types import SimpleNamespace\n-from typing import Dict, Any, Union, TextIO, Optional, List, Tuple\n+from typing import Any, Dict, List, Optional, TextIO, Tuple, Union\n \n import yaml\n from yaml.constructor import FullConstructor\n \n from jina.jaml.helper import (\n-    JinaResolver,\n     JinaLoader,\n-    parse_config_source,\n+    JinaResolver,\n+    get_jina_loader_with_runtime,\n     load_py_modules,\n+    parse_config_source,\n )\n \n __all__ = ['JAML', 'JAMLCompatible']\n@@ -73,9 +74,11 @@ class JAML:\n         JAML.load(...)\n         JAML.dump(...)\n \n+\n         class DummyClass:\n             pass\n \n+\n         JAML.register(DummyClass)\n \n     You can use expressions to programmatically set variables in YAML files and access contexts.\n@@ -125,9 +128,9 @@ class JAML:\n     .. highlight:: python\n     .. code-block:: python\n \n-        obj = JAML.load(fp, substitute=True,\n-                            context={'context_var': 3.14,\n-                                    'context_var2': 'hello-world'})\n+        obj = JAML.load(\n+            fp, substitute=True, context={'context_var': 3.14, 'context_var2': 'hello-world'}\n+        )\n \n     Internal references point to other variables in the yaml file itself, and can be accessed using the following syntax:\n \n@@ -148,7 +151,12 @@ class JAML:\n     \"\"\"\n \n     @staticmethod\n-    def load(stream, substitute: bool = False, context: Dict[str, Any] = None):\n+    def load(\n+        stream,\n+        substitute: bool = False,\n+        context: Dict[str, Any] = None,\n+        runtime_args: Optional[Dict[str, Any]] = None,\n+    ):\n         \"\"\"Parse the first YAML document in a stream and produce the corresponding Python object.\n \n         .. note::\n@@ -157,13 +165,15 @@ class JAML:\n             to load YAML config into objects, please use :meth:`Flow.load_config`,\n             :meth:`BaseExecutor.load_config`, etc.\n \n+        :param stream: the stream to load\n         :param substitute: substitute environment, internal reference and context variables.\n         :param context: context replacement variables in a dict, the value of the dict is the replacement.\n-        :param stream: the stream to load\n+        :param runtime_args: Optional runtime_args to be directly passed without being parsed into a yaml config\n         :return: the Python object\n \n         \"\"\"\n-        r = yaml.load(stream, Loader=JinaLoader)\n+        r = yaml.load(stream, Loader=get_jina_loader_with_runtime(runtime_args))\n+\n         if substitute:\n             r = JAML.expand_dict(r, context)\n         return r\n@@ -562,7 +572,9 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n         data = constructor.construct_mapping(node, deep=True)\n         from jina.jaml.parsers import get_parser\n \n-        return get_parser(cls, version=data.get('version', None)).parse(cls, data)\n+        return get_parser(cls, version=data.get('version', None)).parse(\n+            cls, data, runtime_args=constructor.runtime_args\n+        )\n \n     def save_config(self, filename: Optional[str] = None):\n         \"\"\"\n@@ -594,6 +606,8 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n         uses_metas: Optional[Dict] = None,\n         uses_requests: Optional[Dict] = None,\n         extra_search_paths: Optional[List[str]] = None,\n+        py_modules: Optional[str] = None,\n+        runtime_args: Optional[Dict[str, Any]] = None,\n         **kwargs,\n     ) -> 'JAMLCompatible':\n         \"\"\"A high-level interface for loading configuration with features\n@@ -625,11 +639,11 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n             # load Executor from yaml file and substitute environment variables\n             os.environ['VAR_A'] = 'hello-world'\n             b = BaseExecutor.load_config('a.yml')\n-            assert b.name == hello-world\n+            assert b.name == 'hello-world'\n \n             # load Executor from yaml file and substitute variables from a dict\n             b = BaseExecutor.load_config('a.yml', context={'VAR_A': 'hello-world'})\n-            assert b.name == hello-world\n+            assert b.name == 'hello-world'\n \n             # disable substitute\n             b = BaseExecutor.load_config('a.yml', substitute=False)\n@@ -644,9 +658,22 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n         :param uses_metas: dictionary of parameters to overwrite from the default config's metas field\n         :param uses_requests: dictionary of parameters to overwrite from the default config's requests field\n         :param extra_search_paths: extra paths used when looking for executor yaml files\n+        :param py_modules: Optional py_module from which the object need to be loaded\n+        :param runtime_args: Optional dictionary of parameters runtime_args to be directly passed without being parsed into a yaml config\n+        :param : runtime_args that need to be passed to the yaml\n+\n         :param kwargs: kwargs for parse_config_source\n         :return: :class:`JAMLCompatible` object\n         \"\"\"\n+        if runtime_args:\n+            kwargs[\n+                'runtimes_args'\n+            ] = (\n+                dict()\n+            )  # when we have runtime args it is needed to have an empty runtime args session in the yam config\n+\n+        if py_modules:\n+            kwargs['runtimes_args']['py_modules'] = py_modules\n \n         if isinstance(source, str) and os.path.exists(source):\n             extra_search_paths = (extra_search_paths or []) + [os.path.dirname(source)]\n@@ -723,7 +750,7 @@ class JAMLCompatible(metaclass=JAMLCompatibleType):\n                 # revert yaml's tag and load again, this time with substitution\n                 tag_yml = JAML.unescape(JAML.dump(no_tag_yml))\n             # load into object, no more substitute\n-            return JAML.load(tag_yml, substitute=False)\n+            return JAML.load(tag_yml, substitute=False, runtime_args=runtime_args)\n \n     @classmethod\n     def _override_yml_params(cls, raw_yaml, field_name, override_field):\n\n---\n file path A: jina/jaml/helper.py | file path B: jina/jaml/helper.py\n\n@@ -2,11 +2,11 @@ import collections\n import json\n import os\n import warnings\n-from typing import Union, TextIO, Dict, Tuple, Optional, List\n+from typing import Any, Dict, List, Optional, TextIO, Tuple, Union\n \n from yaml import MappingNode\n from yaml.composer import Composer\n-from yaml.constructor import FullConstructor, ConstructorError\n+from yaml.constructor import ConstructorError, FullConstructor\n from yaml.parser import Parser\n from yaml.reader import Reader\n from yaml.resolver import Resolver\n@@ -91,13 +91,29 @@ class JinaLoader(Reader, Scanner, Parser, Composer, JinaConstructor, JinaResolve\n     :param stream: the stream to load.\n     \"\"\"\n \n-    def __init__(self, stream):\n+    def __init__(self, stream, runtime_args=None):\n         Reader.__init__(self, stream)\n         Scanner.__init__(self)\n         Parser.__init__(self)\n         Composer.__init__(self)\n         JinaConstructor.__init__(self)\n         JinaResolver.__init__(self)\n+        self.runtime_args = runtime_args\n+\n+\n+def get_jina_loader_with_runtime(runtime_args: Optional[Dict[str, Any]] = None):\n+    \"\"\"Create a JinaLoader init function which already stored the runtime_args in the init function, usefully for\n+    `yaml.load(stream,loader=JinaLoader)` which needs a class with a init function with only one parameter\n+\n+    :param runtime_args: Optional runtime_args to be directly passed without being parsed into a yaml config\n+    :return: A function that initialize a JinaLoader with the runtime_args stored within the function\n+\n+    \"\"\"\n+\n+    def _get_loader(stream):\n+        return JinaLoader(stream, runtime_args)\n+\n+    return _get_loader\n \n \n # remove on|On|ON resolver\n\n---\n file path A: jina/jaml/parsers/base.py | file path B: jina/jaml/parsers/base.py\n\n@@ -1,4 +1,4 @@\n-from typing import Dict, Union, TYPE_CHECKING\n+from typing import TYPE_CHECKING, Any, Dict, Optional, Union\n \n if TYPE_CHECKING:\n     from jina.orchestrate.flow.base import Flow\n@@ -16,13 +16,16 @@ class VersionedYAMLParser:\n \n     version = 'legacy'  #: the version number this parser designed for\n \n-    def parse(self, cls: type, data: Dict) -> Union['Flow', 'BaseExecutor']:\n+    def parse(\n+        self, cls: type, data: Dict, runtime_args: Optional[Dict[str, Any]]\n+    ) -> Union['Flow', 'BaseExecutor']:\n         \"\"\"Return the Flow YAML parser given the syntax version number\n \n \n         .. # noqa: DAR401\n         :param cls: target class type to parse into, must be a :class:`JAMLCompatible` type\n         :param data: flow yaml file loaded as python dict\n+        :param runtime_args: Optional runtime_args to be directly passed without being parsed into a yaml config\n         \"\"\"\n         raise NotImplementedError\n \n\n---\n file path A: jina/jaml/parsers/default/v1.py | file path B: jina/jaml/parsers/default/v1.py\n\n@@ -1,7 +1,7 @@\n-from typing import Dict, Type\n+from typing import Any, Dict, Optional, Type\n \n+from jina.jaml import JAML, JAMLCompatible\n from jina.jaml.parsers.base import VersionedYAMLParser\n-from jina.jaml import JAMLCompatible, JAML\n \n \n class V1Parser(VersionedYAMLParser):\n@@ -9,10 +9,16 @@ class V1Parser(VersionedYAMLParser):\n \n     version = '1'  # the version number this parser designed for\n \n-    def parse(self, cls: Type['JAMLCompatible'], data: Dict) -> 'JAMLCompatible':\n+    def parse(\n+        self,\n+        cls: Type['JAMLCompatible'],\n+        data: Dict,\n+        runtime_args: Optional[Dict[str, Any]] = None,\n+    ) -> 'JAMLCompatible':\n         \"\"\"\n         :param cls: target class type to parse into, must be a :class:`JAMLCompatible` type\n         :param data: flow yaml file loaded as python dict\n+        :param runtime_args: Optional runtime_args to be directly passed without being parsed into a yaml config\n         :return: the YAML parser given the syntax version number\n         \"\"\"\n         expanded_data = JAML.expand_dict(data, None)\n\n---\n file path A: jina/jaml/parsers/executor/legacy.py | file path B: jina/jaml/parsers/executor/legacy.py\n\n@@ -1,6 +1,6 @@\n import inspect\n from functools import reduce\n-from typing import Dict, Type, Set\n+from typing import Any, Dict, Optional, Set, Type\n \n from jina.jaml.parsers.base import VersionedYAMLParser\n from jina.serve.executors import BaseExecutor\n@@ -51,10 +51,16 @@ class LegacyParser(VersionedYAMLParser):\n         args = list(map(lambda x: get_class_arguments(x), all_classes))\n         return set(reduce(lambda x, y: x + y, args))\n \n-    def parse(self, cls: Type['BaseExecutor'], data: Dict) -> 'BaseExecutor':\n+    def parse(\n+        self,\n+        cls: Type['BaseExecutor'],\n+        data: Dict,\n+        runtime_args: Optional[Dict[str, Any]] = None,\n+    ) -> 'BaseExecutor':\n         \"\"\"\n         :param cls: target class type to parse into, must be a :class:`JAMLCompatible` type\n         :param data: flow yaml file loaded as python dict\n+        :param runtime_args: Optional runtime_args to be directly passed without being parsed into a yaml config\n         :return: the Flow YAML parser given the syntax version number\n         \"\"\"\n         from jina.logging.predefined import default_logger\n@@ -70,7 +76,7 @@ class LegacyParser(VersionedYAMLParser):\n             **data.get('with', {}),\n             metas=data.get('metas', {}),\n             requests=data.get('requests', {}),\n-            runtime_args=data.get('runtime_args', {}),\n+            runtime_args=runtime_args,\n         )\n         cls._init_from_yaml = False\n \n\n---\n file path A: jina/jaml/parsers/flow/v1.py | file path B: jina/jaml/parsers/flow/v1.py\n\n@@ -1,11 +1,11 @@\n-import os\n import argparse\n-from typing import Dict, Any\n+import os\n+from typing import Any, Dict, Optional\n \n-from jina.jaml.parsers.base import VersionedYAMLParser\n from jina import Flow\n from jina.enums import DeploymentRoleType\n-from jina.helper import expand_env_var, ArgNamespace\n+from jina.helper import ArgNamespace, expand_env_var\n+from jina.jaml.parsers.base import VersionedYAMLParser\n from jina.parsers import set_deployment_parser, set_gateway_parser\n \n \n@@ -50,10 +50,13 @@ class V1Parser(VersionedYAMLParser):\n \n     version = '1'  # the version number this parser designed for\n \n-    def parse(self, cls: type, data: Dict) -> 'Flow':\n+    def parse(\n+        self, cls: type, data: Dict, runtime_args: Optional[Dict[str, Any]] = None\n+    ) -> 'Flow':\n         \"\"\"\n         :param cls: the class registered for dumping/loading\n         :param data: flow yaml file loaded as python dict\n+        :param runtime_args: Optional runtime_args to be directly passed without being parsed into a yaml config\n         :return: the Flow YAML parser given the syntax version number\n         \"\"\"\n         p = data.get('with', {})  # type: Dict[str, Any]\n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -38,14 +38,14 @@ class DataRequestHandler:\n                 uses_with=self.args.uses_with,\n                 uses_metas=self.args.uses_metas,\n                 uses_requests=self.args.uses_requests,\n-                runtime_args={\n+                runtime_args={  # these are not parsed to the yaml config file but are pass directly during init\n                     'workspace': self.args.workspace,\n                     'shard_id': self.args.shard_id,\n                     'shards': self.args.shards,\n                     'replicas': self.args.replicas,\n                     'name': self.args.name,\n-                    'py_modules': self.args.py_modules,\n                 },\n+                py_modules=self.args.py_modules,\n                 extra_search_paths=self.args.extra_search_paths,\n             )\n         except BadConfigSource as ex:\n\n---\n file path A: None | file path B: tests/unit/serve/executors/test_runtime_args.py\n\n@@ -0,0 +1,29 @@\n+import pickle\n+from threading import Lock\n+\n+import pytest\n+\n+from jina.serve.executors import BaseExecutor\n+\n+\n+class NotSerialisable:\n+    def __init__(self):\n+        self.lock = Lock()\n+\n+\n+def test_object_not_seri():\n+    with pytest.raises(TypeError):\n+        serialized = pickle.dumps(NotSerialisable())\n+\n+\n+def test_runtime_args_not_serialisable():\n+\n+    param = NotSerialisable()\n+\n+    b = BaseExecutor.load_config(\n+        'BaseExecutor',\n+        runtime_args={'hello': 'world', 'not_seri': param},\n+    )\n+\n+    assert b.runtime_args.hello == 'world'\n+    assert b.runtime_args.not_seri is param\n\n\n###\n\n", "completion": "fix(executor): runtime args are now passed directly without any parsing (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -138,7 +138,7 @@ jobs:\n           pytest --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml --timeout=600 -v -s --ignore-glob='tests/integration/hub_usage/dummyhub*' ${{ matrix.test-path }}\n           echo \"flag it as jina for codeoverage\"\n           echo \"::set-output name=codecov_flag::jina\"\n-        timeout-minutes: 15\n+        timeout-minutes: 30\n         env:\n           JINAHUB_USERNAME: ${{ secrets.JINAHUB_USERNAME }}\n           JINAHUB_PASSWORD: ${{ secrets.JINAHUB_PASSWORD }}\n\n\n###\n\n", "completion": "fix: increase pytest timeout to 30 (#<issue-num>)"}
{"prompt": " file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -32,13 +32,16 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         \"\"\"\n         super().__init__(args, cancel_event, **kwargs)\n \n-        # Keep this initialization order, otherwise readiness check is not valid\n-        self._data_request_handler = DataRequestHandler(args, self.logger)\n-\n     async def async_setup(self):\n         \"\"\"\n-        Wait for the GRPC server to start\n+        Start the DataRequestHandler and wait for the GRPC server to start\n         \"\"\"\n+\n+        # Keep this initialization order\n+        # otherwise readiness check is not valid\n+        # The DataRequestHandler needs to be started BEFORE the grpc server\n+        self._data_request_handler = DataRequestHandler(self.args, self.logger)\n+\n         self._grpc_server = grpc.aio.server(\n             options=[\n                 ('grpc.max_send_message_length', -1),\n\n---\n file path A: tests/unit/serve/runtimes/worker/test_worker_runtime.py | file path B: tests/unit/serve/runtimes/worker/test_worker_runtime.py\n\n@@ -1,24 +1,23 @@\n import asyncio\n import multiprocessing\n import os\n+import socket\n import time\n from multiprocessing import Process\n from threading import Event\n \n import grpc\n import pytest\n-\n from docarray import Document\n+\n from jina import DocumentArray, Executor, requests\n from jina.clients.request import request_generator\n from jina.parsers import set_pod_parser\n+from jina.proto import jina_pb2, jina_pb2_grpc\n from jina.serve.networking import GrpcConnectionPool\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n-from jina.serve.runtimes.request_handlers.data_request_handler import (\n-    DataRequestHandler,\n-)\n+from jina.serve.runtimes.request_handlers.data_request_handler import DataRequestHandler\n from jina.serve.runtimes.worker import WorkerRuntime\n-from jina.proto import jina_pb2_grpc, jina_pb2\n \n \n @pytest.mark.slow\n@@ -275,5 +274,69 @@ async def test_worker_runtime_graceful_shutdown():\n     assert not WorkerRuntime.is_ready(f'{args.host}:{args.port}')\n \n \n+class SlowInitExecutor(Executor):\n+    def __init__(self, *args, **kwargs):\n+        super().__init__(*args, **kwargs)\n+        time.sleep(5.0)\n+\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        return docs\n+\n+\n+@pytest.mark.timeout(10)\n+@pytest.mark.asyncio\n+async def test_worker_runtime_slow_init_exec():\n+    args = set_pod_parser().parse_args(['--uses', 'SlowInitExecutor'])\n+\n+    cancel_event = multiprocessing.Event()\n+\n+    def start_runtime(args, cancel_event):\n+        with WorkerRuntime(args, cancel_event) as runtime:\n+            runtime.run_forever()\n+\n+    runtime_thread = Process(\n+        target=start_runtime,\n+        args=(args, cancel_event),\n+        daemon=True,\n+    )\n+    runtime_started = time.time()\n+    runtime_thread.start()\n+\n+    # wait a bit to the worker runtime has a chance to finish some things, but not the Executor init (5 secs)\n+    time.sleep(1.0)\n+\n+    # try to connect a TCP socket to the gRPC server\n+    # this should only succeed after the Executor is ready, which should be after 5 seconds\n+    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n+        connected = False\n+        while not connected:\n+            try:\n+                s.connect((args.host, args.port))\n+                connected = True\n+            except ConnectionRefusedError:\n+                time.sleep(0.2)\n+\n+    # Executor sleeps 5 seconds, so at least 5 seconds need to have elapsed here\n+    assert time.time() - runtime_started > 5.0\n+\n+    assert AsyncNewLoopRuntime.wait_for_ready_or_shutdown(\n+        timeout=3.0,\n+        ctrl_address=f'{args.host}:{args.port}',\n+        ready_or_shutdown_event=Event(),\n+    )\n+\n+    result = await GrpcConnectionPool.send_request_async(\n+        _create_test_data_message(), f'{args.host}:{args.port}', timeout=1.0\n+    )\n+\n+    assert len(result.docs) == 1\n+\n+    cancel_event.set()\n+    runtime_thread.join()\n+\n+    assert not AsyncNewLoopRuntime.is_ready(f'{args.host}:{args.port}')\n+\n+\n def _create_test_data_message(counter=0):\n     return list(request_generator('/', DocumentArray([Document(text=str(counter))])))[0]\n\n\n###\n\n", "completion": "fix: start DataRequestHandler before grpc server (#<issue-num>)"}
{"prompt": " file path A: jina/excepts.py | file path B: jina/excepts.py\n\n@@ -81,3 +81,7 @@ class DockerVersionError(SystemError, BaseJinaException):\n \n class NoContainerizedError(Exception, BaseJinaException):\n     \"\"\"Raised when trying to use non-containerized Executor in K8s or Docker Compose\"\"\"\n+\n+\n+class PortAlreadyUsed(RuntimeError, BaseJinaException):\n+    \"\"\"Raised when to use a port which is already used\"\"\"\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -15,6 +15,7 @@ from argparse import ArgumentParser, Namespace\n from collections.abc import MutableMapping\n from datetime import datetime\n from itertools import islice\n+from socket import AF_INET, SOCK_STREAM, socket\n from types import SimpleNamespace\n from typing import (\n     TYPE_CHECKING,\n@@ -1626,3 +1627,11 @@ def _parse_url(host):\n         port = None\n \n     return scheme, host, port\n+\n+\n+def is_port_free(host, port):\n+    with socket(AF_INET, SOCK_STREAM) as session:\n+        if session.connect_ex((host, port)) == 0:\n+            return False\n+        else:\n+            return True\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -39,6 +39,7 @@ from jina.enums import (\n from jina.excepts import (\n     FlowMissingDeploymentError,\n     FlowTopologyError,\n+    PortAlreadyUsed,\n     RuntimeFailToStart,\n )\n from jina.helper import (\n@@ -51,6 +52,7 @@ from jina.helper import (\n     get_internal_ip,\n     get_public_ip,\n     get_rich_console,\n+    is_port_free,\n     typename,\n )\n from jina.jaml import JAMLCompatible\n@@ -471,6 +473,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n         kwargs.update(self._common_kwargs)\n         args = ArgNamespace.kwargs2namespace(kwargs, set_gateway_parser())\n+\n         args.noblock_on_start = True\n         args.expose_graphql_endpoint = (\n             self.args.expose_graphql_endpoint\n@@ -1133,9 +1136,17 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n         :return: this instance\n         \"\"\"\n+\n         if self._build_level.value < FlowBuildLevel.GRAPH.value:\n             self.build(copy_flow=False)\n \n+        port_gateway = self._deployment_nodes[GATEWAY_NAME].args.port\n+\n+        if not (\n+            is_port_free(__default_host__, port_gateway)\n+        ):  # we check if the port is not used at parsing time as well for robustness\n+            raise PortAlreadyUsed(f'port:{port_gateway}')\n+\n         # set env only before the Deployment get started\n         if self.args.env:\n             for k, v in self.args.env.items():\n\n---\n file path A: jina/serve/runtimes/gateway/grpc/__init__.py | file path B: jina/serve/runtimes/gateway/grpc/__init__.py\n\n@@ -3,6 +3,8 @@ import os\n import grpc\n \n from jina import __default_host__\n+from jina.excepts import PortAlreadyUsed\n+from jina.helper import is_port_free\n from jina.proto import jina_pb2_grpc\n from jina.serve.runtimes.gateway import GatewayRuntime\n from jina.serve.runtimes.gateway.request_handling import handle_request, handle_result\n@@ -26,6 +28,9 @@ class GRPCGatewayRuntime(GatewayRuntime):\n             os.unsetenv('http_proxy')\n             os.unsetenv('https_proxy')\n \n+        if not (is_port_free(__default_host__, self.args.port)):\n+            raise PortAlreadyUsed(f'port:{self.args.port}')\n+\n         self.server = grpc.aio.server(\n             options=[\n                 ('grpc.max_send_message_length', -1),\n\n---\n file path A: None | file path B: tests/integration/issues/github_4555/test_port.py\n\n@@ -0,0 +1,36 @@\n+import time\n+from threading import Thread\n+\n+import pytest\n+\n+from jina import Flow\n+from jina.excepts import PortAlreadyUsed\n+\n+\n+def test_two_flow_using_on_same_port_failing(port_generator):\n+    # hacky test but there is now good way to wait that a flow exit\n+\n+    port = port_generator()\n+\n+    f1 = Flow(port=port)\n+    f2 = Flow(port=port)\n+\n+    with f1:\n+        with pytest.raises(PortAlreadyUsed):\n+            with f2:\n+                pass\n+\n+\n+def test_two_flow_using_on_same_build_succed(port_generator):\n+    # hacky test but there is now good way to wait that a flow exit\n+\n+    port = port_generator()\n+\n+    f1 = Flow(port=port)\n+    f2 = Flow(port=port)\n+\n+    with f1:\n+        f2.build()\n+        with pytest.raises(PortAlreadyUsed):\n+            with f2:\n+                pass\n\n---\n file path A: tests/unit/test_helper.py | file path B: tests/unit/test_helper.py\n\n@@ -4,7 +4,7 @@ from types import SimpleNamespace\n import numpy as np\n import pytest\n \n-from jina import Executor, __default_endpoint__\n+from jina import Executor, Flow, __default_endpoint__\n from jina.clients.helper import _safe_callback, pprint_routes\n from jina.excepts import BadClientCallback, NotSupportedError\n from jina.helper import (\n@@ -14,6 +14,7 @@ from jina.helper import (\n     dunder_get,\n     find_request_binding,\n     get_ci_vendor,\n+    is_port_free,\n     is_yaml_filepath,\n     random_port,\n     reset_ports,\n@@ -338,3 +339,16 @@ def test_retry():\n \n     assert result == 'it works'\n     assert try_me.tried_count == 3\n+\n+\n+def test_port_occupied(port_generator):\n+    port = port_generator()\n+    with Flow(port=port):\n+        is_occupied = not (is_port_free('localhost', port))\n+        assert is_occupied\n+\n+\n+def test_port_free(port_generator):\n+    port = port_generator()\n+    is_free = is_port_free('localhost', port)\n+    assert is_free\n\n\n###\n\n", "completion": "fix: check if port is occupied (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/flow-api.md | file path B: docs/fundamentals/flow/flow-api.md\n\n@@ -424,6 +424,9 @@ f.to_k8s_yaml('flow_k8s_configuration')\n This will generate the necessary Kubernetes configuration files for all the `Executors` of the `Flow`.\n The generated folder can be used directly with `kubectl` to deploy the `Flow` to an existing Kubernetes cluster.\n \n+Based on your local Jina version, Jina Hub may rebuild the Docker image during the YAML generation process.\n+If you do not wish to rebuild the image, set the environment variable `JINA_HUB_NO_IMAGE_REBUILD`.\n+\n ## See further\n \n - {ref}`Access the Flow with the Client <client>`\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -21,7 +21,7 @@ The most important methods of the `Flow` object are the following:\n | `.post()`                          | Sends requests to the Flow API.                                                                                                     |\n | `.block()`                         | Blocks execution until the program is terminated. This is useful to keep the Flow alive so it can be used from other places (clients, etc). |\n | `.to_docker_compose_yaml()`        | Generates a Docker-Compose file listing all its Executors as Services.                                                                       |\n-| `.to_k8s_yaml(<output_directory>)` | Generates the Kubernetes configuration files in `<output_directory>`.        \n+| `.to_k8s_yaml(<output_directory>)` | Generates the Kubernetes configuration files in `<output_directory>`. Based on your local Jina version, Jina Hub may rebuild the Docker image during the YAML generation process. If you do not wish to rebuild the image, set the environment variable `JINA_HUB_NO_IMAGE_REBUILD`. |\n \n ## Why should you use a Flow?\n \n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -564,6 +564,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n         *,\n         secret: Optional[str] = None,\n         image_required: bool = True,\n+        rebuild_image: bool = True,\n         force: bool = False,\n     ) -> HubExecutor:\n         \"\"\"Fetch the executor meta info from Jina Hub.\n@@ -571,6 +572,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n         :param tag: the tag of the executor if available, otherwise, use `None` as the value\n         :param secret: the access secret of the executor\n         :param image_required: it indicates whether a Docker image is required or not\n+        :param rebuild_image: it indicates whether Jina Hub need to rebuild image or not\n         :param force: if set to True, access to fetch_meta will always pull latest Executor metas, otherwise, default\n             to local cache\n         :return: meta of executor\n@@ -594,7 +596,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n \n         pull_url = get_hubble_url_v2() + f'/rpc/executor.getPackage'\n \n-        payload = {'id': name, 'include': ['code']}\n+        payload = {'id': name, 'include': ['code'], 'rebuildImage': rebuild_image}\n         if image_required:\n             payload['include'].append('docker')\n         if secret:\n\n---\n file path A: jina/orchestrate/deployments/config/helper.py | file path B: jina/orchestrate/deployments/config/helper.py\n\n@@ -1,21 +1,29 @@\n-from jina import __version__\n+import os\n+\n+from jina import __default_executor__, __version__\n+from jina.enums import PodRoleType\n from jina.hubble.helper import parse_hub_uri\n from jina.hubble.hubio import HubIO\n-from jina.enums import PodRoleType\n-from jina import __default_executor__\n \n \n def get_image_name(uses: str) -> str:\n     \"\"\"The image can be provided in different formats by the user.\n     This function converts it to an image name which can be understood by k8s.\n     It uses the Hub api to get the image name and the latest tag on Docker Hub.\n+\n+    If you don't want to rebuild image on Jina Hub,\n+    you can set `JINA_HUB_NO_IMAGE_REBUILD` environment variable.\n+\n     :param uses: image name\n \n     :return: normalized image name\n     \"\"\"\n     try:\n+        rebuild_image = 'JINA_HUB_NO_IMAGE_REBUILD' not in os.environ\n         scheme, name, tag, secret = parse_hub_uri(uses)\n-        meta_data, _ = HubIO.fetch_meta(name, tag, secret=secret, force=True)\n+        meta_data, _ = HubIO.fetch_meta(\n+            name, tag, secret=secret, rebuild_image=rebuild_image, force=True\n+        )\n         image_name = meta_data.image_name\n         return image_name\n     except Exception:\n@@ -63,6 +71,7 @@ def construct_runtime_container_args(cargs, uses_metas, uses_with, pod_type):\n     :return: Arguments to pass to container\n     \"\"\"\n     import json\n+\n     from jina.helper import ArgNamespace\n     from jina.parsers import set_pod_parser\n \n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1753,7 +1753,11 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n     def to_k8s_yaml(self, output_base_path: str, k8s_namespace: Optional[str] = None):\n         \"\"\"\n-        Converts the Flow into a set of yaml deployments to deploy in Kubernetes\n+        Converts the Flow into a set of yaml deployments to deploy in Kubernetes.\n+\n+        If you don't want to rebuild image on Jina Hub,\n+        you can set `JINA_HUB_NO_IMAGE_REBUILD` environment variable.\n+\n         :param output_base_path: The base path where to dump all the yaml files\n         :param k8s_namespace: The name of the k8s namespace to set for the configurations. If None, the name of the Flow will be used.\n         \"\"\"\n\n---\n file path A: tests/integration/hub_usage/test_hub_usage.py | file path B: tests/integration/hub_usage/test_hub_usage.py\n\n@@ -71,7 +71,14 @@ def test_use_from_local_hub_deployment_level(\n \n     mock = mocker.Mock()\n \n-    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n+    def _mock_fetch(\n+        name,\n+        tag=None,\n+        secret=None,\n+        image_required=True,\n+        rebuild_image=True,\n+        force=False,\n+    ):\n         mock(name=name)\n         return (\n             HubExecutor(\n@@ -99,7 +106,14 @@ def test_use_from_local_hub_flow_level(\n \n     mock = mocker.Mock()\n \n-    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n+    def _mock_fetch(\n+        name,\n+        tag=None,\n+        secret=None,\n+        image_required=True,\n+        rebuild_image=True,\n+        force=False,\n+    ):\n         mock(name=name)\n         return (\n             HubExecutor(\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -172,7 +172,8 @@ def test_push_wrong_dockerfile(\n     )\n \n \n-def test_fetch(mocker, monkeypatch):\n+@pytest.mark.parametrize('rebuild_image', [True, False])\n+def test_fetch(mocker, monkeypatch, rebuild_image):\n     mock = mocker.Mock()\n \n     def _mock_post(url, json, headers=None):\n@@ -182,7 +183,9 @@ def test_fetch(mocker, monkeypatch):\n     monkeypatch.setattr(requests, 'post', _mock_post)\n     args = set_hub_pull_parser().parse_args(['jinahub://dummy_mwu_encoder'])\n \n-    executor, _ = HubIO(args).fetch_meta('dummy_mwu_encoder', None, force=True)\n+    executor, _ = HubIO(args).fetch_meta(\n+        'dummy_mwu_encoder', None, rebuild_image=rebuild_image, force=True\n+    )\n \n     assert executor.uuid == 'dummy_mwu_encoder'\n     assert executor.name == 'alias_dummy'\n@@ -190,9 +193,15 @@ def test_fetch(mocker, monkeypatch):\n     assert executor.image_name == 'jinahub/pod.dummy_mwu_encoder'\n     assert executor.md5sum == 'ecbe3fdd9cbe25dbb85abaaf6c54ec4f'\n \n+    _, mock_kwargs = mock.call_args_list[0]\n+    assert mock_kwargs['json']['rebuildImage'] is rebuild_image\n+\n     executor, _ = HubIO(args).fetch_meta('dummy_mwu_encoder', '', force=True)\n     assert executor.tag == 'v0'\n \n+    _, mock_kwargs = mock.call_args_list[1]\n+    assert mock_kwargs['json']['rebuildImage'] is True  # default value must be True\n+\n     executor, _ = HubIO(args).fetch_meta('dummy_mwu_encoder', 'v0.1', force=True)\n     assert executor.tag == 'v0.1'\n \n@@ -261,7 +270,14 @@ class DownloadMockResponse:\n def test_pull(test_envs, mocker, monkeypatch):\n     mock = mocker.Mock()\n \n-    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n+    def _mock_fetch(\n+        name,\n+        tag=None,\n+        secret=None,\n+        image_required=True,\n+        rebuild_image=True,\n+        force=False,\n+    ):\n         mock(name=name)\n         return (\n             HubExecutor(\n@@ -318,7 +334,14 @@ def test_offline_pull(test_envs, mocker, monkeypatch, tmpfile):\n     version = 'v0'\n \n     @disk_cache_offline(cache_file=str(tmpfile))\n-    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n+    def _mock_fetch(\n+        name,\n+        tag=None,\n+        secret=None,\n+        image_required=True,\n+        rebuild_image=True,\n+        force=False,\n+    ):\n         mock(name=name)\n         if fail_meta_fetch:\n             raise urllib.error.URLError('Failed fetching meta')\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_docker_compose_pod_config.py | file path B: tests/unit/orchestrate/deploymens/config/test_docker_compose_pod_config.py\n\n@@ -382,7 +382,14 @@ def test_docker_compose_yaml_regular_deployment(\n     polling,\n     monkeypatch,\n ):\n-    def _mock_fetch(name, tag=None, secret=None, force=False):\n+    def _mock_fetch(\n+        name,\n+        tag=None,\n+        secret=None,\n+        image_required=True,\n+        rebuild_image=True,\n+        force=False,\n+    ):\n         return (\n             HubExecutor(\n                 uuid='hello',\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_helper.py | file path B: tests/unit/orchestrate/deploymens/config/test_helper.py\n\n@@ -1,8 +1,13 @@\n+import os\n+\n import pytest\n \n from jina import __version__\n+from jina.hubble import HubExecutor\n+from jina.hubble.hubio import HubIO\n from jina.orchestrate.deployments.config.helper import (\n     get_base_executor_version,\n+    get_image_name,\n     to_compatible_name,\n )\n \n@@ -27,3 +32,50 @@ def test_version(is_master, requests_mock):\n \n def test_to_compatible_name():\n     assert to_compatible_name('executor/hey-ha_HO') == 'executor-hey-ha-ho'\n+\n+\n+def test_get_image_name(mocker, monkeypatch):\n+    mock = mocker.Mock()\n+\n+    def _mock_fetch(\n+        name,\n+        tag=None,\n+        secret=None,\n+        image_required=True,\n+        rebuild_image=True,\n+        force=False,\n+    ):\n+        mock(name=name, rebuild_image=rebuild_image)\n+\n+        return (\n+            HubExecutor(\n+                uuid='hello',\n+                name=name,\n+                tag='v0',\n+                image_name=f'jinahub/{name}',\n+                md5sum=None,\n+                visibility=True,\n+                archive_url=None,\n+            ),\n+            False,\n+        )\n+\n+    monkeypatch.setattr(HubIO, 'fetch_meta', _mock_fetch)\n+\n+    uses = 'jinahub://DummyExecutor'\n+\n+    image_name = get_image_name(uses)\n+\n+    assert image_name == 'jinahub/DummyExecutor'\n+\n+    _, mock_kwargs = mock.call_args_list[0]\n+    assert mock_kwargs['rebuild_image'] is True  # default value must be True\n+\n+    os.environ['JINA_HUB_NO_IMAGE_REBUILD'] = '1'\n+\n+    get_image_name(uses)\n+\n+    del os.environ['JINA_HUB_NO_IMAGE_REBUILD']\n+\n+    _, mock_kwargs = mock.call_args_list[1]\n+    assert mock_kwargs['rebuild_image'] is False  # env var is set, so it must be False\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_k8s_deployment_config.py | file path B: tests/unit/orchestrate/deploymens/config/test_k8s_deployment_config.py\n\n@@ -378,7 +378,14 @@ def test_k8s_yaml_regular_deployment(\n     polling,\n     monkeypatch,\n ):\n-    def _mock_fetch(name, tag=None, secret=None, force=False):\n+    def _mock_fetch(\n+        name,\n+        tag=None,\n+        secret=None,\n+        image_required=True,\n+        rebuild_image=True,\n+        force=False,\n+    ):\n         return (\n             HubExecutor(\n                 uuid='hello',\n\n\n###\n\n", "completion": "feat(hubble): add option on fetch_meta for rebuild image or not (#<issue-num>)"}
{"prompt": " file path A: tests/integration/issues/github_4521/__init__.py | file path B: tests/integration/issues/github_4521/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/issues/github_4521/test_blob_transmission.py\n\n@@ -0,0 +1,26 @@\n+import pytest\n+from docarray import Document\n+\n+from jina import Client, Executor, Flow, requests\n+\n+\n+class MyExec(Executor):\n+    @requests\n+    def foo(self, docs, parameters, **kwargs):\n+        decode = parameters['decode']\n+        if decode:\n+            docs[0].text = docs[0].blob.decode('UTF-8')\n+\n+\n+@pytest.mark.parametrize('decode', [True, False])\n+@pytest.mark.parametrize('protocol', ['grpc', 'websocket', 'http'])\n+def test_blob_transmission(decode, protocol):\n+    decode = False\n+    f = Flow(protocol=protocol).add(uses=MyExec)\n+    with f:\n+        c = Client(port=f.port, protocol=protocol)\n+        d = c.post('/', Document(blob=b'hello'), parameters={'decode': decode})[0]\n+    if decode:  # test that the Executor gets the correct data\n+        assert d.text == 'hello'\n+    else:  # test that the response contains the correct data\n+        assert d.blob == b'hello'\n\n\n###\n\n", "completion": "test: add tests for blob over http (#<issue-num>)"}
{"prompt": " file path A: setup.py | file path B: setup.py\n\n@@ -174,6 +174,7 @@ setup(\n         'Programming Language :: Python :: 3.7',\n         'Programming Language :: Python :: 3.8',\n         'Programming Language :: Python :: 3.9',\n+        'Programming Language :: Python :: 3.10',\n         'Programming Language :: Unix Shell',\n         'Environment :: Console',\n         'License :: OSI Approved :: Apache Software License',\n\n\n###\n\n", "completion": "chore: update setup.py to include py310"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -151,6 +151,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12793,3 +12794,39 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```dc8a99ad```](https://github.com/jina-ai/jina/commit/dc8a99addde6f16637cc8439fed4d6208bc6384e)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```17172d5f```](https://github.com/jina-ai/jina/commit/17172d5f8a193480ded73babd0dc4ba5cc3a51c5)] __-__ __version__: the next version will be 3.2.9 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-10></a>\n+## Release Note (`3.2.10`)\n+\n+> Release time: 2022-03-30 08:37:32\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  Jina Dev Bot,  Roshan Jossy,  Tobias Jacobowitz,  Johannes Messner,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```ffdae546```](https://github.com/jina-ai/jina/commit/ffdae546026a434fb1b441e7948bc672fe4b4267)] __-__ __grpc__: add os env bytes counter (#4560) (*Han Xiao*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```c7683026```](https://github.com/jina-ai/jina/commit/c7683026c3f3c99c9bb6903c92b687a9da9aa45d)] __-__ better host scheme parsing (#4559) (*samsja*)\n+ - [[```59e14986```](https://github.com/jina-ai/jina/commit/59e149862342ffb59c531c0dfee4e094b3007e9d)] __-__ pin black version (#4557) (*Tobias Jacobowitz*)\n+ - [[```d1f08482```](https://github.com/jina-ai/jina/commit/d1f08482f1a2cd9f871faa2b161e48b667388130)] __-__ install linkerd in cd pipeline (#4552) (*Tobias Jacobowitz*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```2ce76751```](https://github.com/jina-ai/jina/commit/2ce767517532ebbf85ade4b84cfba0f7bb69c4f9)] __-__ remove jinad (#4550) (*Tobias Jacobowitz*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```e3607334```](https://github.com/jina-ai/jina/commit/e3607334c2afd548cf74664f9e75fbe5b31767aa)] __-__ __tracking__: add scarf tracking (#4553) (*Roshan Jossy*)\n+ - [[```953206fa```](https://github.com/jina-ai/jina/commit/953206fabc3984451c1d9713fce6bda33d22a70e)] __-__ explain https support (#4500) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```98a44f90```](https://github.com/jina-ai/jina/commit/98a44f90464d93ba8015482cf03b0902e74b22cc)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```eb78af6b```](https://github.com/jina-ai/jina/commit/eb78af6b5d8f2cf75a30996e36559673032b4f6f)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```5b292a3f```](https://github.com/jina-ai/jina/commit/5b292a3f67c75f8fd71d37a9f7cd4922c04a1e99)] __-__ __version__: the next version will be 3.2.10 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.10'\n+__version__ = '3.2.11'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.11"}
{"prompt": " file path A: jina/proto/serializer.py | file path B: jina/proto/serializer.py\n\n@@ -1,4 +1,5 @@\n-from typing import List, Union, Iterable\n+import os\n+from typing import Iterable, List, Union\n \n from jina.proto import jina_pb2\n from jina.types.request.control import ControlRequest\n@@ -49,8 +50,13 @@ class DataRequestProto:\n         # noqa: DAR201\n         \"\"\"\n         if not x.is_decompressed:\n-            return x.buffer\n-        return x.proto.SerializePartialToString()\n+            r = x.buffer\n+        else:\n+            r = x.proto.SerializePartialToString()\n+        os.environ['JINA_GRPC_SEND_BYTES'] = str(\n+            len(r) + int(os.environ.get('JINA_GRPC_SEND_BYTES', 0))\n+        )\n+        return r\n \n     @staticmethod\n     def FromString(x: bytes):\n@@ -59,7 +65,9 @@ class DataRequestProto:\n         # noqa: DAR102\n         # noqa: DAR201\n         \"\"\"\n-\n+        os.environ['JINA_GRPC_RECV_BYTES'] = str(\n+            len(x) + int(os.environ.get('JINA_GRPC_RECV_BYTES', 0))\n+        )\n         return DataRequest(x)\n \n \n\n---\n file path A: tests/integration/grpc_bytes_census/__init__.py | file path B: tests/integration/grpc_bytes_census/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/grpc_bytes_census/test_bytes_census.py\n\n@@ -0,0 +1,25 @@\n+import os\n+\n+import pytest\n+\n+from docarray import DocumentArray\n+from jina import Flow\n+\n+\n+@pytest.mark.parametrize('inputs', [None, DocumentArray.empty(10)])\n+def test_grpc_census(inputs):\n+    assert int(os.environ.get('JINA_GRPC_SEND_BYTES', 0)) == 0\n+    assert int(os.environ.get('JINA_GRPC_RECV_BYTES', 0)) == 0\n+    with Flow().add().add() as f:\n+        f.post(\n+            on='/',\n+            inputs=inputs,\n+        )\n+    assert int(os.environ['JINA_GRPC_SEND_BYTES']) > 0\n+    assert int(os.environ['JINA_GRPC_RECV_BYTES']) > 0\n+    # add some route info, so size must be larger\n+    assert int(os.environ['JINA_GRPC_SEND_BYTES']) < int(\n+        os.environ['JINA_GRPC_RECV_BYTES']\n+    )\n+    del os.environ['JINA_GRPC_SEND_BYTES']\n+    del os.environ['JINA_GRPC_RECV_BYTES']\n\n\n###\n\n", "completion": "feat(grpc): add os env bytes counter (#<issue-num>)"}
{"prompt": " file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -201,5 +201,5 @@\n     </qa-bot>\n \n </div>\n-\n+<img referrerpolicy=\"no-referrer-when-downgrade\" src=\"https://static.scarf.sh/a.png?x-pxid=1b470c1d-3b55-4d38-baa8-989bfba2a218\" />\n {%- endblock %}\n\n\n###\n\n", "completion": "docs(tracking): add scarf tracking (#<issue-num>)"}
{"prompt": " file path A: .pre-commit-config.yaml | file path B: .pre-commit-config.yaml\n\n@@ -28,7 +28,7 @@ repos:\n       args:\n       - --select=D101,D102,D103\n - repo: https://github.com/ambv/black\n-  rev: 20.8b1\n+  rev: 22.3.0\n   hooks:\n   - id: black\n     types: [python]\n\n---\n file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -68,7 +68,7 @@ pytest-custom_exit_code:    test\n bs4:                        cicd\n aiostream:                  standard,devel\n jsonschema:                 cicd\n-black==20.8b1:              test\n+black==22.3.0:              test\n portforward>=0.2.4:         cicd\n kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n\n---\n file path A: jina/helloworld/chatbot/my_executors.py | file path B: jina/helloworld/chatbot/my_executors.py\n\n@@ -3,14 +3,14 @@ from typing import Dict\n \n import numpy as np\n import torch\n+from docarray import DocumentArray\n from transformers import AutoModel, AutoTokenizer\n \n from jina import Executor, requests\n-from docarray import DocumentArray\n \n \n class MyTransformer(Executor):\n-    \"\"\"Transformer executor class \"\"\"\n+    \"\"\"Transformer executor class\"\"\"\n \n     def __init__(\n         self,\n@@ -70,7 +70,7 @@ class MyTransformer(Executor):\n \n \n class MyIndexer(Executor):\n-    \"\"\"Simple indexer class \"\"\"\n+    \"\"\"Simple indexer class\"\"\"\n \n     def __init__(self, **kwargs):\n         super().__init__(**kwargs)\n\n---\n file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -393,7 +393,7 @@ class Deployment(BaseDeployment):\n         self.join()\n \n     def update_pod_args(self):\n-        \"\"\" Update args of all its pods based on Deployment args. Including head/tail\"\"\"\n+        \"\"\"Update args of all its pods based on Deployment args. Including head/tail\"\"\"\n         if isinstance(self.args, Dict):\n             # This is used when a Deployment is created in a remote context, where pods & their connections are already given.\n             self.pod_args = self.args\n@@ -408,7 +408,7 @@ class Deployment(BaseDeployment):\n             self.pod_args['head'].port = port\n \n     def update_worker_pod_args(self):\n-        \"\"\" Update args of all its worker pods based on Deployment args. Does not touch head and tail\"\"\"\n+        \"\"\"Update args of all its worker pods based on Deployment args. Does not touch head and tail\"\"\"\n         self.pod_args['pods'] = self._set_pod_args(self.args)\n \n     @property\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -68,7 +68,7 @@ pytest-custom_exit_code:    test\n bs4:                        cicd\n aiostream:                  standard,devel\n jsonschema:                 cicd\n-black==20.8b1:              test\n+black==22.3.0:              test\n portforward>=0.2.4:         cicd\n kubernetes>=18.20.0:        test\n pytest-kind==21.1.3:        test\n\n---\n file path A: jina/serve/runtimes/head/__init__.py | file path B: jina/serve/runtimes/head/__init__.py\n\n@@ -112,7 +112,7 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n         )\n \n     async def async_setup(self):\n-        \"\"\" Wait for the GRPC server to start \"\"\"\n+        \"\"\"Wait for the GRPC server to start\"\"\"\n         self._grpc_server = grpc.aio.server(\n             options=[\n                 ('grpc.max_send_message_length', -1),\n@@ -133,7 +133,7 @@ class HeadRuntime(AsyncNewLoopRuntime, ABC):\n         await self._grpc_server.start()\n \n     async def async_run_forever(self):\n-        \"\"\"Block until the GRPC server is terminated \"\"\"\n+        \"\"\"Block until the GRPC server is terminated\"\"\"\n         self.connection_pool.start()\n         await self._grpc_server.wait_for_termination()\n \n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -162,7 +162,7 @@ class DataRequestHandler:\n                     existing_executor_routes.append(route.executor)\n \n     def close(self):\n-        \"\"\" Close the data request handler, by closing the executor \"\"\"\n+        \"\"\"Close the data request handler, by closing the executor\"\"\"\n         if not self._is_closed:\n             self._executor.close()\n             self._is_closed = True\n\n---\n file path A: jina/serve/runtimes/worker/__init__.py | file path B: jina/serve/runtimes/worker/__init__.py\n\n@@ -3,13 +3,13 @@ import asyncio\n import multiprocessing\n import threading\n from abc import ABC\n-from typing import Optional, Union, List\n+from typing import List, Optional, Union\n \n import grpc\n \n+from jina.proto import jina_pb2_grpc\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n from jina.serve.runtimes.request_handlers.data_request_handler import DataRequestHandler\n-from jina.proto import jina_pb2_grpc\n from jina.types.request.control import ControlRequest\n from jina.types.request.data import DataRequest\n \n@@ -59,7 +59,7 @@ class WorkerRuntime(AsyncNewLoopRuntime, ABC):\n         await self._grpc_server.start()\n \n     async def async_run_forever(self):\n-        \"\"\"Block until the GRPC server is terminated \"\"\"\n+        \"\"\"Block until the GRPC server is terminated\"\"\"\n         await self._grpc_server.wait_for_termination()\n \n     async def async_cancel(self):\n\n---\n file path A: jina/types/request/data.py | file path B: jina/types/request/data.py\n\n@@ -15,7 +15,7 @@ RequestSourceType = TypeVar(\n \n \n class DataRequest(Request):\n-    \"\"\" Represents a DataRequest used for exchanging DocumentArrays to and within a Flow\"\"\"\n+    \"\"\"Represents a DataRequest used for exchanging DocumentArrays to and within a Flow\"\"\"\n \n     class _DataContent:\n         def __init__(self, content: 'jina_pb2.DataRequestProto.DataContentProto'):\n\n---\n file path A: scripts/black.sh | file path B: scripts/black.sh\n\n@@ -1,5 +1,5 @@\n #!/bin/bash\n-pip install black==20.8b1\n+pip install black==22.3.0\n arrVar=()\n echo we ignore non-*.py files and files generated from protobuf\n excluded_files=(\n\n\n###\n\n", "completion": "fix: pin black version (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -3,103 +3,83 @@\n The most convenient way to work with the `Flow` API is the Python Client.\n It enables you to send `Documents` to a running `Flow` in a number of different ways, as shown below.\n \n-```{admonition} Caution\n-:class: caution\n-`Flow` provides a `.post()` method that follows the same interface as `client.post()`.\n-However, once your solution is deployed in the cloud, the Flow interface is not present anymore.\n-Hence, `flow.post()` is not recommended outside of testing or debugging use cases.\n-```\n \n ## HTTP, gRPC, and WebSocket\n \n Jina Flows and Clients support three different networking protocols: HTTP, gRPC, and WebSocket.\n-These can all be used in the same way by using `client.post()`.\n+For each of them, you first connect your Client to the Flow, before you can send requests to it.\n \n-Starting the Flow:\n+### Connect Client to a Flow\n+\n+If there is not already a Flow running in the background or on the network, you can start one:\n \n ```python\n from jina import Flow\n \n-PORT = 12345\n+PORT = 1234\n PROTOCOL = 'grpc'  # one of 'grpc', 'http', 'websocket'\n \n with Flow(port=PORT, protocol=PROTOCOL) as f:\n     f.block()\n ```\n \n-To connect a Client to the Flow's gateway, you need to specify an IP host address and port on which the Flow can be reached.\n-This is done using the `host=` and `port=` constructor keywords.\n-If the Client and the Flow gateway are running on the same machine, the `host=` parameter can be omitted, as it defaults to `'0.0.0.0'`.\n+To connect to the `Flow`, the Client has to specify the followings parameters.\n+All af these have to match the Flow and how it was set up:\n+* the `protocol` it needs to use to communicate with the Flow\n+* the `host` and the `port` as exposed by the Flow\n+* if it needs to use `TLS` encryption\n+\n+You can define these parameters by passing a valid URI scheme as part of the `host` argument:\n \n-Additionally, the connection protocol can be toggled between `'grpc'`, `'http'`, and `'websocket'` using the `protocol=`\n-keyword, where `'grpc'` is the default.\n+````{tab} TLS disabled\n \n ```python\n from jina import Client\n \n-HOST = '0.0.0.0'  # host address where the Flow can be reached\n-PORT = 12345  # port where the Flow can be reached\n-PROTOCOL = 'grpc'  # one of 'grpc', 'http', 'websocket'. Needs to be same as specified by the Flow\n-\n-client = Client(host=HOST, port=PORT, protocol=PROTOCOL)\n+Client(host='http://my.awesome.flow:1234')\n+Client(host='ws://my.awesome.flow:1234')\n+Client(host='grpc://my.awesome.flow:1234')\n ```\n \n-Then, the Client can send requests to the Flow using its `.post()` method.\n-This expects as inputs the {ref}`Executor endpoint <exec-endpoint>` that you want to target, as well as a Document or Iterable of Documents:\n+````\n \n+````{tab} TLS enabled\n \n ```python\n-from docarray import Document, DocumentArray\n-\n-\n-d1 = Document(content='hello')\n-d2 = Document(content='world')\n-\n-\n-def doc_gen():\n-    for j in range(10):\n-        yield Document(content=f'hello {j}')\n-\n-\n-client = Client(host=HOST, port=PORT)\n-\n-client.post('/endpoint', d1)  # Single Document\n-\n-client.post('/endpoint', [d1, d2])  # List of Documents\n+from jina import Client\n \n-client.post('/endpoint', doc_gen)  # Document generator\n+Client(host='https://my.awesome.flow:1234')\n+Client(host='wss://my.awesome.flow:1234')\n+Client(host='grpcs://my.awesome.flow:1234')\n+```\n \n-client.post('/endpoint', DocumentArray([d1, d2]))  # DocumentArray\n+````\n \n-client.post('/endpoint')  # Empty\n-```\n-### Specifying Host scheme\n \n-To connect to the `Flow` the client has to specify the followings parameters:\n-* the `protocol` it needs to use to communicate with the `Flow\n-* the `host` and the `port`on which the Flow is exposed\n-* if he needs to use `tls` encryption\n+Equivalently, you can pass each relevant parameter as a keyword argument:\n \n-You can define these parameters by passing a valid URI scheme as part of the `host` argument:\n+````{tab} TLS disabled\n \n ```python\n-from jina import Client\n-\n-Client(host='https://my.awesome.flow:1234')\n-Client(host='wss://my.awesome.flow:1234')\n-Client(host='grpcs://my.awesome.flow:1234')\n+Client(host='my.awesome.flow', port=1234, protocol='http')\n+Client(host='my.awesome.flow', port=1234, protocol='websocket')\n+Client(host='my.awesome.flow', port=1234, protocol='grpc')\n ```\n \n-You can as well pass each relevant parameter as a keyword argument:\n+````\n+\n+````{tab} TLS enabled\n \n-the following example is equivalent to the one above\n ```python\n Client(host='my.awesome.flow', port=1234, protocol='http', tls=True)\n Client(host='my.awesome.flow', port=1234, protocol='websocket', tls=True)\n Client(host='my.awesome.flow', port=1234, protocol='grpc', tls=True)\n ```\n \n-You can use a mixe of both as well:\n+````\n+\n+\n+You can also use a mixe of both:\n \n ```python\n Client(host='https://my.awesome.flow', port=1234)\n@@ -108,17 +88,65 @@ Client(host='my.awesome.flow:1234', protocol='http', tls=True)\n \n ````{admonition} Caution\n :class: caution\n-You can't define these parameters by keyword arugment and by host scheme (You can't have two sources of truth)\n-Example : the following code will raise an exception\n+You can't define these parameters both by keyword argument and by host scheme - you can't have two sources of truth.\n+Example: the following code will raise an exception:\n ```python\n Client(host='https://my.awesome.flow:1234', port=4321)\n ```\n ````\n \n+````{admonition} Hint\n+:class: hint\n+The arguments above have usefule defaults: `protocol='grpc'` and `host='0.0.0.0'`.\n+This is particularly useful when debugging or accessing a Flow on your local machine.\n \n+To connect to a Flow `f` it is therefore often enough to do the following:\n \n+```{code-block} python\n+c = Client(port=f.port)\n+```\n+````\n+\n+### Send requests to the Flow\n+\n+After a Client has connected to a Flow, it can send requests to the Flow using its `.post()` method.\n+This expects as inputs the {ref}`Executor endpoint <exec-endpoint>` that you want to target, as well as a Document or Iterable of Documents:\n+\n+\n+```python\n+from docarray import Document, DocumentArray\n+\n+\n+d1 = Document(content='hello')\n+d2 = Document(content='world')\n+\n+\n+def doc_gen():\n+    for j in range(10):\n+        yield Document(content=f'hello {j}')\n+\n+\n+client = Client(port=PORT)\n+\n+client.post('/endpoint', d1)  # Single Document\n+\n+client.post('/endpoint', [d1, d2])  # List of Documents\n+\n+client.post('/endpoint', doc_gen)  # Document generator\n+\n+client.post('/endpoint', DocumentArray([d1, d2]))  # DocumentArray\n+\n+client.post('/endpoint')  # Empty\n+```\n \n \n+```{admonition} Caution\n+:class: caution\n+`Flow` also provides a `.post()` method that follows the same interface as `client.post()`.\n+However, once your solution is deployed remotely, the Flow interface is not present anymore.\n+Hence, `flow.post()` is not recommended outside of testing or debugging use cases.\n+```\n+\n \n ### Batching Requests\n \n@@ -386,6 +414,7 @@ with Flow() as f:\n \n ````\n \n+\n ### Custom gRPC compression for GRPC Client\n \n If the communication to the `Flow` needs to be done via gRPC, you can pass `compression` parameter to `client.post` to benefit from (`grpc compression`)[https://grpc.github.io/grpc/python/grpc.html#compression] methods. \n@@ -398,6 +427,25 @@ client = Client()\n client.post(..., compression='Gzip')\n ```\n \n+### TLS support\n+\n+To connect to a Flow that has been {ref}`configured to use TLS <flow-tls>` in combination with gRPC, http, or websocket,\n+set the Client's `tls` parameter to `True`:\n+\n+```python\n+c_http = Client(protocol='http', tls=True, host=..., port=...)\n+c_ws = Client(protocol='websocket', tls=True, host=..., port=...)\n+c_grpc = Client(protocol='grpc', tls=True, host=..., port=...)\n+```\n+\n+The same can be achieved by passing a valid URI to the `host` parameter, and appending 's' to the protocol definition:\n+\n+```python\n+Client(host='https://my.awesome.flow:1234')\n+Client(host='wss://my.awesome.flow:1234')\n+Client(host='grpcs://my.awesome.flow:1234')\n+```\n+\n ## GraphQL\n \n The Jina Client additionally supports fetching data via GraphQL mutations using `client.mutate()`:\n\n---\n file path A: docs/fundamentals/flow/flow-api.md | file path B: docs/fundamentals/flow/flow-api.md\n\n@@ -211,10 +211,46 @@ f = Flow(protocol='http', no_debug_endpoints=True, no_crud_endpoints=True)\n \n After setting up a Flow in this way, the {ref}`default HTTP endpoints <custom-http>` will not be exposed.\n \n-### Add GraphQL endpoint\n+(cors)=\n+### Enable Cross-Origin Resource Sharing (CORS)\n+\n+To make a Flow accessible from a website with a different domain, you need to enable [Cross-Origin Resource Sharing (CORS)](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS).\n+Among other things, CORS is necessary to provide a {ref}`Swagger UI interface <swagger-ui>` for your Flow.\n+\n+Note that CORS is disabled by default, for security reasons.\n+To enable CORS, configure your Flow in the following way:\n+```python\n+from jina import Flow\n+\n+f = Flow(cors=True, protocol='http')\n+```\n+\n+### Advanced configuration options\n+\n+HTTP support in Jina is powered by [Uvicorn](https://www.uvicorn.org/).\n+You can configure the Flow's internal Uvicorn sever to your heart's content by passing `uvicorn_kwargs` to the Flow:\n \n-````{admonition} Attention\n-:class: attention\n+```python\n+from jina import Flow\n+\n+f = Flow(protocol='http', uvicorn_kwargs={'loop': 'asyncio', 'http': 'httptools'})\n+```\n+\n+These arguments will be directly passed to the Uvicorn server.\n+\n+````{admonition} See Also\n+:class: seealso\n+\n+For more details about the arguments that are used here, and about other available settings for the Uvicorn server,\n+see their [website](https://www.uvicorn.org/settings/).\n+\n+````\n+\n+\n+## Add GraphQL endpoint\n+\n+````{admonition} Caution\n+:class: caution\n \n GraphQL support is an optional feature that requires optional dependencies.\n To install these, run `pip install jina[graphql]` or `pip install jina[all]`.\n@@ -238,6 +274,35 @@ f = Flow(protocol='http', expose_graphql_endpont=True)\n For more details about the Jina GraphQL enpoint, see {ref}`here <flow-graphql>`.\n ````\n \n+\n+\n+(flow-tls)=\n+## Enable TLS\n+\n+You can enable TLS encryption between your Flow's Gateway and a Client, for any of the protocols supported by Jina (HTTP, gRPC, and Websocket).\n+\n+````{admonition} Caution\n+:class: caution\n+Enabling TLS will encrypt the data that is transferred between the Flow and the Client.\n+Data that is passed between the microservices configured by the Flow, such as Executors, will **not** be encrypted.\n+````\n+\n+To enable TLS encryption, you need to pass a valid *keyfile* and *certfile* to the Flow, using the `ssl_keyfile` `ssl_certfile`\n+parameters:\n+\n+```python\n+PORT = ...\n+\n+f = Flow(\n+    port=PORT,\n+    ssl_certfile='path/to/certfile.crt',\n+    ssl_keyfile='path/to/keyfile.crt',\n+)\n+```\n+\n+If both of these are provided, the Flow will automatically configure itself to use TLS encryption for its communication with any Client.\n+\n+\n ## Limit outstanding requests\n \n By default, Jina's Client sens requests to the Flow as fast as possible, without any throttling.\n@@ -269,19 +334,6 @@ with Flow(prefetch=2).add(uses=MyExecutor) as f:\n When working with very slow executors and a big amount of data, you must set `prefetch` to some small number to prevent out of memory problems. If you are unsure, always set `prefetch=1`.\n ```\n \n-(cors)=\n-### Enable Cross-Origin Resource Sharing (CORS)\n-\n-To make a Flow accessible from a website with a different domain, you need to enable [Cross-Origin Resource Sharing (CORS)](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS).\n-Among other things, CORS is necessary to provide a {ref}`Swagger UI interface <swagger-ui>` for your Flow.\n-\n-Not that CORS is disabled by default, for security reasons.\n-To enable CORS, configure your Flow in the following way:\n-```python\n-from jina import Flow\n-\n-f = Flow(cors=True, protocol='http')\n-```\n \n ## Generate deployment configuration\n \n\n\n###\n\n", "completion": "docs: explain https support (#<issue-num>)"}
{"prompt": " file path A: .github/workflows/cd.yml | file path B: .github/workflows/cd.yml\n\n@@ -239,6 +239,7 @@ jobs:\n           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n       - name: Test k8s\n         run: |\n+          curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh\n           pytest -v -s --suppress-no-test-exit-code --force-flaky --min-passes 1 --max-runs 5 --cov=jina --cov-report=xml ./tests/k8s/\n         timeout-minutes: 30\n       - name: Check codecov file\n\n\n###\n\n", "completion": "fix: install linkerd in cd pipeline (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -150,6 +150,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12754,3 +12755,40 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```550a50f1```](https://github.com/jina-ai/jina/commit/550a50f1eb86bc819316bfc95a2f395235f6a809)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n  - [[```ee80d2f3```](https://github.com/jina-ai/jina/commit/ee80d2f316a94e17d943c8e487bfd25bd904fddc)] __-__ __version__: the next version will be 3.2.8 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-9></a>\n+## Release Note (`3.2.9`)\n+\n+> Release time: 2022-03-28 08:49:07\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Jina Dev Bot,  Johannes Messner,  Wang Bo,  Joan Fontanals,  Han Xiao,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```a0844f72```](https://github.com/jina-ai/jina/commit/a0844f72c467bc07ec661202540f08b79aa1b9e3)] __-__ __client__: add total_docs to client post kwargs (*Han Xiao*)\n+ - [[```dd5f08e9```](https://github.com/jina-ai/jina/commit/dd5f08e9d0c535de2f0e6b106db3b21c597752cd)] __-__ add grpc tls support on gateway (#4522) (*samsja*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```0f008bc2```](https://github.com/jina-ai/jina/commit/0f008bc281b681e779cdd2fc1daf2be9ea87271d)] __-__ client args are now parse in the client function (#4549) (*samsja*)\n+ - [[```1791a9f6```](https://github.com/jina-ai/jina/commit/1791a9f66a74a46d27d760ff434f2b2ecab29981)] __-__ deployment protocol (#4541) (*Johannes Messner*)\n+ - [[```e17d9558```](https://github.com/jina-ai/jina/commit/e17d9558df33e2281dd4a94ab573c608be4d6e2f)] __-__ deprecation of https (#4537) (*samsja*)\n+ - [[```2d27139c```](https://github.com/jina-ai/jina/commit/2d27139c37590ba4b235ba83145094ec344c51f8)] __-__ move imports to local (#4538) (*samsja*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```dfc6934a```](https://github.com/jina-ai/jina/commit/dfc6934ac20d8fe38952c48154d72344a639c9eb)] __-__ fix create app example (#4543) (*Joan Fontanals*)\n+ - [[```4ef87a50```](https://github.com/jina-ai/jina/commit/4ef87a504860d5910a0309ebe34fd0b14dbf4965)] __-__ fix formatting (#4531) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```84089a02```](https://github.com/jina-ai/jina/commit/84089a0287933ec07b165d32498abc92d6f95898)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```c8ce3b3e```](https://github.com/jina-ai/jina/commit/c8ce3b3e092e761083451ff7c3ebc7f71a23cde1)] __-__ Revert &#34;chore: remove legacy codebooks and figures&#34; (#4546) (*Wang Bo*)\n+ - [[```437943dd```](https://github.com/jina-ai/jina/commit/437943dd2dab87e22b0662b2081f13250918ec01)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```e0367473```](https://github.com/jina-ai/jina/commit/e03674731a7032035cdf6019b0492a58badffeab)] __-__ remove legacy codebooks and figures (#4530) (*Wang Bo*)\n+ - [[```dc8a99ad```](https://github.com/jina-ai/jina/commit/dc8a99addde6f16637cc8439fed4d6208bc6384e)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```17172d5f```](https://github.com/jina-ai/jina/commit/17172d5f8a193480ded73babd0dc4ba5cc3a51c5)] __-__ __version__: the next version will be 3.2.9 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.9'\n+__version__ = '3.2.10'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.10"}
{"prompt": " file path A: jina/clients/__init__.py | file path B: jina/clients/__init__.py\n\n@@ -2,6 +2,8 @@\n import argparse\n from typing import TYPE_CHECKING, Optional, Union, overload\n \n+from jina.helper import parse_client\n+\n __all__ = ['Client']\n \n from jina.enums import GatewayProtocolType\n@@ -66,6 +68,10 @@ def Client(\n     :param kwargs: Additional arguments.\n     :return: An instance of :class:`GRPCClient` or :class:`WebSocketClient`.\n     \"\"\"\n+    if not (\n+        args and isinstance(args, argparse.Namespace)\n+    ):  # we need to parse the kwargs as soon as possible otherwise to get the gateway type\n+        args = parse_client(kwargs)\n \n     protocol = (\n         args.protocol if args else kwargs.get('protocol', GatewayProtocolType.GRPC)\n\n---\n file path A: jina/clients/base/__init__.py | file path B: jina/clients/base/__init__.py\n\n@@ -4,23 +4,12 @@ import argparse\n import inspect\n import os\n from abc import ABC\n-from typing import (\n-    TYPE_CHECKING,\n-    Any,\n-    AsyncIterator,\n-    Callable,\n-    Dict,\n-    Iterator,\n-    Optional,\n-    Tuple,\n-    Union,\n-)\n+from typing import TYPE_CHECKING, AsyncIterator, Callable, Iterator, Optional, Union\n \n from jina.excepts import BadClientInput\n-from jina.helper import ArgNamespace, T, typename\n+from jina.helper import T, parse_client, typename\n from jina.logging.logger import JinaLogger\n from jina.logging.predefined import default_logger\n-from jina.parsers import set_client_cli_parser\n \n if TYPE_CHECKING:\n     from jina.clients.request import GeneratorSourceType\n@@ -45,10 +34,7 @@ class BaseClient(ABC):\n         if args and isinstance(args, argparse.Namespace):\n             self.args = args\n         else:\n-            self._parse_kwargs(kwargs)\n-            self.args = ArgNamespace.kwargs2namespace(\n-                kwargs, set_client_cli_parser(), warn_unknown=True\n-            )\n+            self.args = parse_client(kwargs)\n \n         self.logger = JinaLogger(self.__class__.__name__, **vars(self.args))\n \n@@ -61,39 +47,6 @@ class BaseClient(ABC):\n             os.unsetenv('https_proxy')\n         self._inputs = None\n \n-    def _parse_kwargs(self, kwargs: Dict[str, Any]):\n-\n-        if 'host' in kwargs.keys():\n-            return_scheme = dict()\n-            (\n-                kwargs['host'],\n-                return_scheme['port'],\n-                return_scheme['protocol'],\n-                return_scheme['tls'],\n-            ) = self._parse_host_scheme(kwargs['host'])\n-\n-            for key, value in return_scheme.items():\n-                if value:\n-                    if key in kwargs:\n-                        raise ValueError(\n-                            f\"You can't have two definitions of {key}: you have one in the host scheme and one in the keyword argument\"\n-                        )\n-                    elif value:\n-                        kwargs[key] = value\n-\n-    def _parse_host_scheme(self, host: str) -> Tuple[str, str, str, bool]:\n-        scheme, _hostname, port = _parse_url(host)\n-\n-        tls = None\n-        if scheme in ('grpcs', 'https', 'wss'):\n-            scheme = scheme[:-1]\n-            tls = True\n-\n-        if scheme == 'ws':\n-            scheme = 'websocket'\n-\n-        return _hostname, port, scheme, tls\n-\n     @staticmethod\n     def check_input(inputs: Optional['InputType'] = None, **kwargs) -> None:\n         \"\"\"Validate the inputs and print the first request if success.\n@@ -206,17 +159,3 @@ class BaseClient(ABC):\n         :return: the Client object\n         \"\"\"\n         return self\n-\n-\n-def _parse_url(host):\n-    if '://' in host:\n-        scheme, host = host.split('://')\n-    else:\n-        scheme = None\n-\n-    if ':' in host:\n-        host, port = host.split(':')\n-    else:\n-        port = None\n-\n-    return scheme, host, port\n\n---\n file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -1511,3 +1511,65 @@ def docarray_graphql_compatible():\n     installed_version = pckg_version.parse(__docarray_version__)\n     min_version = pckg_version.parse(GRAPHQL_MIN_DOCARRAY_VERSION)\n     return installed_version >= min_version\n+\n+\n+from jina.helper import ArgNamespace\n+from jina.parsers import set_client_cli_parser\n+\n+\n+def parse_client(kwargs):\n+    kwargs = _parse_kwargs(kwargs)\n+    return ArgNamespace.kwargs2namespace(\n+        kwargs, set_client_cli_parser(), warn_unknown=True\n+    )\n+\n+\n+def _parse_kwargs(kwargs: Dict[str, Any]) -> Dict[str, Any]:\n+\n+    if 'host' in kwargs.keys():\n+        return_scheme = dict()\n+        (\n+            kwargs['host'],\n+            return_scheme['port'],\n+            return_scheme['protocol'],\n+            return_scheme['tls'],\n+        ) = _parse_host_scheme(kwargs['host'])\n+\n+        for key, value in return_scheme.items():\n+            if value:\n+                if key in kwargs:\n+                    raise ValueError(\n+                        f\"You can't have two definitions of {key}: you have one in the host scheme and one in the keyword argument\"\n+                    )\n+                elif value:\n+                    kwargs[key] = value\n+\n+    return kwargs\n+\n+\n+def _parse_host_scheme(host: str) -> Tuple[str, str, str, bool]:\n+    scheme, _hostname, port = _parse_url(host)\n+\n+    tls = None\n+    if scheme in ('grpcs', 'https', 'wss'):\n+        scheme = scheme[:-1]\n+        tls = True\n+\n+    if scheme == 'ws':\n+        scheme = 'websocket'\n+\n+    return _hostname, port, scheme, tls\n+\n+\n+def _parse_url(host):\n+    if '://' in host:\n+        scheme, host = host.split('://')\n+    else:\n+        scheme = None\n+\n+    if ':' in host:\n+        host, port = host.split(':')\n+    else:\n+        port = None\n+\n+    return scheme, host, port\n\n---\n file path A: None | file path B: tests/integration/gateway_clients/test_host_scheme.py\n\n@@ -0,0 +1,14 @@\n+import pytest\n+from docarray import DocumentArray\n+\n+from jina import Client, Flow\n+from jina.helper import random_port\n+\n+\n+@pytest.mark.parametrize('protocol', ['grpc', 'ws', 'http'])\n+def test_client_host_scheme(protocol):\n+    port = random_port()\n+    f = Flow(protocol='websocket' if protocol == 'ws' else protocol, port=port).add()\n+    with f:\n+        c = Client(host=f'{protocol}://localhost:{port}')\n+        c.post('/', inputs=DocumentArray.empty(2))\n\n\n###\n\n", "completion": "fix: client args are now parse in the client function (#<issue-num>)"}
{"prompt": " file path A: jina/orchestrate/deployments/__init__.py | file path B: jina/orchestrate/deployments/__init__.py\n\n@@ -5,18 +5,17 @@ from argparse import Namespace\n from contextlib import ExitStack\n from typing import Dict, List, Optional, Set, Union\n \n-from jina.serve.networking import GrpcConnectionPool, host_is_local\n-from jina.orchestrate.pods import Pod\n-from jina.orchestrate.pods.container import ContainerPod\n-from jina.orchestrate.pods.factory import PodFactory\n-from jina.orchestrate.pods.jinad import JinaDPod\n-from jina import __default_executor__, __default_host__, __docker_host__\n-from jina import helper\n+from jina import __default_executor__, __default_host__, __docker_host__, helper\n from jina.enums import DeploymentRoleType, PodRoleType, PollingType\n from jina.excepts import RuntimeFailToStart, RuntimeRunForeverEarlyError, ScalingFails\n from jina.helper import CatchAllCleanupContextManager\n-from jina.jaml.helper import complete_path\n from jina.hubble.hubio import HubIO\n+from jina.jaml.helper import complete_path\n+from jina.orchestrate.pods import Pod\n+from jina.orchestrate.pods.container import ContainerPod\n+from jina.orchestrate.pods.factory import PodFactory\n+from jina.orchestrate.pods.jinad import JinaDPod\n+from jina.serve.networking import GrpcConnectionPool, host_is_local\n \n \n class BaseDeployment(ExitStack):\n@@ -424,6 +423,17 @@ class Deployment(BaseDeployment):\n         is_sandbox = uses.startswith('jinahub+sandbox://')\n         return is_sandbox\n \n+    @property\n+    def tls_enabled(self):\n+        \"\"\"\n+        Checks whether secure connection via tls is enabled for this Deployment.\n+\n+        :return: True if tls is enabled, False otherwise\n+        \"\"\"\n+        has_cert = getattr(self.args, 'ssl_certfile', None) is not None\n+        has_key = getattr(self.args, 'ssl_keyfile', None) is not None\n+        return self.is_sandbox or (has_cert and has_key)\n+\n     @property\n     def external(self) -> bool:\n         \"\"\"\n@@ -436,10 +446,10 @@ class Deployment(BaseDeployment):\n     @property\n     def protocol(self):\n         \"\"\"\n-        :return: the protocol of this deployment, https or http\n+        :return: the protocol of this deployment\n         \"\"\"\n-        protocol = getattr(self.args, 'protocol', 'http')\n-        return 'https' if self.is_sandbox else protocol\n+        protocol = getattr(self.args, 'protocol', 'grpc')\n+        return str(protocol) + ('s' if self.tls_enabled else '')\n \n     @property\n     def first_pod_args(self) -> Namespace:\n\n---\n file path A: jina/serve/networking.py | file path B: jina/serve/networking.py\n\n@@ -7,13 +7,15 @@ from urllib.parse import urlparse\n import grpc\n from grpc.aio import AioRpcError\n \n+from jina.enums import PollingType\n from jina.logging.logger import JinaLogger\n from jina.proto import jina_pb2_grpc\n-from jina.enums import PollingType\n from jina.types.request import Request\n from jina.types.request.control import ControlRequest\n from jina.types.request.data import DataRequest\n \n+TLS_PROTOCOL_SCHEMES = ['grpcs', 'https', 'wss']\n+\n \n class ReplicaList:\n     \"\"\"\n@@ -35,7 +37,7 @@ class ReplicaList:\n             try:\n                 parsed_address = urlparse(address)\n                 address = parsed_address.netloc if parsed_address.netloc else address\n-                use_tls = parsed_address.scheme == 'https'\n+                use_tls = parsed_address.scheme in TLS_PROTOCOL_SCHEMES\n             except:\n                 use_tls = False\n \n\n---\n file path A: tests/integration/issues/github_4488/__init__.py | file path B: tests/integration/issues/github_4488/__init__.py\n\n\n---\n file path A: None | file path B: tests/integration/issues/github_4488/test_deployment_protocol.py\n\n@@ -0,0 +1,51 @@\n+import os\n+\n+import pytest\n+from docarray import Document\n+\n+from jina import Executor, Flow, requests\n+\n+\n+class MyExec(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        pass\n+\n+\n+@pytest.fixture\n+def cert_prefix():\n+    cur_dir = os.path.dirname(os.path.abspath(__file__))\n+    return f'{cur_dir}/../../../unit/serve/runtimes/gateway/grpc/cert/'\n+\n+\n+@pytest.fixture\n+def cert_pem(cert_prefix):\n+    \"\"\"This is the cert entry of a self-signed local cert\"\"\"\n+    return cert_prefix + '/server.crt'\n+\n+\n+@pytest.fixture\n+def key_pem(cert_prefix):\n+    \"\"\"This is the key entry of a self-signed local cert\"\"\"\n+    return cert_prefix + '/server.key'\n+\n+\n+@pytest.mark.parametrize('protocol', ['http', 'websocket', 'grpc'])\n+@pytest.mark.parametrize('tls', [True, False])\n+def test_deployment_protocol(protocol, tls, cert_pem, key_pem):\n+    cert = cert_pem if tls else None\n+    key = key_pem if tls else None\n+    f = (\n+        Flow(protocol=protocol, ssl_certfile=cert, ssl_keyfile=key)\n+        .add(uses=MyExec)\n+        .add(uses='jinahub+sandbox://DummyHubExecutor')\n+    )\n+    with f:\n+        for node, v in f._deployment_nodes.items():\n+            p = v.protocol.lower()\n+            if node == 'gateway':\n+                assert p == protocol + ('s' if tls else '')\n+            elif node == 'executor0':\n+                assert p == 'grpc'\n+            elif node == 'executor1':\n+                assert p == 'grpcs'\n\n\n###\n\n", "completion": "fix: deployment protocol (#<issue-num>)"}
{"prompt": " file path A: docs/get-started/create-app.md | file path B: docs/get-started/create-app.md\n\n@@ -22,7 +22,7 @@ hello-jina\n \n There may be some other files like `README.md`, `manifest.yml`  `requirements.txt` to provide extra metadata about that Executor. More information {ref}`can be found here<create-executor>`.\n \n-```python\n+```bash\n cd hello-jina\n python app.py\n ```\n@@ -54,7 +54,8 @@ from jina import Executor, DocumentArray, requests\n class MyExecutor(Executor):\n     @requests(on='/get-tensor')\n     def bar(self, docs: DocumentArray, **kwargs):\n-        docs[0].tensor = torch.tensor(np.random.random([10, 2]))\n+        for doc in docs:\n+            doc.tensor = torch.tensor(np.random.random([10, 2]))\n ```\n \n ## A small Jina application\n\n\n###\n\n", "completion": "docs: fix create app example (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/flow-yaml.md | file path B: docs/fundamentals/flow/flow-yaml.md\n\n@@ -84,7 +84,7 @@ In the case that you want to set the same value for the `metas` attributes in **\n help. This is very helpful when you use the executors with local source codes and have all of them in one Python module.\n In the following example, the two executors are defined in the same module.\n \n-````{tab} Use Flow `metas`\n+````{tab} Use Flow metas\n \n ```yaml\n jtype: Flow\n@@ -95,9 +95,10 @@ executors:\n   - uses: FooExecutor\n   - uses: BarExecutor\n ```\n+\n ````\n \n-````{tab} Use Executor `metas`\n+````{tab} Use Executor metas\n \n ```yaml\n jtype: Flow\n@@ -113,5 +114,6 @@ executors:\n         py_modules:\n           - executors.py\n ```\n+\n ````\n \n\n\n###\n\n", "completion": "docs: fix formatting (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -316,7 +316,6 @@ ac_table = {\n             '--proxy',\n             '--port',\n             '--tls',\n-            '--https',\n             '--asyncio',\n             '--return-responses',\n             '--protocol',\n\n---\n file path A: jina/clients/__init__.py | file path B: jina/clients/__init__.py\n\n@@ -40,7 +40,7 @@ def Client(\n     :param protocol: Communication protocol between server and client.\n     :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n     :param return_responses: If set, return results as List of Requests instead of a reduced DocArray.\n-    :param tls: If set, connect to gateway using https\n+    :param tls: If set, connect to gateway using tls encryption\n     :return: the new Client object\n \n     .. # noqa: DAR202\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -114,7 +114,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         :param protocol: Communication protocol between server and client.\n         :param proxy: If set, respect the http_proxy and https_proxy environment variables. otherwise, it will unset these proxy variables before start. gRPC seems to prefer no proxy\n         :param return_responses: If set, return results as List of Requests instead of a reduced DocArray.\n-        :param tls: If set, connect to gateway using https\n+        :param tls: If set, connect to gateway using tls encryption\n \n         .. # noqa: DAR202\n         .. # noqa: DAR101\n\n---\n file path A: jina/parsers/deprecated.py | file path B: jina/parsers/deprecated.py\n\n@@ -5,6 +5,7 @@ DEPRECATED_ARGS_MAPPING = {\n     'port_expose': 'port',\n     'parallel': 'One of \"shards\" (when dividing data in indexers) or \"replicas\" (replicating Executors for performance and reliability)',\n     'port_in': 'port',\n+    'https': 'tls',\n }\n \n \n\n---\n file path A: jina/parsers/helper.py | file path B: jina/parsers/helper.py\n\n@@ -266,33 +266,3 @@ class _ColoredHelpFormatter(argparse.ArgumentDefaultsHelpFormatter):\n \n \n _chf = _ColoredHelpFormatter\n-\n-\n-class DeprecateAction(argparse.Action):\n-    \"\"\"\n-    Action to deprecated an argument in argparse\n-    \"\"\"\n-\n-    def __call__(self, parser, namespace, values, option_string=None):  # noqa\n-        warnings.warn('Argument {self.option_strings} is deprecated and is *ignored*')\n-        delattr(namespace, self.dest)\n-\n-\n-def get_deprecation_renamed_action(\n-    replacement: str, action: Type[argparse.Action] = argparse.Action\n-):\n-    \"\"\"\n-    To deprecate an argument when it has been renamed for argparse\n-\n-    :param replacement: the new argument name\n-    :param action: class of the action that you want to overload with the deprecation to keep the old behavior\n-    :return: a action class that can\n-    \"\"\"\n-\n-    class _DeprecateRenamedAction(action):\n-        def __call__(self, parser, namespace, values, option_string=None):\n-            warnings.warn(\n-                f'Argument {self.option_strings} is deprecated, please use {replacement} instead'\n-            )\n-\n-    return _DeprecateRenamedAction\n\n---\n file path A: jina/parsers/orchestrate/runtimes/remote.py | file path B: jina/parsers/orchestrate/runtimes/remote.py\n\n@@ -1,12 +1,7 @@\n \"\"\"Argparser module for remote runtime\"\"\"\n-from argparse import _StoreTrueAction\n \n from jina import __default_host__, helper\n-from jina.parsers.helper import (\n-    KVAppendAction,\n-    add_arg_group,\n-    get_deprecation_renamed_action,\n-)\n+from jina.parsers.helper import KVAppendAction, add_arg_group\n \n \n def mixin_remote_runtime_parser(parser):\n@@ -46,15 +41,6 @@ def mixin_client_gateway_parser(parser):\n         help='If set, connect to gateway using tls encryption',\n     )\n \n-    gp.add_argument(\n-        '--https',\n-        action=get_deprecation_renamed_action('--tls', _StoreTrueAction),\n-        # action='store_true',\n-        default=False,\n-        help='If set, connect to gateway using https',\n-        dest='tls',\n-    )\n-\n \n def mixin_gateway_parser(parser):\n     \"\"\"Add the options for remote expose at the Gateway\n\n\n###\n\n", "completion": "fix: deprecation of https (#<issue-num>)"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -1,9 +1,6 @@\n import os\n import sys\n \n-from rich import box\n-from rich.table import Table\n-\n \n def _get_run_args(print_args: bool = True):\n     from jina.helper import get_rich_console\n@@ -17,6 +14,9 @@ def _get_run_args(print_args: bool = True):\n     if len(sys.argv) > 1:\n         from argparse import _StoreAction, _StoreTrueAction\n \n+        from rich import box\n+        from rich.table import Table\n+\n         args, unknown = parser.parse_known_args()\n \n         if unknown:\n\n\n###\n\n", "completion": "fix: move imports to local (#<issue-num>)"}
{"prompt": " file path A: None | file path B: docs/_static/cas-dark.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"320px\" height=\"320px\" viewBox=\"0 0 320 320\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>cas-dark2</title>\n+    <g id=\"cas-dark2\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4\">\n+            <rect id=\"\u77e9\u5f62\u5907\u4efd-11\" fill-rule=\"nonzero\" x=\"0\" y=\"0\" width=\"320\" height=\"320\"></rect>\n+            <g id=\"\u7f16\u7ec4-4\u5907\u4efd\" transform=\"translate(30.000000, 30.000000)\">\n+                <rect id=\"\u77e9\u5f62\" x=\"0\" y=\"0\" width=\"260\" height=\"260\"></rect>\n+                <path d=\"M79.8382,105.3338 L79.8387473,198.251658 L79.8581727,198.569286 C79.9609939,199.405908 80.4657239,200.149047 81.2223548,200.549567 L176.1838,250.8168 L175.321116,251.116603 C163.13226,255.212655 148.863942,257.4 136.114898,257.4 L134.366431,257.390613 C98.9122839,257.008932 69.4350516,244.99295 45.5867065,222.191679 L45.1984,221.8164 L45.1984,128.206 L79.8382,105.3338 Z M85.038,151.5364 L198.347845,207.833508 C199.081889,208.198212 199.944933,208.195424 200.676606,207.825983 L253.0606,181.376 L252.68315,182.217944 C238.785339,212.657349 213.438718,236.206074 182.603219,248.332789 L85.0382,196.6848 L85.038,151.5364 Z M94.5854,48.9034 L127.4208,67.6806 L81.0059794,98.3345989 L80.993,98.3434 L41.167499,124.636201 C40.4385768,125.117439 40,125.932528 40,126.80598 L39.9986216,216.903048 C18.4105009,194.129033 5.2,163.554471 5.2,129.944705 L5.21890038,127.743672 C5.35743788,119.682615 6.25685405,111.727068 7.89344246,103.948485 L8.385,101.7094 L94.5854,48.9034 Z M218.465,157.6328 L252.5146,175.825 L199.4902,202.5972 L161.9306,183.976 L218.465,157.6328 Z M103.3058,6.9186 L188.1542,55.1408 L188.3804,96.0284 L95.8260948,43.6198997 L95.5088518,43.4675701 C94.7515813,43.165163 93.8876553,43.2337245 93.1817236,43.6684005 L10.2336,94.7414 L10.4224055,94.1005404 C23.0156994,51.9707113 57.7410478,18.7862444 101.529426,7.36865099 L103.3058,6.9186 Z M135.13399,2.6 L136.796234,2.61010192 C169.453788,3.00718732 200.121611,15.0955821 223.675828,36.1955055 L224.0342,36.5196 L224.4268,78.3016 L193.5804,96.0258 L193.347709,53.6090522 L193.327615,53.3000964 C193.225741,52.4860452 192.743238,51.760275 192.016583,51.3539933 L109.7772,5.3716 L111.117717,5.09626593 C119.474965,3.43580737 127.266317,2.6 135.13399,2.6 Z\" id=\"\u5f62\u72b6\u7ed3\u5408\" fill=\"#FBCB67\" fill-rule=\"nonzero\"></path>\n+            </g>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/_static/cas-light.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"320px\" height=\"320px\" viewBox=\"0 0 320 320\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>cas-dark2</title>\n+    <g id=\"cas-dark2\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4\">\n+            <rect id=\"\u77e9\u5f62\u5907\u4efd-11\" fill-rule=\"nonzero\" x=\"0\" y=\"0\" width=\"320\" height=\"320\"></rect>\n+            <g id=\"\u7f16\u7ec4-4\u5907\u4efd\" transform=\"translate(30.000000, 30.000000)\">\n+                <rect id=\"\u77e9\u5f62\" x=\"0\" y=\"0\" width=\"260\" height=\"260\"></rect>\n+                <path d=\"M79.8382,105.3338 L79.8387473,198.251658 L79.8581727,198.569286 C79.9609939,199.405908 80.4657239,200.149047 81.2223548,200.549567 L176.1838,250.8168 L175.321116,251.116603 C163.13226,255.212655 148.863942,257.4 136.114898,257.4 L134.366431,257.390613 C98.9122839,257.008932 69.4350516,244.99295 45.5867065,222.191679 L45.1984,221.8164 L45.1984,128.206 L79.8382,105.3338 Z M85.038,151.5364 L198.347845,207.833508 C199.081889,208.198212 199.944933,208.195424 200.676606,207.825983 L253.0606,181.376 L252.68315,182.217944 C238.785339,212.657349 213.438718,236.206074 182.603219,248.332789 L85.0382,196.6848 L85.038,151.5364 Z M94.5854,48.9034 L127.4208,67.6806 L81.0059794,98.3345989 L80.993,98.3434 L41.167499,124.636201 C40.4385768,125.117439 40,125.932528 40,126.80598 L39.9986216,216.903048 C18.4105009,194.129033 5.2,163.554471 5.2,129.944705 L5.21890038,127.743672 C5.35743788,119.682615 6.25685405,111.727068 7.89344246,103.948485 L8.385,101.7094 L94.5854,48.9034 Z M218.465,157.6328 L252.5146,175.825 L199.4902,202.5972 L161.9306,183.976 L218.465,157.6328 Z M103.3058,6.9186 L188.1542,55.1408 L188.3804,96.0284 L95.8260948,43.6198997 L95.5088518,43.4675701 C94.7515813,43.165163 93.8876553,43.2337245 93.1817236,43.6684005 L10.2336,94.7414 L10.4224055,94.1005404 C23.0156994,51.9707113 57.7410478,18.7862444 101.529426,7.36865099 L103.3058,6.9186 Z M135.13399,2.6 L136.796234,2.61010192 C169.453788,3.00718732 200.121611,15.0955821 223.675828,36.1955055 L224.0342,36.5196 L224.4268,78.3016 L193.5804,96.0258 L193.347709,53.6090522 L193.327615,53.3000964 C193.225741,52.4860452 192.743238,51.760275 192.016583,51.3539933 L109.7772,5.3716 L111.117717,5.09626593 C119.474965,3.43580737 127.266317,2.6 135.13399,2.6 Z\" id=\"\u5f62\u72b6\u7ed3\u5408\" fill=\"#009191\" fill-rule=\"nonzero\"></path>\n+            </g>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n---\n file path A: docs/_templates/sidebar/navigation.html | file path B: docs/_templates/sidebar/navigation.html\n\n@@ -19,6 +19,10 @@\n             <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/docarray-light.svg', 1) }}\">\n             <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/docarray-dark.svg', 1) }}\">\n             DocArray</a></li>\n+        <li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://clip-as-service.jina.ai\">\n+            <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/cas-light.svg', 1) }}\">\n+            <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/cas-dark.svg', 1) }}\">\n+            CLIP-as-service</a></li>\n     </ul>\n </div>\n \n\n\n###\n\n", "completion": "chore(docs): add banner"}
{"prompt": " file path A: None | file path B: docs/_static/cas-dark.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"320px\" height=\"320px\" viewBox=\"0 0 320 320\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>cas-dark2</title>\n+    <g id=\"cas-dark2\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4\">\n+            <rect id=\"\u77e9\u5f62\u5907\u4efd-11\" fill-rule=\"nonzero\" x=\"0\" y=\"0\" width=\"320\" height=\"320\"></rect>\n+            <g id=\"\u7f16\u7ec4-4\u5907\u4efd\" transform=\"translate(30.000000, 30.000000)\">\n+                <rect id=\"\u77e9\u5f62\" x=\"0\" y=\"0\" width=\"260\" height=\"260\"></rect>\n+                <path d=\"M79.8382,105.3338 L79.8387473,198.251658 L79.8581727,198.569286 C79.9609939,199.405908 80.4657239,200.149047 81.2223548,200.549567 L176.1838,250.8168 L175.321116,251.116603 C163.13226,255.212655 148.863942,257.4 136.114898,257.4 L134.366431,257.390613 C98.9122839,257.008932 69.4350516,244.99295 45.5867065,222.191679 L45.1984,221.8164 L45.1984,128.206 L79.8382,105.3338 Z M85.038,151.5364 L198.347845,207.833508 C199.081889,208.198212 199.944933,208.195424 200.676606,207.825983 L253.0606,181.376 L252.68315,182.217944 C238.785339,212.657349 213.438718,236.206074 182.603219,248.332789 L85.0382,196.6848 L85.038,151.5364 Z M94.5854,48.9034 L127.4208,67.6806 L81.0059794,98.3345989 L80.993,98.3434 L41.167499,124.636201 C40.4385768,125.117439 40,125.932528 40,126.80598 L39.9986216,216.903048 C18.4105009,194.129033 5.2,163.554471 5.2,129.944705 L5.21890038,127.743672 C5.35743788,119.682615 6.25685405,111.727068 7.89344246,103.948485 L8.385,101.7094 L94.5854,48.9034 Z M218.465,157.6328 L252.5146,175.825 L199.4902,202.5972 L161.9306,183.976 L218.465,157.6328 Z M103.3058,6.9186 L188.1542,55.1408 L188.3804,96.0284 L95.8260948,43.6198997 L95.5088518,43.4675701 C94.7515813,43.165163 93.8876553,43.2337245 93.1817236,43.6684005 L10.2336,94.7414 L10.4224055,94.1005404 C23.0156994,51.9707113 57.7410478,18.7862444 101.529426,7.36865099 L103.3058,6.9186 Z M135.13399,2.6 L136.796234,2.61010192 C169.453788,3.00718732 200.121611,15.0955821 223.675828,36.1955055 L224.0342,36.5196 L224.4268,78.3016 L193.5804,96.0258 L193.347709,53.6090522 L193.327615,53.3000964 C193.225741,52.4860452 192.743238,51.760275 192.016583,51.3539933 L109.7772,5.3716 L111.117717,5.09626593 C119.474965,3.43580737 127.266317,2.6 135.13399,2.6 Z\" id=\"\u5f62\u72b6\u7ed3\u5408\" fill=\"#FBCB67\" fill-rule=\"nonzero\"></path>\n+            </g>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n---\n file path A: None | file path B: docs/_static/cas-light.svg\n\n@@ -0,0 +1,13 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<svg width=\"320px\" height=\"320px\" viewBox=\"0 0 320 320\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n+    <title>cas-dark2</title>\n+    <g id=\"cas-dark2\" stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n+        <g id=\"\u7f16\u7ec4\">\n+            <rect id=\"\u77e9\u5f62\u5907\u4efd-11\" fill-rule=\"nonzero\" x=\"0\" y=\"0\" width=\"320\" height=\"320\"></rect>\n+            <g id=\"\u7f16\u7ec4-4\u5907\u4efd\" transform=\"translate(30.000000, 30.000000)\">\n+                <rect id=\"\u77e9\u5f62\" x=\"0\" y=\"0\" width=\"260\" height=\"260\"></rect>\n+                <path d=\"M79.8382,105.3338 L79.8387473,198.251658 L79.8581727,198.569286 C79.9609939,199.405908 80.4657239,200.149047 81.2223548,200.549567 L176.1838,250.8168 L175.321116,251.116603 C163.13226,255.212655 148.863942,257.4 136.114898,257.4 L134.366431,257.390613 C98.9122839,257.008932 69.4350516,244.99295 45.5867065,222.191679 L45.1984,221.8164 L45.1984,128.206 L79.8382,105.3338 Z M85.038,151.5364 L198.347845,207.833508 C199.081889,208.198212 199.944933,208.195424 200.676606,207.825983 L253.0606,181.376 L252.68315,182.217944 C238.785339,212.657349 213.438718,236.206074 182.603219,248.332789 L85.0382,196.6848 L85.038,151.5364 Z M94.5854,48.9034 L127.4208,67.6806 L81.0059794,98.3345989 L80.993,98.3434 L41.167499,124.636201 C40.4385768,125.117439 40,125.932528 40,126.80598 L39.9986216,216.903048 C18.4105009,194.129033 5.2,163.554471 5.2,129.944705 L5.21890038,127.743672 C5.35743788,119.682615 6.25685405,111.727068 7.89344246,103.948485 L8.385,101.7094 L94.5854,48.9034 Z M218.465,157.6328 L252.5146,175.825 L199.4902,202.5972 L161.9306,183.976 L218.465,157.6328 Z M103.3058,6.9186 L188.1542,55.1408 L188.3804,96.0284 L95.8260948,43.6198997 L95.5088518,43.4675701 C94.7515813,43.165163 93.8876553,43.2337245 93.1817236,43.6684005 L10.2336,94.7414 L10.4224055,94.1005404 C23.0156994,51.9707113 57.7410478,18.7862444 101.529426,7.36865099 L103.3058,6.9186 Z M135.13399,2.6 L136.796234,2.61010192 C169.453788,3.00718732 200.121611,15.0955821 223.675828,36.1955055 L224.0342,36.5196 L224.4268,78.3016 L193.5804,96.0258 L193.347709,53.6090522 L193.327615,53.3000964 C193.225741,52.4860452 192.743238,51.760275 192.016583,51.3539933 L109.7772,5.3716 L111.117717,5.09626593 C119.474965,3.43580737 127.266317,2.6 135.13399,2.6 Z\" id=\"\u5f62\u72b6\u7ed3\u5408\" fill=\"#009191\" fill-rule=\"nonzero\"></path>\n+            </g>\n+        </g>\n+    </g>\n+</svg>\n\\ No newline at end of file\n\n---\n file path A: docs/_templates/sidebar/navigation.html | file path B: docs/_templates/sidebar/navigation.html\n\n@@ -19,6 +19,10 @@\n             <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/docarray-light.svg', 1) }}\">\n             <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/docarray-dark.svg', 1) }}\">\n             DocArray</a></li>\n+        <li class=\"toctree-l1\"><a class=\"reference external\" href=\"https://clip-as-service.jina.ai\">\n+            <img class=\"sidebar-ecosys-logo only-light-line\" src=\"{{ pathto('_static/cas-light.svg', 1) }}\">\n+            <img class=\"sidebar-ecosys-logo only-dark-line\" src=\"{{ pathto('_static/cas-dark.svg', 1) }}\">\n+            CLIP-as-service</a></li>\n     </ul>\n </div>\n \n\n\n###\n\n", "completion": "feat(client): add total_docs to client post kwargs"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -149,6 +149,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12722,3 +12723,33 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```b2db7b82```](https://github.com/jina-ai/jina/commit/b2db7b82d9c600f7212016450b2d4de8ccf6acc2)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```734f86fd```](https://github.com/jina-ai/jina/commit/734f86fd5b8a142161c23bb7bf5d1982dcc36d2a)] __-__ __version__: the next version will be 3.2.7 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-8></a>\n+## Release Note (`3.2.8`)\n+\n+> Release time: 2022-03-22 20:26:18\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Nan Wang,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```0ff05200```](https://github.com/jina-ai/jina/commit/0ff0520039d0b3a15ac84afeaf9575dcc52c9c05)] __-__ __client__: add total_docs to client post kwargs (#4528) (*Han Xiao*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```8287e8bc```](https://github.com/jina-ai/jina/commit/8287e8bce1fa1b11060830acd792e020fa51a21b)] __-__ clean up workspace parameter, add default workspace (#4511) (*Johannes Messner*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```535ff6c3```](https://github.com/jina-ai/jina/commit/535ff6c308ceeac4ffc0675af369d27ade66dc66)] __-__ add docs for configuring flow (#4519) (*Nan Wang*)\n+ - [[```b5aefec7```](https://github.com/jina-ai/jina/commit/b5aefec70b5a2970a7557c210668a98e5e5cc3df)] __-__ remove misplaced text (#4527) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```6d25c382```](https://github.com/jina-ai/jina/commit/6d25c3824b2cf5d2ddb79fec6cf657313e74500e)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```550a50f1```](https://github.com/jina-ai/jina/commit/550a50f1eb86bc819316bfc95a2f395235f6a809)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```ee80d2f3```](https://github.com/jina-ai/jina/commit/ee80d2f316a94e17d943c8e487bfd25bd904fddc)] __-__ __version__: the next version will be 3.2.8 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.8'\n+__version__ = '3.2.9'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.9"}
{"prompt": " file path A: cli/__init__.py | file path B: cli/__init__.py\n\n@@ -1,13 +1,12 @@\n import os\n import sys\n \n-from rich import print as pprint\n-from rich.table import Table\n from rich import box\n-from jina.helper import get_rich_console\n+from rich.table import Table\n \n \n def _get_run_args(print_args: bool = True):\n+    from jina.helper import get_rich_console\n     from jina.parsers import get_main_parser\n \n     console = get_rich_console()\n@@ -45,18 +44,16 @@ def _get_run_args(print_args: bool = True):\n             param_str.add_column('Value', justify='left')\n \n             for k, v in sorted(vars(args).items()):\n-\n                 sign = ' ' if default_args.get(k, None) == v else '\ud83d\udd27\ufe0f'\n-                param = f'{k.replace(\"_\", \"-\"): >30.30}'\n-                value = f'=  {str(v):30.30}'\n+                param = k.replace('_', '-')\n+                value = str(v)\n \n                 style = None if default_args.get(k, None) == v else 'blue on yellow'\n \n                 param_str.add_row(sign, param, value, style=style)\n \n             print(f'\\n{logo_str}\\n')\n-            console.print(f'\u25b6\ufe0f  {\" \".join(sys.argv)}')\n-            console.print(param_str)\n+            console.print(f'\u25b6\ufe0f  {\" \".join(sys.argv)}', param_str)\n         return args\n     else:\n         parser.print_help()\n@@ -86,10 +83,11 @@ def _quick_ac_lookup():\n \n def _is_latest_version(suppress_on_error=True):\n     try:\n-        from urllib.request import Request, urlopen\n         import json\n-        from jina import __version__\n         import warnings\n+        from urllib.request import Request, urlopen\n+\n+        from jina import __version__\n \n         req = Request(\n             'https://api.jina.ai/latest', headers={'User-Agent': 'Mozilla/5.0'}\n\n---\n file path A: jina/clients/base/__init__.py | file path B: jina/clients/base/__init__.py\n\n@@ -145,9 +145,16 @@ class BaseClient(ABC):\n         _kwargs.update(kwargs)\n \n         if hasattr(self._inputs, '__len__'):\n-            self._inputs_length = max(1, len(self._inputs) / _kwargs['request_size'])\n+            total_docs = len(self._inputs)\n+        elif 'total_docs' in _kwargs:\n+            total_docs = _kwargs['total_docs']\n         else:\n-            self._inputs_length = None\n+            total_docs = None\n+\n+        self._inputs_length = None\n+\n+        if total_docs:\n+            self._inputs_length = max(1, total_docs / _kwargs['request_size'])\n \n         if inspect.isasyncgen(self.inputs):\n             from jina.clients.request.asyncio import request_generator\n\n\n###\n\n", "completion": "feat(client): add total_docs to client post kwargs (#<issue-num>)"}
{"prompt": " file path A: None | file path B: docs/fundamentals/flow/flow-yaml.md\n\n@@ -0,0 +1,117 @@\n+# Configure a Flow from YAML\n+\n+Instead of constructing a Flow in Python source codes, using a YAML file is the recommended way to configure Flows \n+because it is \n+\n+- independent of the Python source codes,\n+- easy to edit, maintain and extend,\n+- human-readable.\n+\n+## Load and Save a Flow configuration\n+`load_config()` is used to load the Flow configuration from a YAML file. Correspondingly, one uses `save_config()`  to \n+save the Flow configuration. In the following example, `jtype: Flow` in the YAML file tells the parser to construct a \n+`Flow` using this YAML file. \n+\n+`flow.yml`:\n+\n+```yaml\n+jtype: Flow\n+```\n+\n+```python\n+from jina import Flow\n+\n+f = Flow.load_config('flow.yml')  # Load the Flow definition from Yaml file\n+...\n+f.save_config('flow_exported.yml')\n+```\n+\n+## Configure Executors\n+`executors` field in the YAML file is for adding Executors to the Flow. It accepts a list of dictionaries, each of \n+which specifies a configuration of one executor. The dictionary accepts all the arguments from the `add()` method of the \n+Flow. \n+`uses` field is used to define the type of the Executor. As for using a local executor with source codes, the grammar \n+for setting `uses` is the same as that for configuring Executors in a YAML file. As for the other sources, one can \n+assign strings directly, for example `jinahub+sandbox://Hello`. \n+\n+`flow.yml`:\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - name: local_executor_with_source_codes\n+    uses: \n+      jtype: LocalExecutor\n+      metas:\n+        py_modules:\n+          - executors.py\n+      with:\n+        foo: 'Foo'\n+  - name: sandbox_executor\n+    uses: 'jinahub+sandbox://Hello'\n+```\n+\n+`executors.py`:\n+\n+```python\n+from jina import Executor, requests\n+\n+\n+class LocalExecutor(Executor):\n+    def __init__(self, foo, **kwargs):\n+        super().__init__(**kwargs)\n+        self.foo = foo\n+\n+    @requests\n+    def foo(self, **kwargs):\n+        print(f'foo={self.foo}')\n+```\n+\n+## Configure Flow APIs\n+Use `with` field to configure the Flow APIs. It accepts all the arguments in Flow constructor. In the example below, we \n+set the Flow to serve `http` at the port `45678` with CORS being enabled.\n+\n+```yaml\n+jtype: Flow\n+with:\n+  port: 45678\n+  protocol: 'http'\n+  cors: True\n+```\n+\n+## Configure Flow Meta Information\n+In the case that you want to set the same value for the `metas` attributes in **all** the executors, `metas` field can \n+help. This is very helpful when you use the executors with local source codes and have all of them in one Python module.\n+In the following example, the two executors are defined in the same module.\n+\n+````{tab} Use Flow `metas`\n+\n+```yaml\n+jtype: Flow\n+metas:\n+  py_modules:\n+    - executors.py\n+executors:\n+  - uses: FooExecutor\n+  - uses: BarExecutor\n+```\n+````\n+\n+````{tab} Use Executor `metas`\n+\n+```yaml\n+jtype: Flow\n+executors:\n+  - uses:\n+      jtype: FooExecutor\n+      metas:\n+        py_modules:\n+          - executors.py\n+  - uses:\n+      jtype: BarExecutor\n+      metas:\n+        py_modules:\n+          - executors.py\n+```\n+````\n+\n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -142,6 +142,7 @@ Executor and Flow are the two fundamental concepts in Jina.\n :hidden:\n \n create-flow\n+flow-yaml\n flow-api\n access-flow-api\n client\n\n\n###\n\n", "completion": "docs: add docs for configuring flow (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-in-flow.md | file path B: docs/fundamentals/executor/executor-in-flow.md\n\n@@ -33,8 +33,7 @@ The list of the `metas` are:\n \n - `name`: Name given to the `Executor`\n - `description`: Optional description of the Executor\n-- `py_modules`: List of python modules needed to import the Executor \n-- `workspace`: Optional path to be used by the `Executor`\n+- `py_modules`: List of python modules needed to import the Executor\n \n \n ### Runtime args\n@@ -48,7 +47,7 @@ The list of the `runtime_args` is:\n - `replicas`: Number of replicas of the same `Executor` deployed with the `Flow`.\n - `shards`: Number of shards of the same `Executor` deployed with the `Flow`.\n - `shard_id`: Identifier of the `shard` corresponding to the given `Executor` instance.\n-- `workspace`: Path to be used by the `Executor`. This is another way to pass a `workspace` to the `Executor` from the `Flow` ensuring that each `shard` gets a different one.\n+- `workspace`: Path to be used by the `Executor`. Note that the actual workspace directory used by the Executor is obtained by appending `'/<executor_name>/<shard_id>/'` to this value.\n - `py_modules`: Path to the modules needed to import the `Executor`. This is another way to pass `py-modules` to the `Executor` from the `Flow`\n \n \n@@ -61,9 +60,27 @@ The YAML API will ignore `.runtime_args` during save and load as they are not st\n By default, an `Executor` object contains `.requests` as an attribute when loaded from the `Flow`. This attribute is a `Dict` describing the mapping between Executor methods and network endpoints: It holds endpoint strings as keys, and pointers to `function`s as values. \n \n ### Workspace\n-Each `Executor` has a special `workspace` that is reserved for that specific `Executor` instance. The `workspace` property that can be used to extract the `path` to this workspace.\n+Each `Executor` has a special *workspace* that is reserved for that specific Executor instance.\n+The `.workspace` property contains the path to this workspace.\n \n-This `workspace` is generated using the workspace specified in `metas` or `runtime_args` workspace, plus adding special suffixes in case of sharded `Executor`s.\n+This `workspace` is generated using the workspace passed when adding the Executor: `flow.add(..., workspace='path/to/workspace/')`.\n+The value that is passed there is added to the `runtime_args`, and the final `workspace` is generated by appending `'/<executor_name>/<shard_id>/'`,\n+as described above.\n+\n+If the user hasn't provided a workspace, the Executor uses a default workspace, which is defined in the `JINA_DEFAULT_WORKSPACE_BASE`\n+environment variable.\n+\n+````{admonition} Caution\n+:class: caution\n+After you install jina, the `JINA_DEFAULT_WORKSPACE_BASE` environment variable will be set in your `.bashrc`, `.zshrc`, or\n+`.fish` file.\n+\n+To change the default Executor workspace on your system, you can change the value of this environment variable.\n+However, if you directly edit the corresponding command in your `.bashrc` (or `.zshrc`/`.fish`) file, your changes will be reverted the next time\n+you install jina on your system.\n+\n+Instead, you can add `export JINA_DEFAULT_WORKSPACE_BASE=$YOUR_WOKSPACE` after the `# JINA_CLI_END` comment.\n+````\n \n (executor-yaml-interface)=\n ## YAML interface\n@@ -80,7 +97,6 @@ with:\n metas:\n   name: MyExecutor\n   description: \"MyExecutor does a thing to the stuff in your Documents\"\n-  workspace: workspace\n   py_modules:\n     - executor.py\n requests:\n@@ -94,7 +110,6 @@ requests:\n - `metas` is a dictionary. It defines the meta information of that class. It contains the following fields:\n     - `name` is a string. Defines the name of the executor;\n     - `description` is a string. Defines the description of this executor. It will be used in automatic docs UI;\n-    - `workspace` is a string. Defines the workspace of the executor;\n     - `py_modules` is a list of strings. Defines the Python dependencies of the executor;\n - `requests` is a map. Defines the mapping from endpoint to class method name. Useful if one needs to overwrite the default endpoint-to-method mapping defined in the Executor python implementation.\n \n@@ -200,7 +215,6 @@ with:\n metas:\n   name: MyExecutor\n   description: \"MyExecutor does a thing to the stuff in your Documents\"\n-  workspace: workspace\n requests:\n   /index: default_fn\n   /search: default_fn\n@@ -218,7 +232,8 @@ flow2 = Flow().add(\n         'parameter_1': 'overriden_parameter_1',\n         'parameter_2': 'overriden_parameter_2',\n     },\n-    uses_metas={'name': 'Dynamic Name', 'workspace': 'overriden_worskpace'},\n+    uses_metas={'name': 'Dynamic Name'},\n+    workspace='workspace',\n     uses_requests={'/index': 'foo', '/search': 'bar'},\n )\n \n\n---\n file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -281,12 +281,12 @@ from jina import Executor, requests, Flow\n class MyExecutor(Executor):\n     @requests\n     def foo(self, docs, **kwargs):\n-        print(self.metas.workspace)\n+        print(self.metas.name)\n \n \n flow = Flow().add(\n     uses=MyExecutor,\n-    uses_metas={'workspace': 'different_workspace'},\n+    uses_metas={'name': 'different_name'},\n )\n with flow as f:\n     f.post('/')\n@@ -299,7 +299,7 @@ with flow as f:\n \t\ud83d\udd17 Protocol: \t\tGRPC\n \t\ud83c\udfe0 Local access:\t0.0.0.0:58827\n \t\ud83d\udd12 Private network:\t192.168.1.101:58827\n-different_workspace\n+different_name\n ```\n \n \n\n---\n file path A: docs/how-to/scale-out.md | file path B: docs/how-to/scale-out.md\n\n@@ -145,7 +145,7 @@ f = (\n             'dim': 130107,  # the dimension is fitted on the corpus in news dataset\n             'metric': 'cosine',\n         },\n-        uses_metas={'workspace': 'CHANGE-TO-YOUR-PATH/workspace'},\n+        workspace='CHANGE-TO-YOUR-PATH/workspace',\n         install_requirements=True,\n     )\n )\n@@ -174,7 +174,7 @@ f = (\n         name='pqlite_executor',\n         uses='jinahub://PQLiteIndexer',\n         uses_with={'dim': 130107, 'metric': 'cosine'},\n-        uses_metas={'workspace': 'CHANGE-TO-YOUR-PATH/workspace'},\n+        workspace='CHANGE-TO-YOUR-PATH/workspace',\n         install_requirements=True,\n         shards=2,\n     )\n@@ -213,7 +213,7 @@ f = (\n         name='pqlite_executor',\n         uses='jinahub://PQLiteIndexer/v0.2.3-rc',\n         uses_with={'dim': 130107, 'metric': 'cosine'},\n-        uses_metas={'workspace': 'CHANGE-TO-YOUR-PATH/workspace'},\n+        workspace='CHANGE-TO-YOUR-PATH/workspace',\n         install_requirements=True,\n         shards=2,\n         polling=polling_config,\n\n---\n file path A: jina/resources/completions/jina.bash | file path B: jina/resources/completions/jina.bash\n\n@@ -21,5 +21,7 @@ complete -F _jina jina\n # session-wise fix\n ulimit -n 4096\n export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\n+# default workspace for Executors\n+export JINA_DEFAULT_WORKSPACE_BASE=\"${HOME}/.jina/executor-workspace\"\n \n # JINA_CLI_END\n\n---\n file path A: jina/resources/completions/jina.fish | file path B: jina/resources/completions/jina.fish\n\n@@ -28,5 +28,7 @@ end\n # session-wise fix\n ulimit -n 4096\n export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\n+# default workspace for Executors\n+export JINA_DEFAULT_WORKSPACE_BASE=\"${HOME}/.jina/executor-workspace\"\n \n # JINA_CLI_END\n\n---\n file path A: jina/resources/completions/jina.zsh | file path B: jina/resources/completions/jina.zsh\n\n@@ -23,5 +23,7 @@ _jina() {\n # session-wise fix\n ulimit -n 4096\n export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\n+# default workspace for Executors\n+export JINA_DEFAULT_WORKSPACE_BASE=\"${HOME}/.jina/executor-workspace\"\n \n # JINA_CLI_END\n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -2,6 +2,8 @@ import inspect\n import multiprocessing\n import os\n import threading\n+import uuid\n+import warnings\n from concurrent.futures import ThreadPoolExecutor\n from types import SimpleNamespace\n from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union\n@@ -153,6 +155,14 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n         target = SimpleNamespace()\n         # set self values filtered by those non-exist, and non-expandable\n         for k, v in tmp.items():\n+            if k == 'workspace' and not (v is None or v == ''):\n+                warnings.warn(\n+                    'Setting `workspace` via `metas.workspace` is deprecated. '\n+                    'Instead, use `f.add(..., workspace=...)` when defining a a Flow in Python; '\n+                    'the `workspace` parameter when defining a Flow using YAML; '\n+                    'or `--workspace` when starting an Executor using the CLI.',\n+                    category=DeprecationWarning,\n+                )\n             if not hasattr(target, k):\n                 if isinstance(v, str):\n                     if not env_var_regex.findall(v):\n@@ -237,8 +247,10 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n \n         :return: returns the workspace of the current shard of this Executor.\n         \"\"\"\n-        workspace = getattr(self.metas, 'workspace') or getattr(\n-            self.runtime_args, 'workspace', None\n+        workspace = (\n+            getattr(self.metas, 'workspace')\n+            or getattr(self.runtime_args, 'workspace', None)\n+            or os.environ.get('JINA_DEFAULT_WORKSPACE_BASE')\n         )\n         if workspace:\n             complete_workspace = os.path.join(workspace, self.metas.name)\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -1,16 +1,24 @@\n import os\n from copy import deepcopy\n+from pathlib import Path\n+from unittest import mock\n \n import pytest\n-\n from docarray import Document, DocumentArray\n-from jina import Client, Executor, requests\n+\n+from jina import Client, Executor, Flow, requests\n from jina.serve.executors import ReducerExecutor\n from jina.serve.executors.metas import get_default_metas\n \n PORT = 12350\n \n \n+class WorkspaceExec(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        docs.texts = [self.workspace for _ in docs]\n+\n+\n class MyServeExec(Executor):\n     @requests\n     def foo(self, docs, **kwargs):\n@@ -331,3 +339,29 @@ def test_serve(served_exec):\n     docs = Client(port=PORT).post(on='/foo', inputs=DocumentArray.empty(5))\n \n     assert docs.texts == ['foo' for _ in docs]\n+\n+\n+def test_set_workspace(tmpdir):\n+    complete_workspace = os.path.abspath(os.path.join(tmpdir, 'WorkspaceExec', '0'))\n+    with Flow().add(uses=WorkspaceExec, workspace=str(tmpdir)) as f:\n+        resp = f.post(on='/foo', inputs=Document())\n+    assert resp[0].text == complete_workspace\n+    with Flow().add(uses=WorkspaceExec, uses_metas={'workspace': str(tmpdir)}) as f:\n+        resp = f.post(on='/foo', inputs=Document())\n+    assert resp[0].text == complete_workspace\n+\n+\n+def test_default_workspace(tmpdir):\n+    with mock.patch.dict(\n+        os.environ,\n+        {'JINA_DEFAULT_WORKSPACE_BASE': str(os.path.join(tmpdir, 'mock-workspace'))},\n+    ):\n+        with Flow().add(uses=WorkspaceExec) as f:\n+            resp = f.post(on='/foo', inputs=Document())\n+        assert resp[0].text\n+\n+        result_workspace = resp[0].text\n+\n+        assert result_workspace == os.path.join(\n+            os.environ['JINA_DEFAULT_WORKSPACE_BASE'], 'WorkspaceExec', '0'\n+        )\n\n\n###\n\n", "completion": "refactor: clean up workspace parameter, add default workspace (#<issue-num>)"}
{"prompt": " file path A: CONTRIBUTING.md | file path B: CONTRIBUTING.md\n\n@@ -241,7 +241,7 @@ Good docs make developers happy, and we love happy developers! We've got a few d\n * Tutorials/examples\n * Docstrings in Python functions in RST format - generated by Sphinx\n \n-### Building documentation on your local\n+### Building documentation on your local machine\n \n #### Requirements\n \n\n---\n file path A: docs/api.md | file path B: docs/api.md\n\n@@ -1,12 +1,5 @@\n # Python API\n \n-To generate docs, please use:\n-\n-```bash\n-cd docs\n-bash makedocs.sh local-only\n-```\n-\n There are four packages shipped with Jina:\n \n - `jina`: the framework;\n\n\n###\n\n", "completion": "docs: remove misplaced text (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -148,6 +148,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12681,3 +12682,42 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```ed19b735```](https://github.com/jina-ai/jina/commit/ed19b73516847e7460fc8036eb338c4b31ec97dc)] __-__ small refactor (#4505) (*Joan Fontanals*)\n  - [[```075b3a91```](https://github.com/jina-ai/jina/commit/075b3a91bc26221839bc6f636905e71a3c1c782c)] __-__ __version__: the next version will be 3.2.6 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-7></a>\n+## Release Note (`3.2.7`)\n+\n+> Release time: 2022-03-21 12:16:28\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  samsja,  Jina Dev Bot,  Joan Fontanals,  Johannes Messner,  Tobias Jacobowitz,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```b0f839b2```](https://github.com/jina-ai/jina/commit/b0f839b2030b1371518082be7bf79778d6e9f88d)] __-__ improve client interface (#4510) (*samsja*)\n+ - [[```57a6490b```](https://github.com/jina-ai/jina/commit/57a6490b825deae864f89cf6f9fc975fcb7341f8)] __-__ custom gateway image (#4508) (*Tobias Jacobowitz*)\n+ - [[```a97ed52c```](https://github.com/jina-ai/jina/commit/a97ed52c3f4305423ed6819d359e3b4956d126b0)] __-__ Linkerd as default service mesh (#4433) (*Tobias Jacobowitz*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```35026dcc```](https://github.com/jina-ai/jina/commit/35026dcc63bc9814c923ccf156085c682832c491)] __-__ __client__: simplify logics in client post (#4518) (*Han Xiao*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```5dff893b```](https://github.com/jina-ai/jina/commit/5dff893b4904e0ea348e2ce6892ec9f96dae2c07)] __-__ add file imports to migration guide (#4513) (*Johannes Messner*)\n+ - [[```60795df1```](https://github.com/jina-ai/jina/commit/60795df18fa34b59409de6c4b16edeb962bba58e)] __-__ expose and explain gateway service (#4509) (*Johannes Messner*)\n+ - [[```2bacdb33```](https://github.com/jina-ai/jina/commit/2bacdb33d39bb0c9fa189e386e53ff9efe0a8cc7)] __-__ explain host parameter for client and tweak client docs page (#4506) (*Johannes Messner*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```833771b9```](https://github.com/jina-ai/jina/commit/833771b97563dcf4887aaf70a5dfa69e85f38585)] __-__ make sure to await coroutine in test (#4516) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```21415ea8```](https://github.com/jina-ai/jina/commit/21415ea827ab5e4f88ca8fe99dd07c9d89225e82)] __-__ __style__: fix table ui (*Han Xiao*)\n+ - [[```63d7813a```](https://github.com/jina-ai/jina/commit/63d7813af51e26ece417214c07e41697c785312e)] __-__ Fix better enum formatting (#4520) (*samsja*)\n+ - [[```3fad429d```](https://github.com/jina-ai/jina/commit/3fad429dca534ad2c2013f0b8f507708540dd627)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```b2db7b82```](https://github.com/jina-ai/jina/commit/b2db7b82d9c600f7212016450b2d4de8ccf6acc2)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```734f86fd```](https://github.com/jina-ai/jina/commit/734f86fd5b8a142161c23bb7bf5d1982dcc36d2a)] __-__ __version__: the next version will be 3.2.7 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.7'\n+__version__ = '3.2.8'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.8"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1495,7 +1495,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         return self._deployment_nodes.items().__iter__()\n \n     def _init_table(self):\n-        table = Table(title=None, box=None, highlight=True)\n+        table = Table(title=None, box=None, highlight=True, show_header=False)\n         table.add_column('', justify='right')\n         table.add_column('', justify='right')\n         table.add_column('', justify='right')\n@@ -1504,41 +1504,41 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         return table\n \n     def _get_address_table(self, address_table):\n-        address_table.add_row('\ud83d\udd17', 'Protocol: ', f'{self.protocol}')\n+        address_table.add_row('\ud83d\udd17', 'Protocol', f'{self.protocol}')\n         address_table.add_row(\n             '\ud83c\udfe0',\n-            'Local access: ',\n+            'Local access',\n             f'[underline]{self.host}:{self.port}[/underline]',\n         )\n         address_table.add_row(\n             '\ud83d\udd12',\n-            'Private network: ',\n+            'Private network',\n             f'[underline]{self.address_private}:{self.port}[/underline]',\n         )\n \n         if self.address_public:\n             address_table.add_row(\n                 '\ud83c\udf10',\n-                'Public address: ',\n+                'Public address',\n                 f'[underline]{self.address_public}:{self.port}[/underline]',\n             )\n \n         if self.protocol == GatewayProtocolType.HTTP:\n             address_table.add_row(\n                 '\ud83d\udcac',\n-                'Swagger UI: ',\n+                'Swagger UI',\n                 f'[underline]http://localhost:{self.port}/docs[/underline]',\n             )\n \n             address_table.add_row(\n                 '\ud83d\udcda',\n-                'Redoc: ',\n+                'Redoc',\n                 f'[underline]http://localhost:{self.port}/redoc[/underline]',\n             )\n             if self.args.expose_graphql_endpoint:\n                 address_table.add_row(\n                     '\ud83d\udcac',\n-                    'GraphQL UI: ',\n+                    'GraphQL UI',\n                     f'[underline][cyan]http://localhost:{self.port}/graphql[/underline][/cyan]',\n                 )\n \n\n\n###\n\n", "completion": "chore(style): fix table ui"}
{"prompt": " file path A: jina/clients/mixin.py | file path B: jina/clients/mixin.py\n\n@@ -124,7 +124,7 @@ class PostMixin:\n \n         c = self.client\n \n-        if c.args.return_responses is True and return_responses is False:\n+        if c.args.return_responses and not return_responses:\n             warnings.warn(\n                 'return_responses was set in the Client constructor. Therefore, we are overriding the `.post()` input '\n                 'parameter `return_responses`. This argument will be deprecated from the `constructor` '\n@@ -132,33 +132,26 @@ class PostMixin:\n             )\n             return_responses = True\n \n-        return_results = True\n-        if (on_always is not None) or (on_done is not None):\n-            return_results = False\n+        c.show_progress = show_progress\n+        c.continue_on_error = continue_on_error\n+\n+        parameters = _include_results_field_in_param(parameters)\n+        on_error = _wrap_on_error(on_error) if on_error is not None else on_error\n+\n+        from jina import DocumentArray\n+\n+        return_results = (on_always is None) and (on_done is None)\n \n         async def _get_results(*args, **kwargs):\n-            result = []\n-            c.show_progress = show_progress\n-            c.continue_on_error = continue_on_error\n+            result = [] if return_responses else DocumentArray()\n             async for resp in c._get_results(*args, **kwargs):\n                 if return_results:\n-                    result.append(resp)\n-\n-            if return_results:\n-                if not return_responses:\n-                    docs = [r.data.docs for r in result]\n-                    if len(docs) < 1:\n-                        return docs\n+                    if return_responses:\n+                        result.append(resp)\n                     else:\n-                        return docs[0].reduce_all(docs[1:])\n-                else:\n-                    return result\n-\n-        if (on_always is None) and (on_done is None):\n-            return_results = True\n-\n-        parameters = _include_results_field_in_param(parameters)\n-        on_error = _wrap_on_error(on_error) if on_error is not None else on_error\n+                        result.extend(resp.data.docs)\n+            if return_results:\n+                return result\n \n         return run_async(\n             _get_results,\n@@ -219,7 +212,7 @@ class AsyncPostMixin:\n         \"\"\"\n         c = self.client\n \n-        if c.args.return_responses is True and return_responses is False:\n+        if c.args.return_responses and not return_responses:\n             warnings.warn(\n                 'return_responses was set in the Client constructor. Therefore, we are overriding the `.post()` input '\n                 'parameter `return_responses`. This argument will be deprecated from the `constructor` '\n@@ -257,7 +250,6 @@ class AsyncPostMixin:\n \n \n def _wrap_on_error(on_error):\n-\n     num_args = len(signature(on_error).parameters)\n     if num_args == 1:\n         warnings.warn(\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1202,8 +1202,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                 self.close()\n                 raise RuntimeFailToStart\n \n-        success_msg = '[green]\ud83c\udf89 Flow is ready to use![/green]'\n-        console.print(success_msg)\n         if addr_table:\n             print(\n                 addr_table\n\n\n###\n\n", "completion": "refactor(client): simplify logics in client post (#<issue-num>)"}
{"prompt": " file path A: tests/integration/pods/test_pod.py | file path B: tests/integration/pods/test_pod.py\n\n@@ -1,4 +1,5 @@\n import asyncio\n+import inspect\n import json\n import time\n \n@@ -102,7 +103,10 @@ async def test_pods_health_check(port_generator, protocol, health_check):\n         for _port in (head_port, worker_port):\n             check_health_pod(f'0.0.0.0:{_port}')\n \n-        health_check(f'0.0.0.0:{port}')\n+        if inspect.iscoroutinefunction(health_check):\n+            await health_check(f'0.0.0.0:{port}')\n+        else:\n+            health_check(f'0.0.0.0:{port}')\n \n \n @pytest.fixture\n\n\n###\n\n", "completion": "test: make sure to await coroutine in test (#<issue-num>)"}
{"prompt": " file path A: docs/get-started/migrate.md | file path B: docs/get-started/migrate.md\n\n@@ -26,16 +26,18 @@ Many of the changes introduced in Jina 3 are easily adapted to a Jina 2 codebase\n The modifications in the following table should, in most cases, be safe to perform without further thought or effort.\n \n \n-| Jina 2                            | Jina 3              |\n-|-----------------------------------|---------------------|\n-| `doc.blob`                        | `doc.tensor`          |\n-| `doc.buffer`                       | `doc.blob`            |\n-| `docs.get_attributes('attribute')` | `docs[:, 'attribute']` |\n-| `['path1', 'path2']`               | `'path1,path2'`       |\n-| `docs.traverse_flat(paths)`        | `docs['@paths']`      \n-| `docs.flatten()`                    | `docs[...]` |\n-| `doc.SerializeToString()`           | `doc.to_bytes()` |\n-| `Document(bytes)`                   | `Document.from_bytes()` |\n+| Jina 2                                                  | Jina 3                                                |\n+|---------------------------------------------------------|-------------------------------------------------------|\n+| `doc.blob`                                              | `doc.tensor`                                          |\n+| `doc.buffer`                                            | `doc.blob`                                            |\n+| `docs.get_attributes('attribute')`                      | `docs[:, 'attribute']`                                |\n+| `['path1', 'path2']`                                    | `'path1,path2'`                                       |\n+| `docs.traverse_flat(paths)`                             | `docs['@paths']`                                      |\n+| `docs.flatten()`                                        | `docs[...]`                                           |\n+| `doc.SerializeToString()`                               | `doc.to_bytes()`                                      |\n+| `Document(bytes)`                                       | `Document.from_bytes()`                               |\n+| `from jina import Document, DocumentArray`              | `from docarray import Document, DocumentArray`        |\n+\n \n There are, however, some more nuanced changes in Jina 3 as well.\n These are outlined below.\n@@ -81,7 +83,7 @@ to have a better understanding of accessing attributes and elements with `DocArr\n ````{tab} Jina 2\n \n ```python\n-from docarray import Document, DocumentArray\n+from jina import Document, DocumentArray\n \n docs = nested_docs()\n \n@@ -121,6 +123,31 @@ print(docs[...].texts)\n ```\n \n ````\n+\n+**Loading data from files**: DocumentArray introduces a `.from_files()` class method which can be used directly instead of\n+importing a `from_files()` function.\n+\n+````{tab} Jina 2\n+\n+```python\n+from jina import Document, DocumentArray\n+from jina.types.document.generators import from_files\n+\n+docs = DocumentArray(from_files('path/to/files'))\n+```\n+\n+````\n+\n+````{tab} Jina 3 \n+\n+```python\n+from docarray import Document, DocumentArray\n+\n+docs = DocumentArray.from_files('path/to/files')\n+```\n+\n+````\n+\n \\\n **Batching**: Batching operations are delegated to the docarray package and Python builtins:\n \n@@ -151,7 +178,7 @@ important when migrating code that checks for the presence of a certain attribut\n ````{tab} Jina 2\n \n ```python\n-from docarray import Document, DocumentArray\n+from jina import Document, DocumentArray\n \n d = Document()\n print(d.text)\n\n\n###\n\n", "completion": "docs: add file imports to migration guide (#<issue-num>)"}
{"prompt": " file path A: docs/how-to/docker-compose.md | file path B: docs/how-to/docker-compose.md\n\n@@ -76,6 +76,11 @@ Now, we can generate Docker Compose YAML configuration from the Flow:\n f.to_docker_compose_yaml('docker-compose.yml')\n ```\n \n+````{admonition} Hint\n+:class: hint\n+You can use a custom Docker image for the Gateway service. Just set the envrironment variable `JINA_GATEWAY_IMAGE` to the desired image before generating the configuration.\n+````\n+\n let's take a look at the generated compose file:\n ```yaml\n version: '3.3'\n\n---\n file path A: docs/how-to/kubernetes.md | file path B: docs/how-to/kubernetes.md\n\n@@ -47,6 +47,11 @@ flow.to_k8s_yaml('flow_k8s_configuration')\n \n This will create a folder 'flow_k8s_configuration' with a set of Kubernetes YAML configurations for all the deployments composing the Flow\n \n+````{admonition} Hint\n+:class: hint\n+You can use a custom Docker image for the Gateway deployment. Just set the envrironment variable `JINA_GATEWAY_IMAGE` to the desired image before generating the configuration.\n+````\n+\n ## Example\n \n ### Indexing and searching images using CLIP image encoder and PQLiteIndexer\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -88,7 +88,7 @@ __jina_env__ = (\n     'JINA_HUBBLE_REGISTRY',\n     'JINA_HUB_CACHE_DIR',\n     'JINA_HUB_ROOT',\n-    'JINA_K8S_USE_TEST_PIP',\n+    'JINA_GATEWAY_IMAGE',\n     'JINA_LOG_CONFIG',\n     'JINA_LOG_LEVEL',\n     'JINA_LOG_NO_COLOR',\n\n---\n file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -50,11 +50,8 @@ class DockerComposeConfig:\n         ) -> Dict:\n             import os\n \n-            test_pip = os.getenv('JINA_K8S_USE_TEST_PIP') is not None\n-            image_name = (\n-                'jinaai/jina:test-pip'\n-                if test_pip\n-                else f'jinaai/jina:{self.version}-py38-standard'\n+            image_name = os.getenv(\n+                'JINA_GATEWAY_IMAGE', f'jinaai/jina:{self.version}-py38-standard'\n             )\n             cargs = copy.copy(self.service_args)\n             cargs.deployments_addresses = self.deployments_addresses\n@@ -101,11 +98,8 @@ class DockerComposeConfig:\n         def _get_image_name(self, uses: Optional[str]):\n             import os\n \n-            test_pip = os.getenv('JINA_K8S_USE_TEST_PIP') is not None\n-            image_name = (\n-                'jinaai/jina:test-pip'\n-                if test_pip\n-                else f'jinaai/jina:{self.version}-py38-perf'\n+            image_name = os.getenv(\n+                'JINA_GATEWAY_IMAGE', f'jinaai/jina:{self.version}-py38-standard'\n             )\n \n             if uses is not None and uses != __default_executor__:\n\n---\n file path A: jina/orchestrate/deployments/config/k8s.py | file path B: jina/orchestrate/deployments/config/k8s.py\n\n@@ -1,18 +1,18 @@\n import copy\n from argparse import Namespace\n-from typing import Dict, Union, List, Optional, Tuple\n+from typing import Dict, List, Optional, Tuple, Union\n \n from jina import __default_executor__\n from jina.enums import PodRoleType\n from jina.excepts import NoContainerizedError\n-from jina.orchestrate.deployments.config.k8slib import kubernetes_deployment\n from jina.orchestrate.deployments.config.helper import (\n+    construct_runtime_container_args,\n+    get_base_executor_version,\n     get_image_name,\n     to_compatible_name,\n-    get_base_executor_version,\n-    construct_runtime_container_args,\n     validate_uses,\n )\n+from jina.orchestrate.deployments.config.k8slib import kubernetes_deployment\n from jina.serve.networking import GrpcConnectionPool\n from jina.orchestrate.deployments import BaseDeployment\n \n@@ -52,12 +52,10 @@ class K8sDeploymentConfig:\n         ) -> List[Dict]:\n             import os\n \n-            test_pip = os.getenv('JINA_K8S_USE_TEST_PIP') is not None\n-            image_name = (\n-                'jinaai/jina:test-pip'\n-                if test_pip\n-                else f'jinaai/jina:{self.version}-py38-standard'\n+            image_name = os.getenv(\n+                'JINA_GATEWAY_IMAGE', f'jinaai/jina:{self.version}-py38-standard'\n             )\n+\n             cargs = copy.copy(self.deployment_args)\n             cargs.env = None\n             cargs.deployments_addresses = self.k8s_deployments_addresses\n@@ -98,11 +96,8 @@ class K8sDeploymentConfig:\n         def _get_image_name(self, uses: Optional[str]):\n             import os\n \n-            test_pip = os.getenv('JINA_K8S_USE_TEST_PIP') is not None\n-            image_name = (\n-                'jinaai/jina:test-pip'\n-                if test_pip\n-                else f'jinaai/jina:{self.version}-py38-perf'\n+            image_name = os.getenv(\n+                'JINA_GATEWAY_IMAGE', f'jinaai/jina:{self.version}-py38-standard'\n             )\n \n             if uses is not None and uses != __default_executor__:\n\n---\n file path A: tests/docker_compose/conftest.py | file path B: tests/docker_compose/conftest.py\n\n@@ -44,9 +44,9 @@ def build_docker_image(image_name, image_name_tag_map):\n \n @pytest.fixture(autouse=True)\n def set_test_pip_version():\n-    os.environ['JINA_K8S_USE_TEST_PIP'] = 'True'\n+    os.environ['JINA_GATEWAY_IMAGE'] = 'jinaai/jina:test-pip'\n     yield\n-    del os.environ['JINA_K8S_USE_TEST_PIP']\n+    del os.environ['JINA_GATEWAY_IMAGE']\n \n \n @pytest.fixture(autouse=True)\n\n---\n file path A: tests/k8s/conftest.py | file path B: tests/k8s/conftest.py\n\n@@ -112,9 +112,9 @@ def build_docker_image(image_name, image_name_tag_map):\n \n @pytest.fixture(autouse=True)\n def set_test_pip_version():\n-    os.environ['JINA_K8S_USE_TEST_PIP'] = 'True'\n+    os.environ['JINA_GATEWAY_IMAGE'] = 'jinaai/jina:test-pip'\n     yield\n-    del os.environ['JINA_K8S_USE_TEST_PIP']\n+    del os.environ['JINA_GATEWAY_IMAGE']\n \n \n @pytest.fixture(autouse=True)\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_docker_compose_pod_config.py | file path B: tests/unit/orchestrate/deploymens/config/test_docker_compose_pod_config.py\n\n@@ -1,21 +1,14 @@\n-from typing import Union, Dict, Tuple\n import json\n+import os\n+from typing import Dict, Tuple, Union\n+\n import pytest\n \n from jina.helper import Namespace\n from jina.hubble import HubExecutor\n from jina.hubble.hubio import HubIO\n-from jina.parsers import set_deployment_parser, set_gateway_parser\n from jina.orchestrate.deployments.config.docker_compose import DockerComposeConfig\n-\n-\n-@pytest.fixture(autouse=True)\n-def set_test_pip_version():\n-    import os\n-\n-    os.environ['JINA_K8S_USE_TEST_PIP'] = 'True'\n-    yield\n-    del os.environ['JINA_K8S_USE_TEST_PIP']\n+from jina.parsers import set_deployment_parser, set_gateway_parser\n \n \n def namespace_equal(\n@@ -331,7 +324,12 @@ def test_worker_services(name: str, shards: str):\n \n \n @pytest.mark.parametrize('deployments_addresses', [None, {'1': 'executor-head:8081'}])\n-def test_docker_compose_gateway(deployments_addresses):\n+@pytest.mark.parametrize('custom_gateway', ['jinaai/jina:custom-gateway', None])\n+def test_docker_compose_gateway(deployments_addresses, custom_gateway):\n+    if custom_gateway:\n+        os.environ['JINA_GATEWAY_IMAGE'] = custom_gateway\n+    elif 'JINA_GATEWAY_IMAGE' in os.environ:\n+        del os.environ['JINA_GATEWAY_IMAGE']\n     args = set_gateway_parser().parse_args(\n         ['--env', 'ENV_VAR:ENV_VALUE', '--port', '32465']\n     )  # envs are\n@@ -341,7 +339,11 @@ def test_docker_compose_gateway(deployments_addresses):\n     )\n     name, gateway_config = deployment_config.to_docker_compose_config()[0]\n     assert name == 'gateway'\n-    assert gateway_config['image'] == 'jinaai/jina:test-pip'\n+    assert (\n+        gateway_config['image'] == custom_gateway\n+        if custom_gateway\n+        else f'jinaai/jina:{deployment_config.worker_services[0].version}-py38-standard'\n+    )\n     assert gateway_config['entrypoint'] == ['jina']\n     assert gateway_config['ports'] == [f'{args.port}:{args.port}']\n     assert gateway_config['expose'] == [f'{args.port}']\n@@ -430,7 +432,10 @@ def test_docker_compose_yaml_regular_deployment(\n     )\n     head_name, head_config = yaml_configs[0]\n     assert head_name == 'executor-head'\n-    assert head_config['image'] == 'jinaai/jina:test-pip'\n+    assert (\n+        head_config['image']\n+        == f'jinaai/jina:{deployment_config.head_service.version}-py38-standard'\n+    )\n     assert head_config['entrypoint'] == ['jina']\n     head_args = head_config['command']\n     assert head_args[0] == 'executor'\n\n---\n file path A: tests/unit/orchestrate/deploymens/config/test_k8s_deployment_config.py | file path B: tests/unit/orchestrate/deploymens/config/test_k8s_deployment_config.py\n\n@@ -1,24 +1,17 @@\n-from typing import Union, Dict, Tuple\n import json\n+import os\n+from typing import Dict, Tuple, Union\n+\n import pytest\n \n from jina.helper import Namespace\n from jina.hubble import HubExecutor\n from jina.hubble.hubio import HubIO\n-from jina.parsers import set_deployment_parser, set_gateway_parser\n from jina.orchestrate.deployments.config.k8s import K8sDeploymentConfig\n+from jina.parsers import set_deployment_parser, set_gateway_parser\n from jina.serve.networking import GrpcConnectionPool\n \n \n-@pytest.fixture(autouse=True)\n-def set_test_pip_version():\n-    import os\n-\n-    os.environ['JINA_K8S_USE_TEST_PIP'] = 'True'\n-    yield\n-    del os.environ['JINA_K8S_USE_TEST_PIP']\n-\n-\n def namespace_equal(\n     n1: Union[Namespace, Dict], n2: Union[Namespace, Dict], skip_attr: Tuple = ()\n ) -> bool:\n@@ -261,7 +254,12 @@ def assert_config_map_config(\n \n \n @pytest.mark.parametrize('deployments_addresses', [None, {'1': 'address.svc'}])\n-def test_k8s_yaml_gateway(deployments_addresses):\n+@pytest.mark.parametrize('custom_gateway', ['jinaai/jina:custom-gateway', None])\n+def test_k8s_yaml_gateway(deployments_addresses, custom_gateway):\n+    if custom_gateway:\n+        os.environ['JINA_GATEWAY_IMAGE'] = custom_gateway\n+    elif 'JINA_GATEWAY_IMAGE' in os.environ:\n+        del os.environ['JINA_GATEWAY_IMAGE']\n     args = set_gateway_parser().parse_args(\n         ['--env', 'ENV_VAR:ENV_VALUE', '--port', '32465']\n     )  # envs are\n@@ -331,7 +329,11 @@ def test_k8s_yaml_gateway(deployments_addresses):\n     assert len(containers) == 1\n     container = containers[0]\n     assert container['name'] == 'executor'\n-    assert container['image'] == 'jinaai/jina:test-pip'\n+    assert (\n+        container['image'] == custom_gateway\n+        if custom_gateway\n+        else f'jinaai/jina:{deployment_config.worker_deployments[0].version}-py38-standard'\n+    )\n     assert container['imagePullPolicy'] == 'IfNotPresent'\n     assert container['command'] == ['jina']\n     args = container['args']\n@@ -483,7 +485,10 @@ def test_k8s_yaml_regular_deployment(\n     )\n     head_runtime_container = head_containers[0]\n     assert head_runtime_container['name'] == 'executor'\n-    assert head_runtime_container['image'] == 'jinaai/jina:test-pip'\n+    assert (\n+        head_runtime_container['image']\n+        == f'jinaai/jina:{deployment_config.head_deployment.version}-py38-standard'\n+    )\n     assert head_runtime_container['imagePullPolicy'] == 'IfNotPresent'\n     assert head_runtime_container['command'] == ['jina']\n     head_runtime_container_args = head_runtime_container['args']\n\n\n###\n\n", "completion": "feat: custom gateway image (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/architecture-overview.md | file path B: docs/fundamentals/architecture-overview.md\n\n@@ -3,7 +3,7 @@\n \n {ref}`Executor <executor>` and {ref}`Flow <flow>` are the two fundamental concepts in Jina. \n \n-The figure below shows details on how the Flow and Executor abstractions translate into concrete entities, providing all the \n+The figure below shows details on how the Flow and Executor abstractions translate into concrete microservices, providing all the \n serving and scaling features of Jina.\n \n \n@@ -11,14 +11,14 @@ serving and scaling features of Jina.\n :align: center\n ```\n \n-It illustrates how Jina deploys and serves its Flows and Executors.\n+You will not need to understand every detail of this architecture in order to build your first Neural Search app using Jina.\n+But it is useful in order to understand how Jina works, regardless of whether your microservice app runs locally,\n+is orchestrated only by the Flow object itself, or is deployed using a cloud-native infrastructure such as Kubernetes.\n+In fact, you might notice how some naming and concepts are inspired by the Kubernetes architecture.\n \n-You will not need to understand every detail of this architecture in order to build your first Neural Search app using Jina. But it is useful in order to understand how Jina works, regardless of whether it runs locally, orchestrated only by the Flow, or in \n-a cloud-native infrastructure such as Kubernetes. In fact, you can notice how some naming and concepts are inspired by the Kubernetes architecture.\n+The following concepts may appear in the docs, but you don't need to master them as they are mainly designed for advanced or internal use:\n \n-The following concepts may appear in the docs, but you don't need to master them as they are designed to be used only internally:\n-\n-  - **Gateway**: The Gateway is a service started by the Flow which is responsible for exposing the `HTTP`, `WebSocker` or `gRPC` endpoints to the client. Additionally, it keeps knowledge of the topology of the Flow to guarantee that the `Documents` are processed by the Executors in the proper order. It communicates with the Deployments via `gRPC`\n+  - **Gateway**: The Gateway is a service started by the Flow which is responsible for exposing the `HTTP`, `WebSocker` or `gRPC` endpoints to the client. It is the service that the clients of your app will actually talk to. Additionally, it keeps knowledge of the topology of the Flow to guarantee that the `Documents` are processed by the Executors in the proper order. It communicates with the Deployments via `gRPC`\n \n   - **Deployment**: Deployment is an abstraction around Executor that lets the `Gateway` communicate with an Executor. It encapsulates and abstracts internal replication details.\n \n\n---\n file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -6,6 +6,7 @@ Documents \"flow\" through the created pipeline and are processed by Executors.\n \n You can think of Flow as an interface to configure and launch your {ref}`microservice architecture <architecture-overview>`,\n while the heavy lifting is done by the {ref}`services <executor-cookbook>` themselves.\n+In particular, each Flow also launches a *Gateway* service, which can expose all other services through an API that you define.\n \n \n The most important methods of the `Flow` object are the following:\n@@ -24,14 +25,14 @@ The most important methods of the `Flow` object are the following:\n \n ## Why should you use a Flow?\n \n-Once you have learned DocumentArray and Executor, you have been able to split your neural search application into different independent modules and services.\n-But you need to chain them together in order to bring real value and to build and serve an application out of it. That's exactly what Flows enable you to do.\n+Once you have learned DocumentArray and Executor, you are able to split your neural search application into different independent modules and services.\n+But you need to chain them together in order to bring real value and to build and serve an application. That's exactly what Flows enable you to do.\n \n-- Flow connects the microservices (Executors) to build an service with proper client/server style interface in HTTP/gRPC/Websockets\n+- Flows connect microservices (Executors) to build a service with proper client/server style interface over HTTP, gRPC, or Websocket\n \n-- Flow lets you scale these Executors independently to adjust to your requirements.\n+- Flows let you scale these Executors independently to adjust to your requirements\n \n-- Flow allows you to easily use other cloud-native orchestrators, e.g. K8s to manage the service.\n+- Flows allow you to easily use other cloud-native orchestrators, such as Kubernetes, to manage your service\n \n ## Minimum working example\n \n\n\n###\n\n", "completion": "docs: expose and explain gateway service (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -45,6 +45,7 @@ You can access the values of these arguments in the `__init__` body via `self.me\n or modify their values before passing them to `super().__init__()`.\n ````\n \n+(exec-endpoint)=\n ## Methods\n \n Methods of `Executor` can be named and written freely. \n\n---\n file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -9,6 +9,7 @@ It enables you to send `Documents` to a running `Flow` in a number of different\n However, once your solution is deployed in the cloud, the Flow interface is not present anymore.\n Hence, `flow.post()` is not recommended outside of testing or debugging use cases.\n ```\n+\n ## HTTP, gRPC, and WebSocket\n \n Jina Flows and Clients support three different networking protocols: HTTP, gRPC, and WebSocket.\n@@ -19,19 +20,37 @@ Starting the Flow:\n ```python\n from jina import Flow\n \n-port = 12345\n+PORT = 12345\n+PROTOCOL = 'grpc'  # one of 'grpc', 'http', 'websocket'\n \n-with Flow(port=port) as f:\n+with Flow(port=PORT, protocol=PROTOCOL) as f:\n     f.block()\n ```\n \n-Using the Client:\n+To connect a Client to the Flow's gateway, you need to specify an IP host address and port on which the Flow can be reached.\n+This is done using the `host=` and `port=` constructor keywords.\n+If the Client and the Flow gateway are running on the same machine, the `host=` parameter can be omitted, as it defaults to `'0.0.0.0'`.\n+\n+Additionally, the connection protocol can be toggled between `'grpc'`, `'http'`, and `'websocket'` using the `protocol=`\n+keyword, where `'grpc'` is the default.\n \n ```python\n-from docarray import Document, DocumentArray\n from jina import Client\n \n-PORT = 12345\n+HOST = '0.0.0.0'  # host address where the Flow can be reached\n+PORT = 12345  # port where the Flow can be reached\n+PROTOCOL = 'grpc'  # one of 'grpc', 'http', 'websocket'. Needs to be same as specified by the Flow\n+\n+client = Client(host=HOST, port=PORT, protocol=PROTOCOL)\n+```\n+\n+Then, the Client can send requests to the Flow using its `.post()` method.\n+This expects as inputs the {ref}`Executor endpoint <exec-endpoint>` that you want to target, as well as a Document or Iterable of Documents:\n+\n+\n+```python\n+from docarray import Document, DocumentArray\n+\n \n d1 = Document(content='hello')\n d2 = Document(content='world')\n@@ -42,7 +61,7 @@ def doc_gen():\n         yield Document(content=f'hello {j}')\n \n \n-client = Client(port=PORT)\n+client = Client(host=HOST, port=PORT)\n \n client.post('/endpoint', d1)  # Single Document\n \n@@ -235,7 +254,7 @@ with Flow().add() as f, open('output.txt', 'w') as fp:\n         on_always=lambda x: x.docs.save(fp),\n     )\n ```\n-## On failure callback\n+### On failure callback\n \n Additionally, the `on_error` callback can be triggered by a raise of an exception. The callback must take an optional \n `exception` parameters as an argument.\n@@ -322,6 +341,18 @@ with Flow() as f:\n \n ````\n \n+### Custom gRPC compression for GRPC Client\n+\n+If the communication to the `Flow` needs to be done via gRPC, you can pass `compression` parameter to `client.post` to benefit from (`grpc compression`)[https://grpc.github.io/grpc/python/grpc.html#compression] methods. \n+The supported methods are: `NoCompression`, `Gzip` and `Deflate`.\n+\n+```python\n+from jina import Client\n+\n+client = Client()\n+client.post(..., compression='Gzip')\n+```\n+\n ## GraphQL\n \n The Jina Client additionally supports fetching data via GraphQL mutations using `client.mutate()`:\n@@ -376,16 +407,3 @@ async def run_client(port):\n with Flow() as f:  # Using it as a Context Manager will start the Flow\n     asyncio.run(run_client(f.port))\n ```\n-\n-### Custom gRPC compression for GRPC Client\n-\n-If the communication to the `Flow` needs to be done via GRPC, you can pass `compression` parameter to `client.post` to benefit from (`grpc compression`)[https://grpc.github.io/grpc/python/grpc.html#compression] methods. \n-The supported methods are: `NoCompression`, `Gzip` and `Deflate`.\n-\n-```python\n-from jina import Client\n-\n-client = Client()\n-client.post(..., compression='Gzip')\n-```\n-\n\n\n###\n\n", "completion": "docs: explain host parameter for client and tweak client docs page (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -147,6 +147,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12661,3 +12662,19 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```f844904c```](https://github.com/jina-ai/jina/commit/f844904ca88980969256fc6f7a767be6f7f3be94)] __-__ __version__: the next version will be 3.2.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-6></a>\n+## Release Note (`3.2.6`)\n+\n+> Release time: 2022-03-17 11:13:02\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```ed19b735```](https://github.com/jina-ai/jina/commit/ed19b73516847e7460fc8036eb338c4b31ec97dc)] __-__ small refactor (#4505) (*Joan Fontanals*)\n+ - [[```075b3a91```](https://github.com/jina-ai/jina/commit/075b3a91bc26221839bc6f636905e71a3c1c782c)] __-__ __version__: the next version will be 3.2.6 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.6'\n+__version__ = '3.2.7'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.7"}
{"prompt": " file path A: jina/serve/runtimes/gateway/websocket/app.py | file path B: jina/serve/runtimes/gateway/websocket/app.py\n\n@@ -27,6 +27,7 @@ def get_fastapi_app(\n     :param logger: Jina logger.\n     :return: fastapi app\n     \"\"\"\n+\n     from jina.serve.runtimes.gateway.http.models import JinaEndpointRequestModel\n \n     with ImportExtensions(required=True):\n\n\n###\n\n", "completion": "chore: small refactor (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -146,6 +146,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12637,3 +12638,26 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```9266cd54```](https://github.com/jina-ai/jina/commit/9266cd542a83acc46b63db45db4e92cd06d5cb39)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n  - [[```e19b7af0```](https://github.com/jina-ai/jina/commit/e19b7af0fa6f7d9eedef44b864132a74bcc5fb9e)] __-__ __version__: the next version will be 3.2.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-5></a>\n+## Release Note (`3.2.5`)\n+\n+> Release time: 2022-03-17 10:19:39\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```a470ce6c```](https://github.com/jina-ai/jina/commit/a470ce6c59373e2a6c5518bcaa8a13b560abacd5)] __-__ __grpc__: add compression to grpc network interface (#4499) (*Han Xiao*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```e6e38903```](https://github.com/jina-ai/jina/commit/e6e389039c322bc7cd6984f0bc00f905069fa009)] __-__ move import in websocket app (#4504) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```f844904c```](https://github.com/jina-ai/jina/commit/f844904ca88980969256fc6f7a767be6f7f3be94)] __-__ __version__: the next version will be 3.2.5 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.5'\n+__version__ = '3.2.6'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.6"}
{"prompt": " file path A: jina/serve/runtimes/gateway/websocket/app.py | file path B: jina/serve/runtimes/gateway/websocket/app.py\n\n@@ -5,7 +5,6 @@ from jina.clients.request import request_generator\n from jina.enums import DataInputType, WebsocketSubProtocols\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n-from jina.serve.runtimes.gateway.http.models import JinaEndpointRequestModel\n from jina.types.request.data import DataRequest\n \n if TYPE_CHECKING:\n@@ -28,6 +27,7 @@ def get_fastapi_app(\n     :param logger: Jina logger.\n     :return: fastapi app\n     \"\"\"\n+    from jina.serve.runtimes.gateway.http.models import JinaEndpointRequestModel\n \n     with ImportExtensions(required=True):\n         from fastapi import FastAPI, WebSocket, WebSocketDisconnect\n\n\n###\n\n", "completion": "fix: move import in websocket app (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -145,6 +145,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12611,3 +12612,28 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```c7c2c35b```](https://github.com/jina-ai/jina/commit/c7c2c35b8ed22bc4638f1cd485129e63d2c9b3d8)] __-__ __version__: the next version will be 3.2.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-4></a>\n+## Release Note (`3.2.4`)\n+\n+> Release time: 2022-03-17 07:16:28\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Deepankar Mahapatro,  Jina Dev Bot,  Joan Fontanals,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```97d77a35```](https://github.com/jina-ai/jina/commit/97d77a35902f6533ba656b9863b50bbf063bba56)] __-__ __websocket__: json/bytes support (#4501) (*Deepankar Mahapatro*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```05541407```](https://github.com/jina-ai/jina/commit/05541407013d19395c09a6287146924dd5093db4)] __-__ return_responses to post (#4496) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```81106d80```](https://github.com/jina-ai/jina/commit/81106d80bbff1434f41013745ad52cab27aa2f55)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```9266cd54```](https://github.com/jina-ai/jina/commit/9266cd542a83acc46b63db45db4e92cd06d5cb39)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```e19b7af0```](https://github.com/jina-ai/jina/commit/e19b7af0fa6f7d9eedef44b864132a74bcc5fb9e)] __-__ __version__: the next version will be 3.2.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.4'\n+__version__ = '3.2.5'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.5"}
{"prompt": " file path A: docs/fundamentals/flow/client.md | file path B: docs/fundamentals/flow/client.md\n\n@@ -249,7 +249,7 @@ def on_error(resp, exception: Exception):\n \n If no callback is provided, `client.post()` returns a flattened `DocumentArray` containing all Documents of all Requests.\n \n-By setting `return_responses=True` when creating a Client, this behavior can be modified to return a list of Responses\n+By setting `return_responses=True` as an argument to `client.post(return_responses=True), this behavior can be modified to return a list of Responses\n (`DataRequest`s) instead.\n \n If a callback is provided, no results will be returned.\n@@ -289,8 +289,8 @@ from jina import Flow, Client\n from docarray import Document\n \n with Flow() as f:\n-    client = Client(port=f.port, return_responses=True)\n-    resp = client.post(on='', inputs=Document(text='Hi there!'))\n+    client = Client(port=f.port)\n+    resp = client.post(on='', inputs=Document(text='Hi there!'), return_responses=True)\n     print(resp)\n     print(resp[0].docs.texts)\n ```\n\n---\n file path A: jina/clients/mixin.py | file path B: jina/clients/mixin.py\n\n@@ -98,6 +98,7 @@ class PostMixin:\n         request_size: int = 100,\n         show_progress: bool = False,\n         continue_on_error: bool = False,\n+        return_responses: bool = False,\n         **kwargs,\n     ) -> Optional[Union['DocumentArray', List['Response']]]:\n         \"\"\"Post a general data request to the Flow.\n@@ -111,7 +112,9 @@ class PostMixin:\n         :param target_executor: a regex string. Only matching Executors will process the request.\n         :param request_size: the number of Documents per request. <=0 means all inputs in one request.\n         :param show_progress: if set, client will show a progress bar on receiving every request.\n-        :param continue_on_error: if set, a Request that causes callback error will be logged only without blocking the further requests.\n+        :param continue_on_error: if set, a Request that causes callback error will be logged only without blocking the further requests.7\n+        :param return_responses: if set to True, the result will come as Response and not as a `DocumentArray`\n+\n         :param kwargs: additional parameters\n         :return: None or DocumentArray containing all response Documents\n \n@@ -119,11 +122,22 @@ class PostMixin:\n             ``target_executor`` uses ``re.match`` for checking if the pattern is matched. ``target_executor=='foo'`` will match both deployments with the name ``foo`` and ``foo_what_ever_suffix``.\n         \"\"\"\n \n-        return_results = False\n+        c = self.client\n+\n+        if c.args.return_responses is True and return_responses is False:\n+            warnings.warn(\n+                'return_responses was set in the Client constructor. Therefore, we are overriding the `.post()` input '\n+                'parameter `return_responses`. This argument will be deprecated from the `constructor` '\n+                'soon. We recommend passing `return_responses` to the `post` method.'\n+            )\n+            return_responses = True\n+\n+        return_results = True\n+        if (on_always is not None) or (on_done is not None):\n+            return_results = False\n \n         async def _get_results(*args, **kwargs):\n             result = []\n-            c = self.client\n             c.show_progress = show_progress\n             c.continue_on_error = continue_on_error\n             async for resp in c._get_results(*args, **kwargs):\n@@ -131,7 +145,7 @@ class PostMixin:\n                     result.append(resp)\n \n             if return_results:\n-                if not c.args.return_responses:\n+                if not return_responses:\n                     docs = [r.data.docs for r in result]\n                     if len(docs) < 1:\n                         return docs\n@@ -181,6 +195,7 @@ class AsyncPostMixin:\n         request_size: int = 100,\n         show_progress: bool = False,\n         continue_on_error: bool = False,\n+        return_responses: bool = False,\n         **kwargs,\n     ) -> AsyncGenerator[None, Union['DocumentArray', 'Response']]:\n         \"\"\"Async Post a general data request to the Flow.\n@@ -195,6 +210,7 @@ class AsyncPostMixin:\n         :param request_size: the number of Documents per request. <=0 means all inputs in one request.\n         :param show_progress: if set, client will show a progress bar on receiving every request.\n         :param continue_on_error: if set, a Request that causes callback error will be logged only without blocking the further requests.\n+        :param return_responses: if set to True, the result will come as Response and not as a `DocumentArray`\n         :param kwargs: additional parameters\n         :yield: Response object\n \n@@ -202,6 +218,15 @@ class AsyncPostMixin:\n             ``target_executor`` uses ``re.match`` for checking if the pattern is matched. ``target_executor=='foo'`` will match both deployments with the name ``foo`` and ``foo_what_ever_suffix``.\n         \"\"\"\n         c = self.client\n+\n+        if c.args.return_responses is True and return_responses is False:\n+            warnings.warn(\n+                'return_responses was set in the Client constructor. Therefore, we are overriding the `.post()` input '\n+                'parameter `return_responses`. This argument will be deprecated from the `constructor` '\n+                'soon. We recommend passing `return_responses` to the `post` method.'\n+            )\n+            return_responses = True\n+\n         c.show_progress = show_progress\n         c.continue_on_error = continue_on_error\n \n@@ -219,7 +244,7 @@ class AsyncPostMixin:\n             request_size=request_size,\n             **kwargs,\n         ):\n-            if not c.args.return_responses:\n+            if not return_responses:\n                 yield result.data.docs\n             else:\n                 yield result\n\n\n###\n\n", "completion": "refactor: return_responses to post (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -144,6 +144,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12588,3 +12589,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n \n  - [[```88d60e95```](https://github.com/jina-ai/jina/commit/88d60e95b3e1212cd6f74c59c33cc60745c1694c)] __-__ __version__: the next version will be 3.2.2 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-3></a>\n+## Release Note (`3.2.3`)\n+\n+> Release time: 2022-03-16 13:04:52\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```6cb0cd0f```](https://github.com/jina-ai/jina/commit/6cb0cd0fc066cf808df3361f69c105970b286360)] __-__ avoid dependency on pydantic (#4497) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```c7c2c35b```](https://github.com/jina-ai/jina/commit/c7c2c35b8ed22bc4638f1cd485129e63d2c9b3d8)] __-__ __version__: the next version will be 3.2.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.3'\n+__version__ = '3.2.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.4"}
{"prompt": " file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -73,4 +73,4 @@ portforward>=0.2.4:         cicd\n kubernetes>=18.20.0:        perf, standard, devel\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n-sgqlc:                      cicd, graphql\n\\ No newline at end of file\n+sgqlc:                      cicd, graphql\n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -73,4 +73,4 @@ portforward>=0.2.4:         cicd\n kubernetes>=18.20.0:        perf, standard, devel\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n-sgqlc:                      cicd, graphql\n\\ No newline at end of file\n+sgqlc:                      cicd, graphql\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -14,7 +14,6 @@ from jina.helper import (\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n from jina.logging.profile import used_memory_readable\n-from jina.serve.runtimes.gateway.http.models import JinaHealthModel\n \n if TYPE_CHECKING:\n     from jina.serve.networking import GrpcConnectionPool\n@@ -108,6 +107,8 @@ def get_fastapi_app(\n             }\n         )\n \n+        from jina.serve.runtimes.gateway.http.models import JinaHealthModel\n+\n         @app.get(\n             path='/',\n             summary='Get the health of Jina service',\n@@ -261,7 +262,6 @@ def get_fastapi_app(\n             from dataclasses import asdict\n \n             import strawberry\n-            from docarray import DocumentArray\n             from docarray.document.strawberry_type import (\n                 JSONScalar,\n                 StrawberryDocument,\n@@ -269,6 +269,8 @@ def get_fastapi_app(\n             )\n             from strawberry.fastapi import GraphQLRouter\n \n+            from docarray import DocumentArray\n+\n             async def get_docs_from_endpoint(\n                 data, target_executor, parameters, exec_endpoint\n             ):\n\n---\n file path A: jina/serve/runtimes/gateway/http/models.py | file path B: jina/serve/runtimes/gateway/http/models.py\n\n@@ -1,5 +1,4 @@\n from collections import defaultdict\n-from dataclasses import asdict\n from datetime import datetime\n from enum import Enum\n from types import SimpleNamespace\n\n---\n file path A: scripts/latency-tracking/requirements.txt | file path B: scripts/latency-tracking/requirements.txt\n\n@@ -2,4 +2,3 @@ packaging==21.0\n Pillow==9.0.1\n scipy==1.7.0\n uvloop==0.15.2\n-pydantic\n\n\n###\n\n", "completion": "fix: avoid dependency on pydantic (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -143,6 +143,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12568,3 +12569,22 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```d3048f85```](https://github.com/jina-ai/jina/commit/d3048f85734cb886483acfe199ebba9b29588ae5)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n  - [[```30b52b61```](https://github.com/jina-ai/jina/commit/30b52b61e1f0a8f2d4691cf77b23530541af4159)] __-__ __version__: the next version will be 3.2.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-2></a>\n+## Release Note (`3.2.2`)\n+\n+> Release time: 2022-03-16 11:07:23\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```efff1549```](https://github.com/jina-ai/jina/commit/efff15494d3a955b2211dcd2abcd8659c0d006c0)] __-__ rename switch feature (#4494) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```88d60e95```](https://github.com/jina-ai/jina/commit/88d60e95b3e1212cd6f74c59c33cc60745c1694c)] __-__ __version__: the next version will be 3.2.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.2'\n+__version__ = '3.2.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.3"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -304,7 +304,7 @@ ac_table = {\n             '--disable-reduce',\n             '--uses-before',\n             '--uses-after',\n-            '--input-condition',\n+            '--when',\n             '--external',\n             '--deployment-role',\n         ],\n\n---\n file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -485,14 +485,15 @@ The automated merging can be disabled by setting `disable_reduce=True`. This can\n (flow-filter)=\n ### Add filter conditions to Executors\n \n-Starting from `Jina 3.2`, you can filter the input to each\n+Starting from `Jina 3.2.2`, you can filter the input to each\n Executor.\n \n To define a filter condition, you can use [DocArrays rich query language](https://docarray.jina.ai/fundamentals/documentarray/find/#query-by-conditions).\n You can set a filter for each individual Executor, and every Document that does not satisfy the filter condition will be\n removed before reaching that Executor.\n \n-To add a filter condition to an Executor, you pass it to the `input_condition` parameter of `flow.add()`:\n+To add a filter condition to an Executor, you pass it to the `when` parameter of `flow.add()`.\n+This then defines *when* a document will be processed by the Executor:\n \n ````{tab} Python\n \n@@ -503,7 +504,7 @@ emphasize-lines: 4, 9\n from docarray import DocumentArray, Document\n from jina import Flow\n \n-f = Flow().add().add(input_condition={'tags__key': {'$eq': 5}})  # Create the empty Flow, add condition\n+f = Flow().add().add(when={'tags__key': {'$eq': 5}})  # Create the empty Flow, add condition\n \n with f:  # Using it as a Context Manager will start the Flow\n     ret = f.post(\n@@ -529,7 +530,7 @@ print(\n jtype: Flow\n executors:\n   - name: executor\n-    input_condition:\n+    when:\n         tags__key:\n             $eq: 5\n ```\n@@ -559,7 +560,7 @@ print(\n ```\n ````\n \n-Note that whenever a Document does not satisfy the `input_condition` of a filter, the filter removes it *for the entire branch of the Flow*.\n+Note that whenever a Document does not satisfy the `when` condition of a filter, the filter removes it *for the entire branch of the Flow*.\n This means that every Executor that is located behind a filter is affected by this, not just the specific Executor that defines the condition.\n Like with a real-life filter, once something does not pass through it, it will not re-appear behind the filter.\n \n@@ -578,8 +579,8 @@ from jina import Flow\n f = (\n     Flow()\n     .add(name='first')\n-    .add(input_condition={'tags__key': {'$eq': 5}}, needs='first', name='exec1')\n-    .add(input_condition={'tags__key': {'$eq': 4}}, needs='first', name='exec2')\n+    .add(when={'tags__key': {'$eq': 5}}, needs='first', name='exec1')\n+    .add(when={'tags__key': {'$eq': 4}}, needs='first', name='exec2')\n     .needs_all(name='join')\n )  # Create Flow with parallel Executors\n \n@@ -615,8 +616,8 @@ from jina import Flow\n f = (\n     Flow()\n     .add(name='first')\n-    .add(input_condition={'tags__key': {'$eq': 5}}, name='exec1', needs='first')\n-    .add(input_condition={'tags__key': {'$eq': 4}}, needs='exec1', name='exec2)\n+    .add(when={'tags__key': {'$eq': 5}}, name='exec1', needs='first')\n+    .add(when={'tags__key': {'$eq': 4}}, needs='exec1', name='exec2)\n )  # Create Flow with sequential Executors\n \n # Flow topology: Gateway --> first --> exec1 --> exec2 --> Gateway\n\n---\n file path A: docs/how-to/flow-switch.md | file path B: docs/how-to/flow-switch.md\n\n@@ -3,7 +3,7 @@\n \n ````{admonition} Requirements\n :class: note\n-To follow along with this How-To, you need Jina 3.2 or higher.\n+To follow along with this How-To, you need Jina 3.2.2 or higher.\n ````\n \n In this tutorial you will gain a deeper insight into the Flow's {ref}`filter condition feature<flow-filter>`.\n@@ -138,15 +138,15 @@ To solve that problem, you can leverage filter condition to easily build a switc\n In a Jina Flow, you can use the [DocArray query language](https://docarray.jina.ai/fundamentals/documentarray/find/#query-by-conditions) to specify a filter condition for every\n Executor.\n \n-To do this, you pass a condition to the `input_condition` parameter in `flow.add()`:\n+To do this, you pass a condition to the `when` parameter in `flow.add()`:\n \n ```python\n from jina import Flow\n \n-f = Flow().add(input_condition={'tags__key': {'$eq': 5}})\n+f = Flow().add(when={'tags__key': {'$eq': 5}})\n ```\n \n-Then, Documents that do not satisfy the `input_condition` will not reach the associated Executor.\n+Then, Documents that do not satisfy the `when` condition will not reach the associated Executor.\n \n In the use case where you are trying to separate Documents according to the data modality they hold, you need to choose\n a condition accordingly.\n@@ -212,13 +212,13 @@ f = (\n         name='ImageIndexer',\n         uses=ImageIndexer,\n         needs='start_exec',\n-        input_condition={'tensor': {'$exists': True}},\n+        when={'tensor': {'$exists': True}},\n     )\n     .add(\n         name='TextIndexer',\n         uses=TextIndexer,\n         needs='start_exec',\n-        input_condition={'text': {'$exists': True}},\n+        when={'text': {'$exists': True}},\n     )\n     .needs_all()\n )\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -521,8 +521,8 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n     def _get_graph_conditions(self) -> Dict[str, Dict]:\n         graph_condition = {}\n         for node, v in self._deployment_nodes.items():\n-            if v.args.input_condition is not None:\n-                graph_condition[node] = v.args.input_condition\n+            if v.args.when is not None:  # condition on input docs\n+                graph_condition[node] = v.args.when\n \n         return graph_condition\n \n@@ -608,7 +608,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         gpus: Optional[str] = None,\n         host: Optional[str] = '0.0.0.0',\n         host_in: Optional[str] = '0.0.0.0',\n-        input_condition: Optional[dict] = None,\n         install_requirements: Optional[bool] = False,\n         log_config: Optional[str] = None,\n         name: Optional[str] = None,\n@@ -638,6 +637,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         uses_requests: Optional[dict] = None,\n         uses_with: Optional[dict] = None,\n         volumes: Optional[List[str]] = None,\n+        when: Optional[dict] = None,\n         workspace: Optional[str] = None,\n         **kwargs,\n     ) -> Union['Flow', 'AsyncFlow']:\n@@ -663,7 +663,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n               - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display\n         :param host: The host address of the runtime, by default it is 0.0.0.0.\n         :param host_in: The host address for binding to, by default it is 0.0.0.0\n-        :param input_condition: The condition that the documents need to fulfill before reaching the Executor.The condition can be defined in the form of a `DocArray query condition <https://docarray.jina.ai/fundamentals/documentarray/find/#query-by-conditions>`\n         :param install_requirements: If set, install `requirements.txt` in the Hub Executor bundle to local\n         :param log_config: The YAML config of the logger used in this object.\n         :param name: The name of this object.\n@@ -739,6 +738,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n           - If separated by `:`, then the first part will be considered as the local host path and the second part is the path in the container system.\n           - If no split provided, then the basename of that directory will be mounted into container's root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into `/my-workspace` inside the container.\n           - All volumes are mounted with read-write mode.\n+        :param when: The condition that the documents need to fulfill before reaching the Executor.The condition can be defined in the form of a `DocArray query condition <https://docarray.jina.ai/fundamentals/documentarray/find/#query-by-conditions>`\n         :param workspace: The working directory for any IO operations in this object. If not set, then derive from its parent `workspace`.\n         :return: a (new) Flow object with modification\n \n\n---\n file path A: jina/parsers/orchestrate/deployment.py | file path B: jina/parsers/orchestrate/deployment.py\n\n@@ -26,7 +26,7 @@ def mixin_base_deployment_parser(parser):\n     )\n \n     gp.add_argument(\n-        '--input-condition',\n+        '--when',\n         action=KVAppendAction,\n         metavar='KEY: VALUE',\n         nargs='*',\n\n---\n file path A: tests/integration/conditions_feature/flow.yml | file path B: tests/integration/conditions_feature/flow.yml\n\n@@ -8,7 +8,7 @@ executors:\n   workspace: ${{ ENV.TEMP_WORKSPACE }}\n   uses_metas:\n     name: exec1\n-  input_condition:\n+  when:\n     tags__type:\n       $eq : 1\n - name: exec2\n@@ -18,7 +18,7 @@ executors:\n   workspace: ${{ ENV.TEMP_WORKSPACE }}\n   uses_metas:\n     name: exec2\n-  input_condition:\n+  when:\n     tags__type:\n       $gt: 1\n - name: joiner\n\n---\n file path A: tests/integration/conditions_feature/test_condition_behavior.py | file path B: tests/integration/conditions_feature/test_condition_behavior.py\n\n@@ -37,7 +37,7 @@ def shuffle_flow(request, temp_workspace):\n             workspace=os.environ['TEMP_WORKSPACE'],\n             name='exec1',\n             needs=['first'],\n-            input_condition={\n+            when={\n                 '$or': {\n                     'tags__third': {'$eq': 1},\n                     'tags__first': {'$eq': 1},\n@@ -51,9 +51,7 @@ def shuffle_flow(request, temp_workspace):\n             name='exec2',\n             workspace=os.environ['TEMP_WORKSPACE'],\n             needs='first',\n-            input_condition={\n-                '$or': {'tags__second': {'$eq': 1}, 'tags__fifth': {'$eq': 1}}\n-            },\n+            when={'$or': {'tags__second': {'$eq': 1}, 'tags__fifth': {'$eq': 1}}},\n         )\n         .needs_all('joiner')\n     )\n@@ -73,7 +71,7 @@ def flow(request, temp_workspace):\n                 workspace=os.environ['TEMP_WORKSPACE'],\n                 name='exec1',\n                 needs=['first'],\n-                input_condition={'tags__type': {'$eq': 1}},\n+                when={'tags__type': {'$eq': 1}},\n             )\n             .add(\n                 uses=ConditionDumpExecutor,\n@@ -81,7 +79,7 @@ def flow(request, temp_workspace):\n                 uses_metas={'name': 'exec2'},\n                 name='exec2',\n                 needs='first',\n-                input_condition={'tags__type': {'$gt': 1}},\n+                when={'tags__type': {'$gt': 1}},\n             )\n             .needs_all('joiner')\n         )\n@@ -139,7 +137,7 @@ def test_conditions_filtering_on_joiner(tmpdir):\n             name='joiner_test_exec2',\n             needs='first',\n         )\n-        .needs_all('joiner', input_condition={'tags__type': {'$eq': 3}})\n+        .needs_all('joiner', when={'tags__type': {'$eq': 3}})\n     )\n     with flow:\n         ret = flow.post(\n@@ -195,7 +193,7 @@ def test_chained_conditions(tmpdir, temp_workspace):\n             workspace=os.environ['TEMP_WORKSPACE'],\n             name='exec1',\n             needs=['first'],\n-            input_condition={'tags__type': {'$gte': 2}},\n+            when={'tags__type': {'$gte': 2}},\n         )\n         .add(\n             uses=ConditionDumpExecutor,\n@@ -203,7 +201,7 @@ def test_chained_conditions(tmpdir, temp_workspace):\n             uses_metas={'name': 'exec2'},\n             name='exec2',\n             needs='exec1',\n-            input_condition={'tags__type': {'$lte': 1}},\n+            when={'tags__type': {'$lte': 1}},\n         )\n         .needs_all('joiner')\n     )\n\n\n###\n\n", "completion": "refactor: rename switch feature (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -142,6 +142,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12546,3 +12547,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```aabdfeda```](https://github.com/jina-ai/jina/commit/aabdfeda7e784ee89a93d972f2d2527a5e473619)] __-__ bump version number (*Joan Fontanals Martinez*)\n  - [[```c6781e4a```](https://github.com/jina-ai/jina/commit/c6781e4a6e20fb078e5b70e636114120cfda797b)] __-__ __version__: the next version will be 3.1.7 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-1></a>\n+## Release Note (`3.2.1`)\n+\n+> Release time: 2022-03-16 10:01:27\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```0df57198```](https://github.com/jina-ai/jina/commit/0df57198ac7b406bd513db22f58da0c9ea0389eb)] __-__ fix asyncclient return (#4491) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```d2acd11f```](https://github.com/jina-ai/jina/commit/d2acd11f0894c6621b26a0c4fb7679588eee40ae)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d3048f85```](https://github.com/jina-ai/jina/commit/d3048f85734cb886483acfe199ebba9b29588ae5)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```30b52b61```](https://github.com/jina-ai/jina/commit/30b52b61e1f0a8f2d4691cf77b23530541af4159)] __-__ __version__: the next version will be 3.2.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.1'\n+__version__ = '3.2.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.2"}
{"prompt": " file path A: jina/clients/mixin.py | file path B: jina/clients/mixin.py\n\n@@ -182,7 +182,7 @@ class AsyncPostMixin:\n         show_progress: bool = False,\n         continue_on_error: bool = False,\n         **kwargs,\n-    ) -> AsyncGenerator[None, 'Response']:\n+    ) -> AsyncGenerator[None, Union['DocumentArray', 'Response']]:\n         \"\"\"Async Post a general data request to the Flow.\n \n         :param inputs: input data which can be an Iterable, a function which returns an Iterable, or a single Document.\n@@ -208,7 +208,7 @@ class AsyncPostMixin:\n         parameters = _include_results_field_in_param(parameters)\n         on_error = _wrap_on_error(on_error) if on_error is not None else on_error\n \n-        async for r in c._get_results(\n+        async for result in c._get_results(\n             inputs=inputs,\n             on_done=on_done,\n             on_error=on_error,\n@@ -219,7 +219,10 @@ class AsyncPostMixin:\n             request_size=request_size,\n             **kwargs,\n         ):\n-            yield r\n+            if not c.args.return_responses:\n+                yield result.data.docs\n+            else:\n+                yield result\n \n     # ONLY CRUD, for other request please use `.post`\n     index = partialmethod(post, '/index')\n\n---\n file path A: tests/unit/orchestrate/flow/flow-async/test_asyncflow.py | file path B: tests/unit/orchestrate/flow/flow-async/test_asyncflow.py\n\n@@ -3,12 +3,13 @@ import time\n \n import numpy as np\n import pytest\n+from docarray.document.generators import from_ndarray\n \n-from jina import Document, Flow, Executor, requests\n-from jina.orchestrate.flow.asyncio import AsyncFlow\n+from docarray import Document, DocumentArray\n+from jina import Executor, Flow, requests\n from jina.logging.profile import TimeContext\n-from docarray.document.generators import from_ndarray\n-from jina.types.request.data import Response\n+from jina.orchestrate.flow.asyncio import AsyncFlow\n+from jina.types.request.data import Request\n from tests import validate_callback\n \n num_docs = 5\n@@ -36,13 +37,20 @@ def documents(start_index, end_index):\n @pytest.mark.asyncio\n @pytest.mark.parametrize('protocol', ['websocket', 'grpc', 'http'])\n @pytest.mark.parametrize('flow_cls', [Flow, AsyncFlow])\n-async def test_run_async_flow(protocol, mocker, flow_cls):\n+@pytest.mark.parametrize(\n+    'return_responses, return_class', [(True, Request), (False, DocumentArray)]\n+)\n+async def test_run_async_flow(\n+    protocol, mocker, flow_cls, return_responses, return_class\n+):\n     r_val = mocker.Mock()\n-    with flow_cls(protocol=protocol, asyncio=True).add() as f:\n+    with flow_cls(\n+        protocol=protocol, asyncio=True, return_responses=return_responses\n+    ).add() as f:\n         async for r in f.index(\n             from_ndarray(np.random.random([num_docs, 4])), on_done=r_val\n         ):\n-            assert isinstance(r.response, Response)\n+            assert isinstance(r, return_class)\n     validate_callback(r_val, validate)\n \n \n@@ -73,7 +81,7 @@ async def test_run_async_flow_async_input(inputs, mocker):\n     r_val = mocker.Mock()\n     with AsyncFlow(asyncio=True).add() as f:\n         async for r in f.index(inputs, on_done=r_val):\n-            assert isinstance(r.response, Response)\n+            assert isinstance(r, DocumentArray)\n     validate_callback(r_val, validate)\n \n \n@@ -91,7 +99,7 @@ async def run_async_flow_5s(protocol):\n             from_ndarray(np.random.random([num_docs, 4])),\n             on_done=validate,\n         ):\n-            assert isinstance(r.response, Response)\n+            assert isinstance(r, DocumentArray)\n \n \n async def sleep_print():\n@@ -140,7 +148,7 @@ async def test_run_async_flow_other_task_concurrent(protocol):\n async def test_return_results_async_flow(protocol, flow_cls):\n     with flow_cls(protocol=protocol, asyncio=True).add() as f:\n         async for r in f.index(from_ndarray(np.random.random([10, 2]))):\n-            assert isinstance(r.response, Response)\n+            assert isinstance(r, DocumentArray)\n \n \n @pytest.mark.slow\n@@ -151,7 +159,7 @@ async def test_return_results_async_flow(protocol, flow_cls):\n async def test_return_results_async_flow_crud(protocol, flow_api, flow_cls):\n     with flow_cls(protocol=protocol, asyncio=True).add() as f:\n         async for r in getattr(f, flow_api)(documents(0, 10)):\n-            assert isinstance(r.response, Response)\n+            assert isinstance(r, DocumentArray)\n \n \n class MyExec(Executor):\n@@ -165,4 +173,4 @@ class MyExec(Executor):\n async def test_async_flow_empty_data(flow_cls):\n     with flow_cls(asyncio=True).add(uses=MyExec) as f:\n         async for r in f.post('/hello', parameters={'hello': 'world'}):\n-            assert isinstance(r.response, Response)\n+            assert isinstance(r, DocumentArray)\n\n\n###\n\n", "completion": "fix: fix asyncclient return (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -141,6 +141,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12521,3 +12522,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```622c362d```](https://github.com/jina-ai/jina/commit/622c362d094986ab451d72f3dbb72d1951117b37)] __-__ add learning bootcamp call to action (#4485) (*Shubham Saboo*)\n  - [[```084ab6c5```](https://github.com/jina-ai/jina/commit/084ab6c532f2252d27c6c420b73541db9cfd1218)] __-__ __version__: the next version will be 3.1.6 (*Jina Dev Bot*)\n \n+<a name=release-note-3-2-0></a>\n+## Release Note (`3.2.0`)\n+\n+> Release time: 2022-03-15 17:12:36\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Joan Fontanals Martinez,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```a27ea8a4```](https://github.com/jina-ai/jina/commit/a27ea8a46e96ecc96ab1e41f79aa0825341511c9)] __-__ input filters for executors (#4472) (*Johannes Messner*)\n+ - [[```ceb51082```](https://github.com/jina-ai/jina/commit/ceb51082b4ec6f31811945ffc67b734acbbebac2)] __-__ convert embedding/tensor array type at executor level (#4484) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```aabdfeda```](https://github.com/jina-ai/jina/commit/aabdfeda7e784ee89a93d972f2d2527a5e473619)] __-__ bump version number (*Joan Fontanals Martinez*)\n+ - [[```c6781e4a```](https://github.com/jina-ai/jina/commit/c6781e4a6e20fb078e5b70e636114120cfda797b)] __-__ __version__: the next version will be 3.1.7 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.2.0'\n+__version__ = '3.2.1'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.2.1"}
{"prompt": " file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -14,8 +14,8 @@ import signal as _signal\n import sys as _sys\n import types as _types\n import warnings as _warnings\n-import docarray as _docarray\n \n+import docarray as _docarray\n \n if _sys.version_info < (3, 7, 0):\n     raise OSError(f'Jina requires Python >= 3.7, but yours is {_sys.version_info}')\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.1.7'\n+__version__ = '3.2.0'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n@@ -188,19 +188,19 @@ _set_nofile()\n \n # ONLY FIRST CLASS CITIZENS ARE ALLOWED HERE, namely Document, Executor Flow\n \n+# Document\n+from docarray import Document, DocumentArray\n+\n # Client\n from jina.clients import Client\n+from jina.orchestrate.flow.asyncio import AsyncFlow\n \n-# Document\n-from docarray import Document, DocumentArray\n+# Flow\n+from jina.orchestrate.flow.base import Flow\n \n # Executor\n from jina.serve.executors import BaseExecutor as Executor\n from jina.serve.executors.decorators import requests\n \n-# Flow\n-from jina.orchestrate.flow.base import Flow\n-from jina.orchestrate.flow.asyncio import AsyncFlow\n-\n __all__ = [_s for _s in dir() if not _s.startswith('_')]\n __all__.extend(_names_with_underscore)\n\n\n###\n\n", "completion": "chore: bump version number"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -68,6 +68,7 @@ ac_table = {\n             '--port-in',\n             '--host-in',\n             '--native',\n+            '--output-array-type',\n             '--entrypoint',\n             '--docker-kwargs',\n             '--pull-latest',\n@@ -137,6 +138,7 @@ ac_table = {\n             '--port-in',\n             '--host-in',\n             '--native',\n+            '--output-array-type',\n             '--prefetch',\n             '--title',\n             '--description',\n@@ -221,6 +223,7 @@ ac_table = {\n             '--port-in',\n             '--host-in',\n             '--native',\n+            '--output-array-type',\n             '--entrypoint',\n             '--docker-kwargs',\n             '--pull-latest',\n@@ -270,6 +273,7 @@ ac_table = {\n             '--port-in',\n             '--host-in',\n             '--native',\n+            '--output-array-type',\n             '--entrypoint',\n             '--docker-kwargs',\n             '--pull-latest',\n\n---\n file path A: docs/fundamentals/flow/create-flow.md | file path B: docs/fundamentals/flow/create-flow.md\n\n@@ -386,6 +386,32 @@ bar\n foo\n ```\n \n+### Convert array types between Executors\n+\n+Different Executors in a Flow may depend on slightly different `types` for array-like data such as `doc.tensor` and `doc.embedding`,\n+for example because they were written using different machine learning frameworks.\n+As the builder of a Flow you don't always have control over this, for example when using Executors from the Jina Hub.\n+\n+In order to facilitate the integration between different Executors, the Flow allows you to convert `tensor` and `embedding`\n+by using the `f.add(..., output_array_type=..)`:\n+\n+```python\n+from jina import Flow\n+\n+f = Flow().add(uses=MyExecutor, output_array_type='numpy').add(uses=NeedsNumpyExecutor)\n+```\n+\n+This converts the `.tensor` and `.embedding` fields of all output Documents of `MyExecutor` to `numpy.ndarray`, making the data\n+usable by `NeedsNumpyExecutor`. This works regardless of whether MyExecutor populates these fields with arrays/tensors from\n+PyTorch, TensorFlow, or any other popular ML framework.\n+\n+````{admonition} Output types\n+:class: note\n+\n+`output_array_type=` supports more types than `'numpy'`. For a full specification, and further details, take a look at the\n+documentation about [protobuf serialization](https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf).\n+````\n+\n ### External executors\n Usually a `Flow` will manage all of its Executors. \n In some cases it is desirable though to use externally managed Executors. These are named `external Executors`. This is especially useful to share expensive Executors between Flows. Often these Executors are stateless, GPU based Encoders.\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -146,6 +146,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         native: Optional[bool] = False,\n         no_crud_endpoints: Optional[bool] = False,\n         no_debug_endpoints: Optional[bool] = False,\n+        output_array_type: Optional[str] = None,\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n         prefetch: Optional[int] = 0,\n@@ -200,6 +201,11 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n                   Any executor that has `@requests(on=...)` bind with those values will receive data requests.\n         :param no_debug_endpoints: If set, /status /post endpoints are removed from HTTP interface.\n+        :param output_array_type: The type of array `tensor` and `embedding` will be serialized to.\n+\n+          Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which can be found\n+          `here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n+          Defaults to retaining whatever type is returned by the Executor.\n         :param polling: The polling strategy of the Deployment and its endpoints (when `shards>1`).\n               Can be defined for all endpoints of a Deployment or by endpoint.\n               Define per Deployment:\n@@ -594,6 +600,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         log_config: Optional[str] = None,\n         name: Optional[str] = None,\n         native: Optional[bool] = False,\n+        output_array_type: Optional[str] = None,\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n         port_jinad: Optional[int] = 8000,\n@@ -655,6 +662,11 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n           When not given, then the default naming strategy will apply.\n         :param native: If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime.\n+        :param output_array_type: The type of array `tensor` and `embedding` will be serialized to.\n+\n+          Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which can be found\n+          `here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n+          Defaults to retaining whatever type is returned by the Executor.\n         :param polling: The polling strategy of the Deployment and its endpoints (when `shards>1`).\n               Can be defined for all endpoints of a Deployment or by endpoint.\n               Define per Deployment:\n\n---\n file path A: jina/parsers/orchestrate/runtimes/worker.py | file path B: jina/parsers/orchestrate/runtimes/worker.py\n\n@@ -1,9 +1,8 @@\n \"\"\"Argparser module for WorkerRuntime\"\"\"\n import argparse\n \n-from jina.parsers.helper import add_arg_group, _SHOW_ALL_ARGS, KVAppendAction\n-from jina import __default_host__\n-from jina import helper\n+from jina import __default_host__, helper\n+from jina.parsers.helper import _SHOW_ALL_ARGS, KVAppendAction, add_arg_group\n \n \n def mixin_worker_runtime_parser(parser):\n@@ -93,3 +92,16 @@ which should be structured as a python package. For more details, please see the\n         default=False,\n         help='If set, only native Executors is allowed, and the Executor is always run inside WorkerRuntime.',\n     )\n+\n+    gp.add_argument(\n+        '--output-array-type',\n+        type=str,\n+        default=None,\n+        help='''\n+The type of array `tensor` and `embedding` will be serialized to.\n+\n+Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which can be found \n+`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n+Defaults to retaining whatever type is returned by the Executor.\n+''',\n+    )\n\n---\n file path A: jina/serve/runtimes/request_handlers/data_request_handler.py | file path B: jina/serve/runtimes/request_handlers/data_request_handler.py\n\n@@ -1,14 +1,15 @@\n-from typing import Dict, List, TYPE_CHECKING, Optional\n+from typing import TYPE_CHECKING, Dict, List, Optional\n \n from docarray import DocumentArray\n \n from jina import __default_endpoint__\n-from jina.excepts import ExecutorFailToLoad, BadConfigSource\n+from jina.excepts import BadConfigSource, ExecutorFailToLoad\n from jina.serve.executors import BaseExecutor\n from jina.types.request.data import DataRequest\n \n if TYPE_CHECKING:\n     import argparse\n+\n     from jina.logging.logger import JinaLogger\n \n \n@@ -120,18 +121,21 @@ class DataRequestHandler:\n                     f'but getting {return_data!r}'\n                 )\n \n-        DataRequestHandler.replace_docs(requests[0], docs)\n+        DataRequestHandler.replace_docs(requests[0], docs, self.args.output_array_type)\n \n         return requests[0]\n \n     @staticmethod\n-    def replace_docs(request: List['DataRequest'], docs: 'DocumentArray') -> None:\n+    def replace_docs(\n+        request: List['DataRequest'], docs: 'DocumentArray', ndarrray_type: str = None\n+    ) -> None:\n         \"\"\"Replaces the docs in a message with new Documents.\n \n         :param request: The request object\n         :param docs: the new docs to be used\n+        :param ndarrray_type: type tensor and embedding will be converted to\n         \"\"\"\n-        request.data.docs = docs\n+        request.data.set_docs_convert_arrays(docs, ndarray_type=ndarrray_type)\n \n     @staticmethod\n     def replace_parameters(request: List['DataRequest'], parameters: Dict) -> None:\n\n---\n file path A: jina/types/request/data.py | file path B: jina/types/request/data.py\n\n@@ -1,14 +1,13 @@\n import copy\n-from typing import Optional, Dict, TypeVar\n-\n-from google.protobuf import json_format\n+from typing import Dict, Optional, TypeVar\n \n from docarray import DocumentArray\n+from google.protobuf import json_format\n \n-from jina.types.request import Request\n from jina.excepts import BadRequestType\n-from jina.helper import typename, random_identity, cached_property\n+from jina.helper import cached_property, random_identity, typename\n from jina.proto import jina_pb2\n+from jina.types.request import Request\n \n RequestSourceType = TypeVar(\n     'RequestSourceType', jina_pb2.DataRequestProto, str, Dict, bytes\n@@ -42,13 +41,25 @@ class DataRequest(Request):\n \n         @docs.setter\n         def docs(self, value: DocumentArray):\n-            \"\"\"Overide the DocumentArray with the provided one\n+            \"\"\"Override the DocumentArray with the provided one\n+\n+            :param value: a DocumentArray\n+            \"\"\"\n+            self.set_docs_convert_arrays(value, None)\n+\n+        def set_docs_convert_arrays(\n+            self, value: DocumentArray, ndarray_type: Optional[str] = None\n+        ):\n+            \"\"\" \" Convert embedding and tensor to given type, then set DocumentArray\n \n             :param value: a DocumentArray\n+            :param ndarray_type: type embedding and tensor will be converted to\n             \"\"\"\n             if value is not None:\n                 self._loaded_doc_array = None\n-                self._content.docs.CopyFrom(value.to_protobuf())\n+                self._content.docs.CopyFrom(\n+                    value.to_protobuf(ndarray_type=ndarray_type)\n+                )\n \n         @property\n         def docs_bytes(self) -> bytes:\n@@ -59,7 +70,7 @@ class DataRequest(Request):\n \n         @docs_bytes.setter\n         def docs_bytes(self, value: bytes):\n-            \"\"\"Overide the DocumentArray with the provided one\n+            \"\"\"Override the DocumentArray with the provided one\n \n             :param value: a DocumentArray\n             \"\"\"\n\n---\n file path A: None | file path B: tests/unit/orchestrate/flow/flow-orchestrate/test_ndarray_type.py\n\n@@ -0,0 +1,78 @@\n+import numpy as np\n+import pytest\n+import torch\n+from docarray import Document, DocumentArray\n+\n+from jina import Executor, Flow, requests\n+\n+\n+class MyExec(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        pass\n+\n+\n+class ListInExec(Executor):\n+    @requests\n+    def check_list(self, docs, **kwargs):\n+        embedding_is_list = True\n+        tensor_is_list = True\n+        for doc in docs:\n+            embedding_is_list = embedding_is_list and isinstance(doc.embedding, list)\n+            tensor_is_list = tensor_is_list and isinstance(doc.tensor, list)\n+        for doc in docs:\n+            doc.tags['listcheck_embedding'] = embedding_is_list\n+            doc.tags['listcheck_tensor'] = tensor_is_list\n+\n+\n+class NparrayInEec(Executor):\n+    @requests\n+    def check_nparray(self, docs, **kwargs):\n+        embedding_is_nparray = True\n+        tensor_is_nparray = True\n+        for doc in docs:\n+            embedding_is_nparray = embedding_is_nparray and isinstance(\n+                doc.embedding, np.ndarray\n+            )\n+            tensor_is_nparray = tensor_is_nparray and isinstance(doc.tensor, np.ndarray)\n+        for doc in docs:\n+            doc.tags['nparraycheck_embedding'] = embedding_is_nparray\n+            doc.tags['nparraycheck_tensor'] = tensor_is_nparray\n+\n+\n+@pytest.fixture()\n+def linear_flow():\n+    f = (\n+        Flow()\n+        .add(uses=MyExec, output_array_type='numpy')\n+        .add(uses=NparrayInEec, output_array_type='list')\n+        .add(uses=ListInExec)\n+    )\n+    return f\n+\n+\n+def test_array_conversion(linear_flow):\n+    docs = DocumentArray.empty(5)\n+    for doc in docs:\n+        doc.embedding = torch.tensor(np.random.randn(5))\n+        doc.tensor = torch.tensor(np.random.randn(3, 3))\n+\n+    with linear_flow as f:\n+        resp = f.post(on='/foo', inputs=docs)\n+    for doc in resp:\n+        assert doc.tags['nparraycheck_embedding']\n+        assert doc.tags['nparraycheck_tensor']\n+        assert doc.tags['listcheck_embedding']\n+        assert doc.tags['listcheck_tensor']\n+\n+\n+def test_empty_arrays(linear_flow):\n+    docs = DocumentArray.empty(5)\n+\n+    with linear_flow as f:\n+        resp = f.post(on='/foo', inputs=docs)\n+    for doc in resp:\n+        assert not doc.tags['listcheck_embedding']\n+        assert not doc.tags['listcheck_tensor']\n+        assert not doc.tags['nparraycheck_embedding']\n+        assert not doc.tags['nparraycheck_tensor']\n\n\n###\n\n", "completion": "feat: convert embedding/tensor array type at executor level (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -140,6 +140,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12500,3 +12501,23 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```4e6d278a```](https://github.com/jina-ai/jina/commit/4e6d278af3c6272780ccf3aecbc955cbf9701a51)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n  - [[```19e470ae```](https://github.com/jina-ai/jina/commit/19e470ae3660270d401461bd3159f0f58cf6341d)] __-__ __version__: the next version will be 3.1.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-1-6></a>\n+## Release Note (`3.1.6`)\n+\n+> Release time: 2022-03-15 15:00:32\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Shubham Saboo,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```59e7bb51```](https://github.com/jina-ai/jina/commit/59e7bb51d7a49a32da53dfa06847b58ace75b818)] __-__ health check docker (#4467) (*samsja*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```622c362d```](https://github.com/jina-ai/jina/commit/622c362d094986ab451d72f3dbb72d1951117b37)] __-__ add learning bootcamp call to action (#4485) (*Shubham Saboo*)\n+ - [[```084ab6c5```](https://github.com/jina-ai/jina/commit/084ab6c532f2252d27c6c420b73541db9cfd1218)] __-__ __version__: the next version will be 3.1.6 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.1.6'\n+__version__ = '3.1.7'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.1.7"}
{"prompt": " file path A: docs/how-to/docker-compose.md | file path B: docs/how-to/docker-compose.md\n\n@@ -25,6 +25,11 @@ Jina will generate a `docker-compose.yml` configuration file that you can use di\n All Executors in the Flow should be used with `jinahub+docker://...` or `docker://...`.\n ```\n \n+```{caution}\n+If you are using Executor which rely on docker image built with a jina version prior to 3.1.3, please remove the \n+health check from the dump yaml file as they are only compatible with 3.1.3+ otherwise your docker compose services will \n+always be `unhealthy\n+```\n ## Example: Indexing and searching images using CLIP image encoder and PQLiteIndexer\n \n \n\n---\n file path A: jina/orchestrate/deployments/config/docker_compose.py | file path B: jina/orchestrate/deployments/config/docker_compose.py\n\n@@ -1,18 +1,18 @@\n import copy\n from argparse import Namespace\n-from typing import Dict, Union, List, Optional, Tuple\n+from typing import Dict, List, Optional, Tuple, Union\n \n from jina import __default_executor__\n-from jina.excepts import NoContainerizedError\n from jina.enums import PodRoleType\n+from jina.excepts import NoContainerizedError\n+from jina.orchestrate.deployments import BaseDeployment\n from jina.orchestrate.deployments.config.helper import (\n+    construct_runtime_container_args,\n+    get_base_executor_version,\n     get_image_name,\n     to_compatible_name,\n-    get_base_executor_version,\n-    construct_runtime_container_args,\n     validate_uses,\n )\n-from jina.orchestrate.deployments import BaseDeployment\n \n port = 8081\n \n@@ -79,6 +79,9 @@ class DockerComposeConfig:\n             )\n             _args = ArgNamespace.kwargs2list(non_defaults)\n             container_args = ['gateway'] + _args\n+\n+            protocol = str(non_defaults.get('protocol', 'grpc')).lower()\n+\n             return {\n                 'image': image_name,\n                 'entrypoint': ['jina'],\n@@ -89,6 +92,10 @@ class DockerComposeConfig:\n                 'ports': [\n                     f'{cargs.port}:{cargs.port}',\n                 ],\n+                'healthcheck': {\n+                    'test': f'python -m jina.resources.health_check.gateway localhost:{cargs.port} {protocol}',\n+                    'interval': '2s',\n+                },\n             }\n \n         def _get_image_name(self, uses: Optional[str]):\n@@ -135,6 +142,10 @@ class DockerComposeConfig:\n                     'image': image_name,\n                     'entrypoint': ['jina'],\n                     'command': container_args,\n+                    'healthcheck': {\n+                        'test': f'python -m jina.resources.health_check.pod localhost:{cargs.port}',\n+                        'interval': '2s',\n+                    },\n                 }\n                 if env is not None:\n                     config['environment'] = [f'{k}={v}' for k, v in env.items()]\n\n---\n file path A: jina/resources/health_check/__init__.py | file path B: jina/resources/health_check/__init__.py\n\n\n---\n file path A: None | file path B: jina/resources/health_check/gateway.py\n\n@@ -0,0 +1,59 @@\n+from jina.resources.health_check.pod import check_health_pod\n+\n+\n+def check_health_http(addr):\n+    import requests\n+\n+    try:\n+        resp = requests.get(f'http://{addr}/')\n+        if not resp.status_code == 200:\n+            raise RuntimeError(\n+                f'The http gateway is unhealthy http status : {resp.status_code}'\n+            )\n+    except requests.exceptions.RequestException as e:\n+        print('The http gateway is unhealthy')\n+        raise e\n+\n+    print('The http gateway is healthy')\n+\n+\n+async def check_health_websocket(addr):\n+    import websockets\n+\n+    try:\n+        async with websockets.connect(f'ws://{addr}') as websocket:\n+            pass\n+    except websockets.exceptions.WebSocketException as e:\n+        print('The websocket gateway is unhealthy')\n+        raise e\n+\n+    print('The websocket gateway is healthy')\n+\n+\n+if __name__ == '__main__':\n+    \"\"\"\n+    Health check cli (for docker):\n+\n+    Example:\n+        python jina.resources.health_check.pod localhost:1234 http\n+    \"\"\"\n+    import sys\n+\n+    if len(sys.argv) < 3:\n+        raise ValueError(\n+            'You need to specify a address to check health and at protocol'\n+        )\n+\n+    addr = sys.argv[1]\n+    protocol = sys.argv[2]\n+\n+    if protocol == 'grpc':\n+        check_health_pod(addr)\n+    elif protocol == 'http':\n+        check_health_http(addr)\n+    elif protocol == 'websocket':\n+        import asyncio\n+\n+        asyncio.run(check_health_websocket(addr))\n+    else:\n+        raise ValueError(f'{protocol} should be in [\"grpc\",\"http\",\"websocket\"]')\n\n---\n file path A: None | file path B: jina/resources/health_check/pod.py\n\n@@ -0,0 +1,37 @@\n+def check_health_pod(addr: str):\n+    \"\"\"check if a pods is healthy\n+\n+    :param addr: the address on which the pod is serving ex : localhost:1234\n+    \"\"\"\n+    import grpc\n+\n+    from jina.serve.networking import GrpcConnectionPool\n+    from jina.types.request.control import ControlRequest\n+\n+    try:\n+        GrpcConnectionPool.send_request_sync(\n+            request=ControlRequest('STATUS'),\n+            target=addr,\n+        )\n+    except grpc.RpcError as e:\n+        print('The pod is unhealthy')\n+        print(e)\n+        raise e\n+\n+    print('The pod is healthy')\n+\n+\n+if __name__ == '__main__':\n+    \"\"\"\n+    Health check cli (for docker):\n+\n+    Example:\n+        python jina.resources.health_check.pod localhost:1234\n+    \"\"\"\n+    import sys\n+\n+    if len(sys.argv) < 2:\n+        raise ValueError('You need to specify a address to check health')\n+\n+    addr = sys.argv[1]\n+    check_health_pod(addr)\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -14,6 +14,7 @@ from jina.helper import (\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n from jina.logging.profile import used_memory_readable\n+from jina.serve.runtimes.gateway.http.models import JinaHealthModel\n \n if TYPE_CHECKING:\n     from jina.serve.networking import GrpcConnectionPool\n@@ -107,6 +108,19 @@ def get_fastapi_app(\n             }\n         )\n \n+        @app.get(\n+            path='/',\n+            summary='Get the health of Jina service',\n+            response_model=JinaHealthModel,\n+        )\n+        async def _health():\n+            \"\"\"\n+            Get the health of this Jina service.\n+            .. # noqa: DAR201\n+\n+            \"\"\"\n+            return {}\n+\n         @app.get(\n             path='/status',\n             summary='Get the status of Jina service',\n\n---\n file path A: jina/serve/runtimes/gateway/http/models.py | file path B: jina/serve/runtimes/gateway/http/models.py\n\n@@ -8,9 +8,9 @@ from typing import Callable, Dict, List, Optional, Union\n from docarray.document.pydantic_model import PydanticDocumentArray\n from google.protobuf.descriptor import Descriptor, FieldDescriptor\n from google.protobuf.pyext.cpp_message import GeneratedProtocolMessageType\n-from jina.proto.jina_pb2 import DataRequestProto, RouteProto, StatusProto\n from pydantic import BaseConfig, BaseModel, Field, create_model, root_validator\n \n+from jina.proto.jina_pb2 import DataRequestProto, RouteProto, StatusProto\n \n PROTO_TO_PYDANTIC_MODELS = SimpleNamespace()\n PROTOBUF_TO_PYTHON_TYPE = {\n@@ -213,6 +213,12 @@ def _to_camel_case(snake_str: str) -> str:\n     return components[0] + ''.join(x.title() for x in components[1:])\n \n \n+class JinaHealthModel(BaseModel):\n+    \"\"\"Pydantic BaseModel for Jina health check, used as the response model in REST app.\"\"\"\n+\n+    ...\n+\n+\n class JinaStatusModel(BaseModel):\n     \"\"\"Pydantic BaseModel for Jina status, used as the response model in REST app.\"\"\"\n \n\n---\n file path A: tests/docker_compose/test_docker_compose.py | file path B: tests/docker_compose/test_docker_compose.py\n\n@@ -1,24 +1,73 @@\n # kind version has to be bumped to v0.11.1 since pytest-kind is just using v0.10.0 which does not work on ubuntu in ci\n-import pytest\n import os\n+import subprocess\n import time\n+from typing import Dict, List\n+\n+import docker\n+import pytest\n \n-from jina import Flow, Document\n+from jina import Document, Flow\n \n \n class DockerComposeFlow:\n-    def __init__(self, dump_path):\n+\n+    healthy_status = 'healthy'\n+    unhealthy_status = 'unhealthy'\n+\n+    def __init__(self, dump_path, timeout_second=30):\n         self.dump_path = dump_path\n+        self.timeout_second = timeout_second\n \n     def __enter__(self):\n-        os.system(\n-            f\"docker-compose -f {self.dump_path} --project-directory . up  --build -d --remove-orphans\"\n+        subprocess.run(\n+            f'docker-compose -f {self.dump_path} up --build -d --remove-orphans'.split(\n+                ' '\n+            )\n         )\n-        time.sleep(10)\n+\n+        container_ids = (\n+            subprocess.run(\n+                f'docker-compose -f {self.dump_path} ps -q'.split(' '),\n+                capture_output=True,\n+            )\n+            .stdout.decode(\"utf-8\")\n+            .split('\\n')\n+        )\n+        container_ids.remove('')  # remove empty  return line\n+\n+        if not container_ids:\n+            raise RuntimeError('docker-compose ps did not detect any launch container')\n+\n+        client = docker.from_env()\n+\n+        init_time = time.time()\n+        healthy = False\n+\n+        while time.time() - init_time < self.timeout_second:\n+            if self._are_all_container_healthy(container_ids, client):\n+                healthy = True\n+                break\n+            time.sleep(0.1)\n+\n+        if not healthy:\n+            raise RuntimeError('Docker containers are not healthy')\n+\n+    @staticmethod\n+    def _are_all_container_healthy(\n+        container_ids: List[str], client: docker.client.DockerClient\n+    ) -> bool:\n+\n+        for id_ in container_ids:\n+            status = client.containers.get(id_).attrs['State']['Health']['Status']\n+\n+            if status != DockerComposeFlow.healthy_status:\n+                return False\n+        return True\n \n     def __exit__(self, exc_type, exc_val, exc_tb):\n-        os.system(\n-            f\"docker-compose -f {self.dump_path} --project-directory . down --remove-orphans\"\n+        subprocess.run(\n+            f'docker-compose -f {self.dump_path} down --remove-orphans'.split(' ')\n         )\n \n \n@@ -50,7 +99,7 @@ async def run_test(flow, endpoint, num_docs=10, request_size=10):\n @pytest.fixture()\n def flow_with_sharding(docker_images, polling):\n     flow = Flow(name='test-flow-with-sharding', port=9090, protocol='http').add(\n-        name='test_executor',\n+        name='test_executor_sharding',\n         shards=2,\n         replicas=2,\n         uses=f'docker://{docker_images[0]}',\n@@ -62,8 +111,8 @@ def flow_with_sharding(docker_images, polling):\n \n @pytest.fixture\n def flow_configmap(docker_images):\n-    flow = Flow(name='k8s-flow-configmap', port=9090, protocol='http').add(\n-        name='test_executor',\n+    flow = Flow(name='k8s-flow-configmap', port=9091, protocol='http').add(\n+        name='test_executor_configmap',\n         uses=f'docker://{docker_images[0]}',\n         env={'k1': 'v1', 'k2': 'v2'},\n     )\n@@ -75,7 +124,7 @@ def flow_with_needs(docker_images):\n     flow = (\n         Flow(\n             name='test-flow-with-needs',\n-            port=9090,\n+            port=9092,\n             protocol='http',\n         )\n         .add(\n@@ -109,7 +158,7 @@ def flow_with_needs(docker_images):\n     indirect=True,\n )\n async def test_flow_with_needs(logger, flow_with_needs, tmpdir, docker_images):\n-    dump_path = os.path.join(str(tmpdir), 'docker-compose.yml')\n+    dump_path = os.path.join(str(tmpdir), 'docker-compose-flow-with-need.yml')\n     flow_with_needs.to_docker_compose_yaml(dump_path, 'default')\n     with DockerComposeFlow(dump_path):\n         resp = await run_test(\n@@ -137,7 +186,7 @@ async def test_flow_with_needs(logger, flow_with_needs, tmpdir, docker_images):\n )\n @pytest.mark.parametrize('polling', ['ANY', 'ALL'])\n async def test_flow_with_sharding(flow_with_sharding, polling, tmpdir):\n-    dump_path = os.path.join(str(tmpdir), 'docker-compose.yml')\n+    dump_path = os.path.join(str(tmpdir), 'docker-compose-flow-sharding.yml')\n     flow_with_sharding.to_docker_compose_yaml(dump_path)\n \n     with DockerComposeFlow(dump_path):\n@@ -152,10 +201,10 @@ async def test_flow_with_sharding(flow_with_sharding, polling, tmpdir):\n     assert len(docs) == 10\n \n     runtimes_to_visit = {\n-        'test_executor-0/rep-0',\n-        'test_executor-1/rep-0',\n-        'test_executor-0/rep-1',\n-        'test_executor-1/rep-1',\n+        'test_executor_sharding-0/rep-0',\n+        'test_executor_sharding-1/rep-0',\n+        'test_executor_sharding-0/rep-1',\n+        'test_executor_sharding-1/rep-1',\n     }\n \n     for doc in docs:\n@@ -186,7 +235,7 @@ async def test_flow_with_sharding(flow_with_sharding, polling, tmpdir):\n     'docker_images', [['test-executor', 'jinaai/jina']], indirect=True\n )\n async def test_flow_with_configmap(flow_configmap, docker_images, tmpdir):\n-    dump_path = os.path.join(str(tmpdir), 'docker-compose.yml')\n+    dump_path = os.path.join(str(tmpdir), 'docker-compose-flow-configmap.yml')\n     flow_configmap.to_docker_compose_yaml(dump_path)\n \n     with DockerComposeFlow(dump_path):\n@@ -217,7 +266,7 @@ async def test_flow_with_workspace(logger, docker_images, tmpdir):\n         workspace='/shared',\n     )\n \n-    dump_path = os.path.join(str(tmpdir), 'docker-compose.yml')\n+    dump_path = os.path.join(str(tmpdir), 'docker-compose-flow-workspace.yml')\n     flow.to_docker_compose_yaml(dump_path)\n \n     with DockerComposeFlow(dump_path):\n\n---\n file path A: tests/integration/pods/test_pod.py | file path B: tests/integration/pods/test_pod.py\n\n@@ -4,11 +4,16 @@ import time\n \n import pytest\n \n-from jina import Document, Executor, Client, requests\n-from jina.enums import PollingType, PodRoleType\n+from jina import Client, Document, Executor, requests\n+from jina.enums import PodRoleType, PollingType\n+from jina.orchestrate.pods import Pod\n from jina.parsers import set_gateway_parser, set_pod_parser\n+from jina.resources.health_check.gateway import (\n+    check_health_http,\n+    check_health_websocket,\n+)\n+from jina.resources.health_check.pod import check_health_pod\n from jina.serve.networking import GrpcConnectionPool\n-from jina.orchestrate.pods import Pod\n from jina.types.request.control import ControlRequest\n \n \n@@ -53,6 +58,51 @@ async def test_pods_trivial_topology(port_generator):\n     assert len(response_list[0].docs) == 1\n \n \n+@pytest.mark.asyncio\n+@pytest.mark.parametrize(\n+    'protocol, health_check',\n+    [\n+        ('grpc', check_health_pod),\n+        ('http', check_health_http),\n+        ('websocket', check_health_websocket),\n+    ],\n+)\n+# test pods health check\n+async def test_pods_health_check(port_generator, protocol, health_check):\n+    worker_port = port_generator()\n+    head_port = port_generator()\n+    port = port_generator()\n+    graph_description = '{\"start-gateway\": [\"pod0\"], \"pod0\": [\"end-gateway\"]}'\n+    pod_addresses = f'{{\"pod0\": [\"0.0.0.0:{head_port}\"]}}'\n+\n+    # create a single worker pod\n+    worker_pod = _create_worker_pod(worker_port)\n+\n+    # create a single head pod\n+    head_pod = _create_head_pod(head_port)\n+\n+    # create a single gateway pod\n+    gateway_pod = _create_gateway_pod(graph_description, pod_addresses, port, protocol)\n+\n+    with gateway_pod, head_pod, worker_pod:\n+        # this would be done by the Pod, its adding the worker to the head\n+        head_pod.wait_start_success()\n+        worker_pod.wait_start_success()\n+        activate_msg = ControlRequest(command='ACTIVATE')\n+        activate_msg.add_related_entity('worker', '127.0.0.1', worker_port)\n+        assert GrpcConnectionPool.send_request_sync(\n+            activate_msg, f'127.0.0.1:{head_port}'\n+        )\n+\n+        # send requests to the gateway\n+        gateway_pod.wait_start_success()\n+\n+        for _port in (head_port, worker_port):\n+            check_health_pod(f'0.0.0.0:{_port}')\n+\n+        health_check(f'0.0.0.0:{port}')\n+\n+\n @pytest.fixture\n def complete_graph_dict():\n     return {\n@@ -496,7 +546,7 @@ def _create_head_pod(port, name='', polling='ANY', uses_before=None, uses_after=\n     return Pod(args)\n \n \n-def _create_gateway_pod(graph_description, pod_addresses, port):\n+def _create_gateway_pod(graph_description, pod_addresses, port, protocol='grpc'):\n     return Pod(\n         set_gateway_parser().parse_args(\n             [\n@@ -507,6 +557,8 @@ def _create_gateway_pod(graph_description, pod_addresses, port):\n                 '--port',\n                 str(port),\n                 '--noblock-on-start',\n+                '--protocol',\n+                protocol,\n             ]\n         )\n     )\n\n\n###\n\n", "completion": "feat: health check docker (#<issue-num>)"}
{"prompt": " file path A: README.md | file path B: README.md\n\n@@ -355,6 +355,7 @@ Now we have the service up running in Kubernetes!\n \n ## Support\n \n+- Check out the [Learning Bootcamp](https://learn.jina.ai) to get started with Jina.\n - Join our [Slack community](https://slack.jina.ai) to chat to our engineers about your use cases, questions, and\n   support queries.\n - Join our [Engineering All Hands](https://youtube.com/playlist?list=PL3UBBWOUVhFYRUa_gpYYKBqEAkO4sxmne) meet-up to\n\n\n###\n\n", "completion": "chore: add learning bootcamp call to action (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -139,6 +139,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12478,3 +12479,24 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```20b67226```](https://github.com/jina-ai/jina/commit/20b672269e1b658e4fb8d255778e25280c89d79f)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```7dceff65```](https://github.com/jina-ai/jina/commit/7dceff65f2d93bc81989251387eea8f3528a2fde)] __-__ __version__: the next version will be 3.1.4 (*Jina Dev Bot*)\n \n+<a name=release-note-3-1-5></a>\n+## Release Note (`3.1.5`)\n+\n+> Release time: 2022-03-15 12:21:38\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Han Xiao,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```9e054615```](https://github.com/jina-ai/jina/commit/9e0546155eabe47650443f8c159f636d0429e150)] __-__ __executor__: add serve function (#4475) (*Han Xiao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```18c2b242```](https://github.com/jina-ai/jina/commit/18c2b2424b1fafdbace392c4a86ab6a6600a734c)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```4e6d278a```](https://github.com/jina-ai/jina/commit/4e6d278af3c6272780ccf3aecbc955cbf9701a51)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```19e470ae```](https://github.com/jina-ai/jina/commit/19e470ae3660270d401461bd3159f0f58cf6341d)] __-__ __version__: the next version will be 3.1.5 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.1.5'\n+__version__ = '3.1.6'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.1.6"}
{"prompt": " file path A: docs/fundamentals/executor/executor-api.md | file path B: docs/fundamentals/executor/executor-api.md\n\n@@ -315,7 +315,54 @@ print(docs.embeddings.shape)\n ```\n ````\n \n+## Serve Executor stand-alone\n \n+Executors can be served - and remotely accessed - directly, without the need to instantiate a Flow manually.\n+This is especially useful when debugging an Executor in a remote setting.\n+\n+An Executor can be served using the `.serve()` class method:\n+\n+````{tab} Serve Executor\n+\n+```python\n+from jina import Executor, requests\n+from docarray import DocumentArray, Document\n+\n+\n+class MyExec(Executor):\n+    @requests\n+    def foo(self, docs: DocumentArray, **kwargs):\n+        docs[0] = 'executed MyExec'  # custom logic goes here\n+\n+\n+MyExec.serve(port=12345)\n+```\n+\n+````\n+\n+````{tab} Access served Executor\n+\n+```python\n+from jina import Client\n+from docarray import DocumentArray, Document\n+\n+print(Client(port=12345).post(inputs=DocumentArray.empty(1), on='/foo').texts)\n+```\n+```console\n+\n+```\n+['executed MyExec']\n+````\n+\n+Internally, the `.serve()` method creates a Flow and starts it. Therefore, it can take all associated parameters:\n+`uses_with`, `uses_metas`, `uses_requests` are passed to the internal `flow.add()` call, `stop_event` is an Event that stops\n+the Executor, and `**kwargs` is passed to the internal `Flow()` initialisation call.\n+\n+````{admonition} See Also\n+:class: seealso\n+\n+For more details on these arguments and the workings of `Flow`, see the {ref}`Flow section <flow-cookbook>`.\n+````\n \n ### Use async Executors\n \n\n---\n file path A: jina/serve/executors/__init__.py | file path B: jina/serve/executors/__init__.py\n\n@@ -1,21 +1,21 @@\n-from concurrent.futures import ThreadPoolExecutor\n-from typing import TYPE_CHECKING, Any\n import inspect\n+import multiprocessing\n import os\n+import threading\n+from concurrent.futures import ThreadPoolExecutor\n from types import SimpleNamespace\n-from typing import Dict, Optional, Type, List\n+from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union\n \n-from jina.serve.executors.decorators import store_init_kwargs, wrap_func, requests\n-from jina import __default_endpoint__, __args_executor_init__\n+from jina import __args_executor_init__, __default_endpoint__\n from jina.helper import (\n-    typename,\n     ArgNamespace,\n     T,\n     iscoroutinefunction,\n     run_in_threadpool,\n+    typename,\n )\n-from jina.jaml import JAMLCompatible, JAML, env_var_regex, internal_var_regex\n-\n+from jina.jaml import JAML, JAMLCompatible, env_var_regex, internal_var_regex\n+from jina.serve.executors.decorators import requests, store_init_kwargs, wrap_func\n \n if TYPE_CHECKING:\n     from jina import DocumentArray\n@@ -317,6 +317,36 @@ class BaseExecutor(JAMLCompatible, metaclass=ExecutorType):\n             uses_requests=uses_requests,\n         )\n \n+    @classmethod\n+    def serve(\n+        cls,\n+        uses_with: Optional[Dict] = None,\n+        uses_metas: Optional[Dict] = None,\n+        uses_requests: Optional[Dict] = None,\n+        stop_event: Optional[Union[threading.Event, multiprocessing.Event]] = None,\n+        **kwargs,\n+    ):\n+        \"\"\"Serve this Executor in a temporary Flow. Useful in testing an Executor in remote settings.\n+\n+        :param uses_with: dictionary of parameters to overwrite from the default config's with field\n+        :param uses_metas: dictionary of parameters to overwrite from the default config's metas field\n+        :param uses_requests: dictionary of parameters to overwrite from the default config's requests field\n+        :param stop_event: a threading event or a multiprocessing event that once set will resume the control Flow\n+            to main thread.\n+        :param kwargs: other kwargs accepted by the Flow, full list can be found `here <https://docs.jina.ai/api/jina.orchestrate.flow.base/>`\n+\n+        \"\"\"\n+        from jina import Flow\n+\n+        f = Flow(**kwargs).add(\n+            uses=cls,\n+            uses_with=uses_with,\n+            uses_metas=uses_metas,\n+            uses_requests=uses_requests,\n+        )\n+        with f:\n+            f.block(stop_event)\n+\n \n class ReducerExecutor(BaseExecutor):\n     \"\"\"\n\n---\n file path A: tests/unit/serve/executors/test_executor.py | file path B: tests/unit/serve/executors/test_executor.py\n\n@@ -4,10 +4,41 @@ from copy import deepcopy\n import pytest\n \n from docarray import Document, DocumentArray\n-from jina import Executor, requests\n+from jina import Client, Executor, requests\n from jina.serve.executors import ReducerExecutor\n from jina.serve.executors.metas import get_default_metas\n \n+PORT = 12350\n+\n+\n+class MyServeExec(Executor):\n+    @requests\n+    def foo(self, docs, **kwargs):\n+        docs.texts = ['foo' for _ in docs]\n+\n+\n+@pytest.fixture(autouse=False)\n+def served_exec():\n+    import threading\n+    import time\n+\n+    def serve_exec(**kwargs):\n+        MyServeExec.serve(**kwargs)\n+\n+    e = threading.Event()\n+    t = threading.Thread(\n+        name='serve-exec',\n+        target=serve_exec,\n+        kwargs={'port_expose': PORT, 'stop_event': e},\n+    )\n+    t.start()\n+    time.sleep(3)  # allow Flow to start\n+\n+    yield\n+\n+    e.set()  # set event and stop (unblock) the Flow\n+    t.join()\n+\n \n def test_executor_load_from_hub():\n     exec = Executor.from_hub(\n@@ -294,3 +325,9 @@ async def test_async_apply():\n     exec = AsyncExecutor()\n     da1 = await exec.foo(da)\n     assert da1.texts == ['hello'] * N\n+\n+\n+def test_serve(served_exec):\n+    docs = Client(port=PORT).post(on='/foo', inputs=DocumentArray.empty(5))\n+\n+    assert docs.texts == ['foo' for _ in docs]\n\n\n###\n\n", "completion": "feat(executor): add serve function (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -138,6 +138,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12454,3 +12455,25 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```b2f69d5b```](https://github.com/jina-ai/jina/commit/b2f69d5b6522080827e81b9bb7498b1f5af41de4)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n  - [[```e1d43309```](https://github.com/jina-ai/jina/commit/e1d433099a6a910d7595e867a42062b44198615c)] __-__ __version__: the next version will be 3.1.3 (*Jina Dev Bot*)\n \n+<a name=release-note-3-1-4></a>\n+## Release Note (`3.1.4`)\n+\n+> Release time: 2022-03-14 09:45:04\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Johannes Messner,  Joan Fontanals,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```9bdefb0a```](https://github.com/jina-ai/jina/commit/9bdefb0a693c4556e0902ef913f4426e3ef5ff65)] __-__ properly disable graphql endpoint by default (#4471) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```ac47f7ad```](https://github.com/jina-ai/jina/commit/ac47f7ade0c2d4b2677a6058f63cad183bbaa05f)] __-__ update requirement of pillow for latency tracking (#4469) (*Joan Fontanals*)\n+ - [[```a1f9c3a3```](https://github.com/jina-ai/jina/commit/a1f9c3a3a0500a8d6ceb295ca0e84525c2b4d6e7)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```20b67226```](https://github.com/jina-ai/jina/commit/20b672269e1b658e4fb8d255778e25280c89d79f)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```7dceff65```](https://github.com/jina-ai/jina/commit/7dceff65f2d93bc81989251387eea8f3528a2fde)] __-__ __version__: the next version will be 3.1.4 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.1.4'\n+__version__ = '3.1.5'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.1.5"}
{"prompt": " file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -1509,7 +1509,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                 'Redoc: ',\n                 f'[underline]http://localhost:{self.port}/redoc[/underline]',\n             )\n-            if not self.args.no_graphql_endpoint:\n+            if self.args.expose_graphql_endpoint:\n                 address_table.add_row(\n                     '\ud83d\udcac',\n                     'GraphQL UI: ',\n\n\n###\n\n", "completion": "fix: properly disable graphql endpoint by default (#<issue-num>)"}
{"prompt": " file path A: scripts/latency-tracking/requirements.txt | file path B: scripts/latency-tracking/requirements.txt\n\n@@ -1,4 +1,4 @@\n packaging==21.0\n-Pillow==9.0.0\n+Pillow==9.0.1\n scipy==1.7.0\n-uvloop==0.15.2\n\\ No newline at end of file\n+uvloop==0.15.2\n\n\n###\n\n", "completion": "chore: update requirement of pillow for latency tracking (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -137,6 +137,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12422,3 +12423,33 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```877849a9```](https://github.com/jina-ai/jina/commit/877849a9f81c47a3d63d59c255e95061b007a7b0)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```d55afac1```](https://github.com/jina-ai/jina/commit/d55afac119a49fd94e4fa243823c981af0766fcf)] __-__ __version__: the next version will be 3.1.2 (*Jina Dev Bot*)\n \n+<a name=release-note-3-1-3></a>\n+## Release Note (`3.1.3`)\n+\n+> Release time: 2022-03-11 16:22:43\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Zhaofeng Miao,  Delgermurun,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```53980292```](https://github.com/jina-ai/jina/commit/5398029280fe3f4aedd8a8b7058f97fbec353d03)] __-__ use rich to manage ui (#4427) (*samsja*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```9da67557```](https://github.com/jina-ai/jina/commit/9da67557bb50b063b8040170304e078fc568c73c)] __-__ __hubble__: use commit id instead of serial number (#4464) (*Delgermurun*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```89bd5614```](https://github.com/jina-ai/jina/commit/89bd56142d4781ebadb115404f72ed6e1c96532f)] __-__ delete daemon args from pods (#4465) (*samsja*)\n+ - [[```88db7696```](https://github.com/jina-ai/jina/commit/88db769626e4f5b770499cc0ad6ce44e772c8215)] __-__ __hubble__: optimize words (#4466) (*Zhaofeng Miao*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```1d618f8f```](https://github.com/jina-ai/jina/commit/1d618f8f3d08fd09a07dd86abf4ad8df7ce940f5)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```b2f69d5b```](https://github.com/jina-ai/jina/commit/b2f69d5b6522080827e81b9bb7498b1f5af41de4)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```e1d43309```](https://github.com/jina-ai/jina/commit/e1d433099a6a910d7595e867a42062b44198615c)] __-__ __version__: the next version will be 3.1.3 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.1.3'\n+__version__ = '3.1.4'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.1.4"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -77,7 +77,6 @@ ac_table = {\n             '--port-jinad',\n             '--quiet-remote-logs',\n             '--upload-files',\n-            '--daemon',\n             '--runtime-backend',\n             '--runtime',\n             '--runtime-cls',\n@@ -154,7 +153,6 @@ ac_table = {\n             '--port-expose',\n             '--graph-description',\n             '--deployments-addresses',\n-            '--daemon',\n             '--runtime-backend',\n             '--runtime',\n             '--runtime-cls',\n@@ -232,7 +230,6 @@ ac_table = {\n             '--port-jinad',\n             '--quiet-remote-logs',\n             '--upload-files',\n-            '--daemon',\n             '--runtime-backend',\n             '--runtime',\n             '--runtime-cls',\n@@ -282,7 +279,6 @@ ac_table = {\n             '--port-jinad',\n             '--quiet-remote-logs',\n             '--upload-files',\n-            '--daemon',\n             '--runtime-backend',\n             '--runtime',\n             '--runtime-cls',\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -127,7 +127,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         *,\n         connection_list: Optional[str] = None,\n         cors: Optional[bool] = False,\n-        daemon: Optional[bool] = False,\n         default_swagger_ui: Optional[bool] = False,\n         deployments_addresses: Optional[str] = '{}',\n         description: Optional[str] = None,\n@@ -172,7 +171,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n         :param connection_list: dictionary JSON with a list of connections to configure\n         :param cors: If set, a CORS middleware is added to FastAPI frontend to allow cross-origin access.\n-        :param daemon: The Pod attempts to terminate all of its Runtime child processes/threads on existing. setting it to true basically tell the Pod do not wait on the Runtime when closing\n         :param default_swagger_ui: If set, the default swagger ui is used for `/docs` endpoint.\n         :param deployments_addresses: dictionary JSON with the input addresses of each Deployment\n         :param description: The description of this HTTP server. It will be used in automatics docs such as Swagger UI.\n@@ -579,7 +577,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         self,\n         *,\n         connection_list: Optional[str] = None,\n-        daemon: Optional[bool] = False,\n         disable_reduce: Optional[bool] = False,\n         docker_kwargs: Optional[dict] = None,\n         entrypoint: Optional[str] = None,\n@@ -623,7 +620,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         \"\"\"Add an Executor to the current Flow object.\n \n         :param connection_list: dictionary JSON with a list of connections to configure\n-        :param daemon: The Pod attempts to terminate all of its Runtime child processes/threads on existing. setting it to true basically tell the Pod do not wait on the Runtime when closing\n         :param disable_reduce: Disable the built-in reduce mechanism, set this if the reduction is to be handled by the Executor connected to this Head\n         :param docker_kwargs: Dictionary of kwargs arguments that will be passed to Docker SDK when starting the docker '\n           container.\n\n---\n file path A: jina/orchestrate/pods/__init__.py | file path B: jina/orchestrate/pods/__init__.py\n\n@@ -4,16 +4,16 @@ import os\n import threading\n import time\n from abc import ABC, abstractmethod\n-from typing import Type, Union, Dict, Optional\n+from typing import Dict, Optional, Type, Union\n \n-from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n-from jina.jaml import JAML\n-from jina.orchestrate.pods.helper import _get_event, _get_worker, ConditionalEvent\n-from jina import __stop_msg__, __ready_msg__, __windows__\n+from jina import __ready_msg__, __stop_msg__, __windows__\n from jina.enums import PodRoleType, RuntimeBackendType\n from jina.excepts import RuntimeFailToStart, RuntimeRunForeverEarlyError\n from jina.helper import typename\n+from jina.jaml import JAML\n from jina.logging.logger import JinaLogger\n+from jina.orchestrate.pods.helper import ConditionalEvent, _get_event, _get_worker\n+from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n \n __all__ = ['BasePod', 'Pod']\n \n@@ -149,7 +149,6 @@ class BasePod(ABC):\n             getattr(args, 'runtime_backend', RuntimeBackendType.THREAD),\n             events_list=[self.is_ready, self.is_shutdown],\n         )\n-        self.daemon = self.args.daemon\n         self.runtime_ctrl_address = self._get_control_address()\n         self._timeout_ctrl = self.args.timeout_ctrl\n \n\n---\n file path A: jina/orchestrate/pods/container.py | file path B: jina/orchestrate/pods/container.py\n\n@@ -1,25 +1,21 @@\n-import os\n import argparse\n-import time\n-import signal\n-\n+import asyncio\n import multiprocessing\n+import os\n+import signal\n import threading\n+import time\n+from typing import TYPE_CHECKING, Dict, Optional, Union\n \n-from typing import Union, Dict, Optional, TYPE_CHECKING\n-import asyncio\n-\n-from jina import __windows__\n+from jina import __docker_host__, __windows__\n+from jina.helper import random_name, slugify\n from jina.importer import ImportExtensions\n-from jina.orchestrate.pods import BasePod\n-from jina.orchestrate.pods import _get_worker\n+from jina.logging.logger import JinaLogger\n+from jina.orchestrate.pods import BasePod, _get_worker\n from jina.orchestrate.pods.container_helper import (\n-    get_gpu_device_requests,\n     get_docker_network,\n+    get_gpu_device_requests,\n )\n-from jina import __docker_host__\n-from jina.logging.logger import JinaLogger\n-from jina.helper import slugify, random_name\n from jina.serve.runtimes.asyncio import AsyncNewLoopRuntime\n \n if TYPE_CHECKING:\n@@ -36,8 +32,10 @@ def _docker_run(\n ):\n     # important to notice, that client is not assigned as instance member to avoid potential\n     # heavy copy into new process memory space\n-    import docker\n     import warnings\n+\n+    import docker\n+\n     from jina.excepts import BadImageNameError, DockerVersionError\n \n     docker_version = client.version().get('Version')\n@@ -65,10 +63,11 @@ def _docker_run(\n     # the image arg should be ignored otherwise it keeps using ContainerPod in the container\n     # basically all args in Pod-docker arg group should be ignored.\n     # this prevent setting containerPod twice\n-    from jina.parsers import set_pod_parser\n-    from jina.helper import ArgNamespace\n     from pathlib import Path\n \n+    from jina.helper import ArgNamespace\n+    from jina.parsers import set_pod_parser\n+\n     args.native = True\n \n     non_defaults = ArgNamespace.get_non_defaults_args(\n@@ -290,7 +289,6 @@ class ContainerPod(BasePod):\n             self.args.docker_kwargs.pop('extra_hosts')\n         self._net_mode = None\n         self.worker = None\n-        self.daemon = self.args.daemon  #: required here to set process/thread daemon\n         self.container_name = slugify(f'{self.name}/{random_name()}')\n         self.net_mode, self.runtime_ctrl_address = self._get_control_address()\n \n@@ -334,7 +332,6 @@ class ContainerPod(BasePod):\n \n         # Related to potential docker-in-docker communication. If `Runtime` lives already inside a container.\n         # it will need to communicate using the `bridge` network.\n-\n         # In WSL, we need to set ports explicitly\n         net_mode, runtime_ctrl_address = None, ctrl_address\n         if sys.platform in ('linux', 'linux2') and 'microsoft' not in uname().release:\n\n---\n file path A: jina/orchestrate/pods/helper.py | file path B: jina/orchestrate/pods/helper.py\n\n@@ -2,14 +2,13 @@ import multiprocessing\n import threading\n from copy import deepcopy\n from functools import partial\n-from typing import Callable, Dict, Union, TYPE_CHECKING, Optional\n-\n-from jina.enums import GatewayProtocolType, RuntimeBackendType, PodRoleType\n-from jina.hubble.helper import is_valid_huburi\n-from jina.hubble.hubio import HubIO\n+from typing import TYPE_CHECKING, Callable, Dict, Optional, Union\n \n from grpc import RpcError\n \n+from jina.enums import GatewayProtocolType, PodRoleType, RuntimeBackendType\n+from jina.hubble.helper import is_valid_huburi\n+from jina.hubble.hubio import HubIO\n from jina.serve.networking import GrpcConnectionPool\n from jina.types.request.control import ControlRequest\n \n@@ -24,7 +23,7 @@ def _get_worker(\n         RuntimeBackendType.THREAD: threading.Thread,\n         RuntimeBackendType.PROCESS: multiprocessing.Process,\n     }.get(getattr(args, 'runtime_backend', RuntimeBackendType.THREAD))(\n-        target=target, name=name, kwargs=kwargs\n+        target=target, name=name, kwargs=kwargs, daemon=True\n     )\n \n \n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -13,14 +13,6 @@ def mixin_pod_parser(parser):\n \n     gp = add_arg_group(parser, title='Pod')\n \n-    gp.add_argument(\n-        '--daemon',\n-        action='store_true',\n-        default=False,\n-        help='The Pod attempts to terminate all of its Runtime child processes/threads on existing. '\n-        'setting it to true basically tell the Pod do not wait on the Runtime when closing',\n-    )\n-\n     gp.add_argument(\n         '--runtime-backend',\n         '--runtime',\n\n\n###\n\n", "completion": "refactor: delete daemon args from pods (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -669,7 +669,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n             return host, port\n \n         with console.status(\n-            f\"[bold green]Deploying sandbox for ({name}) since no existing one...\"\n+            f\"[bold green]Deploying sandbox for [bold white]{name}[/bold white] since none exists...\"\n         ):\n             try:\n                 json_response = requests.post(\n@@ -687,7 +687,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n \n                 console.log(f\"Deployment completed: {host}:{port}\")\n                 console.log(\n-                    f\"[bold green]This sandbox will be removed when no traffic during {livetime}\"\n+                    f\"[bold green]This sandbox will be removed when no traffic during [bold white]{livetime}[/bold white]\"\n                 )\n             except:\n                 console.log(\"Deployment failed\")\n\n\n###\n\n", "completion": "refactor(hubble): optimize words (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/__init__.py | file path B: jina/hubble/__init__.py\n\n@@ -8,7 +8,7 @@ class HubExecutor:\n \n     uuid: str = None\n     name: Optional[str] = None\n-    sn: Optional[int] = None\n+    commit_id: Optional[str] = None\n     tag: Optional[str] = None\n     visibility: Optional[bool] = None\n     image_name: Optional[str] = None\n\n---\n file path A: jina/hubble/hubapi.py | file path B: jina/hubble/hubapi.py\n\n@@ -6,14 +6,14 @@ import shutil\n from pathlib import Path\n from typing import Tuple\n \n+from jina.helper import random_identity\n from jina.hubble import HubExecutor\n from jina.hubble.helper import (\n-    unpack_package,\n+    get_hub_packages_dir,\n     install_requirements,\n     is_requirements_installed,\n-    get_hub_packages_dir,\n+    unpack_package,\n )\n-from jina.helper import random_identity\n \n \n def get_dist_path(uuid: str, tag: str) -> Tuple[Path, Path]:\n@@ -155,10 +155,10 @@ def install_local(\n     if manifest_path.exists():\n         shutil.copyfile(manifest_path, pkg_dist_path / 'manifest.yml')\n \n-    # store the serial number in local\n-    if executor.sn is not None:\n-        sn_file = pkg_dist_path / f'PKG-SN-{executor.sn}'\n-        sn_file.touch()\n+    # store the commit id in local\n+    if executor.commit_id is not None:\n+        commit_file = pkg_dist_path / f'PKG-COMMIT-{executor.commit_id}'\n+        commit_file.touch()\n \n \n def install_package_dependencies(\n\n---\n file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -611,7 +611,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n         return HubExecutor(\n             uuid=resp['id'],\n             name=resp.get('name', None),\n-            sn=resp.get('sn', None),\n+            commit_id=resp['commit'].get('id'),\n             tag=tag or resp['commit'].get('tags', [None])[0],\n             visibility=resp['visibility'],\n             image_name=image_name,\n@@ -819,10 +819,12 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n                             pkg_path, pkg_dist_path = get_dist_path_of_executor(\n                                 executor\n                             )\n-                            # check serial number to upgrade\n-                            sn_file_path = pkg_dist_path / f'PKG-SN-{executor.sn or 0}'\n-                            if (not sn_file_path.exists()) and any(\n-                                pkg_dist_path.glob('PKG-SN-*')\n+                            # check commit id to upgrade\n+                            commit_file_path = (\n+                                pkg_dist_path / f'PKG-COMMIT-{executor.commit_id or 0}'\n+                            )\n+                            if (not commit_file_path.exists()) and any(\n+                                pkg_dist_path.glob('PKG-COMMIT-*')\n                             ):\n                                 raise FileNotFoundError(\n                                     f'{pkg_path} need to be upgraded'\n\n---\n file path A: tests/unit/hubble/test_hubapi.py | file path B: tests/unit/hubble/test_hubapi.py\n\n@@ -3,7 +3,7 @@ from pathlib import Path\n \n import pytest\n \n-from jina.hubble import hubapi, HubExecutor\n+from jina.hubble import HubExecutor, hubapi\n from jina.hubble.hubapi import list_local\n \n cur_dir = os.path.dirname(os.path.abspath(__file__))\n@@ -16,7 +16,7 @@ def executor_zip_file():\n \n @pytest.fixture\n def test_executor():\n-    return HubExecutor(uuid='hello', name=None, sn=0, tag='v0')\n+    return HubExecutor(uuid='hello', name=None, commit_id='test_commit', tag='v0')\n \n \n @pytest.mark.parametrize('install_deps', [True, False])\n\n\n###\n\n", "completion": "fix(hubble): use commit id instead of serial number (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -136,6 +136,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12376,3 +12377,47 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```3297f4b5```](https://github.com/jina-ai/jina/commit/3297f4b5a793bbbd2b35f0402126ae08d12f4eb9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```e304303d```](https://github.com/jina-ai/jina/commit/e304303de065f029122af8ccd8326d6a7975ab01)] __-__ __version__: the next version will be 3.1.1 (*Jina Dev Bot*)\n \n+<a name=release-note-3-1-2></a>\n+## Release Note (`3.1.2`)\n+\n+> Release time: 2022-03-10 17:43:21\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ Johannes Messner,  Sha Zhou,  Nan Wang,  Jina Dev Bot,  Joan Fontanals,  Delgermurun,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```beb0d8f5```](https://github.com/jina-ai/jina/commit/beb0d8f569530755f7797781a8cb49e1b8a2faaf)] __-__ __hubble__: fetch image only when required (#4445) (*Delgermurun*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```28c16e60```](https://github.com/jina-ai/jina/commit/28c16e6002c9f7f8a35d2b0385e84cb671dfd570)] __-__ graphql dependencies (#4461) (*Johannes Messner*)\n+\n+### \ud83e\uddfc Code Refactoring\n+\n+ - [[```7483c63c```](https://github.com/jina-ai/jina/commit/7483c63c08e28c76e751acf8a62d2573a2d222af)] __-__ remove replica-id and expose public args (#4447) (*Joan Fontanals*)\n+ - [[```ce2be1d4```](https://github.com/jina-ai/jina/commit/ce2be1d4057134f488c882fe83b963b087279b7a)] __-__ remove compression related args (#4446) (*Joan Fontanals*)\n+ - [[```90f253a9```](https://github.com/jina-ai/jina/commit/90f253a969de79a77e783cb5130455d5754684bc)] __-__ remove disable remote (#4444) (*Joan Fontanals*)\n+\n+### \ud83d\udcd7 Documentation\n+\n+ - [[```607ede1b```](https://github.com/jina-ai/jina/commit/607ede1bf0dd8f11ad0d0f5db6f2a005e58b21e0)] __-__ __qabot__: fix flash on ios and disappear on search&amp;404 (#4459) (*Sha Zhou*)\n+ - [[```13f8496d```](https://github.com/jina-ai/jina/commit/13f8496d32b85864da0e06d4aa5817695c131793)] __-__ __clients__: update docstrings (#4460) (*Nan Wang*)\n+ - [[```9b80d53d```](https://github.com/jina-ai/jina/commit/9b80d53d59052ea2699fc957014e1083c79ae1f0)] __-__ fix flow api (#4454) (*Joan Fontanals*)\n+\n+### \ud83c\udfc1 Unit Test and CICD\n+\n+ - [[```19f8ea02```](https://github.com/jina-ai/jina/commit/19f8ea02a85b08991eeb4ccedb8c0af3b06c9a33)] __-__ rename tests for new namings (#4453) (*Joan Fontanals*)\n+ - [[```a37c526a```](https://github.com/jina-ai/jina/commit/a37c526a8381cd11ae226707ea301c1ac0f59851)] __-__ fix tests failures caused by docarray (#4451) (*Joan Fontanals*)\n+ - [[```217a11bb```](https://github.com/jina-ai/jina/commit/217a11bb8dc613ed1136b8b541a68e6d53ca4fc1)] __-__ fix tests failing after new docarray patch (#4449) (*Joan Fontanals*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```63ad1e4f```](https://github.com/jina-ai/jina/commit/63ad1e4f3e20f5bef4f170076bcf8e9f4ae55a51)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```3ac8baeb```](https://github.com/jina-ai/jina/commit/3ac8baeb4cb1684f3b3614667e4c05725af9ecc3)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```877849a9```](https://github.com/jina-ai/jina/commit/877849a9f81c47a3d63d59c255e95061b007a7b0)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```d55afac1```](https://github.com/jina-ai/jina/commit/d55afac119a49fd94e4fa243823c981af0766fcf)] __-__ __version__: the next version will be 3.1.2 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.1.2'\n+__version__ = '3.1.3'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.1.3"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -110,7 +110,7 @@ ac_table = {\n             '--k8s-namespace',\n             '--k8s-disable-connection-pool',\n             '--polling',\n-            '--no-graphql-endpoint',\n+            '--expose-graphql-endpoint',\n             '--uses',\n             '--env',\n             '--inspect',\n@@ -147,7 +147,7 @@ ac_table = {\n             '--no-crud-endpoints',\n             '--expose-endpoints',\n             '--uvicorn-kwargs',\n-            '--no-graphql-endpoint',\n+            '--expose-graphql-endpoint',\n             '--protocol',\n             '--host',\n             '--proxy',\n\n---\n file path A: docs/fundamentals/flow/access-flow-api.md | file path B: docs/fundamentals/flow/access-flow-api.md\n\n@@ -181,7 +181,7 @@ This article does not serve as the introduction to GraphQL.\n If you are not already familiar with GraphQL, we recommend you learn more about GraphQL from the official [GraphQL documentation](https://graphql.org/learn/).\n You may also want to learn about [Strawberry](https://strawberry.rocks/), the library that powers Jina's GraphQL support.\n ````\n-Jina Flows that use the HTTP protocol provide a GraphQL API out of the box, which is located behind the '/graphql' endpoint.\n+Jina Flows that use the HTTP protocol can also provide a GraphQL API, which is located behind the '/graphql' endpoint.\n GraphQL has the advantage of letting the user define their own response schema, which means that only the fields that are required\n will be sent over the wire.\n This is especially useful when the user does not need potentially large fields, like image tensors.\n\n---\n file path A: docs/fundamentals/flow/flow-api.md | file path B: docs/fundamentals/flow/flow-api.md\n\n@@ -211,6 +211,33 @@ f = Flow(protocol='http', no_debug_endpoints=True, no_crud_endpoints=True)\n \n After setting up a Flow in this way, the {ref}`default HTTP endpoints <custom-http>` will not be exposed.\n \n+### Add GraphQL endpoint\n+\n+````{admonition} Attention\n+:class: attention\n+\n+GraphQL support is an optional feature that requires optional dependencies.\n+To install these, run `pip install jina[graphql]` or `pip install jina[all]`.\n+\n+Unfortunately, these dependencies are **not available through Conda**. You will have to use `pip` to be able to use GraphQL\n+feature.\n+````\n+\n+A Flow can optionally expose a [GraphQL](https://graphql.org/) endpoint, located at `/graphql`.\n+To enable this endpoint, all you need to do is set `expose_graphql_endpoint=True` on your HTTP Flow:\n+\n+```python\n+from jina import Flow\n+\n+f = Flow(protocol='http', expose_graphql_endpont=True)\n+```\n+\n+````{admonition} See Also\n+:class: seealso\n+\n+For more details about the Jina GraphQL enpoint, see {ref}`here <flow-graphql>`.\n+````\n+\n ## Limit outstanding requests\n \n By default, Jina's Client sens requests to the Flow as fast as possible, without any throttling.\n\n---\n file path A: extra-requirements.txt | file path B: extra-requirements.txt\n\n@@ -28,7 +28,7 @@\n scipy>=1.6.1:               devel\n fastapi:                    standard, daemon, devel, demo\n uvicorn[standard]:          standard, daemon, devel, demo\n-strawberry-graphql>=0.96.0: standard, daemon, devel\n+strawberry-graphql>=0.96.0: cicd, graphql\n docker:                     standard, daemon, devel\n pathspec:                   standard, daemon, devel\n rich:                       standard, daemon, devel\n@@ -73,4 +73,5 @@ portforward>=0.2.4:         cicd\n kubernetes>=18.20.0:        perf, standard, devel\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n-sgqlc:                      cicd\n\\ No newline at end of file\n+sgqlc:                      cicd, graphql\n+docarray>=0.8.8:            cicd, graphql\n\\ No newline at end of file\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -40,15 +40,15 @@ from jina.excepts import (\n     RuntimeFailToStart,\n )\n from jina.helper import (\n+    GRAPHQL_MIN_DOCARRAY_VERSION,\n     ArgNamespace,\n     CatchAllCleanupContextManager,\n     colored,\n+    docarray_graphql_compatible,\n     download_mermaid_url,\n     get_internal_ip,\n     get_public_ip,\n     typename,\n-    docarray_graphql_compatible,\n-    GRAPHQL_MIN_DOCARRAY_VERSION,\n )\n from jina.jaml import JAMLCompatible\n from jina.logging.logger import JinaLogger\n@@ -134,6 +134,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         disable_reduce: Optional[bool] = False,\n         env: Optional[dict] = None,\n         expose_endpoints: Optional[str] = None,\n+        expose_graphql_endpoint: Optional[bool] = False,\n         graph_description: Optional[str] = '{}',\n         host: Optional[str] = '0.0.0.0',\n         host_in: Optional[str] = '0.0.0.0',\n@@ -142,7 +143,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         native: Optional[bool] = False,\n         no_crud_endpoints: Optional[bool] = False,\n         no_debug_endpoints: Optional[bool] = False,\n-        no_graphql_endpoint: Optional[bool] = False,\n         polling: Optional[str] = 'ANY',\n         port: Optional[int] = None,\n         prefetch: Optional[int] = 0,\n@@ -179,6 +179,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         :param disable_reduce: Disable the built-in reduce mechanism, set this if the reduction is to be handled by the Executor connected to this Head\n         :param env: The map of environment variables that are available inside runtime\n         :param expose_endpoints: A JSON string that represents a map from executor endpoints (`@requests(on=...)`) to HTTP endpoints.\n+        :param expose_graphql_endpoint: If set, /graphql endpoint is added to HTTP interface.\n         :param graph_description: Routing graph for the gateway\n         :param host: The host address of the runtime, by default it is 0.0.0.0.\n         :param host_in: The host address for binding to, by default it is 0.0.0.0\n@@ -197,7 +198,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n \n                   Any executor that has `@requests(on=...)` bind with those values will receive data requests.\n         :param no_debug_endpoints: If set, /status /post endpoints are removed from HTTP interface.\n-        :param no_graphql_endpoint: If set, /graphql endpoint is removed from HTTP interface.\n         :param polling: The polling strategy of the Deployment and its endpoints (when `shards>1`).\n               Can be defined for all endpoints of a Deployment or by endpoint.\n               Define per Deployment:\n@@ -259,10 +259,10 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         self,\n         *,\n         env: Optional[dict] = None,\n+        expose_graphql_endpoint: Optional[bool] = False,\n         inspect: Optional[str] = 'COLLECT',\n         log_config: Optional[str] = None,\n         name: Optional[str] = None,\n-        no_graphql_endpoint: Optional[bool] = False,\n         polling: Optional[str] = 'ANY',\n         quiet: Optional[bool] = False,\n         quiet_error: Optional[bool] = False,\n@@ -274,6 +274,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         \"\"\"Create a Flow. Flow is how Jina streamlines and scales Executors. This overloaded method provides arguments from `jina flow` CLI.\n \n         :param env: The map of environment variables that are available inside runtime\n+        :param expose_graphql_endpoint: If set, /graphql endpoint is added to HTTP interface.\n         :param inspect: The strategy on those inspect deployments in the flow.\n \n               If `REMOVE` is given then all inspect deployments are removed when building the flow.\n@@ -287,7 +288,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n           - ...\n \n           When not given, then the default naming strategy will apply.\n-        :param no_graphql_endpoint: If set, /graphql endpoint is removed from HTTP interface.\n         :param polling: The polling strategy of the Deployment and its endpoints (when `shards>1`).\n               Can be defined for all endpoints of a Deployment or by endpoint.\n               Define per Deployment:\n@@ -325,13 +325,13 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         self._update_args(args, **kwargs)\n         if (\n             self.protocol == GatewayProtocolType.HTTP\n-            and not self.args.no_graphql_endpoint\n+            and self.args.expose_graphql_endpoint\n             and not docarray_graphql_compatible()\n         ):\n-            self.args.no_graphql_endpoint = True\n+            self.args.expose_graphql_endpoint = False\n             warnings.warn(\n                 'DocArray version is incompatible with GraphQL features. '\n-                'Automatically setting no_graphql_endpoint=True. '\n+                'Automatically setting expose_graphql_endpoint=False. '\n                 f'To use GraphQL features, install docarray>={GRAPHQL_MIN_DOCARRAY_VERSION}'\n             )\n \n@@ -449,8 +449,8 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         kwargs.update(self._common_kwargs)\n         args = ArgNamespace.kwargs2namespace(kwargs, set_gateway_parser())\n         args.noblock_on_start = True\n-        args.no_graphql_endpoint = (\n-            self.args.no_graphql_endpoint\n+        args.expose_graphql_endpoint = (\n+            self.args.expose_graphql_endpoint\n         )  # also used in Flow, thus not in kwargs\n         args.graph_description = json.dumps(graph_description)\n         args.deployments_addresses = json.dumps(deployments_addresses)\n@@ -1508,7 +1508,7 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n                     attrs='underline',\n                 )\n             )\n-            if not self.args.no_graphql_endpoint:\n+            if self.args.expose_graphql_endpoint:\n                 address_table.append(\n                     f'\\t\ud83d\udcac GraphQL UI:\\t\\t'\n                     + colored(\n\n---\n file path A: jina/parsers/orchestrate/runtimes/remote.py | file path B: jina/parsers/orchestrate/runtimes/remote.py\n\n@@ -102,10 +102,10 @@ def mixin_graphql_parser(parser=None):\n \n     gp = add_arg_group(parser, title='GraphQL')\n     gp.add_argument(\n-        '--no-graphql-endpoint',\n+        '--expose-graphql-endpoint',\n         action='store_true',\n         default=False,\n-        help='If set, /graphql endpoint is removed from HTTP interface. ',\n+        help='If set, /graphql endpoint is added to HTTP interface. ',\n     )\n \n \n\n---\n file path A: jina/resources/extra-requirements.txt | file path B: jina/resources/extra-requirements.txt\n\n@@ -28,7 +28,7 @@\n scipy>=1.6.1:               devel\n fastapi:                    standard, daemon, devel, demo\n uvicorn[standard]:          standard, daemon, devel, demo\n-strawberry-graphql>=0.96.0: standard, daemon, devel\n+strawberry-graphql>=0.96.0: cicd, graphql\n docker:                     standard, daemon, devel\n pathspec:                   standard, daemon, devel\n rich:                       standard, daemon, devel\n@@ -73,4 +73,5 @@ portforward>=0.2.4:         cicd\n kubernetes>=18.20.0:        perf, standard, devel\n pytest-kind==21.1.3:        test\n pytest-lazy-fixture:        test\n-sgqlc:                      cicd\n\\ No newline at end of file\n+sgqlc:                      cicd, graphql\n+docarray>=0.8.8:            cicd, graphql\n\\ No newline at end of file\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -1,15 +1,15 @@\n import argparse\n import json\n-from typing import TYPE_CHECKING, Dict, List, Optional\n import warnings\n+from typing import TYPE_CHECKING, Dict, List, Optional\n \n from jina import __version__\n from jina.clients.request import request_generator\n from jina.enums import DataInputType\n from jina.helper import (\n-    get_full_version,\n-    docarray_graphql_compatible,\n     GRAPHQL_MIN_DOCARRAY_VERSION,\n+    docarray_graphql_compatible,\n+    get_full_version,\n )\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n@@ -39,13 +39,14 @@ def get_fastapi_app(\n         from fastapi import FastAPI\n         from fastapi.middleware.cors import CORSMiddleware\n         from fastapi.responses import HTMLResponse\n+        from starlette.requests import Request\n+\n         from jina.serve.runtimes.gateway.http.models import (\n             JinaEndpointRequestModel,\n             JinaRequestModel,\n             JinaResponseModel,\n             JinaStatusModel,\n         )\n-        from starlette.requests import Request\n \n     docs_url = '/docs'\n     app = FastAPI(\n@@ -57,11 +58,11 @@ def get_fastapi_app(\n         docs_url=docs_url if args.default_swagger_ui else None,\n     )\n \n-    if not args.no_graphql_endpoint and not docarray_graphql_compatible():\n-        args.no_graphql_endpoint = True\n+    if args.expose_graphql_endpoint and not docarray_graphql_compatible():\n+        args.expose_graphql_endpoint = False\n         warnings.warn(\n             'DocArray version is incompatible with GraphQL features.'\n-            'Setting no_graphql_endpoint=True.'\n+            'Setting expose_graphql_endpoint=False.'\n             f'To use GraphQL features, install docarray>={GRAPHQL_MIN_DOCARRAY_VERSION}'\n         )\n \n@@ -241,18 +242,18 @@ def get_fastapi_app(\n \n         app.add_route(docs_url, _render_custom_swagger_html, include_in_schema=False)\n \n-    if not args.no_graphql_endpoint:\n+    if args.expose_graphql_endpoint:\n         with ImportExtensions(required=True):\n             from dataclasses import asdict\n \n             import strawberry\n             from docarray import DocumentArray\n-            from strawberry.fastapi import GraphQLRouter\n-            from docarray.document.strawberry_type import StrawberryDocument\n             from docarray.document.strawberry_type import (\n                 JSONScalar,\n+                StrawberryDocument,\n                 StrawberryDocumentInput,\n             )\n+            from strawberry.fastapi import GraphQLRouter\n \n             async def get_docs_from_endpoint(\n                 data, target_executor, parameters, exec_endpoint\n\n---\n file path A: tests/integration/graphql/test_graphql.py | file path B: tests/integration/graphql/test_graphql.py\n\n@@ -1,13 +1,14 @@\n import asyncio\n+import time\n import urllib.error\n from typing import Dict\n-import time\n \n import numpy as np\n import pytest\n from docarray.array.document import DocumentArray\n from docarray.document import Document\n-from jina import Executor, Flow, requests, Client\n+\n+from jina import Client, Executor, Flow, requests\n \n PORT_EXPOSE = 53171\n PORT_EXPOSE_NO_GRAPHQL = 53172\n@@ -60,7 +61,7 @@ class GraphQLTestEncoder(Executor):\n @pytest.fixture(scope=\"module\", autouse=True)\n def flow():\n     f = (\n-        Flow(protocol='http', port_expose=PORT_EXPOSE)\n+        Flow(protocol='http', port_expose=PORT_EXPOSE, expose_graphql_endpoint=True)\n         .add(uses=GraphQLTestEncoder, name='Encoder')\n         .add(uses=GraphQLTestIndexer, name='Indexer')\n         .add(uses=SlowExec)\n@@ -76,7 +77,7 @@ def no_graphql_flow():\n         Flow(\n             protocol='http',\n             port_expose=PORT_EXPOSE_NO_GRAPHQL,\n-            no_graphql_endpoint=True,\n+            expose_graphql_endpoint=False,\n             cors=True,\n             no_crud_endpoints=True,\n         )\n\n\n###\n\n", "completion": "fix: graphql dependencies (#<issue-num>)"}
{"prompt": " file path A: docs/_templates/page.html | file path B: docs/_templates/page.html\n\n@@ -182,23 +182,24 @@\n                     </div>\n                 </div>\n                 {% endif %}\n-                <qa-bot\n-                    theme=\"auto\"\n-                    title=\"Jina Bot\"\n-                    description=\"The cloud-native neural search framework\"\n-                >\n-                    <dl>\n-                        <dt>You can ask questions about our docs. Try:</dt>\n-                        <dd>Does Jina support Kubernetes?</dd>\n-                        <dd>What are the basic concepts in Jina?</dd>\n-                        <dd>How to share my Executor?</dd>\n-                    </dl>\n-                </qa-bot>\n             </div>\n \n             {% endblock right_sidebar %}\n         </aside>\n \n     </div>\n+    <qa-bot\n+        title=\"Jina Bot\"\n+        description=\"The cloud-native neural search framework\"\n+        >\n+        <dl>\n+            <dt>You can ask questions about our docs. Try:</dt>\n+            <dd>Does Jina support Kubernetes?</dd>\n+            <dd>What are the basic concepts in Jina?</dd>\n+            <dd>How to share my Executor?</dd>\n+        </dl>\n+    </qa-bot>\n+\n </div>\n+\n {%- endblock %}\n\n---\n file path A: docs/conf.py | file path B: docs/conf.py\n\n@@ -77,7 +77,9 @@ html_css_files = [\n     'docbot.css',\n     'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta2/css/all.min.css',\n ]\n-html_js_files = []\n+html_js_files = [\n+    'https://cdn.jsdelivr.net/npm/qabot@0.4'\n+]\n htmlhelp_basename = slug\n html_show_sourcelink = False\n html_favicon = '_static/favicon.ico'\n@@ -183,7 +185,6 @@ ogp_custom_meta_tags = [\n </script>\n \n <script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n-<script async defer src=\"https://cdn.jsdelivr.net/npm/qabot@0.4\"></script>\n     ''',\n ]\n \n@@ -194,37 +195,12 @@ def configure_qa_bot_ui(app):\n     js_text = \"\"\"\n         document.addEventListener('DOMContentLoaded', function() { \n             document.querySelector('qa-bot').setAttribute('server', '%s');\n-            const theme = localStorage.getItem('theme');\n-            if (theme) {\n-                document.querySelector('qa-bot').setAttribute('theme', theme);\n-            }\n-        });\n-        const ob = new MutationObserver(function(mutations) {\n-            let shouldChange = false;\n-            for (const m of mutations) {\n-                if (m.type !== 'attributes') {\n-                    continue;\n-                }   \n-                if (m.attributeName !== 'data-theme') {\n-                    continue;\n-                }\n-                shouldChange = m.target.dataset.theme;\n-            }\n-\n-            if (!shouldChange) {\n-                return;\n-            }\n-\n-            document.querySelector('qa-bot').setAttribute('theme', shouldChange);\n-        });\n-        ob.observe(document.body, {\n-            attribute:true,\n-            attributeFilter: ['data-theme']\n         });\n         \"\"\" % server_address\n     app.add_js_file(None, body=js_text)\n \n \n+\n def setup(app):\n     from sphinx.domains.python import PyField\n     from sphinx.util.docfields import Field\n\n\n###\n\n", "completion": "docs(qabot): fix flash on ios and disappear on search&404 (#<issue-num>)"}
{"prompt": " file path A: jina/clients/grpc.py | file path B: jina/clients/grpc.py\n\n@@ -18,7 +18,7 @@ class AsyncGRPCClient(GRPCBaseClient, AsyncPostMixin):\n \n     :class:`AsyncGRPCClient` can be very useful in\n     the integration settings, where Jina/Flow/Client is NOT the main logic, but rather served as a part of other program.\n-    In this case, users often do not want to let Jina control the ``asyncio.eventloop``. On contrary, :class:`Client`\n+    In this case, users often do **NOT** want to let Jina control the ``asyncio.eventloop``. On contrary, :class:`Client`\n     is controlling and wrapping the event loop internally, making the Client looks synchronous from outside.\n \n     \"\"\"\n\n---\n file path A: jina/clients/mixin.py | file path B: jina/clients/mixin.py\n\n@@ -1,15 +1,15 @@\n-from functools import partialmethod, wraps\n-from typing import Optional, Dict, List, AsyncGenerator, TYPE_CHECKING, Union\n import warnings\n+from functools import partialmethod, wraps\n from inspect import signature\n+from typing import TYPE_CHECKING, AsyncGenerator, Dict, List, Optional, Union\n \n-from jina.helper import run_async, get_or_reuse_loop\n+from jina.helper import get_or_reuse_loop, run_async\n from jina.importer import ImportExtensions\n \n if TYPE_CHECKING:\n+    from jina import DocumentArray\n     from jina.clients.base import CallbackFnType, InputType\n     from jina.types.request import Response\n-    from jina import DocumentArray\n \n \n def _include_results_field_in_param(parameters: Optional['Dict']) -> 'Dict':\n@@ -102,8 +102,8 @@ class PostMixin:\n     ) -> Optional[Union['DocumentArray', List['Response']]]:\n         \"\"\"Post a general data request to the Flow.\n \n-        :param inputs: input data which can be an Iterable, a function which returns an Iterable, or a single Document id.\n-        :param on: the endpoint is used for identifying the user-defined ``request_type``, labeled by ``@requests(on='/abc')``\n+        :param inputs: input data which can be an Iterable, a function which returns an Iterable, or a single Document.\n+        :param on: the endpoint which is invoked. All the functions in the executors decorated by `@requests(on=...)` with the same endpoint are invoked.\n         :param on_done: the function to be called when the :class:`Request` object is resolved.\n         :param on_error: the function to be called when the :class:`Request` object is rejected.\n         :param on_always: the function to be called when the :class:`Request` object is either resolved or rejected.\n@@ -116,8 +116,7 @@ class PostMixin:\n         :return: None or DocumentArray containing all response Documents\n \n         .. warning::\n-            ``target_executor`` uses ``re.match`` for checking if the pattern is matched.\n-             ``target_executor=='foo'`` will match both deployments with the name ``foo`` and ``foo_what_ever_suffix``.\n+            ``target_executor`` uses ``re.match`` for checking if the pattern is matched. ``target_executor=='foo'`` will match both deployments with the name ``foo`` and ``foo_what_ever_suffix``.\n         \"\"\"\n \n         return_results = False\n@@ -184,13 +183,13 @@ class AsyncPostMixin:\n         continue_on_error: bool = False,\n         **kwargs,\n     ) -> AsyncGenerator[None, 'Response']:\n-        \"\"\"Post a general data request to the Flow.\n+        \"\"\"Async Post a general data request to the Flow.\n \n-        :param inputs: input data which can be an Iterable, a function which returns an Iterable, or a single Document id.\n-        :param on: the endpoint is used for identifying the user-defined ``request_type``, labeled by ``@requests(on='/abc')``\n+        :param inputs: input data which can be an Iterable, a function which returns an Iterable, or a single Document.\n+        :param on: the endpoint which is invoked. All the functions in the executors decorated by `@requests(on=...)` with the same endpoint are invoked.\n         :param on_done: the function to be called when the :class:`Request` object is resolved.\n         :param on_error: the function to be called when the :class:`Request` object is rejected.\n-        :param on_always: the function to be called when the :class:`Request` object is  is either resolved or rejected.\n+        :param on_always: the function to be called when the :class:`Request` object is either resolved or rejected.\n         :param parameters: the kwargs that will be sent to the executor\n         :param target_executor: a regex string. Only matching Executors will process the request.\n         :param request_size: the number of Documents per request. <=0 means all inputs in one request.\n@@ -198,6 +197,9 @@ class AsyncPostMixin:\n         :param continue_on_error: if set, a Request that causes callback error will be logged only without blocking the further requests.\n         :param kwargs: additional parameters\n         :yield: Response object\n+\n+        .. warning::\n+            ``target_executor`` uses ``re.match`` for checking if the pattern is matched. ``target_executor=='foo'`` will match both deployments with the name ``foo`` and ``foo_what_ever_suffix``.\n         \"\"\"\n         c = self.client\n         c.show_progress = show_progress\n\n\n###\n\n", "completion": "docs(clients): update docstrings (#<issue-num>)"}
{"prompt": " file path A: docs/fundamentals/flow/index.md | file path B: docs/fundamentals/flow/index.md\n\n@@ -14,7 +14,7 @@ The most important methods of the `Flow` object are the following:\n |------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------|\n | `.add()`                           | Add an Executor to the Flow                                                                                                                |\n | `.start()`                         | Starts the Flow. This will start all its Executors and check if they are ready to be used.                                                 |\n-| `.stop()`                          | Stops the Flow. This will stop all its Executors.                                                                                          |\n+| `.close()`                         | Stops and closes the Flow. This will stop and shutdown all its Executors.                                                                                          |\n | `with` context manager             | Use the Flow as a context manager. It will automatically start and stop your Flow.                                         |                                                                |\n | `.plot()`                          | Visualizes the Flow. Helpful for building complex pipelines.                                                                                 |\n | `.post()`                          | Sends requests to the Flow API.                                                                                                     |\n\n\n###\n\n", "completion": "docs: fix flow api (#<issue-num>)"}
{"prompt": " file path A: jina/hubble/hubio.py | file path B: jina/hubble/hubio.py\n\n@@ -7,30 +7,30 @@ import json\n import os\n import random\n from pathlib import Path\n-from typing import Optional, Union, Dict\n+from typing import Dict, Optional, Union\n from urllib.parse import urlencode\n \n+from jina import __resources_path__, __version__\n+from jina.helper import ArgNamespace, colored, get_request_header\n from jina.hubble import HubExecutor\n from jina.hubble.helper import (\n     archive_package,\n+    disk_cache_offline,\n     download_with_resume,\n+    get_cache_db,\n+    get_download_cache_dir,\n     get_hubble_url_v2,\n     parse_hub_uri,\n     upload_file,\n-    disk_cache_offline,\n-    get_cache_db,\n-    get_download_cache_dir,\n )\n from jina.hubble.hubapi import (\n-    install_local,\n-    get_dist_path_of_executor,\n-    load_secret,\n     dump_secret,\n+    get_dist_path_of_executor,\n     get_lockfile,\n+    install_local,\n     install_package_dependencies,\n+    load_secret,\n )\n-from jina import __resources_path__, __version__\n-from jina.helper import ArgNamespace, colored, get_request_header\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n from jina.parsers.hubble import set_hub_parser\n@@ -60,9 +60,9 @@ class HubIO:\n         self.logger = JinaLogger(self.__class__.__name__, **vars(args))\n \n         with ImportExtensions(required=True):\n-            import rich\n             import cryptography\n             import filelock\n+            import rich\n \n             assert rich  #: prevent pycharm auto remove the above line\n             assert cryptography\n@@ -71,13 +71,13 @@ class HubIO:\n     def new(self) -> None:\n         \"\"\"Create a new executor folder interactively.\"\"\"\n \n-        from rich import print, box\n-        from rich.prompt import Prompt, Confirm\n-        from rich.panel import Panel\n-        from rich.table import Table\n+        from rich import box, print\n         from rich.console import Console\n+        from rich.panel import Panel\n         from rich.progress import track\n+        from rich.prompt import Confirm, Prompt\n         from rich.syntax import Syntax\n+        from rich.table import Table\n \n         console = Console()\n \n@@ -468,8 +468,8 @@ metas:\n     def _prettyprint_result(self, console, image):\n         # TODO: only support single executor now\n \n-        from rich.table import Table\n         from rich.panel import Panel\n+        from rich.table import Table\n \n         uuid8 = image['id']\n         secret = image['secret']\n@@ -559,13 +559,16 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n     def fetch_meta(\n         name: str,\n         tag: str,\n+        *,\n         secret: Optional[str] = None,\n+        image_required: bool = True,\n         force: bool = False,\n     ) -> HubExecutor:\n         \"\"\"Fetch the executor meta info from Jina Hub.\n         :param name: the UUID/Name of the executor\n         :param tag: the tag of the executor if available, otherwise, use `None` as the value\n         :param secret: the access secret of the executor\n+        :param image_required: it indicates whether a Docker image is required or not\n         :param force: if set to True, access to fetch_meta will always pull latest Executor metas, otherwise, default\n             to local cache\n         :return: meta of executor\n@@ -577,17 +580,18 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n         with ImportExtensions(required=True):\n             import requests\n \n-        pull_url = get_hubble_url_v2() + f'/rpc/executor.getPackage?id={name}'\n-        path_params = {}\n+        pull_url = get_hubble_url_v2() + f'/rpc/executor.getPackage'\n+\n+        payload = {'id': name, 'include': ['code']}\n+        if image_required:\n+            payload['include'].append('docker')\n         if secret:\n-            path_params['secret'] = secret\n+            payload['secret'] = secret\n         if tag:\n-            path_params['tag'] = tag\n-        if path_params:\n-            pull_url += f'&{urlencode(path_params)}'\n+            payload['tag'] = tag\n \n         req_header = get_request_header()\n-        resp = requests.get(pull_url, headers=req_header)\n+        resp = requests.post(pull_url, json=payload, headers=req_header)\n         if resp.status_code != 200:\n             if resp.text:\n                 raise Exception(resp.text)\n@@ -597,7 +601,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n \n         images = resp['package'].get('containers', [])\n         image_name = images[0] if images else None\n-        if not image_name:\n+        if image_required and not image_name:\n             raise Exception(\n                 f'No image found for executor \"{name}\", '\n                 f'tag: {tag}, commit: {resp.get(\"commit\", {}).get(\"id\")}, '\n@@ -635,8 +639,8 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n             'args': args_copy,\n         }\n \n-        from rich.progress import Console\n         import requests\n+        from rich.progress import Console\n \n         console = Console()\n \n@@ -674,9 +678,10 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n                     headers=get_request_header(),\n                 ).json()\n \n-                host = json_response.get('data', {}).get('host', None)\n-                port = json_response.get('data', {}).get('port', None)\n-                livetime = json_response.get('data', {}).get('livetime', '15 mins')\n+                data = json_response.get('data') or {}\n+                host = data.get('host', None)\n+                port = data.get('port', None)\n+                livetime = data.get('livetime', '15 mins')\n                 if not host or not port:\n                     raise Exception(f'Failed to deploy sandbox: {json_response}')\n \n@@ -691,7 +696,7 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n         return host, port\n \n     def _pull_with_progress(self, log_streams, console):\n-        from rich.progress import Progress, DownloadColumn, BarColumn\n+        from rich.progress import BarColumn, DownloadColumn, Progress\n \n         with Progress(\n             \"[progress.description]{task.description}\",\n@@ -730,8 +735,8 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n \n     def _load_docker_client(self):\n         with ImportExtensions(required=True):\n-            import docker.errors\n             import docker\n+            import docker.errors\n             from docker import APIClient\n \n             from jina import __windows__\n@@ -767,10 +772,15 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n             need_pull = self.args.force_update\n             with console.status(f'Pulling {self.args.uri}...') as st:\n                 scheme, name, tag, secret = parse_hub_uri(self.args.uri)\n+                image_required = scheme == 'jinahub+docker'\n \n                 st.update(f'Fetching [bold]{name}[/bold] from Jina Hub ...')\n                 executor, from_cache = HubIO.fetch_meta(\n-                    name, tag, secret=secret, force=need_pull\n+                    name,\n+                    tag,\n+                    secret=secret,\n+                    image_required=image_required,\n+                    force=need_pull,\n                 )\n \n                 presented_id = getattr(executor, 'name', executor.uuid)\n@@ -832,7 +842,11 @@ f = Flow().add(uses='jinahub+sandbox://{executor_name}')\n                             # pull the latest executor meta, as the cached data would expire\n                             if from_cache:\n                                 executor, _ = HubIO.fetch_meta(\n-                                    name, tag, secret=secret, force=True\n+                                    name,\n+                                    tag,\n+                                    secret=secret,\n+                                    image_required=False,\n+                                    force=True,\n                                 )\n \n                             st.update(f'Downloading {name} ...')\n\n---\n file path A: tests/integration/hub_usage/test_hub_usage.py | file path B: tests/integration/hub_usage/test_hub_usage.py\n\n@@ -1,12 +1,13 @@\n import os\n from pathlib import Path\n+\n import pytest\n \n from jina import Flow\n from jina.excepts import RuntimeFailToStart\n-from jina.serve.executors import BaseExecutor\n-from jina.parsers import set_deployment_parser\n from jina.orchestrate.deployments import Deployment\n+from jina.parsers import set_deployment_parser\n+from jina.serve.executors import BaseExecutor\n \n cur_dir = os.path.dirname(os.path.abspath(__file__))\n \n@@ -49,7 +50,7 @@ def test_use_from_local_dir_flow_level():\n \n @pytest.fixture\n def local_hub_executor(tmpdir, test_envs):\n-    from jina.hubble import hubapi, helper, HubExecutor\n+    from jina.hubble import HubExecutor, helper, hubapi\n \n     hubapi._hub_root = Path(os.environ.get('JINA_HUB_ROOT'))\n \n@@ -66,11 +67,11 @@ def local_hub_executor(tmpdir, test_envs):\n def test_use_from_local_hub_deployment_level(\n     test_envs, mocker, monkeypatch, local_hub_executor\n ):\n-    from jina.hubble.hubio import HubIO, HubExecutor\n+    from jina.hubble.hubio import HubExecutor, HubIO\n \n     mock = mocker.Mock()\n \n-    def _mock_fetch(name, tag=None, secret=None, force=False):\n+    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n         mock(name=name)\n         return (\n             HubExecutor(\n@@ -94,11 +95,11 @@ def test_use_from_local_hub_deployment_level(\n def test_use_from_local_hub_flow_level(\n     test_envs, mocker, monkeypatch, local_hub_executor\n ):\n-    from jina.hubble.hubio import HubIO, HubExecutor\n+    from jina.hubble.hubio import HubExecutor, HubIO\n \n     mock = mocker.Mock()\n \n-    def _mock_fetch(name, tag=None, secret=None, force=False):\n+    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n         mock(name=name)\n         return (\n             HubExecutor(\n\n---\n file path A: tests/unit/hubble/test_hubio.py | file path B: tests/unit/hubble/test_hubio.py\n\n@@ -1,9 +1,9 @@\n-from argparse import Namespace\n import itertools\n import json\n import os\n import shutil\n import urllib\n+from argparse import Namespace\n from pathlib import Path\n \n import docker\n@@ -59,7 +59,7 @@ class PostMockResponse:\n         return itertools.chain(logs)\n \n \n-class GetMockResponse:\n+class FetchMetaMockResponse:\n     def __init__(self, response_code: int = 200, no_image=False):\n         self.response_code = response_code\n         self.no_image = no_image\n@@ -166,11 +166,11 @@ def test_push_wrong_dockerfile(\n def test_fetch(mocker, monkeypatch):\n     mock = mocker.Mock()\n \n-    def _mock_get(url, headers=None):\n-        mock(url=url)\n-        return GetMockResponse(response_code=200)\n+    def _mock_post(url, json, headers=None):\n+        mock(url=url, json=json)\n+        return FetchMetaMockResponse(response_code=200)\n \n-    monkeypatch.setattr(requests, 'get', _mock_get)\n+    monkeypatch.setattr(requests, 'post', _mock_post)\n     args = set_hub_pull_parser().parse_args(['jinahub://dummy_mwu_encoder'])\n \n     executor, _ = HubIO(args).fetch_meta('dummy_mwu_encoder', None, force=True)\n@@ -191,17 +191,23 @@ def test_fetch(mocker, monkeypatch):\n def test_fetch_with_no_image(mocker, monkeypatch):\n     mock = mocker.Mock()\n \n-    def _mock_get(url, headers=None):\n-        mock(url=url)\n-        return GetMockResponse(response_code=200, no_image=True)\n+    def _mock_post(url, json, headers=None):\n+        mock(url=url, json=json)\n+        return FetchMetaMockResponse(response_code=200, no_image=True)\n \n-    monkeypatch.setattr(requests, 'get', _mock_get)\n+    monkeypatch.setattr(requests, 'post', _mock_post)\n \n     with pytest.raises(Exception) as exc_info:\n         HubIO.fetch_meta('dummy_mwu_encoder', tag=None, force=True)\n \n     assert exc_info.match('No image found for executor \"dummy_mwu_encoder\"')\n-    assert mock.call_count == 1\n+\n+    executor, _ = HubIO.fetch_meta(\n+        'dummy_mwu_encoder', tag=None, image_required=False, force=True\n+    )\n+\n+    assert executor.image_name is None\n+    assert mock.call_count == 2\n \n \n class DownloadMockResponse:\n@@ -221,7 +227,7 @@ class DownloadMockResponse:\n def test_pull(test_envs, mocker, monkeypatch):\n     mock = mocker.Mock()\n \n-    def _mock_fetch(name, tag=None, secret=None, force=False):\n+    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n         mock(name=name)\n         return (\n             HubExecutor(\n@@ -278,7 +284,7 @@ def test_offline_pull(test_envs, mocker, monkeypatch, tmpfile):\n     version = 'v0'\n \n     @disk_cache_offline(cache_file=str(tmpfile))\n-    def _mock_fetch(name, tag=None, secret=None, force=False):\n+    def _mock_fetch(name, tag=None, secret=None, image_required=True, force=False):\n         mock(name=name)\n         if fail_meta_fetch:\n             raise urllib.error.URLError('Failed fetching meta')\n@@ -360,7 +366,7 @@ def test_pull_with_progress():\n \n @pytest.mark.parametrize('add_dockerfile', [True, False])\n def test_new_without_arguments(monkeypatch, tmpdir, add_dockerfile):\n-    from rich.prompt import Prompt, Confirm\n+    from rich.prompt import Confirm, Prompt\n \n     prompts = iter(\n         [\n\n\n###\n\n", "completion": "feat(hubble): fetch image only when required (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -83,9 +83,7 @@ ac_table = {\n             '--runtime-cls',\n             '--timeout-ready',\n             '--env',\n-            '--expose-public',\n             '--shard-id',\n-            '--replica-id',\n             '--pod-role',\n             '--noblock-on-start',\n             '--shards',\n@@ -162,9 +160,7 @@ ac_table = {\n             '--runtime-cls',\n             '--timeout-ready',\n             '--env',\n-            '--expose-public',\n             '--shard-id',\n-            '--replica-id',\n             '--pod-role',\n             '--noblock-on-start',\n             '--shards',\n@@ -242,9 +238,7 @@ ac_table = {\n             '--runtime-cls',\n             '--timeout-ready',\n             '--env',\n-            '--expose-public',\n             '--shard-id',\n-            '--replica-id',\n             '--pod-role',\n             '--noblock-on-start',\n             '--shards',\n@@ -294,9 +288,7 @@ ac_table = {\n             '--runtime-cls',\n             '--timeout-ready',\n             '--env',\n-            '--expose-public',\n             '--shard-id',\n-            '--replica-id',\n             '--pod-role',\n             '--noblock-on-start',\n             '--shards',\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -134,7 +134,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         disable_reduce: Optional[bool] = False,\n         env: Optional[dict] = None,\n         expose_endpoints: Optional[str] = None,\n-        expose_public: Optional[bool] = False,\n         graph_description: Optional[str] = '{}',\n         host: Optional[str] = '0.0.0.0',\n         host_in: Optional[str] = '0.0.0.0',\n@@ -180,7 +179,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         :param disable_reduce: Disable the built-in reduce mechanism, set this if the reduction is to be handled by the Executor connected to this Head\n         :param env: The map of environment variables that are available inside runtime\n         :param expose_endpoints: A JSON string that represents a map from executor endpoints (`@requests(on=...)`) to HTTP endpoints.\n-        :param expose_public: If set, expose the public IP address to remote when necessary, by default it exposesprivate IP address, which only allows accessing under the same network/subnet. Important to set this to true when the Pod will receive input connections from remote Pods\n         :param graph_description: Routing graph for the gateway\n         :param host: The host address of the runtime, by default it is 0.0.0.0.\n         :param host_in: The host address for binding to, by default it is 0.0.0.0\n@@ -586,7 +584,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n         docker_kwargs: Optional[dict] = None,\n         entrypoint: Optional[str] = None,\n         env: Optional[dict] = None,\n-        expose_public: Optional[bool] = False,\n         external: Optional[bool] = False,\n         force_update: Optional[bool] = False,\n         gpus: Optional[str] = None,\n@@ -634,7 +631,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n           More details can be found in the Docker SDK docs:  https://docker-py.readthedocs.io/en/stable/\n         :param entrypoint: The entrypoint command overrides the ENTRYPOINT in Docker image. when not set then the Docker image ENTRYPOINT takes effective.\n         :param env: The map of environment variables that are available inside runtime\n-        :param expose_public: If set, expose the public IP address to remote when necessary, by default it exposesprivate IP address, which only allows accessing under the same network/subnet. Important to set this to true when the Pod will receive input connections from remote Pods\n         :param external: The Deployment will be considered an external Deployment that has been started independently from the Flow.This Deployment will not be context managed by the Flow.\n         :param force_update: If set, always pull the latest Hub Executor bundle even it exists on local\n         :param gpus: This argument allows dockerized Jina executor discover local gpu devices.\n\n---\n file path A: jina/parsers/orchestrate/pod.py | file path B: jina/parsers/orchestrate/pod.py\n\n@@ -53,15 +53,6 @@ def mixin_pod_parser(parser):\n         help='The map of environment variables that are available inside runtime',\n     )\n \n-    gp.add_argument(\n-        '--expose-public',\n-        action='store_true',\n-        default=False,\n-        help='If set, expose the public IP address to remote when necessary, by default it exposes'\n-        'private IP address, which only allows accessing under the same network/subnet. Important to '\n-        'set this to true when the Pod will receive input connections from remote Pods',\n-    )\n-\n     # hidden CLI used for internal only\n \n     gp.add_argument(\n@@ -73,15 +64,6 @@ def mixin_pod_parser(parser):\n         else argparse.SUPPRESS,\n     )\n \n-    gp.add_argument(\n-        '--replica-id',\n-        type=int,\n-        default=0,\n-        help='the id of the replica of an executor'\n-        if _SHOW_ALL_ARGS\n-        else argparse.SUPPRESS,\n-    )\n-\n     gp.add_argument(\n         '--pod-role',\n         type=PodRoleType.from_string,\n\n\n###\n\n", "completion": "refactor: remove replica-id and expose public args (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -150,9 +150,6 @@ ac_table = {\n             '--expose-endpoints',\n             '--uvicorn-kwargs',\n             '--no-graphql-endpoint',\n-            '--compress',\n-            '--compress-min-bytes',\n-            '--compress-min-ratio',\n             '--protocol',\n             '--host',\n             '--proxy',\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -125,9 +125,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n     def __init__(\n         self,\n         *,\n-        compress: Optional[str] = 'NONE',\n-        compress_min_bytes: Optional[int] = 1024,\n-        compress_min_ratio: Optional[float] = 1.1,\n         connection_list: Optional[str] = None,\n         cors: Optional[bool] = False,\n         daemon: Optional[bool] = False,\n@@ -174,12 +171,6 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n     ):\n         \"\"\"Create a Flow. Flow is how Jina streamlines and scales Executors. This overloaded method provides arguments from `jina gateway` CLI.\n \n-        :param compress: The compress algorithm used over the entire Flow.\n-\n-              Note that this is not necessarily effective,\n-              it depends on the settings of `--compress-min-bytes` and `compress-min-ratio`\n-        :param compress_min_bytes: The original message size must be larger than this number to trigger the compress algorithm, -1 means disable compression.\n-        :param compress_min_ratio: The compression ratio (uncompressed_size/compressed_size) must be higher than this number to trigger the compress algorithm.\n         :param connection_list: dictionary JSON with a list of connections to configure\n         :param cors: If set, a CORS middleware is added to FastAPI frontend to allow cross-origin access.\n         :param daemon: The Pod attempts to terminate all of its Runtime child processes/threads on existing. setting it to true basically tell the Pod do not wait on the Runtime when closing\n\n---\n file path A: jina/parsers/__init__.py | file path B: jina/parsers/__init__.py\n\n@@ -14,17 +14,17 @@ def set_pod_parser(parser=None):\n \n         parser = set_base_parser()\n \n+    from jina.parsers.hubble.pull import mixin_hub_pull_options_parser\n     from jina.parsers.orchestrate.base import mixin_base_ppr_parser\n-    from jina.parsers.orchestrate.runtimes.worker import mixin_worker_runtime_parser\n+    from jina.parsers.orchestrate.pod import mixin_pod_parser\n     from jina.parsers.orchestrate.runtimes.container import (\n         mixin_container_runtime_parser,\n     )\n-    from jina.parsers.orchestrate.runtimes.remote import mixin_remote_runtime_parser\n-    from jina.parsers.orchestrate.pod import mixin_pod_parser\n     from jina.parsers.orchestrate.runtimes.distributed import (\n         mixin_distributed_feature_parser,\n     )\n-    from jina.parsers.hubble.pull import mixin_hub_pull_options_parser\n+    from jina.parsers.orchestrate.runtimes.remote import mixin_remote_runtime_parser\n+    from jina.parsers.orchestrate.runtimes.worker import mixin_worker_runtime_parser\n \n     mixin_base_ppr_parser(parser)\n     mixin_worker_runtime_parser(parser)\n@@ -70,22 +70,20 @@ def set_gateway_parser(parser=None):\n         parser = set_base_parser()\n \n     from jina.parsers.orchestrate.base import mixin_base_ppr_parser\n-    from jina.parsers.orchestrate.runtimes.worker import mixin_worker_runtime_parser\n+    from jina.parsers.orchestrate.pod import mixin_pod_parser\n     from jina.parsers.orchestrate.runtimes.remote import (\n         mixin_gateway_parser,\n-        mixin_prefetch_parser,\n-        mixin_http_gateway_parser,\n-        mixin_compressor_parser,\n         mixin_graphql_parser,\n+        mixin_http_gateway_parser,\n+        mixin_prefetch_parser,\n     )\n-    from jina.parsers.orchestrate.pod import mixin_pod_parser\n+    from jina.parsers.orchestrate.runtimes.worker import mixin_worker_runtime_parser\n \n     mixin_base_ppr_parser(parser)\n     mixin_worker_runtime_parser(parser)\n     mixin_prefetch_parser(parser)\n     mixin_http_gateway_parser(parser)\n     mixin_graphql_parser(parser)\n-    mixin_compressor_parser(parser)\n     mixin_comm_protocol_parser(parser)\n     mixin_gateway_parser(parser)\n     mixin_pod_parser(parser)\n@@ -113,11 +111,11 @@ def set_client_cli_parser(parser=None):\n \n         parser = set_base_parser()\n \n-    from jina.parsers.orchestrate.runtimes.remote import mixin_client_gateway_parser\n     from jina.parsers.client import (\n         mixin_client_features_parser,\n         mixin_comm_protocol_parser,\n     )\n+    from jina.parsers.orchestrate.runtimes.remote import mixin_client_gateway_parser\n \n     mixin_client_gateway_parser(parser)\n     mixin_client_features_parser(parser)\n@@ -152,15 +150,13 @@ def get_main_parser():\n     :return: the parser\n     \"\"\"\n     from jina.parsers.base import set_base_parser\n-    from jina.parsers.helloworld import set_hello_parser\n-    from jina.parsers.helper import _chf, _SHOW_ALL_ARGS\n     from jina.parsers.create import set_new_project_parser\n-\n     from jina.parsers.export_api import set_export_api_parser\n     from jina.parsers.flow import set_flow_parser\n-    from jina.parsers.ping import set_ping_parser\n-\n+    from jina.parsers.helloworld import set_hello_parser\n+    from jina.parsers.helper import _SHOW_ALL_ARGS, _chf\n     from jina.parsers.hubble import set_hub_parser\n+    from jina.parsers.ping import set_ping_parser\n \n     # create the top-level parser\n     parser = set_base_parser()\n\n---\n file path A: jina/parsers/orchestrate/runtimes/remote.py | file path B: jina/parsers/orchestrate/runtimes/remote.py\n\n@@ -199,38 +199,3 @@ def mixin_prefetch_parser(parser=None):\n     \n     Used to control the speed of data input into a Flow. 0 disables prefetch (disabled by default)''',\n     )\n-\n-\n-def mixin_compressor_parser(parser=None):\n-    \"\"\"Add the options for compressors\n-    :param parser: the parser\n-    \"\"\"\n-    gp = add_arg_group(parser, title='Compression')\n-\n-    gp.add_argument(\n-        '--compress',\n-        type=CompressAlgo.from_string,\n-        choices=list(CompressAlgo),\n-        default=CompressAlgo.NONE,\n-        help='''\n-    The compress algorithm used over the entire Flow.\n-\n-    Note that this is not necessarily effective,\n-    it depends on the settings of `--compress-min-bytes` and `compress-min-ratio`''',\n-    )\n-\n-    gp.add_argument(\n-        '--compress-min-bytes',\n-        type=int,\n-        default=1024,\n-        help='The original message size must be larger than this number to trigger the compress algorithm, '\n-        '-1 means disable compression.',\n-    )\n-\n-    gp.add_argument(\n-        '--compress-min-ratio',\n-        type=float,\n-        default=1.1,\n-        help='The compression ratio (uncompressed_size/compressed_size) must be higher than this number '\n-        'to trigger the compress algorithm.',\n-    )\n\n\n###\n\n", "completion": "refactor: remove compression related args (#<issue-num>)"}
{"prompt": " file path A: jina/helloworld/multimodal/my_executors.py | file path B: jina/helloworld/multimodal/my_executors.py\n\n@@ -88,18 +88,14 @@ class TextCrafter(Executor):\n \n     @requests()\n     def filter(self, docs: DocumentArray, **kwargs):\n-        filtered_docs = DocumentArray(\n-            d for d in docs['@c'] if d.mime_type == 'text/plain'\n-        )\n+        filtered_docs = DocumentArray(d for d in docs['@c'] if d.text != '')\n         return filtered_docs\n \n \n class ImageCrafter(Executor):\n     @requests(on=['/index', '/search'])\n     def craft(self, docs: DocumentArray, **kwargs):\n-        filtered_docs = DocumentArray(\n-            d for d in docs['@c'] if d.mime_type == 'image/jpeg'\n-        )\n+        filtered_docs = DocumentArray(d for d in docs['@c'] if d.text == '')\n         target_size = 224\n         for doc in filtered_docs:\n             doc.load_uri_to_image_tensor()\n\n---\n file path A: tests/unit/clients/python/test_request.py | file path B: tests/unit/clients/python/test_request.py\n\n@@ -3,7 +3,6 @@ import sys\n \n import numpy as np\n import pytest\n-from google.protobuf.json_format import MessageToDict, MessageToJson\n \n from docarray import Document\n from jina import Flow\n@@ -73,7 +72,6 @@ def test_request_generate_lines():\n \n     request = next(req)\n     assert len(request.docs) == 100\n-    assert request.docs[0].mime_type == 'text/plain'\n     assert request.docs[0].text == 'i\\'m dummy doc 1'\n \n \n@@ -86,7 +84,6 @@ def test_request_generate_lines_from_list():\n     request = next(req)\n     assert len(request.docs) == 100\n     for index, doc in enumerate(request.docs, 1):\n-        assert doc.mime_type == 'text/plain'\n         assert doc.text == f'i\\'m dummy doc {index}'\n \n \n@@ -101,7 +98,6 @@ def test_request_generate_bytes():\n     assert len(request.docs) == 100\n     for index, doc in enumerate(request.docs, 1):\n         assert doc.text == f'i\\'m dummy doc {index}'\n-        assert doc.mime_type == 'text/plain'\n \n \n def test_request_generate_docs():\n\n---\n file path A: tests/unit/helloworld/multimodal/test_executors.py | file path B: tests/unit/helloworld/multimodal/test_executors.py\n\n@@ -67,7 +67,6 @@ def test_segmenter(segmenter_doc_array, tmpdir):\n     assert len(res) == 2\n     for doc in res:\n         assert len(doc.chunks) == 2\n-        assert doc.chunks[0].mime_type == 'text/plain'\n         assert doc.chunks[1].mime_type == 'image/jpeg'\n         assert doc.chunks[1].mime_type == 'image/jpeg'\n         assert doc.uri.startswith('data')\n\n\n###\n\n", "completion": "test: fix tests failures caused by docarray (#<issue-num>)"}
{"prompt": " file path A: jina/helloworld/multimodal/my_executors.py | file path B: jina/helloworld/multimodal/my_executors.py\n\n@@ -6,8 +6,8 @@ import torch\n import torchvision.models as models\n from transformers import AutoModel, AutoTokenizer\n \n-from jina import Executor, requests\n from docarray import Document, DocumentArray\n+from jina import Executor, requests\n \n \n class Segmenter(Executor):\n@@ -16,8 +16,8 @@ class Segmenter(Executor):\n         for doc in docs:\n             text = doc.tags['caption']\n             uri = f'{os.environ[\"HW_WORKDIR\"]}/people-img/{doc.tags[\"image\"]}'\n-            chunk_text = Document(text=text, mime_type='text/plain')\n-            chunk_uri = Document(uri=uri, mime_type='image/jpeg')\n+            chunk_text = Document(text=text)\n+            chunk_uri = Document(uri=uri)\n             doc.chunks = DocumentArray([chunk_text, chunk_uri])\n             doc.uri = uri\n             doc.convert_uri_to_datauri()\n@@ -89,7 +89,7 @@ class TextCrafter(Executor):\n     @requests()\n     def filter(self, docs: DocumentArray, **kwargs):\n         filtered_docs = DocumentArray(\n-            d for d in docs.traverse_flat('c') if d.mime_type == 'text/plain'\n+            d for d in docs['@c'] if d.mime_type == 'text/plain'\n         )\n         return filtered_docs\n \n@@ -98,7 +98,7 @@ class ImageCrafter(Executor):\n     @requests(on=['/index', '/search'])\n     def craft(self, docs: DocumentArray, **kwargs):\n         filtered_docs = DocumentArray(\n-            d for d in docs.traverse_flat('c') if d.mime_type == 'image/jpeg'\n+            d for d in docs['@c'] if d.mime_type == 'image/jpeg'\n         )\n         target_size = 224\n         for doc in filtered_docs:\n\n---\n file path A: tests/unit/clients/python/test_request.py | file path B: tests/unit/clients/python/test_request.py\n\n@@ -3,7 +3,7 @@ import sys\n \n import numpy as np\n import pytest\n-from google.protobuf.json_format import MessageToJson, MessageToDict\n+from google.protobuf.json_format import MessageToDict, MessageToJson\n \n from docarray import Document\n from jina import Flow\n@@ -111,7 +111,6 @@ def test_request_generate_docs():\n             doc.text = f'i\\'m dummy doc {j}'\n             doc.offset = 1000\n             doc.tags['id'] = 1000  # this will be ignored\n-            doc.mime_type = 'mime_type'\n             yield doc\n \n     req = request_generator('', data=random_docs(100), request_size=100)\n@@ -119,7 +118,6 @@ def test_request_generate_docs():\n     request = next(req)\n     assert len(request.docs) == 100\n     for index, doc in enumerate(request.docs, 1):\n-        assert doc.mime_type == 'mime_type'\n         assert doc.text == f'i\\'m dummy doc {index}'\n         assert doc.offset == 1000\n \n\n---\n file path A: tests/unit/helloworld/multimodal/test_executors.py | file path B: tests/unit/helloworld/multimodal/test_executors.py\n\n@@ -5,19 +5,19 @@ from PIL import Image\n \n from jina import Document, DocumentArray, Flow\n from jina.helloworld.multimodal.my_executors import (\n-    Segmenter,\n-    TextEncoder,\n-    TextCrafter,\n     ImageCrafter,\n     ImageEncoder,\n+    Segmenter,\n+    TextCrafter,\n+    TextEncoder,\n )\n \n \n @pytest.fixture(scope='function')\n def segmenter_doc_array():\n     inputs = [\n-        Document(tags={'caption': 'hello', 'image': '1.png'}),\n-        Document(tags={'caption': 'world', 'image': '2.png'}),\n+        Document(tags={'caption': 'hello', 'image': '1.jpg'}),\n+        Document(tags={'caption': 'world', 'image': '2.jpg'}),\n     ]\n     return DocumentArray(inputs)\n \n@@ -27,7 +27,7 @@ def encoder_doc_array():\n     document = Document()\n     chunk_text = Document(text='hello', mime_type='text/plain')\n     chunk_uri = Document(\n-        uri=f'{os.environ[\"HW_WORKDIR\"]}/people-img/1.png', mime_type='image/jpeg'\n+        uri=f'{os.environ[\"HW_WORKDIR\"]}/people-img/1.jpg', mime_type='image/jpeg'\n     )\n     document.chunks = [chunk_text, chunk_uri]\n     return DocumentArray([document])\n@@ -35,7 +35,7 @@ def encoder_doc_array():\n \n @pytest.fixture(scope='function')\n def encoder_doc_array_for_search(encoder_doc_array, tmpdir):\n-    create_test_img(path=str(tmpdir), file_name='1.png')\n+    create_test_img(path=str(tmpdir), file_name='1.jpg')\n     da = DocumentArray()\n     for doc in encoder_doc_array:\n         for chunk in doc.chunks:\n@@ -60,30 +60,27 @@ def test_segmenter(segmenter_doc_array, tmpdir):\n     into datauri to show the image in front-end.\n     \"\"\"\n \n-    def validate(resp):\n-        assert len(resp.data.docs) == 2\n-        for doc in resp.data.docs:\n-            assert len(doc.chunks) == 2\n-            assert doc.chunks[0].mime_type == 'text/plain'\n-            assert doc.chunks[1].mime_type == 'image/jpeg'\n-            assert doc.uri.startswith('data')\n-\n-    create_test_img(path=str(tmpdir), file_name='1.png')\n-    create_test_img(path=str(tmpdir), file_name='2.png')\n+    create_test_img(path=str(tmpdir), file_name='1.jpg')\n+    create_test_img(path=str(tmpdir), file_name='2.jpg')\n     with Flow().add(uses=Segmenter) as f:\n-        f.index(inputs=segmenter_doc_array, on_done=validate)\n+        res = f.index(inputs=segmenter_doc_array)\n+    assert len(res) == 2\n+    for doc in res:\n+        assert len(doc.chunks) == 2\n+        assert doc.chunks[0].mime_type == 'text/plain'\n+        assert doc.chunks[1].mime_type == 'image/jpeg'\n+        assert doc.chunks[1].mime_type == 'image/jpeg'\n+        assert doc.uri.startswith('data')\n \n \n def test_text_crafter(encoder_doc_array, tmpdir):\n-    def validate(resp):\n-        assert len(resp.data.docs) == 1\n-        doc = resp.data.docs[0]\n-        assert doc.mime_type == 'text/plain'\n-        assert doc.text\n-\n-    create_test_img(path=str(tmpdir), file_name='1.png')\n+    create_test_img(path=str(tmpdir), file_name='1.jpg')\n     with Flow().add(uses=TextCrafter) as f:\n-        f.index(inputs=encoder_doc_array, on_done=validate)\n+        res = f.index(inputs=encoder_doc_array)\n+    assert len(res) == 1\n+    doc = res[0]\n+    assert doc.mime_type == 'text/plain'\n+    assert doc.text\n \n \n @pytest.mark.slow\n@@ -94,16 +91,13 @@ def test_text_encoder(encoder_doc_array, tmpdir):\n     So the 2 chunks should left only 1 chunk with modality of `text/plain`.\n     And the embedding value of the ``Document`` is not empty once we finished encoding.\n     \"\"\"\n-\n-    def validate(resp):\n-        assert len(resp.data.docs) == 1\n-        doc = resp.data.docs[0]\n-        assert doc.mime_type == 'text/plain'\n-        assert doc.embedding is not None\n-\n-    create_test_img(path=str(tmpdir), file_name='1.png')\n+    create_test_img(path=str(tmpdir), file_name='1.jpg')\n     with Flow().add(uses=TextCrafter).add(uses=TextEncoder) as f:\n-        f.index(inputs=encoder_doc_array, on_done=validate)\n+        res = f.index(inputs=encoder_doc_array)\n+    assert len(res) == 1\n+    doc = res[0]\n+    assert doc.mime_type == 'text/plain'\n+    assert doc.embedding is not None\n \n \n def test_image_crafter_index(encoder_doc_array, tmpdir):\n@@ -114,45 +108,37 @@ def test_image_crafter_index(encoder_doc_array, tmpdir):\n     And the tensor value of the ``Document`` is not empty once we finished crafting since\n     we converted image uri/datauri to tensor.\n     \"\"\"\n-\n-    def validate(resp):\n-        assert len(resp.data.docs) == 1\n-        doc = resp.data.docs[0]\n-        assert doc.mime_type == 'image/jpeg'\n-        assert doc.tensor is not None\n-\n-    create_test_img(path=str(tmpdir), file_name='1.png')\n+    create_test_img(path=str(tmpdir), file_name='1.jpg')\n     with Flow().add(uses=ImageCrafter) as f:\n-        f.index(inputs=encoder_doc_array, on_done=validate)\n+        res = f.index(inputs=encoder_doc_array)\n+    assert len(res) == 1\n+    doc = res[0]\n+    assert doc.mime_type == 'image/jpeg'\n+    assert doc.tensor is not None\n \n \n def test_image_crafter_search(encoder_doc_array_for_search, tmpdir):\n-    def validate(resp):\n-        assert len(resp.data.docs) == 1\n-        chunk = resp.data.docs[0]\n-        assert chunk.mime_type == 'image/jpeg'\n-        assert chunk.tensor is not None\n-        assert chunk.uri.startswith('data')\n-\n     with Flow().add(uses=ImageCrafter) as f:\n-        f.search(inputs=encoder_doc_array_for_search, on_done=validate)\n+        res = f.search(inputs=encoder_doc_array_for_search)\n+    assert len(res) == 1\n+    chunk = res[0]\n+    assert chunk.mime_type == 'image/jpeg'\n+    assert chunk.tensor is not None\n+    assert chunk.uri.startswith('data')\n \n \n def test_image_encoder_index(encoder_doc_array, tmpdir):\n     \"\"\"In this test, we input one ``DocumentArray`` with one ``Document``,\n     and the `encode` method in the ``ImageEncoder``.\n     \"\"\"\n-\n-    def validate(resp):\n-        assert len(resp.data.docs) == 1\n-        for doc in resp.data.docs:\n-            assert doc.mime_type == 'image/jpeg'\n-            assert doc.embedding is not None\n-            assert doc.embedding.shape[0] == 1280\n-\n-    create_test_img(path=str(tmpdir), file_name='1.png')\n+    create_test_img(path=str(tmpdir), file_name='1.jpg')\n     with Flow().add(uses=ImageCrafter).add(uses=ImageEncoder) as f:\n-        f.index(inputs=encoder_doc_array, on_done=validate)\n+        res = f.index(inputs=encoder_doc_array)\n+    assert len(res) == 1\n+    for doc in res:\n+        assert doc.mime_type == 'image/jpeg'\n+        assert doc.embedding is not None\n+        assert doc.embedding.shape[0] == 1280\n \n \n def test_image_encoder_search(encoder_doc_array_for_search, tmpdir):\n@@ -160,12 +146,10 @@ def test_image_encoder_search(encoder_doc_array_for_search, tmpdir):\n     and the `encode` method in the ``ImageEncoder``.\n     \"\"\"\n \n-    def validate(resp):\n-        assert len(resp.data.docs) == 1\n-        for doc in resp.data.docs:\n-            assert doc.mime_type == 'image/jpeg'\n-            assert doc.embedding is not None\n-            assert doc.embedding.shape[0] == 1280\n-\n     with Flow().add(uses=ImageCrafter).add(uses=ImageEncoder) as f:\n-        f.search(inputs=encoder_doc_array_for_search, on_done=validate)\n+        res = f.search(inputs=encoder_doc_array_for_search)\n+    assert len(res) == 1\n+    for doc in res:\n+        assert doc.mime_type == 'image/jpeg'\n+        assert doc.embedding is not None\n+        assert doc.embedding.shape[0] == 1280\n\n---\n file path A: tests/unit/types/request/test_request.py | file path B: tests/unit/types/request/test_request.py\n\n@@ -3,15 +3,13 @@ import copy\n import pytest\n from google.protobuf.json_format import MessageToDict, MessageToJson\n \n-from docarray.proto.docarray_pb2 import DocumentProto\n+from docarray import Document, DocumentArray\n from jina.excepts import BadRequestType\n from jina.helper import random_identity\n from jina.proto import jina_pb2\n-from docarray import DocumentArray, Document\n from jina.proto.serializer import DataRequestProto\n from jina.types.request.control import ControlRequest\n from jina.types.request.data import DataRequest, Response\n-from tests import random_docs\n \n \n @pytest.fixture(scope='function')\n\n\n###\n\n", "completion": "test: fix tests failing after new docarray patch (#<issue-num>)"}
{"prompt": " file path A: cli/autocomplete.py | file path B: cli/autocomplete.py\n\n@@ -77,7 +77,6 @@ ac_table = {\n             '--port-jinad',\n             '--quiet-remote-logs',\n             '--upload-files',\n-            '--disable-remote',\n             '--daemon',\n             '--runtime-backend',\n             '--runtime',\n@@ -240,7 +239,6 @@ ac_table = {\n             '--port-jinad',\n             '--quiet-remote-logs',\n             '--upload-files',\n-            '--disable-remote',\n             '--daemon',\n             '--runtime-backend',\n             '--runtime',\n@@ -293,7 +291,6 @@ ac_table = {\n             '--port-jinad',\n             '--quiet-remote-logs',\n             '--upload-files',\n-            '--disable-remote',\n             '--daemon',\n             '--runtime-backend',\n             '--runtime',\n\n---\n file path A: jina/orchestrate/pods/factory.py | file path B: jina/orchestrate/pods/factory.py\n\n@@ -3,13 +3,12 @@ from copy import deepcopy\n from typing import TYPE_CHECKING, Type\n \n from jina import __default_host__\n-from jina.orchestrate.pods import Pod\n-from jina.orchestrate.pods.jinad import JinaDPod\n-from jina.orchestrate.pods.container import ContainerPod\n from jina.enums import PodRoleType\n-\n from jina.hubble.helper import is_valid_huburi\n from jina.hubble.hubio import HubIO\n+from jina.orchestrate.pods import Pod\n+from jina.orchestrate.pods.container import ContainerPod\n+from jina.orchestrate.pods.jinad import JinaDPod\n \n if TYPE_CHECKING:\n     from jina.orchestrate.pods import BasePod\n@@ -30,7 +29,7 @@ class PodFactory:\n         \"\"\"\n         # copy to update but forward original\n         cargs = deepcopy(args)\n-        if cargs.host != __default_host__ and not cargs.disable_remote:\n+        if cargs.host != __default_host__:\n             cargs.timeout_ready = -1\n             return JinaDPod(cargs)\n \n\n---\n file path A: jina/orchestrate/pods/jinad.py | file path B: jina/orchestrate/pods/jinad.py\n\n@@ -1,23 +1,23 @@\n-import copy\n-import asyncio\n import argparse\n-import threading\n+import asyncio\n+import copy\n import multiprocessing\n+import threading\n from pathlib import Path\n-from typing import TYPE_CHECKING, Dict, List, Union, Optional\n+from typing import TYPE_CHECKING, Dict, List, Optional, Union\n \n-from jina.orchestrate.pods import BasePod\n-from jina.orchestrate.pods.helper import _get_worker, is_ready\n-from jina.helper import run_async\n-from jina.jaml.helper import complete_path\n-from jina.importer import ImportExtensions\n from jina.enums import replace_enum_to_str\n-from jina.logging.logger import JinaLogger\n from jina.excepts import (\n     DaemonConnectivityError,\n     DaemonPodCreationFailed,\n     DaemonWorkspaceCreationFailed,\n )\n+from jina.helper import run_async\n+from jina.importer import ImportExtensions\n+from jina.jaml.helper import complete_path\n+from jina.logging.logger import JinaLogger\n+from jina.orchestrate.pods import BasePod\n+from jina.orchestrate.pods.helper import _get_worker, is_ready\n \n if TYPE_CHECKING:\n     import argparse\n@@ -86,8 +86,9 @@ class JinaDProcessTarget:\n         \"\"\"Create Workspace, Pod on remote JinaD server\"\"\"\n         with ImportExtensions(required=True):\n             # rich & aiohttp are used in `AsyncJinaDClient`\n-            import rich\n             import aiohttp\n+            import rich\n+\n             from daemon.clients import AsyncJinaDClient\n \n             assert rich\n@@ -164,9 +165,9 @@ class JinaDProcessTarget:\n         cargs = copy.deepcopy(self.args)\n \n         # TODO:/NOTE this prevents jumping from remote to another remote (Han: 2021.1.17)\n-        # _args.host = __default_host__\n-        # host resetting disables dynamic routing. Use `disable_remote` instead\n-        cargs.disable_remote = True\n+        from jina import __default_host__\n+\n+        cargs.host = __default_host__\n         cargs.log_config = ''  # do not use local log_config\n         cargs.upload_files = []  # reset upload files\n         cargs.noblock_on_start = False  # wait until start success\n\n---\n file path A: jina/parsers/orchestrate/runtimes/distributed.py | file path B: jina/parsers/orchestrate/runtimes/distributed.py\n\n@@ -1,7 +1,7 @@\n \"\"\"Argparser module for distributed runtimes\"\"\"\n import argparse\n \n-from jina.parsers.helper import add_arg_group, _SHOW_ALL_ARGS\n+from jina.parsers.helper import _SHOW_ALL_ARGS, add_arg_group\n \n \n def mixin_distributed_feature_parser(parser):\n@@ -35,12 +35,3 @@ Note,\n - uploaded files are by default isolated across the runs. To ensure files are submitted to the same workspace across different runs, use `--workspace-id` to specify the workspace.\n ''',\n     )\n-\n-    gp.add_argument(\n-        '--disable-remote',\n-        action='store_true',\n-        default=False,\n-        help='If set, remote pod invocation is avoided. This is used by pods created by JinaD'\n-        if _SHOW_ALL_ARGS\n-        else argparse.SUPPRESS,\n-    )\n\n\n###\n\n", "completion": "refactor: remove disable remote (#<issue-num>)"}
{"prompt": " file path A: CHANGELOG.md | file path B: CHANGELOG.md\n\n@@ -135,6 +135,7 @@\n \n \n \n+\n \n \n # Change Logs\n@@ -12347,3 +12348,30 @@ Jina is released on every Friday evening. The PyPi package and Docker Image will\n  - [[```55d900d4```](https://github.com/jina-ai/jina/commit/55d900d42f17211f3d6c7792fd36b937e4f1ef44)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n  - [[```5547aa01```](https://github.com/jina-ai/jina/commit/5547aa015b4b9734775e9c34043ec687b2c3811c)] __-__ __version__: the next version will be 3.0.5 (*Jina Dev Bot*)\n \n+<a name=release-note-3-1-1></a>\n+## Release Note (`3.1.1`)\n+\n+> Release time: 2022-03-07 17:53:51\n+\n+\n+\n+\ud83d\ude47 We'd like to thank all contributors for this new release! In particular,\n+ samsja,  Johannes Messner,  Jina Dev Bot,  \ud83d\ude47\n+\n+\n+### \ud83c\udd95 New Features\n+\n+ - [[```45a53f5a```](https://github.com/jina-ai/jina/commit/45a53f5a450dfddbe28f387a987a8c33c8a9b67a)] __-__ add isort and flake8  (#4437) (*samsja*)\n+\n+### \ud83d\udc1e Bug fixes\n+\n+ - [[```cf36445c```](https://github.com/jina-ai/jina/commit/cf36445c5a09c00519eb8281d3cb72fad07ae41c)] __-__ flake precommit (#4443) (*samsja*)\n+ - [[```2f597e1e```](https://github.com/jina-ai/jina/commit/2f597e1e32ac6baeb5fd4a473d532e706d618c0a)] __-__ disable graphql featues if docarray version does not support it (#4442) (*Johannes Messner*)\n+\n+### \ud83c\udf79 Other Improvements\n+\n+ - [[```fd6ba920```](https://github.com/jina-ai/jina/commit/fd6ba920746751c406764b877e90159f33375920)] __-__ update announcement in readme and docs (*Jina Dev Bot*)\n+ - [[```f97c7ac1```](https://github.com/jina-ai/jina/commit/f97c7ac1fe82c4963461abfffb29a44dab8fa503)] __-__ __contributor__: update contributors (*Jina Dev Bot*)\n+ - [[```3297f4b5```](https://github.com/jina-ai/jina/commit/3297f4b5a793bbbd2b35f0402126ae08d12f4eb9)] __-__ __docs__: update TOC (*Jina Dev Bot*)\n+ - [[```e304303d```](https://github.com/jina-ai/jina/commit/e304303de065f029122af8ccd8326d6a7975ab01)] __-__ __version__: the next version will be 3.1.1 (*Jina Dev Bot*)\n+\n\n---\n file path A: jina/__init__.py | file path B: jina/__init__.py\n\n@@ -60,7 +60,7 @@ elif _sys.version_info >= (3, 8, 0) and _platform.system() == 'Darwin':\n # this is managed by git tag and updated on every release\n # NOTE: this represents the NEXT release version\n \n-__version__ = '3.1.1'\n+__version__ = '3.1.2'\n \n # do not change this line manually\n # this is managed by proto/build-proto.sh and updated on every execution\n\n\n###\n\n", "completion": "chore(version): the next version will be 3.1.2"}
{"prompt": " file path A: .pre-commit-config.yaml | file path B: .pre-commit-config.yaml\n\n@@ -7,6 +7,7 @@ repos:\n         args:\n           - --max-complexity=10\n           - --max-line-length=127\n+          - --select=E9,F63,F7,F82\n - repo: https://github.com/terrencepreilly/darglint\n   rev: v1.5.8\n   hooks:\n\n\n###\n\n", "completion": "fix: flake precommit (#<issue-num>)"}
{"prompt": " file path A: jina/helper.py | file path B: jina/helper.py\n\n@@ -15,6 +15,7 @@ from argparse import ArgumentParser, Namespace\n from collections.abc import MutableMapping\n from datetime import datetime\n from itertools import islice\n+from packaging import version as pckg_version\n from types import SimpleNamespace\n from typing import (\n     Callable,\n@@ -32,7 +33,7 @@ from typing import (\n     TYPE_CHECKING,\n )\n \n-from jina import __windows__\n+from jina import __windows__, __docarray_version__\n \n __all__ = [\n     'batch_iterator',\n@@ -57,6 +58,7 @@ __all__ = [\n     'get_readable_size',\n     'get_or_reuse_loop',\n     'T',\n+    'docarray_graphql_compatible',\n ]\n \n \n@@ -75,7 +77,15 @@ def deprecated_alias(**aliases):\n     For example:\n         .. highlight:: python\n         .. code-block:: python\n-            @deprecated_alias(input_fn=('inputs', 0), buffer=('input_fn', 0), callback=('on_done', 1), output_fn=('on_done', 1))\n+\n+            @deprecated_alias(\n+                input_fn=('inputs', 0),\n+                buffer=('input_fn', 0),\n+                callback=('on_done', 1),\n+                output_fn=('on_done', 1),\n+            )\n+            def some_function(inputs, input_fn, on_done):\n+                pass\n \n     :param aliases: maps aliases to new arguments\n     :return: wrapper\n@@ -182,8 +192,9 @@ def batch_iterator(\n     For example:\n     .. highlight:: python\n     .. code-block:: python\n+\n             for req in batch_iterator(data, batch_size, split_over_axis):\n-                # Do something with batch\n+                pass  # Do something with batch\n \n     :param data: Data source.\n     :param batch_size: Size of one batch.\n@@ -266,7 +277,9 @@ def countdown(t: int, reason: str = 'I am blocking this thread') -> None:\n     For example:\n         .. highlight:: python\n         .. code-block:: python\n-            countdown(10, reason=colored('re-fetch access token', 'cyan', attrs=['bold', 'reverse']))\n+            countdown(\n+                10, reason=colored('re-fetch access token', 'cyan', attrs=['bold', 'reverse'])\n+            )\n \n     :param t: Countdown time.\n     :param reason: A string message of reason for this Countdown.\n@@ -1395,7 +1408,6 @@ def extend_rest_interface(app: 'FastAPI') -> 'FastAPI':\n     .. code-block:: python\n \n         def extend_rest_interface(app: 'FastAPI'):\n-\n             @app.get('/extension1')\n             async def root():\n                 return {\"message\": \"Hello World\"}\n@@ -1450,3 +1462,16 @@ def get_request_header() -> Dict:\n         **envs,\n     }\n     return header\n+\n+\n+GRAPHQL_MIN_DOCARRAY_VERSION = '0.8.8'  # graphql requires this or higher\n+\n+\n+def docarray_graphql_compatible():\n+    \"\"\"Check if installed docarray version is compatible with GraphQL features.\n+\n+    :return: True if compatible, False if not\n+    \"\"\"\n+    installed_version = pckg_version.parse(__docarray_version__)\n+    min_version = pckg_version.parse(GRAPHQL_MIN_DOCARRAY_VERSION)\n+    return installed_version >= min_version\n\n---\n file path A: jina/orchestrate/flow/base.py | file path B: jina/orchestrate/flow/base.py\n\n@@ -10,6 +10,7 @@ import sys\n import threading\n import time\n import uuid\n+import warnings\n from collections import OrderedDict\n from contextlib import ExitStack\n from typing import (\n@@ -46,6 +47,8 @@ from jina.helper import (\n     get_internal_ip,\n     get_public_ip,\n     typename,\n+    docarray_graphql_compatible,\n+    GRAPHQL_MIN_DOCARRAY_VERSION,\n )\n from jina.jaml import JAMLCompatible\n from jina.logging.logger import JinaLogger\n@@ -331,6 +334,17 @@ class Flow(PostMixin, JAMLCompatible, ExitStack, metaclass=FlowType):\n             GATEWAY_NAME\n         ]  #: default first deployment is gateway, will add when build()\n         self._update_args(args, **kwargs)\n+        if (\n+            self.protocol == GatewayProtocolType.HTTP\n+            and not self.args.no_graphql_endpoint\n+            and not docarray_graphql_compatible()\n+        ):\n+            self.args.no_graphql_endpoint = True\n+            warnings.warn(\n+                'DocArray version is incompatible with GraphQL features. '\n+                'Automatically setting no_graphql_endpoint=True. '\n+                f'To use GraphQL features, install docarray>={GRAPHQL_MIN_DOCARRAY_VERSION}'\n+            )\n \n         if isinstance(self.args, argparse.Namespace):\n             self.logger = JinaLogger(\n\n---\n file path A: jina/serve/runtimes/gateway/http/app.py | file path B: jina/serve/runtimes/gateway/http/app.py\n\n@@ -1,11 +1,16 @@\n import argparse\n import json\n from typing import TYPE_CHECKING, Dict, List, Optional\n+import warnings\n \n from jina import __version__\n from jina.clients.request import request_generator\n from jina.enums import DataInputType\n-from jina.helper import get_full_version\n+from jina.helper import (\n+    get_full_version,\n+    docarray_graphql_compatible,\n+    GRAPHQL_MIN_DOCARRAY_VERSION,\n+)\n from jina.importer import ImportExtensions\n from jina.logging.logger import JinaLogger\n from jina.logging.profile import used_memory_readable\n@@ -52,6 +57,14 @@ def get_fastapi_app(\n         docs_url=docs_url if args.default_swagger_ui else None,\n     )\n \n+    if not args.no_graphql_endpoint and not docarray_graphql_compatible():\n+        args.no_graphql_endpoint = True\n+        warnings.warn(\n+            'DocArray version is incompatible with GraphQL features.'\n+            'Setting no_graphql_endpoint=True.'\n+            f'To use GraphQL features, install docarray>={GRAPHQL_MIN_DOCARRAY_VERSION}'\n+        )\n+\n     if args.cors:\n         app.add_middleware(\n             CORSMiddleware,\n\n\n###\n\n", "completion": "fix: disable graphql featues if docarray version does not support it (#<issue-num>)"}
